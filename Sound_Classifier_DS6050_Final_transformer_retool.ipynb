{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "mBSFTJ5M_z-H"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n",
    "from torch.cuda import manual_seed_all\n",
    "from torch import manual_seed as torch_manual_seed\n",
    "from torch.backends import cudnn\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "3uDKfjRHMuxk"
   },
   "outputs": [],
   "source": [
    "# pre spectrogram augmentations\n",
    "# these are examples and can be changed based on domain knowledge\n",
    "\n",
    "def stretch_waveform(waveform, rate=1.2):\n",
    "    time_stretch = T.TimeStretch()\n",
    "    # `rate > 1.0` speeds up, `rate < 1.0` slows down\n",
    "    return time_stretch(waveform, rate)\n",
    "\n",
    "def shift_pitch(waveform, sample_rate=44100, n_steps = 2):\n",
    "    pitch_shift = T.PitchShift(sample_rate, n_steps)  # Shift up by 2 semitones\n",
    "    return pitch_shift(waveform)\n",
    "\n",
    "def scale_volume(waveform, factor = None):\n",
    "    if factor is None:\n",
    "        waveform *= torch.FloatTensor(1).uniform_(0.8, 1.5).item()  # Amplifies waveform by random factor\n",
    "    else:\n",
    "        waveform *= factor\n",
    "    return waveform\n",
    "\n",
    "def crop_waveform(waveform, crop_size):\n",
    "    start = torch.randint(0, max(1, waveform.size(-1) - crop_size), (1,)).item()\n",
    "    return waveform[:, start:start + crop_size]\n",
    "\n",
    "def apply_reverb(waveform):\n",
    "    reverb = T.Reverberate()\n",
    "    return reverb(waveform)\n",
    "\n",
    "def time_shift(waveform, shift):\n",
    "    return torch.roll(waveform, shifts=shift, dims=-1)\n",
    "\n",
    "def add_noise(waveform, noise_level=0.005):\n",
    "    noise = torch.randn_like(waveform) * noise_level\n",
    "    return waveform + noise\n",
    "\n",
    "# Augment on-the-fly stochastically\n",
    "# again these are just examples and do not necessarily utilize the methods above\n",
    "def augment_waveform(data):\n",
    "    waveform, sample_rate = data\n",
    "    if torch.rand(1).item() > 0.9:\n",
    "        waveform = add_noise(waveform)\n",
    "    if torch.rand(1).item() > 0.9:\n",
    "        waveform = time_shift(waveform, shifts=torch.randint(-waveform.size(-1) // 2, waveform.size(-1) // 2, (1,)).item())\n",
    "    if torch.rand(1).item() > 0.9:\n",
    "        waveform = scale_volume(waveform)\n",
    "    if torch.rand(1).item() > 0.9:\n",
    "        waveform = apply_reverb(waveform)\n",
    "    if torch.rand(1).item() > 0.9:\n",
    "        waveform = shift_pitch(waveform, sample_rate, n_steps= torch.randint(-12, 12, (1,)).item())\n",
    "    if torch.rand(1).item() > 0.9:\n",
    "        waveform = stretch_waveform(waveform, rate= torch.FloatTensor(1).uniform_(0.5, 1.5).item())\n",
    "    return waveform, sample_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "Ww8OMV8nNZcf"
   },
   "outputs": [],
   "source": [
    "# Create a MelSpectrogram transformation\n",
    "mel_spectrogram_transform = T.MelSpectrogram(\n",
    "    sample_rate=44100,         # Default sample rate, change if needed\n",
    "    n_fft=1024,                # Number of FFT bins\n",
    "    hop_length=512,            # Hop length between windows\n",
    "    n_mels=64                  # Number of Mel bands\n",
    ")\n",
    "\n",
    "def waveform_to_spectrogram(data):\n",
    "    waveform, sample_rate = data\n",
    "    spectrogram = mel_spectrogram_transform(waveform)  # Apply the spectrogram transformation\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "khV1u_wUIR-o"
   },
   "outputs": [],
   "source": [
    "# post spectrogram augmentations\n",
    "\n",
    "# Example augmentations, could add more\n",
    "time_mask = T.TimeMasking(time_mask_param=10)\n",
    "\n",
    "freq_mask = T.FrequencyMasking(freq_mask_param=8)\n",
    "\n",
    "# hybridizes two sounds\n",
    "def mixup(spectrogram1, spectrogram2, alpha=0.2):\n",
    "    lam = torch.FloatTensor(1).uniform_(0, alpha).item()\n",
    "    return lam * spectrogram1 + (1 - lam) * spectrogram2\n",
    "\n",
    "# should probably implement a randomization process like above\n",
    "def augment_spectrogram(spectrogram):\n",
    "    augmented = time_mask(spectrogram)  # Apply time masking\n",
    "    augmented = freq_mask(augmented)   # Apply frequency masking\n",
    "    return augmented\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "2U9n6Z-fPiwY"
   },
   "outputs": [],
   "source": [
    "# Decode audio files\n",
    "def decode_audio(file_tuple):\n",
    "    file_path, file = file_tuple\n",
    "    waveform, sample_rate = torchaudio.load(file_path)\n",
    "    return waveform, sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "class UrbanSoundDataset(Dataset):\n",
    "    def __init__(self, audio_path, fold, csv_path, transform=None):\n",
    "        self.audio_path = os.path.join(audio_path, f\"fold{fold}\")\n",
    "        self.file_list = [os.path.join(self.audio_path, f) for f in os.listdir(self.audio_path) if f.endswith(\".wav\")]\n",
    "        self.transform = transform\n",
    "\n",
    "        # Load the metadata CSV file\n",
    "        self.metadata = pd.read_csv(csv_path)\n",
    "\n",
    "    def get_label(self, file_name):\n",
    "        \"\"\"Fetch the class label for a given file name from the metadata.\"\"\"\n",
    "        label_row = self.metadata.loc[self.metadata['slice_file_name'] == file_name, 'class']\n",
    "        if not label_row.empty:\n",
    "            return label_row.values[0]\n",
    "        else:\n",
    "            raise ValueError(f\"File name {file_name} not found in metadata CSV.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load the audio file\n",
    "        file_path = self.file_list[idx]\n",
    "        waveform, sample_rate = torchaudio.load(file_path)\n",
    "\n",
    "        # Convert mono to stereo if necessary\n",
    "        if waveform.size(0) == 1:  # If mono\n",
    "            waveform = waveform.repeat(3, 1)\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            waveform = self.transform(waveform)\n",
    "\n",
    "        # Extract the file name from the path\n",
    "        file_name = os.path.basename(file_path)\n",
    "\n",
    "        # Get the corresponding label for the file\n",
    "        label = self.get_label(file_name)\n",
    "\n",
    "        return waveform, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asm2fe/.local/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torchaudio.transforms as T\n",
    "\n",
    "# Example transformations\n",
    "def augment_waveform(waveform):\n",
    "    # Add your augmentation logic here (e.g., noise addition, time stretch, etc.)\n",
    "    return waveform\n",
    "\n",
    "waveform_to_spectrogram = T.MelSpectrogram(sample_rate=16000, n_mels=128)\n",
    "augment_spectrogram = T.AmplitudeToDB()\n",
    "\n",
    "# Combine transformations into a callable function\n",
    "def transform_pipeline(waveform):\n",
    "    waveform = augment_waveform(waveform)\n",
    "    spectrogram = waveform_to_spectrogram(waveform)\n",
    "    # spectrogram = augment_spectrogram(spectrogram)\n",
    "    return spectrogram\n",
    "\n",
    "def pad_with_noise(spectrogram, max_time, noise_std=0.01):\n",
    "    \"\"\"\n",
    "    Pads a spectrogram with Gaussian noise instead of zeros.\n",
    "\n",
    "    Args:\n",
    "        spectrogram (Tensor): Shape (channels, freq_bins, time_steps)\n",
    "        max_time (int): Target time dimension\n",
    "        noise_std (float): Standard deviation of the Gaussian noise\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Padded spectrogram with noise\n",
    "    \"\"\"\n",
    "    # Compute how much padding is needed\n",
    "    pad_amount = max_time - spectrogram.size(2)\n",
    "    \n",
    "    if pad_amount > 0:\n",
    "        # Generate random noise matching the shape of missing time steps\n",
    "        noise = torch.randn((spectrogram.size(0), spectrogram.size(1), pad_amount)) * noise_std\n",
    "        \n",
    "        # Concatenate noise along the time axis\n",
    "        spectrogram = torch.cat([spectrogram, noise], dim=2)\n",
    "    \n",
    "    return spectrogram\n",
    "\n",
    "# def convert_to_three_channels(spectrogram):\n",
    "#     # Convert [2, 224, 224] to [3, 224, 224]\n",
    "#     if spectrogram.size(0) == 2:\n",
    "#         # Duplicate the first channel to create a third channel\n",
    "#         return torch.cat((spectrogram, spectrogram[0:1, :, :]), dim=0)\n",
    "#     return spectrogram\n",
    "\n",
    "def convert_to_three_channels(spectrogram):\n",
    "    # Convert [2, 224, 224] to [3, 224, 224]\n",
    "    if spectrogram.size(0) == 2:\n",
    "        # Calculate the mean of the two channels\n",
    "        mean_channel = torch.mean(spectrogram, dim=0, keepdim=True)\n",
    "        # Concatenate the mean channel as the third channel\n",
    "        return torch.cat((spectrogram, mean_channel), dim=0)\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "\n",
    "class ViT(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    vision transformer Class, derived from Pytorch. Intended for model manipulation (i.e. unfreezing layers, etc.)\n",
    "    To use model, try (vit_b_32).model(data)\n",
    "    \"\"\"\n",
    "    def __init__(self, weights = \"DEFAULT\", drop = 0.5):\n",
    "        super().__init__()  # Initialize the nn.Module base class\n",
    "        self.model = torchvision.models.vit_b_32(weights = weights)\n",
    "        \n",
    "        # Get the number of input features to the classification head\n",
    "        num_features = self.model.heads.head.in_features\n",
    "\n",
    "        # Replace the classification head\n",
    "        self.model.heads.head = nn.Sequential(\n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(num_features, 10)  # UrbanSound8k has 10 output classes\n",
    "        )\n",
    "\n",
    "        # Make sure classifier layers are trainable (optional if you're freezing others)\n",
    "        for param in self.model.heads.head.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)  # Delegate forward pass to the original ViT\n",
    "\n",
    "    def layer_change(self, layer=0):\n",
    "        # Freeze from encoder layers 0 up to (but not including) layer `layer`\n",
    "        for i, block in enumerate(self.model.encoder.layers):\n",
    "            if i < layer:\n",
    "                for param in block.parameters():\n",
    "                    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ViT()\n",
    "# for param in model.model.features.named_parameters():\n",
    "#     print(param[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and testing loops\n",
    "\n",
    "def train_loop(train_dataloader, val_dataloader, model, loss_fn, optimizer, scheduler_warmup=None,\\\n",
    "    scheduler_main = None, epochs=1, warmup_epochs = 10, patience = 6):\n",
    "    model.train()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Store metrics\n",
    "    epoch_train_losses = []  # Track training loss across epochs\n",
    "    epoch_val_losses = []  # Track validation loss across epochs\n",
    "    epoch_val_accuracies = []  # Track validation accuracy across epochs\n",
    "\n",
    "    # Training loop with early stopping\n",
    "    early_stopping = EarlyStopping(patience=patience, min_delta=0.01)\n",
    "    \n",
    "    early_stop_epoch = None\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        size = len(train_dataloader.dataset)\n",
    "        total_loss = 0  # Initialize variable to accumulate training loss\n",
    "        \n",
    "\n",
    "        for batch, (X, y) in enumerate(train_dataloader):\n",
    "            # Compute prediction and loss\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Print progress periodically\n",
    "            total_batches = len(train_dataloader)\n",
    "            if batch % (total_batches // 5) == 0:  # Prints 5 times per epoch\n",
    "                current = (batch + 1) * len(X)\n",
    "                print(f\"loss: {loss.item():>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "        # Average training loss for the epoch\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "        # print(len(train_dataloader))\n",
    "        print(f\"Training Loss (Epoch): {avg_train_loss:>7f}\")\n",
    "        epoch_train_losses.append(avg_train_loss)\n",
    "\n",
    "        # **Validation Step**\n",
    "        print(\"Validating...\")\n",
    "        avg_val_loss, val_accuracy = test_loop(val_dataloader, model, loss_fn, verbose=False)\n",
    "        print(f\"Validation Loss: {avg_val_loss:.6f}, Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "\n",
    "        # Track validation metrics\n",
    "        epoch_val_losses.append(avg_val_loss)\n",
    "        epoch_val_accuracies.append(val_accuracy)\n",
    "        \n",
    "        if epoch < warmup_epochs:\n",
    "            scheduler_warmup.step()\n",
    "        else:\n",
    "            scheduler_main.step()\n",
    "        \n",
    "        # Check for early stopping\n",
    "        early_stopping(avg_val_loss)\n",
    "        if early_stopping.stop_training:\n",
    "            print(\"Early stopping triggered. Training stopped.\")\n",
    "            early_stop_epoch = epoch\n",
    "            break\n",
    "\n",
    "    # Return metrics for tracking/aggregation across folds\n",
    "    return epoch_train_losses, epoch_val_losses, epoch_val_accuracies, early_stop_epoch\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn, verbose=True):\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    # Average loss and accuracy for this fold\n",
    "    avg_test_loss = test_loss / num_batches\n",
    "    accuracy = correct / size\n",
    "    if verbose:\n",
    "        print(f\"Test Error: \\n Accuracy: {(100*accuracy):>0.1f}%, Avg loss: {avg_test_loss:>8f} \\n\")\n",
    "    return avg_test_loss, accuracy  # Return both average loss and accuracy for this fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "BLCzmvxcHvKs"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    # Resize and normalize for ViT\n",
    "    resize_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize for ViT\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Standard ImageNet normalization\n",
    "    ])\n",
    "    \n",
    "    inputs, labels = zip(*batch)  # Separate inputs and labels\n",
    "    max_time = max(spectrogram.size(2) for spectrogram in inputs)\n",
    "\n",
    "    # Pad inputs to the same length along the time dimension\n",
    "    padded_inputs = [\n",
    "        torch.nn.functional.pad(input, (0, max_time - input.size(2)))\n",
    "        for input in inputs\n",
    "    ]\n",
    "\n",
    "    # Convert to 3 channels and resize\n",
    "    resized_inputs = [resize_transform(convert_to_three_channels(input).float()) for input in padded_inputs]\n",
    "    \n",
    "    # Map labels to numeric class IDs\n",
    "    class_mapping = {\n",
    "        \"air_conditioner\": 0,\n",
    "        \"car_horn\": 1,\n",
    "        \"children_playing\": 2,\n",
    "        \"dog_bark\": 3,\n",
    "        \"drilling\": 4,\n",
    "        \"engine_idling\": 5,\n",
    "        \"gun_shot\": 6,\n",
    "        \"jackhammer\": 7,\n",
    "        \"siren\": 8,\n",
    "        \"street_music\": 9\n",
    "    }\n",
    "\n",
    "    numeric_labels = [class_mapping[label] for label in labels]\n",
    "\n",
    "    # Stack inputs and labels\n",
    "    return torch.stack(resized_inputs), torch.tensor(numeric_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3, min_delta=0.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How many epochs to wait for improvement.\n",
    "            min_delta (float): Minimum change in monitored value to qualify as improvement.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.stop_training = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None or val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.stop_training = True   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sfs/gpfs/tardis/home/asm2fe/UrbanAdversary\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# Specify paths and batch size\n",
    "AUDIO_PATH = \"./UrbanSound8K/audio\"\n",
    "CSV_PATH = \"./UrbanSound8K/metadata/UrbanSound8K.csv\"\n",
    "\n",
    "def setup_seed(seed):\n",
    "    torch_manual_seed(seed)\n",
    "    manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    cudnn.deterministic = True\n",
    "\n",
    "from torch.optim.lr_scheduler import LambdaLR, CosineAnnealingLR\n",
    "\n",
    "\n",
    "\n",
    "def dense_tune(layer = 0, lr = 2e-4, weight_decay = 0.2, weights = \"DEFAULT\", drop = 0.5, SEED = 666,\\\n",
    "     warmup_epochs = 3, total_epochs = 20, batch_size = 70, folds = 10):\n",
    "\n",
    "    # Example: Warmup for first n epochs, then cosine schedule\n",
    "    def warmup_lambda(epoch):\n",
    "        if epoch < warmup_epochs:\n",
    "            return float(epoch) / float(max(1, warmup_epochs))\n",
    "        return 1.0\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    setup_seed(SEED)\n",
    "\n",
    "    # Variables to accumulate metrics across folds\n",
    "    fold_train_losses = []\n",
    "    fold_val_losses = []\n",
    "    fold_val_accuracies = []\n",
    "\n",
    "    # Loop through folds\n",
    "    for fold in range(1, folds+1):\n",
    "        model = ViT(weights = weights, drop = drop)\n",
    "        # model.layer_change(layer = layer) # freeze first conv and dense block(s) if desired\n",
    "\n",
    "        print(f\"Processing Fold {fold}\")\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay = weight_decay)\n",
    "        \n",
    "        scheduler_warmup = LambdaLR(optimizer, lr_lambda=warmup_lambda)\n",
    "        scheduler_main = CosineAnnealingLR(optimizer, T_max=total_epochs - warmup_epochs)\n",
    "        # Initialize dataset and DataLoader\n",
    "        dataset = UrbanSoundDataset(audio_path=AUDIO_PATH, fold=fold, transform=transform_pipeline, csv_path=CSV_PATH)\n",
    "        train_indices, val_indices = train_test_split(list(range(len(dataset))), test_size=0.2, random_state=42)\n",
    "\n",
    "        train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "        val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
    "\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "        val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "        # Train and validate (over multiple epochs per fold)\n",
    "        epoch_train_losses, epoch_val_losses, epoch_val_accuracies, early_stop_epoch = train_loop(\n",
    "            train_dataloader, val_dataloader, model, loss_fn, optimizer, scheduler_warmup,\\\n",
    "                scheduler_main, epochs=total_epochs\n",
    "        )\n",
    "\n",
    "        # # Aggregate metrics up to the stopping epoch\n",
    "        # if early_stop_epoch is not None:\n",
    "        #     print(early_stop_epoch+1)\n",
    "        #     fold_train_losses.append(sum(epoch_train_losses) / (early_stop_epoch+1))  # Mean up to early stop\n",
    "        #     fold_val_losses.append(sum(epoch_val_losses) / (early_stop_epoch+1))      # Mean up to early stop\n",
    "        #     fold_val_accuracies.append(sum(epoch_val_accuracies) / (early_stop_epoch+1))  # Mean up to early stop\n",
    "        # else:\n",
    "        #     # If no early stopping occurred, aggregate metrics across all epochs\n",
    "        #     fold_train_losses.append(sum(epoch_train_losses) / len(epoch_train_losses))\n",
    "        #     fold_val_losses.append(sum(epoch_val_losses) / len(epoch_val_losses))\n",
    "        #     fold_val_accuracies.append(sum(epoch_val_accuracies) / len(epoch_val_accuracies))\n",
    "\n",
    "        # Aggregate fold-level metrics (e.g., mean across all epochs)\n",
    "        # print(epoch_train_losses)\n",
    "        # print(epoch_val_losses)\n",
    "        # print(epoch_val_accuracies)\n",
    "        fold_train_losses.append(sum(epoch_train_losses) / len(epoch_train_losses))  # Mean of training losses\n",
    "        fold_val_losses.append(sum(epoch_val_losses) / len(epoch_val_losses))        # Mean of validation losses\n",
    "        fold_val_accuracies.append(epoch_val_accuracies[-1])  # Mean of validation accuracies\n",
    "\n",
    "    # Compute average metrics across folds\n",
    "    # print(fold_train_losses)\n",
    "    # print(fold_val_losses)\n",
    "    # print(fold_val_accuracies)\n",
    "    mean_train_loss = sum(fold_train_losses) / len(fold_train_losses)\n",
    "    mean_val_loss = sum(fold_val_losses) / len(fold_val_losses)\n",
    "    mean_val_accuracy = sum(fold_val_accuracies) / len(fold_val_accuracies)\n",
    "\n",
    "    print(f\"\\nCross-Validation Results:\")\n",
    "    print(f\"Avg Training Loss: {mean_train_loss:.6f}\")\n",
    "    print(f\"Avg Validation Loss: {mean_val_loss:.6f}\")\n",
    "    print(f\"Avg Validation Accuracy: {mean_val_accuracy * 100:.2f}%\")\n",
    "    return mean_train_loss, mean_val_loss, mean_val_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def dense_grid_search(param_grid):\n",
    "    param_names = list(param_grid.keys())\n",
    "    param_combinations = list(itertools.product(*param_grid.values()))\n",
    "\n",
    "    best_params = None\n",
    "    best_score = -float('inf')  # For maximizing validation accuracy\n",
    "    all_results = []\n",
    "\n",
    "    for combination in param_combinations:\n",
    "        # Map combination to hyperparameters\n",
    "        params = dict(zip(param_names, combination))\n",
    "        print(f\"Testing combination: {params}\")\n",
    "\n",
    "        # Call dense_tune with the current parameter combination\n",
    "        mean_train_loss, mean_val_loss, mean_val_accuracy = dense_tune(\n",
    "            layer=params[\"layer\"],\n",
    "            lr=params[\"lr\"],\n",
    "            weight_decay=params[\"weight_decay\"],\n",
    "            drop=params[\"drop\"],\n",
    "            warmup_epochs=params[\"warmup_epochs\"],\n",
    "            total_epochs=params[\"total_epochs\"],\n",
    "            batch_size =params[\"batch_size\"],\n",
    "            folds = 1\n",
    "        )\n",
    "\n",
    "        # Store results\n",
    "        result = {\n",
    "            \"params\": params,\n",
    "            \"train_loss\": mean_train_loss,\n",
    "            \"val_loss\": mean_val_loss,\n",
    "            \"val_accuracy\": mean_val_accuracy\n",
    "        }\n",
    "        all_results.append(result)\n",
    "\n",
    "        # Update best score and parameters\n",
    "        if mean_val_accuracy > best_score:\n",
    "            best_score = mean_val_accuracy\n",
    "            best_params = params\n",
    "    print(f\"Best parameters were: {best_params}\")\n",
    "    print(f\"Best score was: {best_score}\")\n",
    "    return best_params, best_score, all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"layer\": [3, 2, 1],              # Number of frozen layers\n",
    "    \"lr\": [3e-4, 1e-4],       # Learning rates\n",
    "    \"weight_decay\": [0.1, 0.05],     # Weight decay values\n",
    "    \"drop\": [0.8, 0.6],             # Dropout rates\n",
    "    \"warmup_epochs\": [3, 5],        # Warmup epochs\n",
    "    \"total_epochs\": [25],            # Total epochs\n",
    "    \"batch_size\": [35, 70]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing combination: {'layer': 0, 'lr': 0.0003, 'weight_decay': 0.05, 'drop': 0.8, 'warmup_epochs': 3, 'total_epochs': 25, 'batch_size': 70}\n",
      "Processing Fold 1\n",
      "Epoch 1/25\n",
      "loss: 2.531940  [   70/  698]\n",
      "loss: 2.543593  [  210/  698]\n",
      "loss: 2.527890  [  350/  698]\n",
      "loss: 2.537947  [  490/  698]\n",
      "loss: 2.460474  [  630/  698]\n",
      "Training Loss (Epoch): 2.571000\n",
      "Validating...\n",
      "Validation Loss: 2.409121, Validation Accuracy: 12.00%\n",
      "Epoch 2/25\n",
      "loss: 2.297287  [   70/  698]\n",
      "loss: 2.088383  [  210/  698]\n",
      "loss: 2.001848  [  350/  698]\n",
      "loss: 2.230670  [  490/  698]\n",
      "loss: 2.013240  [  630/  698]\n",
      "Training Loss (Epoch): 2.116037\n",
      "Validating...\n",
      "Validation Loss: 1.963075, Validation Accuracy: 24.00%\n",
      "Epoch 3/25\n",
      "loss: 2.030062  [   70/  698]\n",
      "loss: 1.769564  [  210/  698]\n",
      "loss: 1.819320  [  350/  698]\n",
      "loss: 1.516873  [  490/  698]\n",
      "loss: 1.633342  [  630/  698]\n",
      "Training Loss (Epoch): 1.747023\n",
      "Validating...\n",
      "Validation Loss: 1.711125, Validation Accuracy: 32.57%\n",
      "Epoch 4/25\n",
      "loss: 1.482898  [   70/  698]\n",
      "loss: 1.500882  [  210/  698]\n",
      "loss: 1.427355  [  350/  698]\n",
      "loss: 1.187610  [  490/  698]\n",
      "loss: 1.339155  [  630/  698]\n",
      "Training Loss (Epoch): 1.357226\n",
      "Validating...\n",
      "Validation Loss: 1.205356, Validation Accuracy: 54.86%\n",
      "Epoch 5/25\n",
      "loss: 1.054865  [   70/  698]\n",
      "loss: 1.096589  [  210/  698]\n",
      "loss: 1.037555  [  350/  698]\n",
      "loss: 0.744355  [  490/  698]\n",
      "loss: 1.048730  [  630/  698]\n",
      "Training Loss (Epoch): 0.971771\n",
      "Validating...\n",
      "Validation Loss: 0.974086, Validation Accuracy: 65.14%\n",
      "Epoch 6/25\n",
      "loss: 0.560321  [   70/  698]\n",
      "loss: 0.875344  [  210/  698]\n",
      "loss: 0.559968  [  350/  698]\n",
      "loss: 0.568778  [  490/  698]\n",
      "loss: 0.559251  [  630/  698]\n",
      "Training Loss (Epoch): 0.648471\n",
      "Validating...\n",
      "Validation Loss: 0.842832, Validation Accuracy: 72.57%\n",
      "Epoch 7/25\n",
      "loss: 0.359805  [   70/  698]\n",
      "loss: 0.546815  [  210/  698]\n",
      "loss: 0.576023  [  350/  698]\n",
      "loss: 0.567309  [  490/  698]\n",
      "loss: 0.363489  [  630/  698]\n",
      "Training Loss (Epoch): 0.444936\n",
      "Validating...\n",
      "Validation Loss: 0.829823, Validation Accuracy: 74.29%\n",
      "Epoch 8/25\n",
      "loss: 0.302897  [   70/  698]\n",
      "loss: 0.168746  [  210/  698]\n",
      "loss: 0.271511  [  350/  698]\n",
      "loss: 0.351615  [  490/  698]\n",
      "loss: 0.260309  [  630/  698]\n",
      "Training Loss (Epoch): 0.303115\n",
      "Validating...\n",
      "Validation Loss: 0.806635, Validation Accuracy: 75.43%\n",
      "Epoch 9/25\n",
      "loss: 0.251675  [   70/  698]\n",
      "loss: 0.261909  [  210/  698]\n",
      "loss: 0.206478  [  350/  698]\n",
      "loss: 0.210559  [  490/  698]\n",
      "loss: 0.314573  [  630/  698]\n",
      "Training Loss (Epoch): 0.221777\n",
      "Validating...\n",
      "Validation Loss: 0.792575, Validation Accuracy: 75.43%\n",
      "Epoch 10/25\n",
      "loss: 0.148325  [   70/  698]\n",
      "loss: 0.150734  [  210/  698]\n",
      "loss: 0.159595  [  350/  698]\n",
      "loss: 0.091529  [  490/  698]\n",
      "loss: 0.429945  [  630/  698]\n",
      "Training Loss (Epoch): 0.189403\n",
      "Validating...\n",
      "Validation Loss: 0.814008, Validation Accuracy: 76.00%\n",
      "Epoch 11/25\n",
      "loss: 0.190078  [   70/  698]\n",
      "loss: 0.070746  [  210/  698]\n",
      "loss: 0.206171  [  350/  698]\n",
      "loss: 0.093302  [  490/  698]\n",
      "loss: 0.237918  [  630/  698]\n",
      "Training Loss (Epoch): 0.143171\n",
      "Validating...\n",
      "Validation Loss: 0.706940, Validation Accuracy: 78.29%\n",
      "Epoch 12/25\n",
      "loss: 0.173534  [   70/  698]\n",
      "loss: 0.055665  [  210/  698]\n",
      "loss: 0.096027  [  350/  698]\n",
      "loss: 0.120708  [  490/  698]\n",
      "loss: 0.124495  [  630/  698]\n",
      "Training Loss (Epoch): 0.107092\n",
      "Validating...\n",
      "Validation Loss: 0.742626, Validation Accuracy: 77.14%\n",
      "Epoch 13/25\n",
      "loss: 0.111684  [   70/  698]\n",
      "loss: 0.093620  [  210/  698]\n",
      "loss: 0.078653  [  350/  698]\n",
      "loss: 0.075656  [  490/  698]\n",
      "loss: 0.068099  [  630/  698]\n",
      "Training Loss (Epoch): 0.082512\n",
      "Validating...\n",
      "Validation Loss: 0.690017, Validation Accuracy: 80.57%\n",
      "Epoch 14/25\n",
      "loss: 0.084860  [   70/  698]\n",
      "loss: 0.031877  [  210/  698]\n",
      "loss: 0.026281  [  350/  698]\n",
      "loss: 0.105508  [  490/  698]\n",
      "loss: 0.100500  [  630/  698]\n",
      "Training Loss (Epoch): 0.065135\n",
      "Validating...\n",
      "Validation Loss: 0.715370, Validation Accuracy: 81.14%\n",
      "Epoch 15/25\n",
      "loss: 0.030938  [   70/  698]\n",
      "loss: 0.034913  [  210/  698]\n",
      "loss: 0.050611  [  350/  698]\n",
      "loss: 0.127923  [  490/  698]\n",
      "loss: 0.154412  [  630/  698]\n",
      "Training Loss (Epoch): 0.071841\n",
      "Validating...\n",
      "Validation Loss: 0.795709, Validation Accuracy: 80.57%\n",
      "Epoch 16/25\n",
      "loss: 0.105896  [   70/  698]\n",
      "loss: 0.105716  [  210/  698]\n",
      "loss: 0.064051  [  350/  698]\n",
      "loss: 0.066450  [  490/  698]\n",
      "loss: 0.057569  [  630/  698]\n",
      "Training Loss (Epoch): 0.069456\n",
      "Validating...\n",
      "Validation Loss: 0.774430, Validation Accuracy: 79.43%\n",
      "Epoch 17/25\n",
      "loss: 0.068618  [   70/  698]\n",
      "loss: 0.018896  [  210/  698]\n",
      "loss: 0.107577  [  350/  698]\n",
      "loss: 0.491323  [  490/  698]\n",
      "loss: 0.022568  [  630/  698]\n",
      "Training Loss (Epoch): 0.113950\n",
      "Validating...\n",
      "Validation Loss: 1.028384, Validation Accuracy: 73.14%\n",
      "Epoch 18/25\n",
      "loss: 0.115603  [   70/  698]\n",
      "loss: 0.145932  [  210/  698]\n",
      "loss: 0.144762  [  350/  698]\n",
      "loss: 0.229151  [  490/  698]\n",
      "loss: 0.106037  [  630/  698]\n",
      "Training Loss (Epoch): 0.142036\n",
      "Validating...\n",
      "Validation Loss: 0.833497, Validation Accuracy: 78.29%\n",
      "Epoch 19/25\n",
      "loss: 0.197187  [   70/  698]\n",
      "loss: 0.102598  [  210/  698]\n",
      "loss: 0.096132  [  350/  698]\n",
      "loss: 0.114093  [  490/  698]\n",
      "loss: 0.032069  [  630/  698]\n",
      "Training Loss (Epoch): 0.099986\n",
      "Validating...\n",
      "Validation Loss: 0.724014, Validation Accuracy: 77.14%\n",
      "Early stopping triggered. Training stopped.\n",
      "\n",
      "Cross-Validation Results:\n",
      "Avg Training Loss: 0.603470\n",
      "Avg Validation Loss: 1.018928\n",
      "Avg Validation Accuracy: 77.14%\n",
      "Testing combination: {'layer': 0, 'lr': 0.0003, 'weight_decay': 0.05, 'drop': 0.8, 'warmup_epochs': 3, 'total_epochs': 25, 'batch_size': 35}\n",
      "Processing Fold 1\n",
      "Epoch 1/25\n",
      "loss: 2.602622  [   35/  698]\n",
      "loss: 2.566953  [  175/  698]\n",
      "loss: 2.623257  [  315/  698]\n",
      "loss: 2.722848  [  455/  698]\n",
      "loss: 2.384184  [  595/  698]\n",
      "Training Loss (Epoch): 2.572142\n",
      "Validating...\n",
      "Validation Loss: 2.389176, Validation Accuracy: 10.86%\n",
      "Epoch 2/25\n",
      "loss: 2.227701  [   35/  698]\n",
      "loss: 2.004468  [  175/  698]\n",
      "loss: 1.860748  [  315/  698]\n",
      "loss: 2.244191  [  455/  698]\n",
      "loss: 1.696103  [  595/  698]\n",
      "Training Loss (Epoch): 2.005909\n",
      "Validating...\n",
      "Validation Loss: 1.662245, Validation Accuracy: 38.86%\n",
      "Epoch 3/25\n",
      "loss: 1.598332  [   35/  698]\n",
      "loss: 1.345660  [  175/  698]\n",
      "loss: 1.439975  [  315/  698]\n",
      "loss: 0.995339  [  455/  698]\n",
      "loss: 1.218137  [  595/  698]\n",
      "Training Loss (Epoch): 1.379014\n",
      "Validating...\n",
      "Validation Loss: 1.244539, Validation Accuracy: 53.14%\n",
      "Epoch 4/25\n",
      "loss: 0.782738  [   35/  698]\n",
      "loss: 1.873188  [  175/  698]\n",
      "loss: 0.989171  [  315/  698]\n",
      "loss: 0.898143  [  455/  698]\n",
      "loss: 0.790692  [  595/  698]\n",
      "Training Loss (Epoch): 1.086517\n",
      "Validating...\n",
      "Validation Loss: 1.713750, Validation Accuracy: 37.71%\n",
      "Epoch 5/25\n",
      "loss: 1.041194  [   35/  698]\n",
      "loss: 0.814362  [  175/  698]\n",
      "loss: 1.072146  [  315/  698]\n",
      "loss: 0.719510  [  455/  698]\n",
      "loss: 0.895324  [  595/  698]\n",
      "Training Loss (Epoch): 1.025134\n",
      "Validating...\n",
      "Validation Loss: 1.364861, Validation Accuracy: 50.86%\n",
      "Epoch 6/25\n",
      "loss: 0.907300  [   35/  698]\n",
      "loss: 0.775348  [  175/  698]\n",
      "loss: 0.514611  [  315/  698]\n",
      "loss: 0.691025  [  455/  698]\n",
      "loss: 0.577814  [  595/  698]\n",
      "Training Loss (Epoch): 0.630976\n",
      "Validating...\n",
      "Validation Loss: 1.092818, Validation Accuracy: 64.00%\n",
      "Epoch 7/25\n",
      "loss: 0.263932  [   35/  698]\n",
      "loss: 0.430404  [  175/  698]\n",
      "loss: 0.453590  [  315/  698]\n",
      "loss: 0.579746  [  455/  698]\n",
      "loss: 0.337908  [  595/  698]\n",
      "Training Loss (Epoch): 0.404599\n",
      "Validating...\n",
      "Validation Loss: 1.056703, Validation Accuracy: 65.71%\n",
      "Epoch 8/25\n",
      "loss: 0.306234  [   35/  698]\n",
      "loss: 0.134310  [  175/  698]\n",
      "loss: 0.240840  [  315/  698]\n",
      "loss: 0.357222  [  455/  698]\n",
      "loss: 0.255125  [  595/  698]\n",
      "Training Loss (Epoch): 0.264837\n",
      "Validating...\n",
      "Validation Loss: 0.951707, Validation Accuracy: 70.86%\n",
      "Epoch 9/25\n",
      "loss: 0.115904  [   35/  698]\n",
      "loss: 0.543981  [  175/  698]\n",
      "loss: 0.065977  [  315/  698]\n",
      "loss: 0.173280  [  455/  698]\n",
      "loss: 0.314046  [  595/  698]\n",
      "Training Loss (Epoch): 0.213715\n",
      "Validating...\n",
      "Validation Loss: 1.003318, Validation Accuracy: 66.29%\n",
      "Epoch 10/25\n",
      "loss: 0.098027  [   35/  698]\n",
      "loss: 0.128088  [  175/  698]\n",
      "loss: 0.083734  [  315/  698]\n",
      "loss: 0.078472  [  455/  698]\n",
      "loss: 0.314027  [  595/  698]\n",
      "Training Loss (Epoch): 0.157728\n",
      "Validating...\n",
      "Validation Loss: 0.950242, Validation Accuracy: 70.86%\n",
      "Epoch 11/25\n",
      "loss: 0.046934  [   35/  698]\n",
      "loss: 0.031173  [  175/  698]\n",
      "loss: 0.206131  [  315/  698]\n",
      "loss: 0.042267  [  455/  698]\n",
      "loss: 0.082660  [  595/  698]\n",
      "Training Loss (Epoch): 0.118805\n",
      "Validating...\n",
      "Validation Loss: 1.004397, Validation Accuracy: 71.43%\n",
      "Epoch 12/25\n",
      "loss: 0.174818  [   35/  698]\n",
      "loss: 0.015468  [  175/  698]\n",
      "loss: 0.099443  [  315/  698]\n",
      "loss: 0.062024  [  455/  698]\n",
      "loss: 0.045410  [  595/  698]\n",
      "Training Loss (Epoch): 0.118355\n",
      "Validating...\n",
      "Validation Loss: 0.925000, Validation Accuracy: 75.43%\n",
      "Epoch 13/25\n",
      "loss: 0.240297  [   35/  698]\n",
      "loss: 0.171380  [  175/  698]\n",
      "loss: 0.073785  [  315/  698]\n",
      "loss: 0.028769  [  455/  698]\n",
      "loss: 0.057297  [  595/  698]\n",
      "Training Loss (Epoch): 0.073119\n",
      "Validating...\n",
      "Validation Loss: 0.996797, Validation Accuracy: 70.29%\n",
      "Epoch 14/25\n",
      "loss: 0.014774  [   35/  698]\n",
      "loss: 0.066610  [  175/  698]\n",
      "loss: 0.018658  [  315/  698]\n",
      "loss: 0.019800  [  455/  698]\n",
      "loss: 0.094474  [  595/  698]\n",
      "Training Loss (Epoch): 0.174899\n",
      "Validating...\n",
      "Validation Loss: 0.987934, Validation Accuracy: 70.86%\n",
      "Epoch 15/25\n",
      "loss: 0.116404  [   35/  698]\n",
      "loss: 0.176091  [  175/  698]\n",
      "loss: 0.168690  [  315/  698]\n",
      "loss: 0.195814  [  455/  698]\n",
      "loss: 0.157307  [  595/  698]\n",
      "Training Loss (Epoch): 0.216136\n",
      "Validating...\n",
      "Validation Loss: 1.136747, Validation Accuracy: 65.71%\n",
      "Epoch 16/25\n",
      "loss: 0.081778  [   35/  698]\n",
      "loss: 0.216819  [  175/  698]\n",
      "loss: 0.077372  [  315/  698]\n",
      "loss: 0.102036  [  455/  698]\n",
      "loss: 0.051042  [  595/  698]\n",
      "Training Loss (Epoch): 0.105701\n",
      "Validating...\n",
      "Validation Loss: 1.083978, Validation Accuracy: 67.43%\n",
      "Epoch 17/25\n",
      "loss: 0.153944  [   35/  698]\n",
      "loss: 0.043000  [  175/  698]\n",
      "loss: 0.061981  [  315/  698]\n",
      "loss: 0.103010  [  455/  698]\n",
      "loss: 0.046832  [  595/  698]\n",
      "Training Loss (Epoch): 0.073817\n",
      "Validating...\n",
      "Validation Loss: 1.019468, Validation Accuracy: 72.00%\n",
      "Epoch 18/25\n",
      "loss: 0.068631  [   35/  698]\n",
      "loss: 0.204263  [  175/  698]\n",
      "loss: 0.118877  [  315/  698]\n",
      "loss: 0.072112  [  455/  698]\n",
      "loss: 0.025444  [  595/  698]\n",
      "Training Loss (Epoch): 0.069983\n",
      "Validating...\n",
      "Validation Loss: 0.939658, Validation Accuracy: 73.14%\n",
      "Early stopping triggered. Training stopped.\n",
      "\n",
      "Cross-Validation Results:\n",
      "Avg Training Loss: 0.593966\n",
      "Avg Validation Loss: 1.195741\n",
      "Avg Validation Accuracy: 73.14%\n",
      "Testing combination: {'layer': 0, 'lr': 0.0003, 'weight_decay': 0.05, 'drop': 0.8, 'warmup_epochs': 5, 'total_epochs': 25, 'batch_size': 70}\n",
      "Processing Fold 1\n",
      "Epoch 1/25\n",
      "loss: 2.531940  [   70/  698]\n",
      "loss: 2.543593  [  210/  698]\n",
      "loss: 2.527890  [  350/  698]\n",
      "loss: 2.537947  [  490/  698]\n",
      "loss: 2.460474  [  630/  698]\n",
      "Training Loss (Epoch): 2.571000\n",
      "Validating...\n",
      "Validation Loss: 2.409121, Validation Accuracy: 12.00%\n",
      "Epoch 2/25\n",
      "loss: 2.297287  [   70/  698]\n",
      "loss: 2.022491  [  210/  698]\n",
      "loss: 1.972268  [  350/  698]\n",
      "loss: 2.131237  [  490/  698]\n",
      "loss: 1.907783  [  630/  698]\n",
      "Training Loss (Epoch): 2.058479\n",
      "Validating...\n",
      "Validation Loss: 1.827085, Validation Accuracy: 37.14%\n",
      "Epoch 3/25\n",
      "loss: 1.877372  [   70/  698]\n",
      "loss: 1.506395  [  210/  698]\n",
      "loss: 1.509719  [  350/  698]\n",
      "loss: 1.218667  [  490/  698]\n",
      "loss: 1.076497  [  630/  698]\n",
      "Training Loss (Epoch): 1.426759\n",
      "Validating...\n",
      "Validation Loss: 1.181015, Validation Accuracy: 58.29%\n",
      "Epoch 4/25\n",
      "loss: 0.930250  [   70/  698]\n",
      "loss: 0.854690  [  210/  698]\n",
      "loss: 0.721649  [  350/  698]\n",
      "loss: 0.707858  [  490/  698]\n",
      "loss: 0.608246  [  630/  698]\n",
      "Training Loss (Epoch): 0.754550\n",
      "Validating...\n",
      "Validation Loss: 0.626242, Validation Accuracy: 81.14%\n",
      "Epoch 5/25\n",
      "loss: 0.385876  [   70/  698]\n",
      "loss: 0.438375  [  210/  698]\n",
      "loss: 0.348751  [  350/  698]\n",
      "loss: 0.300349  [  490/  698]\n",
      "loss: 0.438508  [  630/  698]\n",
      "Training Loss (Epoch): 0.403727\n",
      "Validating...\n",
      "Validation Loss: 0.498511, Validation Accuracy: 82.29%\n",
      "Epoch 6/25\n",
      "loss: 0.133434  [   70/  698]\n",
      "loss: 0.346759  [  210/  698]\n",
      "loss: 0.173411  [  350/  698]\n",
      "loss: 0.096897  [  490/  698]\n",
      "loss: 0.302180  [  630/  698]\n",
      "Training Loss (Epoch): 0.223022\n",
      "Validating...\n",
      "Validation Loss: 0.544752, Validation Accuracy: 82.86%\n",
      "Epoch 7/25\n",
      "loss: 0.084852  [   70/  698]\n",
      "loss: 0.131350  [  210/  698]\n",
      "loss: 0.053002  [  350/  698]\n",
      "loss: 0.144100  [  490/  698]\n",
      "loss: 0.783737  [  630/  698]\n",
      "Training Loss (Epoch): 0.243096\n",
      "Validating...\n",
      "Validation Loss: 0.833908, Validation Accuracy: 76.00%\n",
      "Epoch 8/25\n",
      "loss: 0.336393  [   70/  698]\n",
      "loss: 0.252090  [  210/  698]\n",
      "loss: 0.417261  [  350/  698]\n",
      "loss: 0.446256  [  490/  698]\n",
      "loss: 0.397485  [  630/  698]\n",
      "Training Loss (Epoch): 0.334417\n",
      "Validating...\n",
      "Validation Loss: 0.846445, Validation Accuracy: 74.29%\n",
      "Epoch 9/25\n",
      "loss: 0.203284  [   70/  698]\n",
      "loss: 0.185027  [  210/  698]\n",
      "loss: 0.179581  [  350/  698]\n",
      "loss: 0.195760  [  490/  698]\n",
      "loss: 0.220255  [  630/  698]\n",
      "Training Loss (Epoch): 0.171180\n",
      "Validating...\n",
      "Validation Loss: 0.767523, Validation Accuracy: 71.43%\n",
      "Epoch 10/25\n",
      "loss: 0.174756  [   70/  698]\n",
      "loss: 0.096634  [  210/  698]\n",
      "loss: 0.138331  [  350/  698]\n",
      "loss: 0.089388  [  490/  698]\n",
      "loss: 0.110611  [  630/  698]\n",
      "Training Loss (Epoch): 0.116580\n",
      "Validating...\n",
      "Validation Loss: 0.763456, Validation Accuracy: 77.71%\n",
      "Epoch 11/25\n",
      "loss: 0.161741  [   70/  698]\n",
      "loss: 0.043244  [  210/  698]\n",
      "loss: 0.387015  [  350/  698]\n",
      "loss: 0.133785  [  490/  698]\n",
      "loss: 0.712530  [  630/  698]\n",
      "Training Loss (Epoch): 0.309125\n",
      "Validating...\n",
      "Validation Loss: 1.173946, Validation Accuracy: 64.57%\n",
      "Early stopping triggered. Training stopped.\n",
      "\n",
      "Cross-Validation Results:\n",
      "Avg Training Loss: 0.782903\n",
      "Avg Validation Loss: 1.042909\n",
      "Avg Validation Accuracy: 64.57%\n",
      "Testing combination: {'layer': 0, 'lr': 0.0003, 'weight_decay': 0.05, 'drop': 0.8, 'warmup_epochs': 5, 'total_epochs': 25, 'batch_size': 35}\n",
      "Processing Fold 1\n",
      "Epoch 1/25\n",
      "loss: 2.602622  [   35/  698]\n",
      "loss: 2.566953  [  175/  698]\n",
      "loss: 2.623257  [  315/  698]\n",
      "loss: 2.722848  [  455/  698]\n",
      "loss: 2.384184  [  595/  698]\n",
      "Training Loss (Epoch): 2.572142\n",
      "Validating...\n",
      "Validation Loss: 2.389176, Validation Accuracy: 10.86%\n",
      "Epoch 2/25\n",
      "loss: 2.227701  [   35/  698]\n",
      "loss: 1.958764  [  175/  698]\n",
      "loss: 1.830315  [  315/  698]\n",
      "loss: 2.158767  [  455/  698]\n",
      "loss: 1.620002  [  595/  698]\n",
      "Training Loss (Epoch): 1.934947\n",
      "Validating...\n",
      "Validation Loss: 1.427774, Validation Accuracy: 57.14%\n",
      "Epoch 3/25\n",
      "loss: 1.419840  [   35/  698]\n",
      "loss: 1.113920  [  175/  698]\n",
      "loss: 1.042180  [  315/  698]\n",
      "loss: 0.628620  [  455/  698]\n",
      "loss: 0.605209  [  595/  698]\n",
      "Training Loss (Epoch): 0.991225\n",
      "Validating...\n",
      "Validation Loss: 0.850491, Validation Accuracy: 71.43%\n",
      "Epoch 4/25\n",
      "loss: 0.463922  [   35/  698]\n",
      "loss: 0.543220  [  175/  698]\n",
      "loss: 0.378059  [  315/  698]\n",
      "loss: 0.298081  [  455/  698]\n",
      "loss: 0.229828  [  595/  698]\n",
      "Training Loss (Epoch): 0.463941\n",
      "Validating...\n",
      "Validation Loss: 0.788841, Validation Accuracy: 71.43%\n",
      "Epoch 5/25\n",
      "loss: 0.357734  [   35/  698]\n",
      "loss: 0.418437  [  175/  698]\n",
      "loss: 0.309855  [  315/  698]\n",
      "loss: 0.530264  [  455/  698]\n",
      "loss: 0.338397  [  595/  698]\n",
      "Training Loss (Epoch): 0.413660\n",
      "Validating...\n",
      "Validation Loss: 0.862486, Validation Accuracy: 71.43%\n",
      "Epoch 6/25\n",
      "loss: 0.249800  [   35/  698]\n",
      "loss: 0.332101  [  175/  698]\n",
      "loss: 0.700035  [  315/  698]\n",
      "loss: 0.821701  [  455/  698]\n",
      "loss: 0.299550  [  595/  698]\n",
      "Training Loss (Epoch): 0.405623\n",
      "Validating...\n",
      "Validation Loss: 0.579609, Validation Accuracy: 77.71%\n",
      "Epoch 7/25\n",
      "loss: 0.087926  [   35/  698]\n",
      "loss: 0.055627  [  175/  698]\n",
      "loss: 0.171224  [  315/  698]\n",
      "loss: 0.531576  [  455/  698]\n",
      "loss: 0.516554  [  595/  698]\n",
      "Training Loss (Epoch): 0.235281\n",
      "Validating...\n",
      "Validation Loss: 0.861954, Validation Accuracy: 72.57%\n",
      "Epoch 8/25\n",
      "loss: 0.177312  [   35/  698]\n",
      "loss: 0.089708  [  175/  698]\n",
      "loss: 0.141248  [  315/  698]\n",
      "loss: 0.200138  [  455/  698]\n",
      "loss: 0.117029  [  595/  698]\n",
      "Training Loss (Epoch): 0.157000\n",
      "Validating...\n",
      "Validation Loss: 0.838552, Validation Accuracy: 76.00%\n",
      "Epoch 9/25\n",
      "loss: 0.047002  [   35/  698]\n",
      "loss: 0.137974  [  175/  698]\n",
      "loss: 0.026641  [  315/  698]\n",
      "loss: 0.147401  [  455/  698]\n",
      "loss: 0.120875  [  595/  698]\n",
      "Training Loss (Epoch): 0.080153\n",
      "Validating...\n",
      "Validation Loss: 0.841145, Validation Accuracy: 78.29%\n",
      "Epoch 10/25\n",
      "loss: 0.035701  [   35/  698]\n",
      "loss: 0.030359  [  175/  698]\n",
      "loss: 0.056066  [  315/  698]\n",
      "loss: 0.015779  [  455/  698]\n",
      "loss: 0.078385  [  595/  698]\n",
      "Training Loss (Epoch): 0.054564\n",
      "Validating...\n",
      "Validation Loss: 0.727486, Validation Accuracy: 80.00%\n",
      "Epoch 11/25\n",
      "loss: 0.006043  [   35/  698]\n",
      "loss: 0.007100  [  175/  698]\n",
      "loss: 0.060749  [  315/  698]\n",
      "loss: 0.009015  [  455/  698]\n",
      "loss: 0.050611  [  595/  698]\n",
      "Training Loss (Epoch): 0.057353\n",
      "Validating...\n",
      "Validation Loss: 1.047074, Validation Accuracy: 74.86%\n",
      "Epoch 12/25\n",
      "loss: 0.129477  [   35/  698]\n",
      "loss: 0.021040  [  175/  698]\n",
      "loss: 0.116161  [  315/  698]\n",
      "loss: 0.019754  [  455/  698]\n",
      "loss: 0.056085  [  595/  698]\n",
      "Training Loss (Epoch): 0.070421\n",
      "Validating...\n",
      "Validation Loss: 0.628359, Validation Accuracy: 82.29%\n",
      "Early stopping triggered. Training stopped.\n",
      "\n",
      "Cross-Validation Results:\n",
      "Avg Training Loss: 0.619693\n",
      "Avg Validation Loss: 0.986912\n",
      "Avg Validation Accuracy: 82.29%\n",
      "Testing combination: {'layer': 0, 'lr': 0.0003, 'weight_decay': 0.05, 'drop': 0.6, 'warmup_epochs': 3, 'total_epochs': 25, 'batch_size': 70}\n",
      "Processing Fold 1\n",
      "Epoch 1/25\n",
      "loss: 2.355740  [   70/  698]\n",
      "loss: 2.507039  [  210/  698]\n",
      "loss: 2.443720  [  350/  698]\n",
      "loss: 2.425064  [  490/  698]\n",
      "loss: 2.446517  [  630/  698]\n",
      "Training Loss (Epoch): 2.461197\n",
      "Validating...\n",
      "Validation Loss: 2.409121, Validation Accuracy: 12.00%\n",
      "Epoch 2/25\n",
      "loss: 2.297287  [   70/  698]\n",
      "loss: 2.145640  [  210/  698]\n",
      "loss: 1.970447  [  350/  698]\n",
      "loss: 2.245209  [  490/  698]\n",
      "loss: 1.949303  [  630/  698]\n",
      "Training Loss (Epoch): 2.105464\n",
      "Validating...\n",
      "Validation Loss: 1.909311, Validation Accuracy: 24.57%\n",
      "Epoch 3/25\n",
      "loss: 1.984440  [   70/  698]\n",
      "loss: 1.782001  [  210/  698]\n",
      "loss: 1.747725  [  350/  698]\n",
      "loss: 1.466601  [  490/  698]\n",
      "loss: 1.550006  [  630/  698]\n",
      "Training Loss (Epoch): 1.678053\n",
      "Validating...\n",
      "Validation Loss: 1.549149, Validation Accuracy: 42.86%\n",
      "Epoch 4/25\n",
      "loss: 1.281987  [   70/  698]\n",
      "loss: 1.377845  [  210/  698]\n",
      "loss: 1.367698  [  350/  698]\n",
      "loss: 1.074864  [  490/  698]\n",
      "loss: 1.264982  [  630/  698]\n",
      "Training Loss (Epoch): 1.268743\n",
      "Validating...\n",
      "Validation Loss: 1.266569, Validation Accuracy: 51.43%\n",
      "Epoch 5/25\n",
      "loss: 1.013465  [   70/  698]\n",
      "loss: 0.971660  [  210/  698]\n",
      "loss: 0.974765  [  350/  698]\n",
      "loss: 0.649663  [  490/  698]\n",
      "loss: 0.941712  [  630/  698]\n",
      "Training Loss (Epoch): 0.888459\n",
      "Validating...\n",
      "Validation Loss: 0.933824, Validation Accuracy: 68.57%\n",
      "Epoch 6/25\n",
      "loss: 0.500088  [   70/  698]\n",
      "loss: 0.802824  [  210/  698]\n",
      "loss: 0.553215  [  350/  698]\n",
      "loss: 0.437023  [  490/  698]\n",
      "loss: 0.494741  [  630/  698]\n",
      "Training Loss (Epoch): 0.574912\n",
      "Validating...\n",
      "Validation Loss: 0.830887, Validation Accuracy: 72.00%\n",
      "Epoch 7/25\n",
      "loss: 0.341232  [   70/  698]\n",
      "loss: 0.466910  [  210/  698]\n",
      "loss: 0.525559  [  350/  698]\n",
      "loss: 0.444233  [  490/  698]\n",
      "loss: 0.345643  [  630/  698]\n",
      "Training Loss (Epoch): 0.414837\n",
      "Validating...\n",
      "Validation Loss: 0.939646, Validation Accuracy: 70.86%\n",
      "Epoch 8/25\n",
      "loss: 0.316487  [   70/  698]\n",
      "loss: 0.237036  [  210/  698]\n",
      "loss: 0.207417  [  350/  698]\n",
      "loss: 0.358430  [  490/  698]\n",
      "loss: 0.232322  [  630/  698]\n",
      "Training Loss (Epoch): 0.287549\n",
      "Validating...\n",
      "Validation Loss: 0.874265, Validation Accuracy: 75.43%\n",
      "Epoch 9/25\n",
      "loss: 0.288331  [   70/  698]\n",
      "loss: 0.343277  [  210/  698]\n",
      "loss: 0.160233  [  350/  698]\n",
      "loss: 0.184510  [  490/  698]\n",
      "loss: 0.302385  [  630/  698]\n",
      "Training Loss (Epoch): 0.220431\n",
      "Validating...\n",
      "Validation Loss: 0.682899, Validation Accuracy: 78.29%\n",
      "Epoch 10/25\n",
      "loss: 0.136418  [   70/  698]\n",
      "loss: 0.107525  [  210/  698]\n",
      "loss: 0.097238  [  350/  698]\n",
      "loss: 0.075180  [  490/  698]\n",
      "loss: 0.248626  [  630/  698]\n",
      "Training Loss (Epoch): 0.131891\n",
      "Validating...\n",
      "Validation Loss: 0.747248, Validation Accuracy: 75.43%\n",
      "Epoch 11/25\n",
      "loss: 0.157679  [   70/  698]\n",
      "loss: 0.065892  [  210/  698]\n",
      "loss: 0.177193  [  350/  698]\n",
      "loss: 0.053357  [  490/  698]\n",
      "loss: 0.086153  [  630/  698]\n",
      "Training Loss (Epoch): 0.100745\n",
      "Validating...\n",
      "Validation Loss: 0.730525, Validation Accuracy: 77.14%\n",
      "Epoch 12/25\n",
      "loss: 0.178248  [   70/  698]\n",
      "loss: 0.037451  [  210/  698]\n",
      "loss: 0.063253  [  350/  698]\n",
      "loss: 0.117005  [  490/  698]\n",
      "loss: 0.102908  [  630/  698]\n",
      "Training Loss (Epoch): 0.086860\n",
      "Validating...\n",
      "Validation Loss: 0.726893, Validation Accuracy: 80.00%\n",
      "Epoch 13/25\n",
      "loss: 0.097584  [   70/  698]\n",
      "loss: 0.069392  [  210/  698]\n",
      "loss: 0.041347  [  350/  698]\n",
      "loss: 0.071142  [  490/  698]\n",
      "loss: 0.065022  [  630/  698]\n",
      "Training Loss (Epoch): 0.083331\n",
      "Validating...\n",
      "Validation Loss: 0.731307, Validation Accuracy: 79.43%\n",
      "Epoch 14/25\n",
      "loss: 0.114902  [   70/  698]\n",
      "loss: 0.094078  [  210/  698]\n",
      "loss: 0.046432  [  350/  698]\n",
      "loss: 0.113894  [  490/  698]\n",
      "loss: 0.046891  [  630/  698]\n",
      "Training Loss (Epoch): 0.077387\n",
      "Validating...\n",
      "Validation Loss: 0.653268, Validation Accuracy: 81.14%\n",
      "Epoch 15/25\n",
      "loss: 0.019364  [   70/  698]\n",
      "loss: 0.065876  [  210/  698]\n",
      "loss: 0.019737  [  350/  698]\n",
      "loss: 0.081546  [  490/  698]\n",
      "loss: 0.129676  [  630/  698]\n",
      "Training Loss (Epoch): 0.057723\n",
      "Validating...\n",
      "Validation Loss: 0.735325, Validation Accuracy: 80.57%\n",
      "Epoch 16/25\n",
      "loss: 0.028906  [   70/  698]\n",
      "loss: 0.106831  [  210/  698]\n",
      "loss: 0.040195  [  350/  698]\n",
      "loss: 0.043296  [  490/  698]\n",
      "loss: 0.026257  [  630/  698]\n",
      "Training Loss (Epoch): 0.044969\n",
      "Validating...\n",
      "Validation Loss: 0.710074, Validation Accuracy: 81.71%\n",
      "Epoch 17/25\n",
      "loss: 0.074644  [   70/  698]\n",
      "loss: 0.016242  [  210/  698]\n",
      "loss: 0.051933  [  350/  698]\n",
      "loss: 0.067766  [  490/  698]\n",
      "loss: 0.012057  [  630/  698]\n",
      "Training Loss (Epoch): 0.042522\n",
      "Validating...\n",
      "Validation Loss: 0.696730, Validation Accuracy: 81.14%\n",
      "Epoch 18/25\n",
      "loss: 0.089235  [   70/  698]\n",
      "loss: 0.016099  [  210/  698]\n",
      "loss: 0.056564  [  350/  698]\n",
      "loss: 0.034813  [  490/  698]\n",
      "loss: 0.055570  [  630/  698]\n",
      "Training Loss (Epoch): 0.044444\n",
      "Validating...\n",
      "Validation Loss: 0.768478, Validation Accuracy: 80.00%\n",
      "Epoch 19/25\n",
      "loss: 0.051549  [   70/  698]\n",
      "loss: 0.060732  [  210/  698]\n",
      "loss: 0.018124  [  350/  698]\n",
      "loss: 0.069207  [  490/  698]\n",
      "loss: 0.012689  [  630/  698]\n",
      "Training Loss (Epoch): 0.043862\n",
      "Validating...\n",
      "Validation Loss: 0.713635, Validation Accuracy: 81.14%\n",
      "Epoch 20/25\n",
      "loss: 0.026581  [   70/  698]\n",
      "loss: 0.043687  [  210/  698]\n",
      "loss: 0.014376  [  350/  698]\n",
      "loss: 0.008290  [  490/  698]\n",
      "loss: 0.084057  [  630/  698]\n",
      "Training Loss (Epoch): 0.042520\n",
      "Validating...\n",
      "Validation Loss: 0.731694, Validation Accuracy: 82.29%\n",
      "Early stopping triggered. Training stopped.\n",
      "\n",
      "Cross-Validation Results:\n",
      "Avg Training Loss: 0.532795\n",
      "Avg Validation Loss: 0.967042\n",
      "Avg Validation Accuracy: 82.29%\n",
      "Testing combination: {'layer': 0, 'lr': 0.0003, 'weight_decay': 0.05, 'drop': 0.6, 'warmup_epochs': 3, 'total_epochs': 25, 'batch_size': 35}\n",
      "Processing Fold 1\n",
      "Epoch 1/25\n",
      "loss: 2.395155  [   35/  698]\n",
      "loss: 2.471717  [  175/  698]\n",
      "loss: 2.474921  [  315/  698]\n",
      "loss: 2.523694  [  455/  698]\n",
      "loss: 2.325230  [  595/  698]\n",
      "Training Loss (Epoch): 2.451109\n",
      "Validating...\n",
      "Validation Loss: 2.389176, Validation Accuracy: 10.86%\n",
      "Epoch 2/25\n",
      "loss: 2.227701  [   35/  698]\n",
      "loss: 1.984321  [  175/  698]\n",
      "loss: 1.806061  [  315/  698]\n",
      "loss: 2.353527  [  455/  698]\n",
      "loss: 1.622619  [  595/  698]\n",
      "Training Loss (Epoch): 1.963645\n",
      "Validating...\n",
      "Validation Loss: 1.653327, Validation Accuracy: 38.86%\n",
      "Epoch 3/25\n",
      "loss: 1.502954  [   35/  698]\n",
      "loss: 1.283560  [  175/  698]\n",
      "loss: 1.335542  [  315/  698]\n",
      "loss: 0.971176  [  455/  698]\n",
      "loss: 1.160547  [  595/  698]\n",
      "Training Loss (Epoch): 1.301119\n",
      "Validating...\n",
      "Validation Loss: 1.172975, Validation Accuracy: 61.71%\n",
      "Epoch 4/25\n",
      "loss: 0.652484  [   35/  698]\n",
      "loss: 0.805763  [  175/  698]\n",
      "loss: 0.622019  [  315/  698]\n",
      "loss: 0.573035  [  455/  698]\n",
      "loss: 0.422663  [  595/  698]\n",
      "Training Loss (Epoch): 0.777515\n",
      "Validating...\n",
      "Validation Loss: 1.015433, Validation Accuracy: 69.71%\n",
      "Epoch 5/25\n",
      "loss: 0.572730  [   35/  698]\n",
      "loss: 0.516210  [  175/  698]\n",
      "loss: 0.705455  [  315/  698]\n",
      "loss: 0.389541  [  455/  698]\n",
      "loss: 0.451688  [  595/  698]\n",
      "Training Loss (Epoch): 0.546274\n",
      "Validating...\n",
      "Validation Loss: 0.965843, Validation Accuracy: 70.29%\n",
      "Epoch 6/25\n",
      "loss: 0.140419  [   35/  698]\n",
      "loss: 0.306202  [  175/  698]\n",
      "loss: 0.252030  [  315/  698]\n",
      "loss: 0.216293  [  455/  698]\n",
      "loss: 0.094261  [  595/  698]\n",
      "Training Loss (Epoch): 0.235817\n",
      "Validating...\n",
      "Validation Loss: 0.941915, Validation Accuracy: 70.86%\n",
      "Epoch 7/25\n",
      "loss: 0.058461  [   35/  698]\n",
      "loss: 0.054849  [  175/  698]\n",
      "loss: 0.127349  [  315/  698]\n",
      "loss: 0.226313  [  455/  698]\n",
      "loss: 0.217989  [  595/  698]\n",
      "Training Loss (Epoch): 0.139977\n",
      "Validating...\n",
      "Validation Loss: 0.899361, Validation Accuracy: 73.71%\n",
      "Epoch 8/25\n",
      "loss: 0.087894  [   35/  698]\n",
      "loss: 0.035107  [  175/  698]\n",
      "loss: 0.048243  [  315/  698]\n",
      "loss: 0.113932  [  455/  698]\n",
      "loss: 0.120400  [  595/  698]\n",
      "Training Loss (Epoch): 0.087828\n",
      "Validating...\n",
      "Validation Loss: 0.849315, Validation Accuracy: 74.86%\n",
      "Epoch 9/25\n",
      "loss: 0.050947  [   35/  698]\n",
      "loss: 0.308977  [  175/  698]\n",
      "loss: 0.040069  [  315/  698]\n",
      "loss: 0.117226  [  455/  698]\n",
      "loss: 0.249627  [  595/  698]\n",
      "Training Loss (Epoch): 0.087927\n",
      "Validating...\n",
      "Validation Loss: 1.044775, Validation Accuracy: 72.00%\n",
      "Epoch 10/25\n",
      "loss: 0.065890  [   35/  698]\n",
      "loss: 0.063056  [  175/  698]\n",
      "loss: 0.048169  [  315/  698]\n",
      "loss: 0.031763  [  455/  698]\n",
      "loss: 0.075506  [  595/  698]\n",
      "Training Loss (Epoch): 0.082343\n",
      "Validating...\n",
      "Validation Loss: 0.903989, Validation Accuracy: 73.14%\n",
      "Epoch 11/25\n",
      "loss: 0.034307  [   35/  698]\n",
      "loss: 0.311908  [  175/  698]\n",
      "loss: 0.233285  [  315/  698]\n",
      "loss: 0.042749  [  455/  698]\n",
      "loss: 0.159401  [  595/  698]\n",
      "Training Loss (Epoch): 0.122612\n",
      "Validating...\n",
      "Validation Loss: 0.986154, Validation Accuracy: 72.00%\n",
      "Epoch 12/25\n",
      "loss: 0.201539  [   35/  698]\n",
      "loss: 0.038576  [  175/  698]\n",
      "loss: 0.055759  [  315/  698]\n",
      "loss: 0.007208  [  455/  698]\n",
      "loss: 0.019867  [  595/  698]\n",
      "Training Loss (Epoch): 0.067652\n",
      "Validating...\n",
      "Validation Loss: 0.994859, Validation Accuracy: 71.43%\n",
      "Epoch 13/25\n",
      "loss: 0.221576  [   35/  698]\n",
      "loss: 0.087000  [  175/  698]\n",
      "loss: 0.055747  [  315/  698]\n",
      "loss: 0.014023  [  455/  698]\n",
      "loss: 0.023283  [  595/  698]\n",
      "Training Loss (Epoch): 0.051580\n",
      "Validating...\n",
      "Validation Loss: 0.879672, Validation Accuracy: 76.57%\n",
      "Epoch 14/25\n",
      "loss: 0.011911  [   35/  698]\n",
      "loss: 0.029993  [  175/  698]\n",
      "loss: 0.018501  [  315/  698]\n",
      "loss: 0.024525  [  455/  698]\n",
      "loss: 0.016224  [  595/  698]\n",
      "Training Loss (Epoch): 0.115762\n",
      "Validating...\n",
      "Validation Loss: 0.931305, Validation Accuracy: 76.00%\n",
      "Early stopping triggered. Training stopped.\n",
      "\n",
      "Cross-Validation Results:\n",
      "Avg Training Loss: 0.573654\n",
      "Avg Validation Loss: 1.116293\n",
      "Avg Validation Accuracy: 76.00%\n",
      "Testing combination: {'layer': 0, 'lr': 0.0003, 'weight_decay': 0.05, 'drop': 0.6, 'warmup_epochs': 5, 'total_epochs': 25, 'batch_size': 70}\n",
      "Processing Fold 1\n",
      "Epoch 1/25\n",
      "loss: 2.355740  [   70/  698]\n",
      "loss: 2.507039  [  210/  698]\n",
      "loss: 2.443720  [  350/  698]\n",
      "loss: 2.425064  [  490/  698]\n",
      "loss: 2.446517  [  630/  698]\n",
      "Training Loss (Epoch): 2.461197\n",
      "Validating...\n",
      "Validation Loss: 2.409121, Validation Accuracy: 12.00%\n",
      "Epoch 2/25\n",
      "loss: 2.297287  [   70/  698]\n",
      "loss: 1.996011  [  210/  698]\n",
      "loss: 1.946928  [  350/  698]\n",
      "loss: 2.164209  [  490/  698]\n",
      "loss: 1.954405  [  630/  698]\n",
      "Training Loss (Epoch): 2.064092\n",
      "Validating...\n",
      "Validation Loss: 1.863857, Validation Accuracy: 26.86%\n",
      "Epoch 3/25\n",
      "loss: 1.928641  [   70/  698]\n",
      "loss: 1.598691  [  210/  698]\n",
      "loss: 1.613805  [  350/  698]\n",
      "loss: 1.279437  [  490/  698]\n",
      "loss: 1.350074  [  630/  698]\n",
      "Training Loss (Epoch): 1.511702\n",
      "Validating...\n",
      "Validation Loss: 1.277173, Validation Accuracy: 52.57%\n",
      "Epoch 4/25\n",
      "loss: 0.972860  [   70/  698]\n",
      "loss: 1.287806  [  210/  698]\n",
      "loss: 0.964949  [  350/  698]\n",
      "loss: 0.911754  [  490/  698]\n",
      "loss: 0.766790  [  630/  698]\n",
      "Training Loss (Epoch): 0.994412\n",
      "Validating...\n",
      "Validation Loss: 0.994355, Validation Accuracy: 69.14%\n",
      "Epoch 5/25\n",
      "loss: 0.772709  [   70/  698]\n",
      "loss: 0.662172  [  210/  698]\n",
      "loss: 0.546972  [  350/  698]\n",
      "loss: 0.547015  [  490/  698]\n",
      "loss: 0.621174  [  630/  698]\n",
      "Training Loss (Epoch): 0.635029\n",
      "Validating...\n",
      "Validation Loss: 0.715832, Validation Accuracy: 74.29%\n",
      "Epoch 6/25\n",
      "loss: 0.242831  [   70/  698]\n",
      "loss: 0.470240  [  210/  698]\n",
      "loss: 0.287269  [  350/  698]\n",
      "loss: 0.220372  [  490/  698]\n",
      "loss: 0.229283  [  630/  698]\n",
      "Training Loss (Epoch): 0.331601\n",
      "Validating...\n",
      "Validation Loss: 0.632726, Validation Accuracy: 76.57%\n",
      "Epoch 7/25\n",
      "loss: 0.097632  [   70/  698]\n",
      "loss: 0.130444  [  210/  698]\n",
      "loss: 0.229021  [  350/  698]\n",
      "loss: 0.208801  [  490/  698]\n",
      "loss: 0.173888  [  630/  698]\n",
      "Training Loss (Epoch): 0.192991\n",
      "Validating...\n",
      "Validation Loss: 0.665566, Validation Accuracy: 77.71%\n",
      "Epoch 8/25\n",
      "loss: 0.133016  [   70/  698]\n",
      "loss: 0.096840  [  210/  698]\n",
      "loss: 0.196602  [  350/  698]\n",
      "loss: 0.240346  [  490/  698]\n",
      "loss: 0.108689  [  630/  698]\n",
      "Training Loss (Epoch): 0.169276\n",
      "Validating...\n",
      "Validation Loss: 0.549515, Validation Accuracy: 80.57%\n",
      "Epoch 9/25\n",
      "loss: 0.143259  [   70/  698]\n",
      "loss: 0.057226  [  210/  698]\n",
      "loss: 0.080850  [  350/  698]\n",
      "loss: 0.148719  [  490/  698]\n",
      "loss: 0.144807  [  630/  698]\n",
      "Training Loss (Epoch): 0.097835\n",
      "Validating...\n",
      "Validation Loss: 0.686570, Validation Accuracy: 76.00%\n",
      "Epoch 10/25\n",
      "loss: 0.120225  [   70/  698]\n",
      "loss: 0.084117  [  210/  698]\n",
      "loss: 0.072578  [  350/  698]\n",
      "loss: 0.051276  [  490/  698]\n",
      "loss: 0.093002  [  630/  698]\n",
      "Training Loss (Epoch): 0.088065\n",
      "Validating...\n",
      "Validation Loss: 0.663845, Validation Accuracy: 78.29%\n",
      "Epoch 11/25\n",
      "loss: 0.067441  [   70/  698]\n",
      "loss: 0.013933  [  210/  698]\n",
      "loss: 0.065467  [  350/  698]\n",
      "loss: 0.062480  [  490/  698]\n",
      "loss: 0.050272  [  630/  698]\n",
      "Training Loss (Epoch): 0.054413\n",
      "Validating...\n",
      "Validation Loss: 0.705160, Validation Accuracy: 75.43%\n",
      "Epoch 12/25\n",
      "loss: 0.103953  [   70/  698]\n",
      "loss: 0.013571  [  210/  698]\n",
      "loss: 0.052347  [  350/  698]\n",
      "loss: 0.034493  [  490/  698]\n",
      "loss: 0.021995  [  630/  698]\n",
      "Training Loss (Epoch): 0.050908\n",
      "Validating...\n",
      "Validation Loss: 0.704043, Validation Accuracy: 77.71%\n",
      "Epoch 13/25\n",
      "loss: 0.108292  [   70/  698]\n",
      "loss: 0.043111  [  210/  698]\n",
      "loss: 0.022420  [  350/  698]\n",
      "loss: 0.092176  [  490/  698]\n",
      "loss: 0.047323  [  630/  698]\n",
      "Training Loss (Epoch): 0.050071\n",
      "Validating...\n",
      "Validation Loss: 0.697718, Validation Accuracy: 78.29%\n",
      "Epoch 14/25\n",
      "loss: 0.096278  [   70/  698]\n",
      "loss: 0.020584  [  210/  698]\n",
      "loss: 0.011440  [  350/  698]\n",
      "loss: 0.079420  [  490/  698]\n",
      "loss: 0.028701  [  630/  698]\n",
      "Training Loss (Epoch): 0.045499\n",
      "Validating...\n",
      "Validation Loss: 0.568786, Validation Accuracy: 80.00%\n",
      "Early stopping triggered. Training stopped.\n",
      "\n",
      "Cross-Validation Results:\n",
      "Avg Training Loss: 0.624792\n",
      "Avg Validation Loss: 0.938162\n",
      "Avg Validation Accuracy: 80.00%\n",
      "Testing combination: {'layer': 0, 'lr': 0.0003, 'weight_decay': 0.05, 'drop': 0.6, 'warmup_epochs': 5, 'total_epochs': 25, 'batch_size': 35}\n",
      "Processing Fold 1\n",
      "Epoch 1/25\n",
      "loss: 2.395155  [   35/  698]\n",
      "loss: 2.471717  [  175/  698]\n",
      "loss: 2.474921  [  315/  698]\n",
      "loss: 2.523694  [  455/  698]\n",
      "loss: 2.325230  [  595/  698]\n",
      "Training Loss (Epoch): 2.451109\n",
      "Validating...\n",
      "Validation Loss: 2.389176, Validation Accuracy: 10.86%\n",
      "Epoch 2/25\n",
      "loss: 2.227701  [   35/  698]\n",
      "loss: 1.882127  [  175/  698]\n",
      "loss: 1.716266  [  315/  698]\n",
      "loss: 2.203719  [  455/  698]\n",
      "loss: 1.471357  [  595/  698]\n",
      "Training Loss (Epoch): 1.800046\n",
      "Validating...\n",
      "Validation Loss: 1.198135, Validation Accuracy: 67.43%\n",
      "Epoch 3/25\n",
      "loss: 1.107980  [   35/  698]\n",
      "loss: 0.848250  [  175/  698]\n",
      "loss: 0.786855  [  315/  698]\n",
      "loss: 0.581406  [  455/  698]\n",
      "loss: 0.543987  [  595/  698]\n",
      "Training Loss (Epoch): 0.890417\n",
      "Validating...\n",
      "Validation Loss: 1.491789, Validation Accuracy: 46.86%\n",
      "Epoch 4/25\n",
      "loss: 1.060045  [   35/  698]\n",
      "loss: 1.630562  [  175/  698]\n",
      "loss: 1.217844  [  315/  698]\n",
      "loss: 1.152238  [  455/  698]\n",
      "loss: 1.067973  [  595/  698]\n",
      "Training Loss (Epoch): 1.364299\n",
      "Validating...\n",
      "Validation Loss: 1.264733, Validation Accuracy: 54.86%\n",
      "Epoch 5/25\n",
      "loss: 0.730335  [   35/  698]\n",
      "loss: 0.984227  [  175/  698]\n",
      "loss: 1.113291  [  315/  698]\n",
      "loss: 0.827403  [  455/  698]\n",
      "loss: 0.834470  [  595/  698]\n",
      "Training Loss (Epoch): 0.868226\n",
      "Validating...\n",
      "Validation Loss: 1.146050, Validation Accuracy: 60.57%\n",
      "Epoch 6/25\n",
      "loss: 0.741639  [   35/  698]\n",
      "loss: 0.791187  [  175/  698]\n",
      "loss: 0.432439  [  315/  698]\n",
      "loss: 0.496682  [  455/  698]\n",
      "loss: 0.314684  [  595/  698]\n",
      "Training Loss (Epoch): 0.533467\n",
      "Validating...\n",
      "Validation Loss: 1.020703, Validation Accuracy: 68.00%\n",
      "Epoch 7/25\n",
      "loss: 0.194935  [   35/  698]\n",
      "loss: 0.222694  [  175/  698]\n",
      "loss: 0.365393  [  315/  698]\n",
      "loss: 0.489095  [  455/  698]\n",
      "loss: 0.283742  [  595/  698]\n",
      "Training Loss (Epoch): 0.299889\n",
      "Validating...\n",
      "Validation Loss: 1.111571, Validation Accuracy: 64.00%\n",
      "Epoch 8/25\n",
      "loss: 0.260118  [   35/  698]\n",
      "loss: 0.113931  [  175/  698]\n",
      "loss: 0.092545  [  315/  698]\n",
      "loss: 0.251102  [  455/  698]\n",
      "loss: 0.181771  [  595/  698]\n",
      "Training Loss (Epoch): 0.181244\n",
      "Validating...\n",
      "Validation Loss: 0.993298, Validation Accuracy: 67.43%\n",
      "Epoch 9/25\n",
      "loss: 0.046696  [   35/  698]\n",
      "loss: 0.156816  [  175/  698]\n",
      "loss: 0.033729  [  315/  698]\n",
      "loss: 0.320658  [  455/  698]\n",
      "loss: 0.211736  [  595/  698]\n",
      "Training Loss (Epoch): 0.141652\n",
      "Validating...\n",
      "Validation Loss: 1.013020, Validation Accuracy: 68.57%\n",
      "Epoch 10/25\n",
      "loss: 0.300606  [   35/  698]\n",
      "loss: 0.096197  [  175/  698]\n",
      "loss: 0.070771  [  315/  698]\n",
      "loss: 0.105015  [  455/  698]\n",
      "loss: 0.178672  [  595/  698]\n",
      "Training Loss (Epoch): 0.122072\n",
      "Validating...\n",
      "Validation Loss: 0.891785, Validation Accuracy: 74.29%\n",
      "Epoch 11/25\n",
      "loss: 0.068192  [   35/  698]\n",
      "loss: 0.017370  [  175/  698]\n",
      "loss: 0.137680  [  315/  698]\n",
      "loss: 0.027403  [  455/  698]\n",
      "loss: 0.135704  [  595/  698]\n",
      "Training Loss (Epoch): 0.082411\n",
      "Validating...\n",
      "Validation Loss: 1.027273, Validation Accuracy: 69.71%\n",
      "Epoch 12/25\n",
      "loss: 0.135138  [   35/  698]\n",
      "loss: 0.013384  [  175/  698]\n",
      "loss: 0.063186  [  315/  698]\n",
      "loss: 0.064101  [  455/  698]\n",
      "loss: 0.032648  [  595/  698]\n",
      "Training Loss (Epoch): 0.068034\n",
      "Validating...\n",
      "Validation Loss: 0.912274, Validation Accuracy: 74.29%\n",
      "Epoch 13/25\n",
      "loss: 0.224259  [   35/  698]\n",
      "loss: 0.114249  [  175/  698]\n",
      "loss: 0.021162  [  315/  698]\n",
      "loss: 0.012284  [  455/  698]\n",
      "loss: 0.076054  [  595/  698]\n",
      "Training Loss (Epoch): 0.074516\n",
      "Validating...\n",
      "Validation Loss: 1.045110, Validation Accuracy: 70.29%\n",
      "Epoch 14/25\n",
      "loss: 0.020405  [   35/  698]\n",
      "loss: 0.204502  [  175/  698]\n",
      "loss: 0.032667  [  315/  698]\n",
      "loss: 0.039823  [  455/  698]\n",
      "loss: 0.039384  [  595/  698]\n",
      "Training Loss (Epoch): 0.221398\n",
      "Validating...\n",
      "Validation Loss: 0.841721, Validation Accuracy: 74.29%\n",
      "Epoch 15/25\n",
      "loss: 0.050821  [   35/  698]\n",
      "loss: 0.062990  [  175/  698]\n",
      "loss: 0.395407  [  315/  698]\n",
      "loss: 0.128545  [  455/  698]\n",
      "loss: 0.179876  [  595/  698]\n",
      "Training Loss (Epoch): 0.146791\n",
      "Validating...\n",
      "Validation Loss: 1.035587, Validation Accuracy: 73.14%\n",
      "Epoch 16/25\n",
      "loss: 0.124606  [   35/  698]\n",
      "loss: 0.081252  [  175/  698]\n",
      "loss: 0.050998  [  315/  698]\n",
      "loss: 0.073284  [  455/  698]\n",
      "loss: 0.107388  [  595/  698]\n",
      "Training Loss (Epoch): 0.087233\n",
      "Validating...\n",
      "Validation Loss: 0.954237, Validation Accuracy: 75.43%\n",
      "Epoch 17/25\n",
      "loss: 0.130373  [   35/  698]\n",
      "loss: 0.043788  [  175/  698]\n",
      "loss: 0.017821  [  315/  698]\n",
      "loss: 0.137716  [  455/  698]\n",
      "loss: 0.025017  [  595/  698]\n",
      "Training Loss (Epoch): 0.057046\n",
      "Validating...\n",
      "Validation Loss: 0.945220, Validation Accuracy: 73.71%\n",
      "Epoch 18/25\n",
      "loss: 0.033584  [   35/  698]\n",
      "loss: 0.050929  [  175/  698]\n",
      "loss: 0.094562  [  315/  698]\n",
      "loss: 0.052810  [  455/  698]\n",
      "loss: 0.014166  [  595/  698]\n",
      "Training Loss (Epoch): 0.045417\n",
      "Validating...\n",
      "Validation Loss: 0.933299, Validation Accuracy: 75.43%\n",
      "Epoch 19/25\n",
      "loss: 0.036544  [   35/  698]\n",
      "loss: 0.061178  [  175/  698]\n",
      "loss: 0.005068  [  315/  698]\n",
      "loss: 0.199101  [  455/  698]\n",
      "loss: 0.055275  [  595/  698]\n",
      "Training Loss (Epoch): 0.052471\n",
      "Validating...\n",
      "Validation Loss: 0.961854, Validation Accuracy: 74.29%\n",
      "Epoch 20/25\n",
      "loss: 0.051418  [   35/  698]\n",
      "loss: 0.071149  [  175/  698]\n",
      "loss: 0.040397  [  315/  698]\n",
      "loss: 0.027880  [  455/  698]\n",
      "loss: 0.069014  [  595/  698]\n",
      "Training Loss (Epoch): 0.044243\n",
      "Validating...\n",
      "Validation Loss: 0.813802, Validation Accuracy: 77.14%\n",
      "Epoch 21/25\n",
      "loss: 0.002478  [   35/  698]\n",
      "loss: 0.021905  [  175/  698]\n",
      "loss: 0.013754  [  315/  698]\n",
      "loss: 0.001617  [  455/  698]\n",
      "loss: 0.001549  [  595/  698]\n",
      "Training Loss (Epoch): 0.040444\n",
      "Validating...\n",
      "Validation Loss: 0.818893, Validation Accuracy: 78.29%\n",
      "Epoch 22/25\n",
      "loss: 0.091993  [   35/  698]\n",
      "loss: 0.001218  [  175/  698]\n",
      "loss: 0.016415  [  315/  698]\n",
      "loss: 0.015791  [  455/  698]\n",
      "loss: 0.109373  [  595/  698]\n",
      "Training Loss (Epoch): 0.035202\n",
      "Validating...\n",
      "Validation Loss: 0.809603, Validation Accuracy: 78.29%\n",
      "Epoch 23/25\n",
      "loss: 0.014691  [   35/  698]\n",
      "loss: 0.001515  [  175/  698]\n",
      "loss: 0.055028  [  315/  698]\n",
      "loss: 0.015455  [  455/  698]\n",
      "loss: 0.001366  [  595/  698]\n",
      "Training Loss (Epoch): 0.034522\n",
      "Validating...\n",
      "Validation Loss: 0.814545, Validation Accuracy: 76.57%\n",
      "Epoch 24/25\n",
      "loss: 0.055361  [   35/  698]\n",
      "loss: 0.001671  [  175/  698]\n",
      "loss: 0.069088  [  315/  698]\n",
      "loss: 0.040662  [  455/  698]\n",
      "loss: 0.001558  [  595/  698]\n",
      "Training Loss (Epoch): 0.034805\n",
      "Validating...\n",
      "Validation Loss: 0.816852, Validation Accuracy: 76.57%\n",
      "Epoch 25/25\n",
      "loss: 0.054733  [   35/  698]\n",
      "loss: 0.052945  [  175/  698]\n",
      "loss: 0.015620  [  315/  698]\n",
      "loss: 0.013908  [  455/  698]\n",
      "loss: 0.002073  [  595/  698]\n",
      "Training Loss (Epoch): 0.034865\n",
      "Validating...\n",
      "Validation Loss: 0.819131, Validation Accuracy: 76.57%\n",
      "\n",
      "Cross-Validation Results:\n",
      "Avg Training Loss: 0.388473\n",
      "Avg Validation Loss: 1.042786\n",
      "Avg Validation Accuracy: 76.57%\n",
      "Testing combination: {'layer': 0, 'lr': 0.0003, 'weight_decay': 0.1, 'drop': 0.8, 'warmup_epochs': 3, 'total_epochs': 25, 'batch_size': 70}\n",
      "Processing Fold 1\n",
      "Epoch 1/25\n",
      "loss: 2.531940  [   70/  698]\n",
      "loss: 2.543593  [  210/  698]\n",
      "loss: 2.527890  [  350/  698]\n",
      "loss: 2.537947  [  490/  698]\n",
      "loss: 2.460474  [  630/  698]\n",
      "Training Loss (Epoch): 2.571000\n",
      "Validating...\n",
      "Validation Loss: 2.409121, Validation Accuracy: 12.00%\n",
      "Epoch 2/25\n",
      "loss: 2.297287  [   70/  698]\n",
      "loss: 2.088382  [  210/  698]\n",
      "loss: 2.001813  [  350/  698]\n",
      "loss: 2.230623  [  490/  698]\n",
      "loss: 2.013169  [  630/  698]\n",
      "Training Loss (Epoch): 2.115983\n",
      "Validating...\n",
      "Validation Loss: 1.963041, Validation Accuracy: 24.00%\n",
      "Epoch 3/25\n",
      "loss: 2.030364  [   70/  698]\n",
      "loss: 1.769393  [  210/  698]\n",
      "loss: 1.819143  [  350/  698]\n",
      "loss: 1.516693  [  490/  698]\n",
      "loss: 1.633076  [  630/  698]\n",
      "Training Loss (Epoch): 1.746838\n",
      "Validating...\n",
      "Validation Loss: 1.710680, Validation Accuracy: 32.57%\n",
      "Epoch 4/25\n",
      "loss: 1.482414  [   70/  698]\n",
      "loss: 1.500467  [  210/  698]\n",
      "loss: 1.427189  [  350/  698]\n",
      "loss: 1.187390  [  490/  698]\n",
      "loss: 1.339162  [  630/  698]\n",
      "Training Loss (Epoch): 1.357075\n",
      "Validating...\n",
      "Validation Loss: 1.205515, Validation Accuracy: 54.86%\n",
      "Epoch 5/25\n",
      "loss: 1.054638  [   70/  698]\n",
      "loss: 1.095561  [  210/  698]\n",
      "loss: 1.037041  [  350/  698]\n",
      "loss: 0.743040  [  490/  698]\n",
      "loss: 1.046407  [  630/  698]\n",
      "Training Loss (Epoch): 0.971315\n",
      "Validating...\n",
      "Validation Loss: 0.973746, Validation Accuracy: 65.14%\n",
      "Epoch 6/25\n",
      "loss: 0.560771  [   70/  698]\n",
      "loss: 0.873042  [  210/  698]\n",
      "loss: 0.558018  [  350/  698]\n",
      "loss: 0.572957  [  490/  698]\n",
      "loss: 0.565388  [  630/  698]\n",
      "Training Loss (Epoch): 0.648628\n",
      "Validating...\n",
      "Validation Loss: 0.847488, Validation Accuracy: 72.57%\n",
      "Epoch 7/25\n",
      "loss: 0.358726  [   70/  698]\n",
      "loss: 0.555784  [  210/  698]\n",
      "loss: 0.577132  [  350/  698]\n",
      "loss: 0.567700  [  490/  698]\n",
      "loss: 0.361501  [  630/  698]\n",
      "Training Loss (Epoch): 0.446854\n",
      "Validating...\n",
      "Validation Loss: 0.827419, Validation Accuracy: 73.71%\n",
      "Epoch 8/25\n",
      "loss: 0.295418  [   70/  698]\n",
      "loss: 0.160788  [  210/  698]\n",
      "loss: 0.278372  [  350/  698]\n",
      "loss: 0.353149  [  490/  698]\n",
      "loss: 0.262746  [  630/  698]\n",
      "Training Loss (Epoch): 0.303728\n",
      "Validating...\n",
      "Validation Loss: 0.793499, Validation Accuracy: 76.57%\n",
      "Epoch 9/25\n",
      "loss: 0.246826  [   70/  698]\n",
      "loss: 0.265795  [  210/  698]\n",
      "loss: 0.192805  [  350/  698]\n",
      "loss: 0.160501  [  490/  698]\n",
      "loss: 0.283755  [  630/  698]\n",
      "Training Loss (Epoch): 0.204902\n",
      "Validating...\n",
      "Validation Loss: 0.728864, Validation Accuracy: 76.57%\n",
      "Epoch 10/25\n",
      "loss: 0.146027  [   70/  698]\n",
      "loss: 0.145084  [  210/  698]\n",
      "loss: 0.118000  [  350/  698]\n",
      "loss: 0.063583  [  490/  698]\n",
      "loss: 0.452727  [  630/  698]\n",
      "Training Loss (Epoch): 0.173470\n",
      "Validating...\n",
      "Validation Loss: 0.791476, Validation Accuracy: 75.43%\n",
      "Epoch 11/25\n",
      "loss: 0.161588  [   70/  698]\n",
      "loss: 0.097610  [  210/  698]\n",
      "loss: 0.154352  [  350/  698]\n",
      "loss: 0.094767  [  490/  698]\n",
      "loss: 0.211898  [  630/  698]\n",
      "Training Loss (Epoch): 0.135786\n",
      "Validating...\n",
      "Validation Loss: 0.707805, Validation Accuracy: 79.43%\n",
      "Epoch 12/25\n",
      "loss: 0.190002  [   70/  698]\n",
      "loss: 0.063459  [  210/  698]\n",
      "loss: 0.083520  [  350/  698]\n",
      "loss: 0.134244  [  490/  698]\n",
      "loss: 0.159020  [  630/  698]\n",
      "Training Loss (Epoch): 0.102452\n",
      "Validating...\n",
      "Validation Loss: 0.782323, Validation Accuracy: 79.43%\n",
      "Epoch 13/25\n",
      "loss: 0.110493  [   70/  698]\n",
      "loss: 0.096017  [  210/  698]\n",
      "loss: 0.074169  [  350/  698]\n",
      "loss: 0.052062  [  490/  698]\n",
      "loss: 0.069515  [  630/  698]\n",
      "Training Loss (Epoch): 0.077081\n",
      "Validating...\n",
      "Validation Loss: 0.695089, Validation Accuracy: 77.71%\n",
      "Epoch 14/25\n",
      "loss: 0.072602  [   70/  698]\n",
      "loss: 0.044075  [  210/  698]\n",
      "loss: 0.036036  [  350/  698]\n",
      "loss: 0.140957  [  490/  698]\n",
      "loss: 0.103796  [  630/  698]\n",
      "Training Loss (Epoch): 0.074649\n",
      "Validating...\n",
      "Validation Loss: 0.774763, Validation Accuracy: 78.86%\n",
      "Epoch 15/25\n",
      "loss: 0.020483  [   70/  698]\n",
      "loss: 0.055971  [  210/  698]\n",
      "loss: 0.033586  [  350/  698]\n",
      "loss: 0.113173  [  490/  698]\n",
      "loss: 0.175290  [  630/  698]\n",
      "Training Loss (Epoch): 0.063608\n",
      "Validating...\n",
      "Validation Loss: 0.892621, Validation Accuracy: 77.14%\n",
      "Epoch 16/25\n",
      "loss: 0.034741  [   70/  698]\n",
      "loss: 0.111715  [  210/  698]\n",
      "loss: 0.028079  [  350/  698]\n",
      "loss: 0.075979  [  490/  698]\n",
      "loss: 0.063269  [  630/  698]\n",
      "Training Loss (Epoch): 0.069589\n",
      "Validating...\n",
      "Validation Loss: 0.736334, Validation Accuracy: 78.29%\n",
      "Epoch 17/25\n",
      "loss: 0.107361  [   70/  698]\n",
      "loss: 0.017915  [  210/  698]\n",
      "loss: 0.080630  [  350/  698]\n",
      "loss: 0.118529  [  490/  698]\n",
      "loss: 0.035439  [  630/  698]\n",
      "Training Loss (Epoch): 0.066082\n",
      "Validating...\n",
      "Validation Loss: 0.629713, Validation Accuracy: 78.29%\n",
      "Epoch 18/25\n",
      "loss: 0.091857  [   70/  698]\n",
      "loss: 0.033701  [  210/  698]\n",
      "loss: 0.071814  [  350/  698]\n",
      "loss: 0.022124  [  490/  698]\n",
      "loss: 0.064360  [  630/  698]\n",
      "Training Loss (Epoch): 0.050234\n",
      "Validating...\n",
      "Validation Loss: 0.844710, Validation Accuracy: 78.86%\n",
      "Epoch 19/25\n",
      "loss: 0.052507  [   70/  698]\n",
      "loss: 0.042769  [  210/  698]\n",
      "loss: 0.020368  [  350/  698]\n",
      "loss: 0.089678  [  490/  698]\n",
      "loss: 0.010961  [  630/  698]\n",
      "Training Loss (Epoch): 0.043969\n",
      "Validating...\n",
      "Validation Loss: 0.826943, Validation Accuracy: 80.00%\n",
      "Epoch 20/25\n",
      "loss: 0.027318  [   70/  698]\n",
      "loss: 0.042746  [  210/  698]\n",
      "loss: 0.018108  [  350/  698]\n",
      "loss: 0.010857  [  490/  698]\n",
      "loss: 0.075832  [  630/  698]\n",
      "Training Loss (Epoch): 0.041509\n",
      "Validating...\n",
      "Validation Loss: 0.802089, Validation Accuracy: 78.86%\n",
      "Epoch 21/25\n",
      "loss: 0.008012  [   70/  698]\n",
      "loss: 0.015242  [  210/  698]\n",
      "loss: 0.020340  [  350/  698]\n",
      "loss: 0.057683  [  490/  698]\n",
      "loss: 0.010798  [  630/  698]\n",
      "Training Loss (Epoch): 0.036479\n",
      "Validating...\n",
      "Validation Loss: 0.809770, Validation Accuracy: 80.00%\n",
      "Epoch 22/25\n",
      "loss: 0.062376  [   70/  698]\n",
      "loss: 0.011376  [  210/  698]\n",
      "loss: 0.059991  [  350/  698]\n",
      "loss: 0.023510  [  490/  698]\n",
      "loss: 0.085894  [  630/  698]\n",
      "Training Loss (Epoch): 0.037454\n",
      "Validating...\n",
      "Validation Loss: 0.776535, Validation Accuracy: 80.57%\n",
      "Epoch 23/25\n",
      "loss: 0.019260  [   70/  698]\n",
      "loss: 0.038702  [  210/  698]\n",
      "loss: 0.090182  [  350/  698]\n",
      "loss: 0.033062  [  490/  698]\n",
      "loss: 0.008551  [  630/  698]\n",
      "Training Loss (Epoch): 0.039539\n",
      "Validating...\n",
      "Validation Loss: 0.789797, Validation Accuracy: 80.00%\n",
      "Early stopping triggered. Training stopped.\n",
      "\n",
      "Cross-Validation Results:\n",
      "Avg Training Loss: 0.494705\n",
      "Avg Validation Loss: 0.970406\n",
      "Avg Validation Accuracy: 80.00%\n",
      "Testing combination: {'layer': 0, 'lr': 0.0003, 'weight_decay': 0.1, 'drop': 0.8, 'warmup_epochs': 3, 'total_epochs': 25, 'batch_size': 35}\n",
      "Processing Fold 1\n",
      "Epoch 1/25\n",
      "loss: 2.602622  [   35/  698]\n",
      "loss: 2.566953  [  175/  698]\n",
      "loss: 2.623257  [  315/  698]\n",
      "loss: 2.722848  [  455/  698]\n",
      "loss: 2.384184  [  595/  698]\n",
      "Training Loss (Epoch): 2.572142\n",
      "Validating...\n",
      "Validation Loss: 2.389176, Validation Accuracy: 10.86%\n",
      "Epoch 2/25\n",
      "loss: 2.227701  [   35/  698]\n",
      "loss: 2.004493  [  175/  698]\n",
      "loss: 1.860802  [  315/  698]\n",
      "loss: 2.244330  [  455/  698]\n",
      "loss: 1.696228  [  595/  698]\n",
      "Training Loss (Epoch): 2.005998\n",
      "Validating...\n",
      "Validation Loss: 1.662521, Validation Accuracy: 38.86%\n",
      "Epoch 3/25\n",
      "loss: 1.598664  [   35/  698]\n",
      "loss: 1.345879  [  175/  698]\n",
      "loss: 1.440797  [  315/  698]\n",
      "loss: 0.995799  [  455/  698]\n",
      "loss: 1.218507  [  595/  698]\n",
      "Training Loss (Epoch): 1.379512\n",
      "Validating...\n",
      "Validation Loss: 1.244932, Validation Accuracy: 53.14%\n",
      "Epoch 4/25\n",
      "loss: 0.783560  [   35/  698]\n",
      "loss: 1.859477  [  175/  698]\n",
      "loss: 0.982649  [  315/  698]\n",
      "loss: 0.856030  [  455/  698]\n",
      "loss: 0.704840  [  595/  698]\n",
      "Training Loss (Epoch): 1.041199\n",
      "Validating...\n",
      "Validation Loss: 1.133311, Validation Accuracy: 63.43%\n",
      "Epoch 5/25\n",
      "loss: 0.633926  [   35/  698]\n",
      "loss: 0.706665  [  175/  698]\n",
      "loss: 0.679967  [  315/  698]\n",
      "loss: 0.615237  [  455/  698]\n",
      "loss: 0.445653  [  595/  698]\n",
      "Training Loss (Epoch): 0.681851\n",
      "Validating...\n",
      "Validation Loss: 0.901649, Validation Accuracy: 70.29%\n",
      "Epoch 6/25\n",
      "loss: 0.376168  [   35/  698]\n",
      "loss: 0.372330  [  175/  698]\n",
      "loss: 0.463074  [  315/  698]\n",
      "loss: 0.382615  [  455/  698]\n",
      "loss: 0.383931  [  595/  698]\n",
      "Training Loss (Epoch): 0.367005\n",
      "Validating...\n",
      "Validation Loss: 0.934211, Validation Accuracy: 67.43%\n",
      "Epoch 7/25\n",
      "loss: 0.218709  [   35/  698]\n",
      "loss: 0.353199  [  175/  698]\n",
      "loss: 0.275849  [  315/  698]\n",
      "loss: 0.263757  [  455/  698]\n",
      "loss: 0.170018  [  595/  698]\n",
      "Training Loss (Epoch): 0.231813\n",
      "Validating...\n",
      "Validation Loss: 0.863961, Validation Accuracy: 74.29%\n",
      "Epoch 8/25\n",
      "loss: 0.156697  [   35/  698]\n",
      "loss: 0.050392  [  175/  698]\n",
      "loss: 0.093162  [  315/  698]\n",
      "loss: 0.232579  [  455/  698]\n",
      "loss: 0.120436  [  595/  698]\n",
      "Training Loss (Epoch): 0.122467\n",
      "Validating...\n",
      "Validation Loss: 0.831996, Validation Accuracy: 74.29%\n",
      "Epoch 9/25\n",
      "loss: 0.056310  [   35/  698]\n",
      "loss: 0.176131  [  175/  698]\n",
      "loss: 0.109145  [  315/  698]\n",
      "loss: 0.135522  [  455/  698]\n",
      "loss: 0.225801  [  595/  698]\n",
      "Training Loss (Epoch): 0.091462\n",
      "Validating...\n",
      "Validation Loss: 0.819330, Validation Accuracy: 76.00%\n",
      "Epoch 10/25\n",
      "loss: 0.056950  [   35/  698]\n",
      "loss: 0.065529  [  175/  698]\n",
      "loss: 0.040967  [  315/  698]\n",
      "loss: 0.047645  [  455/  698]\n",
      "loss: 0.120605  [  595/  698]\n",
      "Training Loss (Epoch): 0.091284\n",
      "Validating...\n",
      "Validation Loss: 0.781621, Validation Accuracy: 78.86%\n",
      "Epoch 11/25\n",
      "loss: 0.023055  [   35/  698]\n",
      "loss: 0.161232  [  175/  698]\n",
      "loss: 0.112996  [  315/  698]\n",
      "loss: 0.073143  [  455/  698]\n",
      "loss: 0.079721  [  595/  698]\n",
      "Training Loss (Epoch): 0.091116\n",
      "Validating...\n",
      "Validation Loss: 0.893649, Validation Accuracy: 73.14%\n",
      "Epoch 12/25\n",
      "loss: 0.150368  [   35/  698]\n",
      "loss: 0.041827  [  175/  698]\n",
      "loss: 0.093509  [  315/  698]\n",
      "loss: 0.046031  [  455/  698]\n",
      "loss: 0.075570  [  595/  698]\n",
      "Training Loss (Epoch): 0.100465\n",
      "Validating...\n",
      "Validation Loss: 1.058012, Validation Accuracy: 72.00%\n",
      "Epoch 13/25\n",
      "loss: 0.225257  [   35/  698]\n",
      "loss: 0.147189  [  175/  698]\n",
      "loss: 0.037798  [  315/  698]\n",
      "loss: 0.066430  [  455/  698]\n",
      "loss: 0.064379  [  595/  698]\n",
      "Training Loss (Epoch): 0.093144\n",
      "Validating...\n",
      "Validation Loss: 0.919543, Validation Accuracy: 73.71%\n",
      "Epoch 14/25\n",
      "loss: 0.030095  [   35/  698]\n",
      "loss: 0.008292  [  175/  698]\n",
      "loss: 0.021545  [  315/  698]\n",
      "loss: 0.031804  [  455/  698]\n",
      "loss: 0.130602  [  595/  698]\n",
      "Training Loss (Epoch): 0.172123\n",
      "Validating...\n",
      "Validation Loss: 0.769748, Validation Accuracy: 77.14%\n",
      "Epoch 15/25\n",
      "loss: 0.037164  [   35/  698]\n",
      "loss: 0.102145  [  175/  698]\n",
      "loss: 0.167448  [  315/  698]\n",
      "loss: 0.216197  [  455/  698]\n",
      "loss: 0.148708  [  595/  698]\n",
      "Training Loss (Epoch): 0.145478\n",
      "Validating...\n",
      "Validation Loss: 0.958676, Validation Accuracy: 72.00%\n",
      "Epoch 16/25\n",
      "loss: 0.045768  [   35/  698]\n",
      "loss: 0.091686  [  175/  698]\n",
      "loss: 0.067928  [  315/  698]\n",
      "loss: 0.117552  [  455/  698]\n",
      "loss: 0.076407  [  595/  698]\n",
      "Training Loss (Epoch): 0.077297\n",
      "Validating...\n",
      "Validation Loss: 0.804655, Validation Accuracy: 76.57%\n",
      "Epoch 17/25\n",
      "loss: 0.132706  [   35/  698]\n",
      "loss: 0.012609  [  175/  698]\n",
      "loss: 0.023095  [  315/  698]\n",
      "loss: 0.139858  [  455/  698]\n",
      "loss: 0.024442  [  595/  698]\n",
      "Training Loss (Epoch): 0.049297\n",
      "Validating...\n",
      "Validation Loss: 0.805962, Validation Accuracy: 76.00%\n",
      "Epoch 18/25\n",
      "loss: 0.039525  [   35/  698]\n",
      "loss: 0.021643  [  175/  698]\n",
      "loss: 0.089213  [  315/  698]\n",
      "loss: 0.058827  [  455/  698]\n",
      "loss: 0.022078  [  595/  698]\n",
      "Training Loss (Epoch): 0.044946\n",
      "Validating...\n",
      "Validation Loss: 0.840218, Validation Accuracy: 74.86%\n",
      "Epoch 19/25\n",
      "loss: 0.039714  [   35/  698]\n",
      "loss: 0.033159  [  175/  698]\n",
      "loss: 0.006080  [  315/  698]\n",
      "loss: 0.235923  [  455/  698]\n",
      "loss: 0.002903  [  595/  698]\n",
      "Training Loss (Epoch): 0.049443\n",
      "Validating...\n",
      "Validation Loss: 0.814771, Validation Accuracy: 79.43%\n",
      "Epoch 20/25\n",
      "loss: 0.024490  [   35/  698]\n",
      "loss: 0.025955  [  175/  698]\n",
      "loss: 0.032884  [  315/  698]\n",
      "loss: 0.015438  [  455/  698]\n",
      "loss: 0.174811  [  595/  698]\n",
      "Training Loss (Epoch): 0.044505\n",
      "Validating...\n",
      "Validation Loss: 0.790072, Validation Accuracy: 79.43%\n",
      "Early stopping triggered. Training stopped.\n",
      "\n",
      "Cross-Validation Results:\n",
      "Avg Training Loss: 0.472627\n",
      "Avg Validation Loss: 1.010901\n",
      "Avg Validation Accuracy: 79.43%\n",
      "Testing combination: {'layer': 0, 'lr': 0.0003, 'weight_decay': 0.1, 'drop': 0.8, 'warmup_epochs': 5, 'total_epochs': 25, 'batch_size': 70}\n",
      "Processing Fold 1\n",
      "Epoch 1/25\n",
      "loss: 2.531940  [   70/  698]\n",
      "loss: 2.543593  [  210/  698]\n",
      "loss: 2.527890  [  350/  698]\n",
      "loss: 2.537947  [  490/  698]\n",
      "loss: 2.460474  [  630/  698]\n",
      "Training Loss (Epoch): 2.571000\n",
      "Validating...\n",
      "Validation Loss: 2.409121, Validation Accuracy: 12.00%\n",
      "Epoch 2/25\n",
      "loss: 2.297287  [   70/  698]\n",
      "loss: 2.022495  [  210/  698]\n",
      "loss: 1.972282  [  350/  698]\n",
      "loss: 2.131267  [  490/  698]\n",
      "loss: 1.907844  [  630/  698]\n",
      "Training Loss (Epoch): 2.058504\n",
      "Validating...\n",
      "Validation Loss: 1.827170, Validation Accuracy: 37.14%\n",
      "Epoch 3/25\n",
      "loss: 1.877462  [   70/  698]\n",
      "loss: 1.506540  [  210/  698]\n",
      "loss: 1.509891  [  350/  698]\n",
      "loss: 1.218850  [  490/  698]\n",
      "loss: 1.076706  [  630/  698]\n",
      "Training Loss (Epoch): 1.426920\n",
      "Validating...\n",
      "Validation Loss: 1.181177, Validation Accuracy: 58.29%\n",
      "Epoch 4/25\n",
      "loss: 0.930467  [   70/  698]\n",
      "loss: 0.855023  [  210/  698]\n",
      "loss: 0.722002  [  350/  698]\n",
      "loss: 0.708148  [  490/  698]\n",
      "loss: 0.608660  [  630/  698]\n",
      "Training Loss (Epoch): 0.754883\n",
      "Validating...\n",
      "Validation Loss: 0.626534, Validation Accuracy: 81.14%\n",
      "Epoch 5/25\n",
      "loss: 0.386175  [   70/  698]\n",
      "loss: 0.438811  [  210/  698]\n",
      "loss: 0.348976  [  350/  698]\n",
      "loss: 0.301077  [  490/  698]\n",
      "loss: 0.439182  [  630/  698]\n",
      "Training Loss (Epoch): 0.404072\n",
      "Validating...\n",
      "Validation Loss: 0.498586, Validation Accuracy: 82.29%\n",
      "Epoch 6/25\n",
      "loss: 0.133416  [   70/  698]\n",
      "loss: 0.347852  [  210/  698]\n",
      "loss: 0.174082  [  350/  698]\n",
      "loss: 0.097414  [  490/  698]\n",
      "loss: 0.301908  [  630/  698]\n",
      "Training Loss (Epoch): 0.223401\n",
      "Validating...\n",
      "Validation Loss: 0.544663, Validation Accuracy: 82.29%\n",
      "Epoch 7/25\n",
      "loss: 0.084833  [   70/  698]\n",
      "loss: 0.129708  [  210/  698]\n",
      "loss: 0.050922  [  350/  698]\n",
      "loss: 0.144477  [  490/  698]\n",
      "loss: 0.741901  [  630/  698]\n",
      "Training Loss (Epoch): 0.236132\n",
      "Validating...\n",
      "Validation Loss: 0.775605, Validation Accuracy: 77.14%\n",
      "Epoch 8/25\n",
      "loss: 0.317409  [   70/  698]\n",
      "loss: 0.265933  [  210/  698]\n",
      "loss: 0.508736  [  350/  698]\n",
      "loss: 0.408878  [  490/  698]\n",
      "loss: 0.361373  [  630/  698]\n",
      "Training Loss (Epoch): 0.338691\n",
      "Validating...\n",
      "Validation Loss: 0.838255, Validation Accuracy: 72.00%\n",
      "Epoch 9/25\n",
      "loss: 0.250211  [   70/  698]\n",
      "loss: 0.373918  [  210/  698]\n",
      "loss: 0.201686  [  350/  698]\n",
      "loss: 0.179273  [  490/  698]\n",
      "loss: 0.147329  [  630/  698]\n",
      "Training Loss (Epoch): 0.183335\n",
      "Validating...\n",
      "Validation Loss: 0.669452, Validation Accuracy: 80.00%\n",
      "Epoch 10/25\n",
      "loss: 0.078867  [   70/  698]\n",
      "loss: 0.067178  [  210/  698]\n",
      "loss: 0.103358  [  350/  698]\n",
      "loss: 0.060336  [  490/  698]\n",
      "loss: 0.065795  [  630/  698]\n",
      "Training Loss (Epoch): 0.077054\n",
      "Validating...\n",
      "Validation Loss: 0.587472, Validation Accuracy: 81.71%\n",
      "Epoch 11/25\n",
      "loss: 0.076975  [   70/  698]\n",
      "loss: 0.014417  [  210/  698]\n",
      "loss: 0.067242  [  350/  698]\n",
      "loss: 0.069170  [  490/  698]\n",
      "loss: 0.046446  [  630/  698]\n",
      "Training Loss (Epoch): 0.076737\n",
      "Validating...\n",
      "Validation Loss: 0.828837, Validation Accuracy: 77.71%\n",
      "Early stopping triggered. Training stopped.\n",
      "\n",
      "Cross-Validation Results:\n",
      "Avg Training Loss: 0.759157\n",
      "Avg Validation Loss: 0.980625\n",
      "Avg Validation Accuracy: 77.71%\n",
      "Testing combination: {'layer': 0, 'lr': 0.0003, 'weight_decay': 0.1, 'drop': 0.8, 'warmup_epochs': 5, 'total_epochs': 25, 'batch_size': 35}\n",
      "Processing Fold 1\n",
      "Epoch 1/25\n",
      "loss: 2.602622  [   35/  698]\n",
      "loss: 2.566953  [  175/  698]\n",
      "loss: 2.623257  [  315/  698]\n",
      "loss: 2.722848  [  455/  698]\n",
      "loss: 2.384184  [  595/  698]\n",
      "Training Loss (Epoch): 2.572142\n",
      "Validating...\n",
      "Validation Loss: 2.389176, Validation Accuracy: 10.86%\n",
      "Epoch 2/25\n",
      "loss: 2.227701  [   35/  698]\n",
      "loss: 1.958786  [  175/  698]\n",
      "loss: 1.830366  [  315/  698]\n",
      "loss: 2.158857  [  455/  698]\n",
      "loss: 1.620185  [  595/  698]\n",
      "Training Loss (Epoch): 1.935038\n",
      "Validating...\n",
      "Validation Loss: 1.427981, Validation Accuracy: 57.14%\n",
      "Epoch 3/25\n",
      "loss: 1.420033  [   35/  698]\n",
      "loss: 1.114224  [  175/  698]\n",
      "loss: 1.042697  [  315/  698]\n",
      "loss: 0.628810  [  455/  698]\n",
      "loss: 0.605635  [  595/  698]\n",
      "Training Loss (Epoch): 0.991510\n",
      "Validating...\n",
      "Validation Loss: 0.850761, Validation Accuracy: 71.43%\n",
      "Epoch 4/25\n",
      "loss: 0.464364  [   35/  698]\n",
      "loss: 0.543527  [  175/  698]\n",
      "loss: 0.378153  [  315/  698]\n",
      "loss: 0.297828  [  455/  698]\n",
      "loss: 0.229829  [  595/  698]\n",
      "Training Loss (Epoch): 0.464166\n",
      "Validating...\n",
      "Validation Loss: 0.791124, Validation Accuracy: 71.43%\n",
      "Epoch 5/25\n",
      "loss: 0.358708  [   35/  698]\n",
      "loss: 0.417851  [  175/  698]\n",
      "loss: 0.313851  [  315/  698]\n",
      "loss: 0.519135  [  455/  698]\n",
      "loss: 0.337353  [  595/  698]\n",
      "Training Loss (Epoch): 0.415803\n",
      "Validating...\n",
      "Validation Loss: 0.868363, Validation Accuracy: 72.57%\n",
      "Epoch 6/25\n",
      "loss: 0.230304  [   35/  698]\n",
      "loss: 0.328141  [  175/  698]\n",
      "loss: 0.595449  [  315/  698]\n",
      "loss: 0.576307  [  455/  698]\n",
      "loss: 0.292277  [  595/  698]\n",
      "Training Loss (Epoch): 0.302847\n",
      "Validating...\n",
      "Validation Loss: 0.636918, Validation Accuracy: 74.86%\n",
      "Epoch 7/25\n",
      "loss: 0.176863  [   35/  698]\n",
      "loss: 0.039131  [  175/  698]\n",
      "loss: 0.146452  [  315/  698]\n",
      "loss: 0.454342  [  455/  698]\n",
      "loss: 0.504750  [  595/  698]\n",
      "Training Loss (Epoch): 0.260972\n",
      "Validating...\n",
      "Validation Loss: 0.970033, Validation Accuracy: 73.71%\n",
      "Epoch 8/25\n",
      "loss: 0.190630  [   35/  698]\n",
      "loss: 0.173138  [  175/  698]\n",
      "loss: 0.059108  [  315/  698]\n",
      "loss: 0.200073  [  455/  698]\n",
      "loss: 0.112112  [  595/  698]\n",
      "Training Loss (Epoch): 0.119642\n",
      "Validating...\n",
      "Validation Loss: 0.658214, Validation Accuracy: 78.29%\n",
      "Epoch 9/25\n",
      "loss: 0.123199  [   35/  698]\n",
      "loss: 0.242995  [  175/  698]\n",
      "loss: 0.022510  [  315/  698]\n",
      "loss: 0.076948  [  455/  698]\n",
      "loss: 0.124850  [  595/  698]\n",
      "Training Loss (Epoch): 0.074875\n",
      "Validating...\n",
      "Validation Loss: 1.051156, Validation Accuracy: 76.57%\n",
      "Epoch 10/25\n",
      "loss: 0.037104  [   35/  698]\n",
      "loss: 0.026231  [  175/  698]\n",
      "loss: 0.028769  [  315/  698]\n",
      "loss: 0.016094  [  455/  698]\n",
      "loss: 0.075197  [  595/  698]\n",
      "Training Loss (Epoch): 0.058582\n",
      "Validating...\n",
      "Validation Loss: 0.868737, Validation Accuracy: 74.29%\n",
      "Epoch 11/25\n",
      "loss: 0.022600  [   35/  698]\n",
      "loss: 0.006077  [  175/  698]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdense_grid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[62]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mdense_grid_search\u001b[39m\u001b[34m(param_grid)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTesting combination: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Call dense_tune with the current parameter combination\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m mean_train_loss, mean_val_loss, mean_val_accuracy = \u001b[43mdense_tune\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlayer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdrop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwarmup_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwarmup_epochs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtotal_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtotal_epochs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbatch_size\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfolds\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     26\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Store results\u001b[39;00m\n\u001b[32m     29\u001b[39m result = {\n\u001b[32m     30\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m: params,\n\u001b[32m     31\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m\"\u001b[39m: mean_train_loss,\n\u001b[32m     32\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m\"\u001b[39m: mean_val_loss,\n\u001b[32m     33\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mval_accuracy\u001b[39m\u001b[33m\"\u001b[39m: mean_val_accuracy\n\u001b[32m     34\u001b[39m }\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[61]\u001b[39m\u001b[32m, line 57\u001b[39m, in \u001b[36mdense_tune\u001b[39m\u001b[34m(layer, lr, weight_decay, weights, drop, SEED, warmup_epochs, total_epochs, batch_size, folds)\u001b[39m\n\u001b[32m     54\u001b[39m val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m, collate_fn=custom_collate_fn)\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# Train and validate (over multiple epochs per fold)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m epoch_train_losses, epoch_val_losses, epoch_val_accuracies, early_stop_epoch = \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler_warmup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscheduler_main\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_epochs\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# # Aggregate metrics up to the stopping epoch\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# if early_stop_epoch is not None:\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m#     print(early_stop_epoch+1)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# print(epoch_val_losses)\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# print(epoch_val_accuracies)\u001b[39;00m\n\u001b[32m     78\u001b[39m fold_train_losses.append(\u001b[38;5;28msum\u001b[39m(epoch_train_losses) / \u001b[38;5;28mlen\u001b[39m(epoch_train_losses))  \u001b[38;5;66;03m# Mean of training losses\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mtrain_loop\u001b[39m\u001b[34m(train_dataloader, val_dataloader, model, loss_fn, optimizer, scheduler_warmup, scheduler_main, epochs, warmup_epochs, patience)\u001b[39m\n\u001b[32m     20\u001b[39m size = \u001b[38;5;28mlen\u001b[39m(train_dataloader.dataset)\n\u001b[32m     21\u001b[39m total_loss = \u001b[32m0\u001b[39m  \u001b[38;5;66;03m# Initialize variable to accumulate training loss\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Compute prediction and loss\u001b[39;49;00m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_collation:\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataset, \u001b[33m\"\u001b[39m\u001b[33m__getitems__\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__:\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     52\u001b[39m         data = [\u001b[38;5;28mself\u001b[39m.dataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/utils/data/dataset.py:420\u001b[39m, in \u001b[36mSubset.__getitems__\u001b[39m\u001b[34m(self, indices)\u001b[39m\n\u001b[32m    418\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__([\u001b[38;5;28mself\u001b[39m.indices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/utils/data/dataset.py:420\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    418\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__([\u001b[38;5;28mself\u001b[39m.indices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mUrbanSoundDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Apply transformations\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     waveform = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaveform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Extract the file name from the path\u001b[39;00m\n\u001b[32m     40\u001b[39m file_name = os.path.basename(file_path)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mtransform_pipeline\u001b[39m\u001b[34m(waveform)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtransform_pipeline\u001b[39m(waveform):\n\u001b[32m     13\u001b[39m     waveform = augment_waveform(waveform)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     spectrogram = \u001b[43mwaveform_to_spectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaveform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# spectrogram = augment_spectrogram(spectrogram)\u001b[39;00m\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m spectrogram\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torchaudio/transforms/_transforms.py:619\u001b[39m, in \u001b[36mMelSpectrogram.forward\u001b[39m\u001b[34m(self, waveform)\u001b[39m\n\u001b[32m    611\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, waveform: Tensor) -> Tensor:\n\u001b[32m    612\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    613\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    614\u001b[39m \u001b[33;03m        waveform (Tensor): Tensor of audio of dimension (..., time).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    617\u001b[39m \u001b[33;03m        Tensor: Mel frequency spectrogram of size (..., ``n_mels``, time).\u001b[39;00m\n\u001b[32m    618\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m     specgram = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mspectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaveform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    620\u001b[39m     mel_specgram = \u001b[38;5;28mself\u001b[39m.mel_scale(specgram)\n\u001b[32m    621\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m mel_specgram\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torchaudio/transforms/_transforms.py:110\u001b[39m, in \u001b[36mSpectrogram.forward\u001b[39m\u001b[34m(self, waveform)\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, waveform: Tensor) -> Tensor:\n\u001b[32m    101\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[33;03m        waveform (Tensor): Tensor of audio of dimension (..., time).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    108\u001b[39m \u001b[33;03m        Fourier bins, and time is the number of window hops (n_frame).\u001b[39;00m\n\u001b[32m    109\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mspectrogram\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwaveform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhop_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwin_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpower\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnormalized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpad_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43monesided\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torchaudio/functional/functional.py:126\u001b[39m, in \u001b[36mspectrogram\u001b[39m\u001b[34m(waveform, pad, window, n_fft, hop_length, win_length, power, normalized, center, pad_mode, onesided, return_complex)\u001b[39m\n\u001b[32m    123\u001b[39m waveform = waveform.reshape(-\u001b[32m1\u001b[39m, shape[-\u001b[32m1\u001b[39m])\n\u001b[32m    125\u001b[39m \u001b[38;5;66;03m# default values are consistent with librosa.core.spectrum._spectrogram\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m spec_f = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstft\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mwaveform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhop_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwin_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwin_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpad_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnormalized\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframe_length_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43monesided\u001b[49m\u001b[43m=\u001b[49m\u001b[43monesided\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[38;5;66;03m# unpack batch\u001b[39;00m\n\u001b[32m    140\u001b[39m spec_f = spec_f.reshape(shape[:-\u001b[32m1\u001b[39m] + spec_f.shape[-\u001b[32m2\u001b[39m:])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/functional.py:709\u001b[39m, in \u001b[36mstft\u001b[39m\u001b[34m(input, n_fft, hop_length, win_length, window, center, pad_mode, normalized, onesided, return_complex)\u001b[39m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28minput\u001b[39m = F.pad(\u001b[38;5;28minput\u001b[39m.view(extended_shape), [pad, pad], pad_mode)\n\u001b[32m    708\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28minput\u001b[39m.view(\u001b[38;5;28minput\u001b[39m.shape[-signal_dim:])\n\u001b[32m--> \u001b[39m\u001b[32m709\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstft\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m    710\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    711\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    712\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    713\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwin_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    714\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    715\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnormalized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    716\u001b[39m \u001b[43m    \u001b[49m\u001b[43monesided\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "dense_grid_search(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1\n",
      "Epoch 1/20\n",
      "loss: 2.531940  [   70/  698]\n",
      "loss: 2.543593  [  210/  698]\n",
      "loss: 2.527890  [  350/  698]\n",
      "loss: 2.537947  [  490/  698]\n",
      "loss: 2.460474  [  630/  698]\n",
      "Training Loss (Epoch): 2.571000\n",
      "Validating...\n",
      "Validation Loss: 2.409121, Validation Accuracy: 12.00%\n",
      "Epoch 2/20\n",
      "loss: 2.297287  [   70/  698]\n",
      "loss: 2.088383  [  210/  698]\n",
      "loss: 2.001848  [  350/  698]\n",
      "loss: 2.230670  [  490/  698]\n",
      "loss: 2.013240  [  630/  698]\n",
      "Training Loss (Epoch): 2.116037\n",
      "Validating...\n",
      "Validation Loss: 1.963075, Validation Accuracy: 24.00%\n",
      "Epoch 3/20\n",
      "loss: 2.030062  [   70/  698]\n",
      "loss: 1.769564  [  210/  698]\n",
      "loss: 1.819320  [  350/  698]\n",
      "loss: 1.516873  [  490/  698]\n",
      "loss: 1.633342  [  630/  698]\n",
      "Training Loss (Epoch): 1.747023\n",
      "Validating...\n",
      "Validation Loss: 1.711125, Validation Accuracy: 32.57%\n",
      "Epoch 4/20\n",
      "loss: 1.482898  [   70/  698]\n",
      "loss: 1.500882  [  210/  698]\n",
      "loss: 1.427355  [  350/  698]\n",
      "loss: 1.187610  [  490/  698]\n",
      "loss: 1.339155  [  630/  698]\n",
      "Training Loss (Epoch): 1.357226\n",
      "Validating...\n",
      "Validation Loss: 1.205356, Validation Accuracy: 54.86%\n",
      "Epoch 5/20\n",
      "loss: 1.054865  [   70/  698]\n",
      "loss: 1.096589  [  210/  698]\n",
      "loss: 1.037555  [  350/  698]\n",
      "loss: 0.744355  [  490/  698]\n",
      "loss: 1.048730  [  630/  698]\n",
      "Training Loss (Epoch): 0.971771\n",
      "Validating...\n",
      "Validation Loss: 0.974086, Validation Accuracy: 65.14%\n",
      "Epoch 6/20\n",
      "loss: 0.560321  [   70/  698]\n",
      "loss: 0.875344  [  210/  698]\n",
      "loss: 0.559968  [  350/  698]\n",
      "loss: 0.568778  [  490/  698]\n",
      "loss: 0.559251  [  630/  698]\n",
      "Training Loss (Epoch): 0.648471\n",
      "Validating...\n",
      "Validation Loss: 0.842832, Validation Accuracy: 72.57%\n",
      "Epoch 7/20\n",
      "loss: 0.359805  [   70/  698]\n",
      "loss: 0.546815  [  210/  698]\n",
      "loss: 0.576023  [  350/  698]\n",
      "loss: 0.567309  [  490/  698]\n",
      "loss: 0.363489  [  630/  698]\n",
      "Training Loss (Epoch): 0.444936\n",
      "Validating...\n",
      "Validation Loss: 0.829823, Validation Accuracy: 74.29%\n",
      "Epoch 8/20\n",
      "loss: 0.302897  [   70/  698]\n",
      "loss: 0.168746  [  210/  698]\n",
      "loss: 0.271511  [  350/  698]\n",
      "loss: 0.351615  [  490/  698]\n",
      "loss: 0.260309  [  630/  698]\n",
      "Training Loss (Epoch): 0.303115\n",
      "Validating...\n",
      "Validation Loss: 0.806635, Validation Accuracy: 75.43%\n",
      "Epoch 9/20\n",
      "loss: 0.251675  [   70/  698]\n",
      "loss: 0.261909  [  210/  698]\n",
      "loss: 0.206478  [  350/  698]\n",
      "loss: 0.210559  [  490/  698]\n",
      "loss: 0.314573  [  630/  698]\n",
      "Training Loss (Epoch): 0.221777\n",
      "Validating...\n",
      "Validation Loss: 0.792575, Validation Accuracy: 75.43%\n",
      "Epoch 10/20\n",
      "loss: 0.148325  [   70/  698]\n",
      "loss: 0.150734  [  210/  698]\n",
      "loss: 0.159595  [  350/  698]\n",
      "loss: 0.091529  [  490/  698]\n",
      "loss: 0.429945  [  630/  698]\n",
      "Training Loss (Epoch): 0.189403\n",
      "Validating...\n",
      "Validation Loss: 0.814008, Validation Accuracy: 76.00%\n",
      "Epoch 11/20\n",
      "loss: 0.190078  [   70/  698]\n",
      "loss: 0.070746  [  210/  698]\n",
      "loss: 0.206171  [  350/  698]\n",
      "loss: 0.093302  [  490/  698]\n",
      "loss: 0.237918  [  630/  698]\n",
      "Training Loss (Epoch): 0.143171\n",
      "Validating...\n",
      "Validation Loss: 0.706940, Validation Accuracy: 78.29%\n",
      "Epoch 12/20\n",
      "loss: 0.173534  [   70/  698]\n",
      "loss: 0.055608  [  210/  698]\n",
      "loss: 0.095934  [  350/  698]\n",
      "loss: 0.120541  [  490/  698]\n",
      "loss: 0.124452  [  630/  698]\n",
      "Training Loss (Epoch): 0.106997\n",
      "Validating...\n",
      "Validation Loss: 0.742828, Validation Accuracy: 77.14%\n",
      "Epoch 13/20\n",
      "loss: 0.111574  [   70/  698]\n",
      "loss: 0.093672  [  210/  698]\n",
      "loss: 0.078060  [  350/  698]\n",
      "loss: 0.075699  [  490/  698]\n",
      "loss: 0.068215  [  630/  698]\n",
      "Training Loss (Epoch): 0.082374\n",
      "Validating...\n",
      "Validation Loss: 0.686305, Validation Accuracy: 80.57%\n",
      "Epoch 14/20\n",
      "loss: 0.084445  [   70/  698]\n",
      "loss: 0.031935  [  210/  698]\n",
      "loss: 0.026466  [  350/  698]\n",
      "loss: 0.104614  [  490/  698]\n",
      "loss: 0.100257  [  630/  698]\n",
      "Training Loss (Epoch): 0.065063\n",
      "Validating...\n",
      "Validation Loss: 0.715027, Validation Accuracy: 81.71%\n",
      "Epoch 15/20\n",
      "loss: 0.030393  [   70/  698]\n",
      "loss: 0.035860  [  210/  698]\n",
      "loss: 0.062405  [  350/  698]\n",
      "loss: 0.121987  [  490/  698]\n",
      "loss: 0.158389  [  630/  698]\n",
      "Training Loss (Epoch): 0.073145\n",
      "Validating...\n",
      "Validation Loss: 0.801565, Validation Accuracy: 78.29%\n",
      "Epoch 16/20\n",
      "loss: 0.110274  [   70/  698]\n",
      "loss: 0.103829  [  210/  698]\n",
      "loss: 0.057251  [  350/  698]\n",
      "loss: 0.063646  [  490/  698]\n",
      "loss: 0.065733  [  630/  698]\n",
      "Training Loss (Epoch): 0.073043\n",
      "Validating...\n",
      "Validation Loss: 0.795933, Validation Accuracy: 76.57%\n",
      "Early stopping triggered. Training stopped.\n",
      "[2.5710001468658445, 2.116037154197693, 1.7470226287841797, 1.3572259545326233, 0.9717705309391022, 0.6484713077545166, 0.4449359327554703, 0.3031148687005043, 0.22177695780992507, 0.18940347358584403, 0.1431711558252573, 0.10699676349759102, 0.0823744885623455, 0.06506294496357441, 0.0731445400044322, 0.07304325141012669]\n",
      "[2.4091214338938394, 1.9630751212437947, 1.711125135421753, 1.2053561409314473, 0.9740855892499288, 0.8428319295247396, 0.829822838306427, 0.8066352009773254, 0.7925751407941183, 0.8140081961949667, 0.7069396376609802, 0.7428282300631205, 0.6863048473993937, 0.7150267163912455, 0.8015649120012919, 0.7959333658218384]\n",
      "[0.12, 0.24, 0.32571428571428573, 0.5485714285714286, 0.6514285714285715, 0.7257142857142858, 0.7428571428571429, 0.7542857142857143, 0.7542857142857143, 0.76, 0.7828571428571428, 0.7714285714285715, 0.8057142857142857, 0.8171428571428572, 0.7828571428571428, 0.7657142857142857]\n",
      "Processing Fold 2\n",
      "Epoch 1/20\n",
      "loss: 2.499060  [   70/  710]\n",
      "loss: 2.694121  [  210/  710]\n",
      "loss: 2.444147  [  350/  710]\n",
      "loss: 2.723069  [  490/  710]\n",
      "loss: 2.611161  [  630/  710]\n",
      "loss: 2.809653  [  110/  710]\n",
      "Training Loss (Epoch): 2.592649\n",
      "Validating...\n",
      "Validation Loss: 2.338950, Validation Accuracy: 9.55%\n",
      "Epoch 2/20\n",
      "loss: 2.314924  [   70/  710]\n",
      "loss: 2.155209  [  210/  710]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdense_tune\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDEFAULT\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.8\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 58\u001b[39m, in \u001b[36mdense_tune\u001b[39m\u001b[34m(layer, lr, weight_decay, weights, drop, SEED, warmup_epochs, total_epochs)\u001b[39m\n\u001b[32m     55\u001b[39m val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m, collate_fn=custom_collate_fn)\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# Train and validate (over multiple epochs per fold)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m epoch_train_losses, epoch_val_losses, epoch_val_accuracies, early_stop_epoch = \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler_warmup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscheduler_main\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_epochs\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# # Aggregate metrics up to the stopping epoch\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# if early_stop_epoch is not None:\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m#     print(early_stop_epoch+1)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     74\u001b[39m \n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# Aggregate fold-level metrics (e.g., mean across all epochs)\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28mprint\u001b[39m(epoch_train_losses)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mtrain_loop\u001b[39m\u001b[34m(train_dataloader, val_dataloader, model, loss_fn, optimizer, scheduler_warmup, scheduler_main, epochs, warmup_epochs)\u001b[39m\n\u001b[32m     20\u001b[39m size = \u001b[38;5;28mlen\u001b[39m(train_dataloader.dataset)\n\u001b[32m     21\u001b[39m total_loss = \u001b[32m0\u001b[39m  \u001b[38;5;66;03m# Initialize variable to accumulate training loss\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Compute prediction and loss\u001b[39;49;00m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_collation:\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataset, \u001b[33m\"\u001b[39m\u001b[33m__getitems__\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__:\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     52\u001b[39m         data = [\u001b[38;5;28mself\u001b[39m.dataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/utils/data/dataset.py:420\u001b[39m, in \u001b[36mSubset.__getitems__\u001b[39m\u001b[34m(self, indices)\u001b[39m\n\u001b[32m    418\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__([\u001b[38;5;28mself\u001b[39m.indices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/utils/data/dataset.py:420\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    418\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__([\u001b[38;5;28mself\u001b[39m.indices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mUrbanSoundDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[32m     27\u001b[39m     \u001b[38;5;66;03m# Load the audio file\u001b[39;00m\n\u001b[32m     28\u001b[39m     file_path = \u001b[38;5;28mself\u001b[39m.file_list[idx]\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     waveform, sample_rate = \u001b[43mtorchaudio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     \u001b[38;5;66;03m# Convert mono to stereo if necessary\u001b[39;00m\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m waveform.size(\u001b[32m0\u001b[39m) == \u001b[32m1\u001b[39m:  \u001b[38;5;66;03m# If mono\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torchaudio/_backend/utils.py:205\u001b[39m, in \u001b[36mget_load_func.<locals>.load\u001b[39m\u001b[34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size, backend)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Load audio data from source.\u001b[39;00m\n\u001b[32m    129\u001b[39m \n\u001b[32m    130\u001b[39m \u001b[33;03mBy default (``normalize=True``, ``channels_first=True``), this function returns Tensor with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    202\u001b[39m \u001b[33;03m        `[channel, time]` else `[time, channel]`.\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    204\u001b[39m backend = dispatcher(uri, \u001b[38;5;28mformat\u001b[39m, backend)\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torchaudio/_backend/ffmpeg.py:297\u001b[39m, in \u001b[36mFFmpegBackend.load\u001b[39m\u001b[34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\n\u001b[32m    289\u001b[39m     uri: InputType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    295\u001b[39m     buffer_size: \u001b[38;5;28mint\u001b[39m = \u001b[32m4096\u001b[39m,\n\u001b[32m    296\u001b[39m ) -> Tuple[torch.Tensor, \u001b[38;5;28mint\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torchaudio/_backend/ffmpeg.py:91\u001b[39m, in \u001b[36mload_audio\u001b[39m\u001b[34m(src, frame_offset, num_frames, convert, channels_first, format, buffer_size)\u001b[39m\n\u001b[32m     89\u001b[39m sample_rate = \u001b[38;5;28mint\u001b[39m(s.get_src_stream_info(s.default_audio_stream).sample_rate)\n\u001b[32m     90\u001b[39m \u001b[38;5;28mfilter\u001b[39m = _get_load_filter(frame_offset, num_frames, convert)\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m waveform = \u001b[43m_load_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m waveform, sample_rate\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torchaudio/_backend/ffmpeg.py:70\u001b[39m, in \u001b[36m_load_audio\u001b[39m\u001b[34m(s, filter, channels_first)\u001b[39m\n\u001b[32m     68\u001b[39m s.add_audio_stream(-\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m, filter_desc=\u001b[38;5;28mfilter\u001b[39m)\n\u001b[32m     69\u001b[39m s.process_all_packets()\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m chunk = \u001b[43ms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunk \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mFailed to decode audio.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torio/io/_streaming_media_decoder.py:916\u001b[39m, in \u001b[36mStreamingMediaDecoder.pop_chunks\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    908\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Pop one chunk from all the output stream buffers.\u001b[39;00m\n\u001b[32m    909\u001b[39m \n\u001b[32m    910\u001b[39m \u001b[33;03mReturns:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    913\u001b[39m \u001b[33;03m        If a buffer does not contain any frame, then `None` is returned instead.\u001b[39;00m\n\u001b[32m    914\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    915\u001b[39m ret = []\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_be\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    917\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m chunk \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    918\u001b[39m         ret.append(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "dense_tune(layer = 0, lr = 3e-4, weight_decay = 0.05, weights = \"DEFAULT\", drop = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dense_tune(layer = 1, lr = 3e-4, weight_decay = 0.05, weights = \"DEFAULT\", drop = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dense_tune(layer = 2, lr = 3e-4, weight_decay = 0.05, weights = \"DEFAULT\", drop = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dense_tune(layer = 3, lr = 3e-4, weight_decay = 0.05, weights = \"DEFAULT\", drop = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dense_tune(layer = 0, lr = 3e-4, weight_decay = 0.05, weights = None, drop = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_tune(layer = 0, lr = 3e-4, weight_decay = 0.05, weights = None, drop = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchaudio\n",
    "\n",
    "# audio_path = \"./UrbanSound8k/audio/fold1/137156-9-0-30.wav\"\n",
    "# waveform, sample_rate = torchaudio.load(audio_path)\n",
    "# print(f\"Shape: {waveform.shape}, Sample Rate: {sample_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_stereogram(spectrogram):\n",
    "    # Convert to numpy\n",
    "    spectrogram_np = spectrogram.numpy()  # Shape: (2, Freq, Time)\n",
    "\n",
    "    # Plot left and right channels\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(6, 6), constrained_layout=True)\n",
    "\n",
    "    axs[0].imshow(spectrogram_np[0], aspect='auto', origin='lower', cmap='magma')\n",
    "    axs[0].set_title(f\"Spectrogram {i+1} - Left Channel\")\n",
    "    axs[0].set_ylabel(\"Frequency Bins\")\n",
    "    axs[0].set_xlabel(\"Time Frames\")\n",
    "\n",
    "    axs[1].imshow(spectrogram_np[1], aspect='auto', origin='lower', cmap='magma')\n",
    "    axs[1].set_title(f\"Spectrogram {i+1} - Right Channel\")\n",
    "    axs[1].set_ylabel(\"Frequency Bins\")\n",
    "    axs[1].set_xlabel(\"Time Frames\")\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "urbad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
