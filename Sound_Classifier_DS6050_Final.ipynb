{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "mBSFTJ5M_z-H"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n",
    "from torch.cuda import manual_seed_all\n",
    "from torch import manual_seed as torch_manual_seed\n",
    "from torch.backends import cudnn\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "3uDKfjRHMuxk"
   },
   "outputs": [],
   "source": [
    "# pre spectrogram augmentations\n",
    "# these are examples and can be changed based on domain knowledge\n",
    "\n",
    "def stretch_waveform(waveform, rate=1.2):\n",
    "    time_stretch = T.TimeStretch()\n",
    "    # `rate > 1.0` speeds up, `rate < 1.0` slows down\n",
    "    return time_stretch(waveform, rate)\n",
    "\n",
    "def shift_pitch(waveform, sample_rate=44100, n_steps = 2):\n",
    "    pitch_shift = T.PitchShift(sample_rate, n_steps)  # Shift up by 2 semitones\n",
    "    return pitch_shift(waveform)\n",
    "\n",
    "def scale_volume(waveform, factor = None):\n",
    "    if factor is None:\n",
    "        waveform *= torch.FloatTensor(1).uniform_(0.8, 1.5).item()  # Amplifies waveform by random factor\n",
    "    else:\n",
    "        waveform *= factor\n",
    "    return waveform\n",
    "\n",
    "def crop_waveform(waveform, crop_size):\n",
    "    start = torch.randint(0, max(1, waveform.size(-1) - crop_size), (1,)).item()\n",
    "    return waveform[:, start:start + crop_size]\n",
    "\n",
    "def apply_reverb(waveform):\n",
    "    reverb = T.Reverberate()\n",
    "    return reverb(waveform)\n",
    "\n",
    "def time_shift(waveform, shift):\n",
    "    return torch.roll(waveform, shifts=shift, dims=-1)\n",
    "\n",
    "def add_noise(waveform, noise_level=0.005):\n",
    "    noise = torch.randn_like(waveform) * noise_level\n",
    "    return waveform + noise\n",
    "\n",
    "# Augment on-the-fly stochastically\n",
    "# again these are just examples and do not necessarily utilize the methods above\n",
    "def augment_waveform(data):\n",
    "    waveform, sample_rate = data\n",
    "    if torch.rand(1).item() > 0.9:\n",
    "        waveform = add_noise(waveform)\n",
    "    if torch.rand(1).item() > 0.9:\n",
    "        waveform = time_shift(waveform, shifts=torch.randint(-waveform.size(-1) // 2, waveform.size(-1) // 2, (1,)).item())\n",
    "    if torch.rand(1).item() > 0.9:\n",
    "        waveform = scale_volume(waveform)\n",
    "    if torch.rand(1).item() > 0.9:\n",
    "        waveform = apply_reverb(waveform)\n",
    "    if torch.rand(1).item() > 0.9:\n",
    "        waveform = shift_pitch(waveform, sample_rate, n_steps= torch.randint(-12, 12, (1,)).item())\n",
    "    if torch.rand(1).item() > 0.9:\n",
    "        waveform = stretch_waveform(waveform, rate= torch.FloatTensor(1).uniform_(0.5, 1.5).item())\n",
    "    return waveform, sample_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Ww8OMV8nNZcf"
   },
   "outputs": [],
   "source": [
    "# Create a MelSpectrogram transformation\n",
    "mel_spectrogram_transform = T.MelSpectrogram(\n",
    "    sample_rate=44100,         # Default sample rate, change if needed\n",
    "    n_fft=1024,                # Number of FFT bins\n",
    "    hop_length=512,            # Hop length between windows\n",
    "    n_mels=64                  # Number of Mel bands\n",
    ")\n",
    "\n",
    "def waveform_to_spectrogram(data):\n",
    "    waveform, sample_rate = data\n",
    "    spectrogram = mel_spectrogram_transform(waveform)  # Apply the spectrogram transformation\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "khV1u_wUIR-o"
   },
   "outputs": [],
   "source": [
    "# post spectrogram augmentations\n",
    "\n",
    "# Example augmentations, could add more\n",
    "time_mask = T.TimeMasking(time_mask_param=10)\n",
    "\n",
    "freq_mask = T.FrequencyMasking(freq_mask_param=8)\n",
    "\n",
    "# hybridizes two sounds\n",
    "def mixup(spectrogram1, spectrogram2, alpha=0.2):\n",
    "    lam = torch.FloatTensor(1).uniform_(0, alpha).item()\n",
    "    return lam * spectrogram1 + (1 - lam) * spectrogram2\n",
    "\n",
    "# should probably implement a randomization process like above\n",
    "def augment_spectrogram(spectrogram):\n",
    "    augmented = time_mask(spectrogram)  # Apply time masking\n",
    "    augmented = freq_mask(augmented)   # Apply frequency masking\n",
    "    return augmented\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "2U9n6Z-fPiwY"
   },
   "outputs": [],
   "source": [
    "# Decode audio files\n",
    "def decode_audio(file_tuple):\n",
    "    file_path, file = file_tuple\n",
    "    waveform, sample_rate = torchaudio.load(file_path)\n",
    "    return waveform, sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "class UrbanSoundDataset(Dataset):\n",
    "    def __init__(self, audio_path, fold, csv_path, transform=None):\n",
    "        self.audio_path = os.path.join(audio_path, f\"fold{fold}\")\n",
    "        self.file_list = [os.path.join(self.audio_path, f) for f in os.listdir(self.audio_path) if f.endswith(\".wav\")]\n",
    "        self.transform = transform\n",
    "\n",
    "        # Load the metadata CSV file\n",
    "        self.metadata = pd.read_csv(csv_path)\n",
    "\n",
    "    def get_label(self, file_name):\n",
    "        \"\"\"Fetch the class label for a given file name from the metadata.\"\"\"\n",
    "        label_row = self.metadata.loc[self.metadata['slice_file_name'] == file_name, 'class']\n",
    "        if not label_row.empty:\n",
    "            return label_row.values[0]\n",
    "        else:\n",
    "            raise ValueError(f\"File name {file_name} not found in metadata CSV.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load the audio file\n",
    "        file_path = self.file_list[idx]\n",
    "        waveform, sample_rate = torchaudio.load(file_path)\n",
    "\n",
    "        # Convert mono to stereo if necessary\n",
    "        if waveform.size(0) == 1:  # If mono\n",
    "            waveform = waveform.repeat(3, 1)\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            waveform = self.transform(waveform)\n",
    "\n",
    "        # Extract the file name from the path\n",
    "        file_name = os.path.basename(file_path)\n",
    "\n",
    "        # Get the corresponding label for the file\n",
    "        label = self.get_label(file_name)\n",
    "\n",
    "        return waveform, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asm2fe/.local/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torchaudio.transforms as T\n",
    "\n",
    "# Example transformations\n",
    "def augment_waveform(waveform):\n",
    "    # Add your augmentation logic here (e.g., noise addition, time stretch, etc.)\n",
    "    return waveform\n",
    "\n",
    "waveform_to_spectrogram = T.MelSpectrogram(sample_rate=16000, n_mels=128)\n",
    "augment_spectrogram = T.AmplitudeToDB()\n",
    "\n",
    "# Combine transformations into a callable function\n",
    "def transform_pipeline(waveform):\n",
    "    waveform = augment_waveform(waveform)\n",
    "    spectrogram = waveform_to_spectrogram(waveform)\n",
    "    # spectrogram = augment_spectrogram(spectrogram)\n",
    "    return spectrogram\n",
    "\n",
    "def pad_with_noise(spectrogram, max_time, noise_std=0.01):\n",
    "    \"\"\"\n",
    "    Pads a spectrogram with Gaussian noise instead of zeros.\n",
    "\n",
    "    Args:\n",
    "        spectrogram (Tensor): Shape (channels, freq_bins, time_steps)\n",
    "        max_time (int): Target time dimension\n",
    "        noise_std (float): Standard deviation of the Gaussian noise\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Padded spectrogram with noise\n",
    "    \"\"\"\n",
    "    # Compute how much padding is needed\n",
    "    pad_amount = max_time - spectrogram.size(2)\n",
    "    \n",
    "    if pad_amount > 0:\n",
    "        # Generate random noise matching the shape of missing time steps\n",
    "        noise = torch.randn((spectrogram.size(0), spectrogram.size(1), pad_amount)) * noise_std\n",
    "        \n",
    "        # Concatenate noise along the time axis\n",
    "        spectrogram = torch.cat([spectrogram, noise], dim=2)\n",
    "    \n",
    "    return spectrogram\n",
    "\n",
    "# def convert_to_three_channels(spectrogram):\n",
    "#     # Convert [2, 224, 224] to [3, 224, 224]\n",
    "#     if spectrogram.size(0) == 2:\n",
    "#         # Duplicate the first channel to create a third channel\n",
    "#         return torch.cat((spectrogram, spectrogram[0:1, :, :]), dim=0)\n",
    "#     return spectrogram\n",
    "\n",
    "def convert_to_three_channels(spectrogram):\n",
    "    # Convert [2, 224, 224] to [3, 224, 224]\n",
    "    if spectrogram.size(0) == 2:\n",
    "        # Calculate the mean of the two channels\n",
    "        mean_channel = torch.mean(spectrogram, dim=0, keepdim=True)\n",
    "        # Concatenate the mean channel as the third channel\n",
    "        return torch.cat((spectrogram, mean_channel), dim=0)\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "\n",
    "class densenet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    DenseNet Class, derived from Pytorch. Intended for model manipulation (i.e. unfreezing layers, etc.)\n",
    "    To use model, try (densenet).model(data)\n",
    "    May change to reflect manual implementation of densenet161.\n",
    "    \"\"\"\n",
    "    def __init__(self, weights = \"DEFAULT\", drop = 0.5):\n",
    "        super().__init__()  # Initialize the nn.Module base class\n",
    "        self.model = torchvision.models.densenet161(weights = weights)\n",
    "        \n",
    "        num_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Dropout(drop),  # Add dropout with 50% probability\n",
    "            nn.Linear(num_features, 10)  # Adjust for 10 output classes (UrbanSound8k)\n",
    "        )\n",
    "        \n",
    "        # Ensure classifier is trainable\n",
    "        for param in self.model.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)  # Delegate forward pass to the original DenseNet\n",
    "\n",
    "    def layer_change(self, layer=0):\n",
    "        if layer > 0:    \n",
    "            # Freeze earlier layers (optional)\n",
    "            for name, param in self.model.features.named_parameters():\n",
    "                if \"conv0\" in name or \"denseblock1\" in name:  # Freeze initial layers and denseblock1\n",
    "                    param.requires_grad = False\n",
    "        if layer > 1:    \n",
    "            # Freeze earlier layers (optional)\n",
    "            for name, param in self.model.features.named_parameters():\n",
    "                if \"denseblock2\" in name:  # Freeze initial layers and denseblock2\n",
    "                    param.requires_grad = False\n",
    "        if layer > 2:    \n",
    "            # Freeze earlier layers (optional)\n",
    "            for name, param in self.model.features.named_parameters():\n",
    "                if \"denseblock3\" in name:  # Freeze initial layers and denseblock3\n",
    "                    param.requires_grad = False\n",
    "        if layer > 3:    \n",
    "            # Freeze earlier layers (optional)\n",
    "            for name, param in self.model.features.named_parameters():\n",
    "                if \"denseblock4\" in name:  # Freeze initial layers and denseblock4\n",
    "                    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = densenet()\n",
    "# for param in model.model.features.named_parameters():\n",
    "#     print(param[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and testing loops\n",
    "\n",
    "def train_loop(train_dataloader, val_dataloader, model, loss_fn, optimizer, scheduler=None, epochs=1):\n",
    "    model.train()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Store metrics\n",
    "    epoch_train_losses = []  # Track training loss across epochs\n",
    "    epoch_val_losses = []  # Track validation loss across epochs\n",
    "    epoch_val_accuracies = []  # Track validation accuracy across epochs\n",
    "\n",
    "    # Training loop with early stopping\n",
    "    early_stopping = EarlyStopping(patience=3, min_delta=0.005)\n",
    "    \n",
    "    early_stop_epoch = None\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        size = len(train_dataloader.dataset)\n",
    "        total_loss = 0  # Initialize variable to accumulate training loss\n",
    "        \n",
    "\n",
    "        for batch, (X, y) in enumerate(train_dataloader):\n",
    "            # Compute prediction and loss\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Print progress periodically\n",
    "            total_batches = len(train_dataloader)\n",
    "            if batch % (total_batches // 5) == 0:  # Prints 5 times per epoch\n",
    "                current = (batch + 1) * len(X)\n",
    "                print(f\"loss: {loss.item():>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "        # Average training loss for the epoch\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "        # print(len(train_dataloader))\n",
    "        print(f\"Training Loss (Epoch): {avg_train_loss:>7f}\")\n",
    "        epoch_train_losses.append(avg_train_loss)\n",
    "\n",
    "        # **Validation Step**\n",
    "        print(\"Validating...\")\n",
    "        avg_val_loss, val_accuracy = test_loop(val_dataloader, model, loss_fn, verbose=False)\n",
    "        print(f\"Validation Loss: {avg_val_loss:.6f}, Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "\n",
    "        # Track validation metrics\n",
    "        epoch_val_losses.append(avg_val_loss)\n",
    "        epoch_val_accuracies.append(val_accuracy)\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(val_accuracy)\n",
    "            print(f\"Learning Rate: {scheduler.get_last_lr()}\")\n",
    "        \n",
    "        # Check for early stopping\n",
    "        early_stopping(avg_val_loss)\n",
    "        if early_stopping.stop_training:\n",
    "            print(\"Early stopping triggered. Training stopped.\")\n",
    "            early_stop_epoch = epoch\n",
    "            break\n",
    "\n",
    "    # Return metrics for tracking/aggregation across folds\n",
    "    return epoch_train_losses, epoch_val_losses, epoch_val_accuracies, early_stop_epoch\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn, verbose=True):\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    # Average loss and accuracy for this fold\n",
    "    avg_test_loss = test_loss / num_batches\n",
    "    accuracy = correct / size\n",
    "    if verbose:\n",
    "        print(f\"Test Error: \\n Accuracy: {(100*accuracy):>0.1f}%, Avg loss: {avg_test_loss:>8f} \\n\")\n",
    "    return avg_test_loss, accuracy  # Return both average loss and accuracy for this fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "BLCzmvxcHvKs"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    # Resize and normalize for DenseNet\n",
    "    resize_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize for DenseNet\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Standard ImageNet normalization\n",
    "    ])\n",
    "    \n",
    "    inputs, labels = zip(*batch)  # Separate inputs and labels\n",
    "    max_time = max(spectrogram.size(2) for spectrogram in inputs)\n",
    "\n",
    "    # Pad inputs to the same length along the time dimension\n",
    "    padded_inputs = [\n",
    "        torch.nn.functional.pad(input, (0, max_time - input.size(2)))\n",
    "        for input in inputs\n",
    "    ]\n",
    "\n",
    "    # Convert to 3 channels and resize\n",
    "    resized_inputs = [resize_transform(convert_to_three_channels(input)) for input in padded_inputs]\n",
    "    \n",
    "    # Map labels to numeric class IDs\n",
    "    class_mapping = {\n",
    "        \"air_conditioner\": 0,\n",
    "        \"car_horn\": 1,\n",
    "        \"children_playing\": 2,\n",
    "        \"dog_bark\": 3,\n",
    "        \"drilling\": 4,\n",
    "        \"engine_idling\": 5,\n",
    "        \"gun_shot\": 6,\n",
    "        \"jackhammer\": 7,\n",
    "        \"siren\": 8,\n",
    "        \"street_music\": 9\n",
    "    }\n",
    "\n",
    "    numeric_labels = [class_mapping[label] for label in labels]\n",
    "\n",
    "    # Stack inputs and labels\n",
    "    return torch.stack(resized_inputs), torch.tensor(numeric_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3, min_delta=0.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How many epochs to wait for improvement.\n",
    "            min_delta (float): Minimum change in monitored value to qualify as improvement.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.stop_training = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None or val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.stop_training = True   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sfs/gpfs/tardis/home/asm2fe/UrbanAdversary\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# Specify paths and batch size\n",
    "AUDIO_PATH = \"./UrbanSound8K/audio\"\n",
    "CSV_PATH = \"./UrbanSound8K/metadata/UrbanSound8K.csv\"\n",
    "\n",
    "\n",
    "def setup_seed(seed):\n",
    "    torch_manual_seed(seed)\n",
    "    manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    cudnn.deterministic = True\n",
    "\n",
    "def dense_tune(layer = 0, lr = 2e-4, weight_decay = 0.1, weights = \"DEFAULT\", drop = 0.8, SEED = 666,\\\n",
    "     total_epochs = 25, batch_size = 70, folds = 10):\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    setup_seed(SEED)\n",
    "\n",
    "    # Variables to accumulate metrics across folds\n",
    "    fold_train_losses = []\n",
    "    fold_val_losses = []\n",
    "    fold_val_accuracies = []\n",
    "\n",
    "    # Loop through folds\n",
    "    for fold in range(1, folds+1):\n",
    "        model = densenet(weights = weights, drop = drop)\n",
    "        model.layer_change(layer = layer) # freeze first conv and dense block(s) if desired\n",
    "\n",
    "        print(f\"Processing Fold {fold}\")\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay = weight_decay)\n",
    "        # optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001, weight_decay = 0.01, momentum = 0.9)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='max', factor=0.2, patience=1, threshold_mode = 'abs', threshold= 0.1, min_lr=1e-6)\n",
    "\n",
    "        # Initialize dataset and DataLoader\n",
    "        dataset = UrbanSoundDataset(audio_path=AUDIO_PATH, fold=fold, transform=transform_pipeline, csv_path=CSV_PATH)\n",
    "        train_indices, val_indices = train_test_split(list(range(len(dataset))), test_size=0.2, random_state=42)\n",
    "\n",
    "        train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "        val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
    "\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "        val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "        # Train and validate (over multiple epochs per fold)\n",
    "        epoch_train_losses, epoch_val_losses, epoch_val_accuracies, early_stop_epoch = train_loop(\n",
    "            train_dataloader, val_dataloader, model, loss_fn, optimizer, scheduler, epochs=total_epochs\n",
    "        )\n",
    "\n",
    "        # # Aggregate metrics up to the stopping epoch\n",
    "        # if early_stop_epoch is not None:\n",
    "        #     print(early_stop_epoch+1)\n",
    "        #     fold_train_losses.append(sum(epoch_train_losses) / (early_stop_epoch+1))  # Mean up to early stop\n",
    "        #     fold_val_losses.append(sum(epoch_val_losses) / (early_stop_epoch+1))      # Mean up to early stop\n",
    "        #     fold_val_accuracies.append(sum(epoch_val_accuracies) / (early_stop_epoch+1))  # Mean up to early stop\n",
    "        # else:\n",
    "        #     # If no early stopping occurred, aggregate metrics across all epochs\n",
    "        #     fold_train_losses.append(sum(epoch_train_losses) / len(epoch_train_losses))\n",
    "        #     fold_val_losses.append(sum(epoch_val_losses) / len(epoch_val_losses))\n",
    "        #     fold_val_accuracies.append(sum(epoch_val_accuracies) / len(epoch_val_accuracies))\n",
    "\n",
    "        # Aggregate fold-level metrics (e.g., mean across all epochs)\n",
    "        fold_train_losses.append(sum(epoch_train_losses) / len(epoch_train_losses))  # Mean of training losses\n",
    "        fold_val_losses.append(sum(epoch_val_losses) / len(epoch_val_losses))        # Mean of validation losses\n",
    "        fold_val_accuracies.append(epoch_val_accuracies[-1])  # Last validation accuracy\n",
    "\n",
    "    # Compute average metrics across folds\n",
    "    mean_train_loss = sum(fold_train_losses) / len(fold_train_losses)\n",
    "    mean_val_loss = sum(fold_val_losses) / len(fold_val_losses)\n",
    "    mean_val_accuracy = sum(fold_val_accuracies) / len(fold_val_accuracies)\n",
    "\n",
    "    print(f\"\\nCross-Validation Results:\")\n",
    "    print(f\"Avg Training Loss: {mean_train_loss:.6f}\")\n",
    "    print(f\"Avg Validation Loss: {mean_val_loss:.6f}\")\n",
    "    print(f\"Avg Validation Accuracy: {mean_val_accuracy * 100:.2f}%\")\n",
    "    return mean_train_loss, mean_val_loss, mean_val_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def dense_grid_search(param_grid):\n",
    "    param_names = list(param_grid.keys())\n",
    "    param_combinations = list(itertools.product(*param_grid.values()))\n",
    "\n",
    "    best_params = None\n",
    "    best_score = -float('inf')  # For maximizing validation accuracy\n",
    "    all_results = []\n",
    "\n",
    "    for combination in param_combinations:\n",
    "        # Map combination to hyperparameters\n",
    "        params = dict(zip(param_names, combination))\n",
    "        print(f\"Testing combination: {params}\")\n",
    "\n",
    "        # Call dense_tune with the current parameter combination\n",
    "        mean_train_loss, mean_val_loss, mean_val_accuracy = dense_tune(\n",
    "            layer=params[\"layer\"],\n",
    "            lr=params[\"lr\"],\n",
    "            weight_decay=params[\"weight_decay\"],\n",
    "            drop=params[\"drop\"],\n",
    "            total_epochs=params[\"total_epochs\"],\n",
    "            batch_size =params[\"batch_size\"],\n",
    "            folds = 1\n",
    "        )\n",
    "\n",
    "        # Store results\n",
    "        result = {\n",
    "            \"params\": params,\n",
    "            \"train_loss\": mean_train_loss,\n",
    "            \"val_loss\": mean_val_loss,\n",
    "            \"val_accuracy\": mean_val_accuracy\n",
    "        }\n",
    "        all_results.append(result)\n",
    "\n",
    "        # Update best score and parameters\n",
    "        if mean_val_accuracy > best_score:\n",
    "            best_score = mean_val_accuracy\n",
    "            best_params = params\n",
    "    print(f\"Best parameters were: {best_params}\")\n",
    "    print(f\"Best score was: {best_score}\")\n",
    "    return best_params, best_score, all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"layer\": [1, 4],              # Number of frozen layers\n",
    "    \"lr\": [2e-4, 1e-4],       # Learning rates\n",
    "    \"weight_decay\": [0.1],     # Weight decay values\n",
    "    \"drop\": [0.8],             # Dropout rates\n",
    "    \"total_epochs\": [25],            # Total epochs\n",
    "    \"batch_size\": [128, 70]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params, best_score, all_results = dense_grid_search(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1\n",
      "Epoch 1/25\n",
      "loss: 2.405449  [   90/  698]\n",
      "loss: 2.282286  [  180/  698]\n",
      "loss: 2.220563  [  270/  698]\n",
      "loss: 1.982337  [  360/  698]\n",
      "loss: 2.166603  [  450/  698]\n",
      "loss: 1.963308  [  540/  698]\n",
      "loss: 1.965091  [  630/  698]\n",
      "loss: 1.977088  [  544/  698]\n",
      "Training Loss (Epoch): 2.120341\n",
      "Validating...\n",
      "Validation Loss: 2.069569, Validation Accuracy: 33.71%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/25\n",
      "loss: 2.036608  [   90/  698]\n",
      "loss: 1.837848  [  180/  698]\n",
      "loss: 1.532725  [  270/  698]\n",
      "loss: 1.485199  [  360/  698]\n",
      "loss: 1.196341  [  450/  698]\n",
      "loss: 1.920359  [  540/  698]\n",
      "loss: 1.570403  [  630/  698]\n",
      "loss: 1.642428  [  544/  698]\n",
      "Training Loss (Epoch): 1.652739\n",
      "Validating...\n",
      "Validation Loss: 1.563174, Validation Accuracy: 51.43%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/25\n",
      "loss: 1.660900  [   90/  698]\n",
      "loss: 1.498411  [  180/  698]\n",
      "loss: 1.279416  [  270/  698]\n",
      "loss: 1.222381  [  360/  698]\n",
      "loss: 1.201174  [  450/  698]\n",
      "loss: 0.991683  [  540/  698]\n",
      "loss: 1.016858  [  630/  698]\n",
      "loss: 0.824230  [  544/  698]\n",
      "Training Loss (Epoch): 1.211882\n",
      "Validating...\n",
      "Validation Loss: 0.818219, Validation Accuracy: 73.71%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/25\n",
      "loss: 0.691094  [   90/  698]\n",
      "loss: 0.770220  [  180/  698]\n",
      "loss: 0.857879  [  270/  698]\n",
      "loss: 0.815771  [  360/  698]\n",
      "loss: 0.470683  [  450/  698]\n",
      "loss: 0.643970  [  540/  698]\n",
      "loss: 0.672839  [  630/  698]\n",
      "loss: 0.695953  [  544/  698]\n",
      "Training Loss (Epoch): 0.702301\n",
      "Validating...\n",
      "Validation Loss: 0.689204, Validation Accuracy: 73.14%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/25\n",
      "loss: 0.483815  [   90/  698]\n",
      "loss: 0.649300  [  180/  698]\n",
      "loss: 0.406108  [  270/  698]\n",
      "loss: 0.327305  [  360/  698]\n",
      "loss: 0.370922  [  450/  698]\n",
      "loss: 0.388553  [  540/  698]\n",
      "loss: 0.363992  [  630/  698]\n",
      "loss: 0.183096  [  544/  698]\n",
      "Training Loss (Epoch): 0.396636\n",
      "Validating...\n",
      "Validation Loss: 0.420951, Validation Accuracy: 86.29%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/25\n",
      "loss: 0.224142  [   90/  698]\n",
      "loss: 0.200145  [  180/  698]\n",
      "loss: 0.168539  [  270/  698]\n",
      "loss: 0.105496  [  360/  698]\n",
      "loss: 0.127363  [  450/  698]\n",
      "loss: 0.242986  [  540/  698]\n",
      "loss: 0.253466  [  630/  698]\n",
      "loss: 0.273806  [  544/  698]\n",
      "Training Loss (Epoch): 0.199493\n",
      "Validating...\n",
      "Validation Loss: 0.402347, Validation Accuracy: 83.43%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 7/25\n",
      "loss: 0.245783  [   90/  698]\n",
      "loss: 0.099569  [  180/  698]\n",
      "loss: 0.103937  [  270/  698]\n",
      "loss: 0.270722  [  360/  698]\n",
      "loss: 0.234677  [  450/  698]\n",
      "loss: 0.160244  [  540/  698]\n",
      "loss: 0.266313  [  630/  698]\n",
      "loss: 0.441882  [  544/  698]\n",
      "Training Loss (Epoch): 0.227891\n",
      "Validating...\n",
      "Validation Loss: 0.323474, Validation Accuracy: 90.29%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 8/25\n",
      "loss: 0.107782  [   90/  698]\n",
      "loss: 0.124459  [  180/  698]\n",
      "loss: 0.136166  [  270/  698]\n",
      "loss: 0.113030  [  360/  698]\n",
      "loss: 0.169714  [  450/  698]\n",
      "loss: 0.128961  [  540/  698]\n",
      "loss: 0.052074  [  630/  698]\n",
      "loss: 0.119654  [  544/  698]\n",
      "Training Loss (Epoch): 0.118980\n",
      "Validating...\n",
      "Validation Loss: 0.273050, Validation Accuracy: 90.86%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 9/25\n",
      "loss: 0.080198  [   90/  698]\n",
      "loss: 0.087695  [  180/  698]\n",
      "loss: 0.112617  [  270/  698]\n",
      "loss: 0.086925  [  360/  698]\n",
      "loss: 0.046991  [  450/  698]\n",
      "loss: 0.088238  [  540/  698]\n",
      "loss: 0.070641  [  630/  698]\n",
      "loss: 0.072770  [  544/  698]\n",
      "Training Loss (Epoch): 0.080759\n",
      "Validating...\n",
      "Validation Loss: 0.219002, Validation Accuracy: 92.00%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 10/25\n",
      "loss: 0.096892  [   90/  698]\n",
      "loss: 0.043860  [  180/  698]\n",
      "loss: 0.088562  [  270/  698]\n",
      "loss: 0.013263  [  360/  698]\n",
      "loss: 0.142480  [  450/  698]\n",
      "loss: 0.052474  [  540/  698]\n",
      "loss: 0.037036  [  630/  698]\n",
      "loss: 0.024843  [  544/  698]\n",
      "Training Loss (Epoch): 0.062426\n",
      "Validating...\n",
      "Validation Loss: 0.218337, Validation Accuracy: 92.57%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 11/25\n",
      "loss: 0.069933  [   90/  698]\n",
      "loss: 0.095066  [  180/  698]\n",
      "loss: 0.048942  [  270/  698]\n",
      "loss: 0.015734  [  360/  698]\n",
      "loss: 0.089892  [  450/  698]\n",
      "loss: 0.075463  [  540/  698]\n",
      "loss: 0.055224  [  630/  698]\n",
      "loss: 0.024050  [  544/  698]\n",
      "Training Loss (Epoch): 0.059288\n",
      "Validating...\n",
      "Validation Loss: 0.218268, Validation Accuracy: 92.57%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 12/25\n",
      "loss: 0.026033  [   90/  698]\n",
      "loss: 0.051076  [  180/  698]\n",
      "loss: 0.065733  [  270/  698]\n",
      "loss: 0.029787  [  360/  698]\n",
      "loss: 0.061510  [  450/  698]\n",
      "loss: 0.067925  [  540/  698]\n",
      "loss: 0.095424  [  630/  698]\n",
      "loss: 0.069772  [  544/  698]\n",
      "Training Loss (Epoch): 0.058407\n",
      "Validating...\n",
      "Validation Loss: 0.217621, Validation Accuracy: 92.57%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 2\n",
      "Epoch 1/25\n",
      "loss: 2.470328  [   90/  710]\n",
      "loss: 2.253719  [  180/  710]\n",
      "loss: 2.114245  [  270/  710]\n",
      "loss: 2.247858  [  360/  710]\n",
      "loss: 2.019561  [  450/  710]\n",
      "loss: 1.985078  [  540/  710]\n",
      "loss: 1.804819  [  630/  710]\n",
      "loss: 1.696040  [  640/  710]\n",
      "Training Loss (Epoch): 2.073956\n",
      "Validating...\n",
      "Validation Loss: 1.986503, Validation Accuracy: 35.96%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/25\n",
      "loss: 1.868141  [   90/  710]\n",
      "loss: 1.729531  [  180/  710]\n",
      "loss: 1.721151  [  270/  710]\n",
      "loss: 1.573185  [  360/  710]\n",
      "loss: 1.175785  [  450/  710]\n",
      "loss: 1.031899  [  540/  710]\n",
      "loss: 1.406090  [  630/  710]\n",
      "loss: 1.811968  [  640/  710]\n",
      "Training Loss (Epoch): 1.539719\n",
      "Validating...\n",
      "Validation Loss: 1.075177, Validation Accuracy: 61.24%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/25\n",
      "loss: 0.929264  [   90/  710]\n",
      "loss: 1.011334  [  180/  710]\n",
      "loss: 0.941710  [  270/  710]\n",
      "loss: 1.021052  [  360/  710]\n",
      "loss: 0.896440  [  450/  710]\n",
      "loss: 0.747386  [  540/  710]\n",
      "loss: 0.965482  [  630/  710]\n",
      "loss: 0.655574  [  640/  710]\n",
      "Training Loss (Epoch): 0.896030\n",
      "Validating...\n",
      "Validation Loss: 0.753107, Validation Accuracy: 72.47%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/25\n",
      "loss: 0.641199  [   90/  710]\n",
      "loss: 0.611537  [  180/  710]\n",
      "loss: 0.474918  [  270/  710]\n",
      "loss: 0.572226  [  360/  710]\n",
      "loss: 0.527960  [  450/  710]\n",
      "loss: 0.344476  [  540/  710]\n",
      "loss: 0.437297  [  630/  710]\n",
      "loss: 0.419414  [  640/  710]\n",
      "Training Loss (Epoch): 0.503628\n",
      "Validating...\n",
      "Validation Loss: 0.619677, Validation Accuracy: 82.02%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/25\n",
      "loss: 0.287581  [   90/  710]\n",
      "loss: 0.191881  [  180/  710]\n",
      "loss: 0.238879  [  270/  710]\n",
      "loss: 0.183256  [  360/  710]\n",
      "loss: 0.329585  [  450/  710]\n",
      "loss: 0.364237  [  540/  710]\n",
      "loss: 0.240562  [  630/  710]\n",
      "loss: 0.272094  [  640/  710]\n",
      "Training Loss (Epoch): 0.263509\n",
      "Validating...\n",
      "Validation Loss: 0.637154, Validation Accuracy: 84.83%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/25\n",
      "loss: 0.214480  [   90/  710]\n",
      "loss: 0.176553  [  180/  710]\n",
      "loss: 0.298942  [  270/  710]\n",
      "loss: 0.368694  [  360/  710]\n",
      "loss: 0.275756  [  450/  710]\n",
      "loss: 0.248358  [  540/  710]\n",
      "loss: 0.126217  [  630/  710]\n",
      "loss: 0.220451  [  640/  710]\n",
      "Training Loss (Epoch): 0.241182\n",
      "Validating...\n",
      "Validation Loss: 0.633740, Validation Accuracy: 83.71%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 7/25\n",
      "loss: 0.230883  [   90/  710]\n",
      "loss: 0.423861  [  180/  710]\n",
      "loss: 0.271890  [  270/  710]\n",
      "loss: 0.297112  [  360/  710]\n",
      "loss: 0.172608  [  450/  710]\n",
      "loss: 0.172232  [  540/  710]\n",
      "loss: 0.265754  [  630/  710]\n",
      "loss: 0.429429  [  640/  710]\n",
      "Training Loss (Epoch): 0.282971\n",
      "Validating...\n",
      "Validation Loss: 0.546863, Validation Accuracy: 88.20%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 8/25\n",
      "loss: 0.250712  [   90/  710]\n",
      "loss: 0.139088  [  180/  710]\n",
      "loss: 0.313991  [  270/  710]\n",
      "loss: 0.124027  [  360/  710]\n",
      "loss: 0.152156  [  450/  710]\n",
      "loss: 0.135322  [  540/  710]\n",
      "loss: 0.080735  [  630/  710]\n",
      "loss: 0.099536  [  640/  710]\n",
      "Training Loss (Epoch): 0.161946\n",
      "Validating...\n",
      "Validation Loss: 0.458537, Validation Accuracy: 88.76%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 9/25\n",
      "loss: 0.096128  [   90/  710]\n",
      "loss: 0.088577  [  180/  710]\n",
      "loss: 0.078008  [  270/  710]\n",
      "loss: 0.109524  [  360/  710]\n",
      "loss: 0.089528  [  450/  710]\n",
      "loss: 0.046269  [  540/  710]\n",
      "loss: 0.051399  [  630/  710]\n",
      "loss: 0.091568  [  640/  710]\n",
      "Training Loss (Epoch): 0.081375\n",
      "Validating...\n",
      "Validation Loss: 0.438619, Validation Accuracy: 90.45%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 10/25\n",
      "loss: 0.016508  [   90/  710]\n",
      "loss: 0.053205  [  180/  710]\n",
      "loss: 0.070558  [  270/  710]\n",
      "loss: 0.045675  [  360/  710]\n",
      "loss: 0.066241  [  450/  710]\n",
      "loss: 0.091523  [  540/  710]\n",
      "loss: 0.042348  [  630/  710]\n",
      "loss: 0.081954  [  640/  710]\n",
      "Training Loss (Epoch): 0.058501\n",
      "Validating...\n",
      "Validation Loss: 0.438069, Validation Accuracy: 89.89%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 11/25\n",
      "loss: 0.042508  [   90/  710]\n",
      "loss: 0.026419  [  180/  710]\n",
      "loss: 0.039224  [  270/  710]\n",
      "loss: 0.093563  [  360/  710]\n",
      "loss: 0.098384  [  450/  710]\n",
      "loss: 0.011555  [  540/  710]\n",
      "loss: 0.050026  [  630/  710]\n",
      "loss: 0.060606  [  640/  710]\n",
      "Training Loss (Epoch): 0.052786\n",
      "Validating...\n",
      "Validation Loss: 0.438496, Validation Accuracy: 88.76%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 12/25\n",
      "loss: 0.057590  [   90/  710]\n",
      "loss: 0.029422  [  180/  710]\n",
      "loss: 0.054055  [  270/  710]\n",
      "loss: 0.080827  [  360/  710]\n",
      "loss: 0.032587  [  450/  710]\n",
      "loss: 0.047523  [  540/  710]\n",
      "loss: 0.052225  [  630/  710]\n",
      "loss: 0.041751  [  640/  710]\n",
      "Training Loss (Epoch): 0.049498\n",
      "Validating...\n",
      "Validation Loss: 0.439046, Validation Accuracy: 88.76%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 3\n",
      "Epoch 1/25\n",
      "loss: 2.431556  [   90/  740]\n",
      "loss: 2.447099  [  180/  740]\n",
      "loss: 2.347650  [  270/  740]\n",
      "loss: 2.220742  [  360/  740]\n",
      "loss: 2.199235  [  450/  740]\n",
      "loss: 2.095266  [  540/  740]\n",
      "loss: 2.158897  [  630/  740]\n",
      "loss: 1.971539  [  720/  740]\n",
      "loss: 1.846524  [  180/  740]\n",
      "Training Loss (Epoch): 2.190945\n",
      "Validating...\n",
      "Validation Loss: 2.080452, Validation Accuracy: 35.14%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/25\n",
      "loss: 1.895742  [   90/  740]\n",
      "loss: 1.777748  [  180/  740]\n",
      "loss: 1.685973  [  270/  740]\n",
      "loss: 1.330097  [  360/  740]\n",
      "loss: 1.270761  [  450/  740]\n",
      "loss: 1.095289  [  540/  740]\n",
      "loss: 1.256463  [  630/  740]\n",
      "loss: 1.193181  [  720/  740]\n",
      "loss: 1.193705  [  180/  740]\n",
      "Training Loss (Epoch): 1.410995\n",
      "Validating...\n",
      "Validation Loss: 1.118991, Validation Accuracy: 61.62%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/25\n",
      "loss: 0.977957  [   90/  740]\n",
      "loss: 1.029958  [  180/  740]\n",
      "loss: 0.924624  [  270/  740]\n",
      "loss: 1.144442  [  360/  740]\n",
      "loss: 0.712006  [  450/  740]\n",
      "loss: 0.717241  [  540/  740]\n",
      "loss: 0.928417  [  630/  740]\n",
      "loss: 0.489009  [  720/  740]\n",
      "loss: 0.785972  [  180/  740]\n",
      "Training Loss (Epoch): 0.856625\n",
      "Validating...\n",
      "Validation Loss: 1.480831, Validation Accuracy: 51.89%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/25\n",
      "loss: 1.180424  [   90/  740]\n",
      "loss: 0.948606  [  180/  740]\n",
      "loss: 0.897173  [  270/  740]\n",
      "loss: 0.753890  [  360/  740]\n",
      "loss: 0.691036  [  450/  740]\n",
      "loss: 0.717496  [  540/  740]\n",
      "loss: 0.841583  [  630/  740]\n",
      "loss: 0.510578  [  720/  740]\n",
      "loss: 0.335064  [  180/  740]\n",
      "Training Loss (Epoch): 0.763983\n",
      "Validating...\n",
      "Validation Loss: 1.090812, Validation Accuracy: 61.08%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 5/25\n",
      "loss: 0.771571  [   90/  740]\n",
      "loss: 0.853813  [  180/  740]\n",
      "loss: 0.622889  [  270/  740]\n",
      "loss: 0.407411  [  360/  740]\n",
      "loss: 0.590308  [  450/  740]\n",
      "loss: 0.438085  [  540/  740]\n",
      "loss: 0.398579  [  630/  740]\n",
      "loss: 0.448989  [  720/  740]\n",
      "loss: 0.459596  [  180/  740]\n",
      "Training Loss (Epoch): 0.554582\n",
      "Validating...\n",
      "Validation Loss: 0.621989, Validation Accuracy: 79.46%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 6/25\n",
      "loss: 0.337496  [   90/  740]\n",
      "loss: 0.349011  [  180/  740]\n",
      "loss: 0.368584  [  270/  740]\n",
      "loss: 0.612726  [  360/  740]\n",
      "loss: 0.455470  [  450/  740]\n",
      "loss: 0.515546  [  540/  740]\n",
      "loss: 0.491457  [  630/  740]\n",
      "loss: 0.319401  [  720/  740]\n",
      "loss: 0.259065  [  180/  740]\n",
      "Training Loss (Epoch): 0.412084\n",
      "Validating...\n",
      "Validation Loss: 0.547993, Validation Accuracy: 82.16%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 7/25\n",
      "loss: 0.400272  [   90/  740]\n",
      "loss: 0.317211  [  180/  740]\n",
      "loss: 0.289838  [  270/  740]\n",
      "loss: 0.293431  [  360/  740]\n",
      "loss: 0.368787  [  450/  740]\n",
      "loss: 0.363725  [  540/  740]\n",
      "loss: 0.272745  [  630/  740]\n",
      "loss: 0.120587  [  720/  740]\n",
      "loss: 0.266143  [  180/  740]\n",
      "Training Loss (Epoch): 0.299193\n",
      "Validating...\n",
      "Validation Loss: 0.440336, Validation Accuracy: 82.16%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 8/25\n",
      "loss: 0.276626  [   90/  740]\n",
      "loss: 0.173534  [  180/  740]\n",
      "loss: 0.221343  [  270/  740]\n",
      "loss: 0.279204  [  360/  740]\n",
      "loss: 0.309335  [  450/  740]\n",
      "loss: 0.104350  [  540/  740]\n",
      "loss: 0.302458  [  630/  740]\n",
      "loss: 0.244524  [  720/  740]\n",
      "loss: 0.324022  [  180/  740]\n",
      "Training Loss (Epoch): 0.248377\n",
      "Validating...\n",
      "Validation Loss: 0.412859, Validation Accuracy: 82.70%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 9/25\n",
      "loss: 0.238023  [   90/  740]\n",
      "loss: 0.309675  [  180/  740]\n",
      "loss: 0.242012  [  270/  740]\n",
      "loss: 0.109785  [  360/  740]\n",
      "loss: 0.169856  [  450/  740]\n",
      "loss: 0.233318  [  540/  740]\n",
      "loss: 0.153357  [  630/  740]\n",
      "loss: 0.294576  [  720/  740]\n",
      "loss: 0.261171  [  180/  740]\n",
      "Training Loss (Epoch): 0.223530\n",
      "Validating...\n",
      "Validation Loss: 0.396643, Validation Accuracy: 85.41%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 10/25\n",
      "loss: 0.269558  [   90/  740]\n",
      "loss: 0.135340  [  180/  740]\n",
      "loss: 0.171343  [  270/  740]\n",
      "loss: 0.186582  [  360/  740]\n",
      "loss: 0.285313  [  450/  740]\n",
      "loss: 0.192299  [  540/  740]\n",
      "loss: 0.208395  [  630/  740]\n",
      "loss: 0.223426  [  720/  740]\n",
      "loss: 0.118563  [  180/  740]\n",
      "Training Loss (Epoch): 0.198980\n",
      "Validating...\n",
      "Validation Loss: 0.394475, Validation Accuracy: 84.86%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 11/25\n",
      "loss: 0.244117  [   90/  740]\n",
      "loss: 0.221677  [  180/  740]\n",
      "loss: 0.199288  [  270/  740]\n",
      "loss: 0.159919  [  360/  740]\n",
      "loss: 0.179031  [  450/  740]\n",
      "loss: 0.203638  [  540/  740]\n",
      "loss: 0.184300  [  630/  740]\n",
      "loss: 0.229453  [  720/  740]\n",
      "loss: 0.137858  [  180/  740]\n",
      "Training Loss (Epoch): 0.195476\n",
      "Validating...\n",
      "Validation Loss: 0.392114, Validation Accuracy: 84.86%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 12/25\n",
      "loss: 0.238351  [   90/  740]\n",
      "loss: 0.193203  [  180/  740]\n",
      "loss: 0.117917  [  270/  740]\n",
      "loss: 0.159677  [  360/  740]\n",
      "loss: 0.238131  [  450/  740]\n",
      "loss: 0.242348  [  540/  740]\n",
      "loss: 0.173098  [  630/  740]\n",
      "loss: 0.298613  [  720/  740]\n",
      "loss: 0.355418  [  180/  740]\n",
      "Training Loss (Epoch): 0.224084\n",
      "Validating...\n",
      "Validation Loss: 0.391636, Validation Accuracy: 84.86%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 13/25\n",
      "loss: 0.147212  [   90/  740]\n",
      "loss: 0.123353  [  180/  740]\n",
      "loss: 0.250857  [  270/  740]\n",
      "loss: 0.159013  [  360/  740]\n",
      "loss: 0.228217  [  450/  740]\n",
      "loss: 0.342520  [  540/  740]\n",
      "loss: 0.271831  [  630/  740]\n",
      "loss: 0.143290  [  720/  740]\n",
      "loss: 0.103162  [  180/  740]\n",
      "Training Loss (Epoch): 0.196606\n",
      "Validating...\n",
      "Validation Loss: 0.392192, Validation Accuracy: 84.86%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 14/25\n",
      "loss: 0.225153  [   90/  740]\n",
      "loss: 0.133515  [  180/  740]\n",
      "loss: 0.175464  [  270/  740]\n",
      "loss: 0.191837  [  360/  740]\n",
      "loss: 0.143599  [  450/  740]\n",
      "loss: 0.221424  [  540/  740]\n",
      "loss: 0.252064  [  630/  740]\n",
      "loss: 0.380046  [  720/  740]\n",
      "loss: 0.184042  [  180/  740]\n",
      "Training Loss (Epoch): 0.211905\n",
      "Validating...\n",
      "Validation Loss: 0.392597, Validation Accuracy: 84.32%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 15/25\n",
      "loss: 0.127616  [   90/  740]\n",
      "loss: 0.269677  [  180/  740]\n",
      "loss: 0.136072  [  270/  740]\n",
      "loss: 0.267721  [  360/  740]\n",
      "loss: 0.372147  [  450/  740]\n",
      "loss: 0.211298  [  540/  740]\n",
      "loss: 0.164521  [  630/  740]\n",
      "loss: 0.228452  [  720/  740]\n",
      "loss: 0.028920  [  180/  740]\n",
      "Training Loss (Epoch): 0.200714\n",
      "Validating...\n",
      "Validation Loss: 0.394402, Validation Accuracy: 84.86%\n",
      "Learning Rate: [1e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 4\n",
      "Epoch 1/25\n",
      "loss: 2.432444  [   90/  792]\n",
      "loss: 2.285558  [  180/  792]\n",
      "loss: 2.156574  [  270/  792]\n",
      "loss: 2.158754  [  360/  792]\n",
      "loss: 2.230663  [  450/  792]\n",
      "loss: 2.301335  [  540/  792]\n",
      "loss: 2.040027  [  630/  792]\n",
      "loss: 2.075621  [  720/  792]\n",
      "loss: 1.773295  [  648/  792]\n",
      "Training Loss (Epoch): 2.161586\n",
      "Validating...\n",
      "Validation Loss: 1.965996, Validation Accuracy: 49.49%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/25\n",
      "loss: 1.994952  [   90/  792]\n",
      "loss: 1.778431  [  180/  792]\n",
      "loss: 1.768032  [  270/  792]\n",
      "loss: 1.504908  [  360/  792]\n",
      "loss: 1.562764  [  450/  792]\n",
      "loss: 1.484846  [  540/  792]\n",
      "loss: 1.280471  [  630/  792]\n",
      "loss: 1.246265  [  720/  792]\n",
      "loss: 1.176535  [  648/  792]\n",
      "Training Loss (Epoch): 1.533023\n",
      "Validating...\n",
      "Validation Loss: 0.978097, Validation Accuracy: 64.65%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/25\n",
      "loss: 0.988134  [   90/  792]\n",
      "loss: 1.009940  [  180/  792]\n",
      "loss: 0.868975  [  270/  792]\n",
      "loss: 1.083495  [  360/  792]\n",
      "loss: 0.717228  [  450/  792]\n",
      "loss: 0.743432  [  540/  792]\n",
      "loss: 0.814246  [  630/  792]\n",
      "loss: 0.605222  [  720/  792]\n",
      "loss: 0.657927  [  648/  792]\n",
      "Training Loss (Epoch): 0.832067\n",
      "Validating...\n",
      "Validation Loss: 0.912345, Validation Accuracy: 76.77%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/25\n",
      "loss: 0.388594  [   90/  792]\n",
      "loss: 0.666378  [  180/  792]\n",
      "loss: 0.552632  [  270/  792]\n",
      "loss: 0.622800  [  360/  792]\n",
      "loss: 0.459900  [  450/  792]\n",
      "loss: 0.690561  [  540/  792]\n",
      "loss: 0.363715  [  630/  792]\n",
      "loss: 0.458736  [  720/  792]\n",
      "loss: 0.733869  [  648/  792]\n",
      "Training Loss (Epoch): 0.548576\n",
      "Validating...\n",
      "Validation Loss: 1.140292, Validation Accuracy: 75.76%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/25\n",
      "loss: 0.508003  [   90/  792]\n",
      "loss: 0.358409  [  180/  792]\n",
      "loss: 0.312922  [  270/  792]\n",
      "loss: 0.331348  [  360/  792]\n",
      "loss: 0.501836  [  450/  792]\n",
      "loss: 0.411249  [  540/  792]\n",
      "loss: 0.342374  [  630/  792]\n",
      "loss: 0.425148  [  720/  792]\n",
      "loss: 0.292183  [  648/  792]\n",
      "Training Loss (Epoch): 0.387052\n",
      "Validating...\n",
      "Validation Loss: 1.064650, Validation Accuracy: 74.24%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 6/25\n",
      "loss: 0.484914  [   90/  792]\n",
      "loss: 0.532824  [  180/  792]\n",
      "loss: 0.299963  [  270/  792]\n",
      "loss: 0.290522  [  360/  792]\n",
      "loss: 0.164037  [  450/  792]\n",
      "loss: 0.317011  [  540/  792]\n",
      "loss: 0.259495  [  630/  792]\n",
      "loss: 0.188056  [  720/  792]\n",
      "loss: 0.175389  [  648/  792]\n",
      "Training Loss (Epoch): 0.301357\n",
      "Validating...\n",
      "Validation Loss: 0.684250, Validation Accuracy: 84.34%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 7/25\n",
      "loss: 0.266106  [   90/  792]\n",
      "loss: 0.291487  [  180/  792]\n",
      "loss: 0.183338  [  270/  792]\n",
      "loss: 0.153096  [  360/  792]\n",
      "loss: 0.111700  [  450/  792]\n",
      "loss: 0.112228  [  540/  792]\n",
      "loss: 0.116512  [  630/  792]\n",
      "loss: 0.215958  [  720/  792]\n",
      "loss: 0.171564  [  648/  792]\n",
      "Training Loss (Epoch): 0.180221\n",
      "Validating...\n",
      "Validation Loss: 0.565418, Validation Accuracy: 85.86%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 8/25\n",
      "loss: 0.103440  [   90/  792]\n",
      "loss: 0.110666  [  180/  792]\n",
      "loss: 0.100178  [  270/  792]\n",
      "loss: 0.124684  [  360/  792]\n",
      "loss: 0.128664  [  450/  792]\n",
      "loss: 0.128097  [  540/  792]\n",
      "loss: 0.166148  [  630/  792]\n",
      "loss: 0.132707  [  720/  792]\n",
      "loss: 0.064501  [  648/  792]\n",
      "Training Loss (Epoch): 0.117676\n",
      "Validating...\n",
      "Validation Loss: 0.581531, Validation Accuracy: 85.86%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 9/25\n",
      "loss: 0.116438  [   90/  792]\n",
      "loss: 0.071212  [  180/  792]\n",
      "loss: 0.076322  [  270/  792]\n",
      "loss: 0.142884  [  360/  792]\n",
      "loss: 0.066378  [  450/  792]\n",
      "loss: 0.087108  [  540/  792]\n",
      "loss: 0.079910  [  630/  792]\n",
      "loss: 0.131160  [  720/  792]\n",
      "loss: 0.112637  [  648/  792]\n",
      "Training Loss (Epoch): 0.098228\n",
      "Validating...\n",
      "Validation Loss: 0.617092, Validation Accuracy: 86.87%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 10/25\n",
      "loss: 0.068009  [   90/  792]\n",
      "loss: 0.063059  [  180/  792]\n",
      "loss: 0.044355  [  270/  792]\n",
      "loss: 0.086571  [  360/  792]\n",
      "loss: 0.099052  [  450/  792]\n",
      "loss: 0.108917  [  540/  792]\n",
      "loss: 0.164841  [  630/  792]\n",
      "loss: 0.067807  [  720/  792]\n",
      "loss: 0.071300  [  648/  792]\n",
      "Training Loss (Epoch): 0.085990\n",
      "Validating...\n",
      "Validation Loss: 0.631807, Validation Accuracy: 86.87%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 5\n",
      "Epoch 1/25\n",
      "loss: 2.416323  [   90/  748]\n",
      "loss: 2.253427  [  180/  748]\n",
      "loss: 2.308515  [  270/  748]\n",
      "loss: 2.198513  [  360/  748]\n",
      "loss: 2.065434  [  450/  748]\n",
      "loss: 2.217897  [  540/  748]\n",
      "loss: 1.974398  [  630/  748]\n",
      "loss: 1.862207  [  720/  748]\n",
      "loss: 2.218092  [  252/  748]\n",
      "Training Loss (Epoch): 2.168312\n",
      "Validating...\n",
      "Validation Loss: 2.098597, Validation Accuracy: 28.72%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/25\n",
      "loss: 1.829305  [   90/  748]\n",
      "loss: 1.775963  [  180/  748]\n",
      "loss: 1.502172  [  270/  748]\n",
      "loss: 1.413593  [  360/  748]\n",
      "loss: 1.248649  [  450/  748]\n",
      "loss: 1.103545  [  540/  748]\n",
      "loss: 1.149645  [  630/  748]\n",
      "loss: 1.141796  [  720/  748]\n",
      "loss: 1.125693  [  252/  748]\n",
      "Training Loss (Epoch): 1.365596\n",
      "Validating...\n",
      "Validation Loss: 1.649540, Validation Accuracy: 48.40%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/25\n",
      "loss: 1.270329  [   90/  748]\n",
      "loss: 1.038602  [  180/  748]\n",
      "loss: 1.019898  [  270/  748]\n",
      "loss: 1.098338  [  360/  748]\n",
      "loss: 0.793111  [  450/  748]\n",
      "loss: 0.813775  [  540/  748]\n",
      "loss: 0.593349  [  630/  748]\n",
      "loss: 0.823530  [  720/  748]\n",
      "loss: 0.645768  [  252/  748]\n",
      "Training Loss (Epoch): 0.899633\n",
      "Validating...\n",
      "Validation Loss: 1.054920, Validation Accuracy: 69.15%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/25\n",
      "loss: 0.378463  [   90/  748]\n",
      "loss: 0.519722  [  180/  748]\n",
      "loss: 0.494196  [  270/  748]\n",
      "loss: 0.439027  [  360/  748]\n",
      "loss: 0.416671  [  450/  748]\n",
      "loss: 0.384173  [  540/  748]\n",
      "loss: 0.492745  [  630/  748]\n",
      "loss: 0.669285  [  720/  748]\n",
      "loss: 0.343287  [  252/  748]\n",
      "Training Loss (Epoch): 0.459730\n",
      "Validating...\n",
      "Validation Loss: 1.024441, Validation Accuracy: 71.81%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/25\n",
      "loss: 0.332561  [   90/  748]\n",
      "loss: 0.310999  [  180/  748]\n",
      "loss: 0.601309  [  270/  748]\n",
      "loss: 0.296944  [  360/  748]\n",
      "loss: 0.573434  [  450/  748]\n",
      "loss: 0.325408  [  540/  748]\n",
      "loss: 0.398760  [  630/  748]\n",
      "loss: 0.304382  [  720/  748]\n",
      "loss: 0.280837  [  252/  748]\n",
      "Training Loss (Epoch): 0.380515\n",
      "Validating...\n",
      "Validation Loss: 0.848052, Validation Accuracy: 77.66%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 6/25\n",
      "loss: 0.538109  [   90/  748]\n",
      "loss: 0.344409  [  180/  748]\n",
      "loss: 0.341585  [  270/  748]\n",
      "loss: 0.175815  [  360/  748]\n",
      "loss: 0.254656  [  450/  748]\n",
      "loss: 0.196279  [  540/  748]\n",
      "loss: 0.228648  [  630/  748]\n",
      "loss: 0.255886  [  720/  748]\n",
      "loss: 0.199493  [  252/  748]\n",
      "Training Loss (Epoch): 0.281653\n",
      "Validating...\n",
      "Validation Loss: 0.731324, Validation Accuracy: 85.64%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 7/25\n",
      "loss: 0.335758  [   90/  748]\n",
      "loss: 0.185191  [  180/  748]\n",
      "loss: 0.162616  [  270/  748]\n",
      "loss: 0.225352  [  360/  748]\n",
      "loss: 0.100562  [  450/  748]\n",
      "loss: 0.206824  [  540/  748]\n",
      "loss: 0.179752  [  630/  748]\n",
      "loss: 0.123050  [  720/  748]\n",
      "loss: 0.088165  [  252/  748]\n",
      "Training Loss (Epoch): 0.178585\n",
      "Validating...\n",
      "Validation Loss: 0.542034, Validation Accuracy: 85.64%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 8/25\n",
      "loss: 0.200189  [   90/  748]\n",
      "loss: 0.162586  [  180/  748]\n",
      "loss: 0.114843  [  270/  748]\n",
      "loss: 0.113664  [  360/  748]\n",
      "loss: 0.093795  [  450/  748]\n",
      "loss: 0.147058  [  540/  748]\n",
      "loss: 0.102184  [  630/  748]\n",
      "loss: 0.039541  [  720/  748]\n",
      "loss: 0.097656  [  252/  748]\n",
      "Training Loss (Epoch): 0.119057\n",
      "Validating...\n",
      "Validation Loss: 0.573992, Validation Accuracy: 88.30%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 9/25\n",
      "loss: 0.086876  [   90/  748]\n",
      "loss: 0.076802  [  180/  748]\n",
      "loss: 0.111429  [  270/  748]\n",
      "loss: 0.082070  [  360/  748]\n",
      "loss: 0.072179  [  450/  748]\n",
      "loss: 0.112440  [  540/  748]\n",
      "loss: 0.054458  [  630/  748]\n",
      "loss: 0.110100  [  720/  748]\n",
      "loss: 0.275275  [  252/  748]\n",
      "Training Loss (Epoch): 0.109070\n",
      "Validating...\n",
      "Validation Loss: 0.514451, Validation Accuracy: 86.70%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 10/25\n",
      "loss: 0.138814  [   90/  748]\n",
      "loss: 0.077036  [  180/  748]\n",
      "loss: 0.057238  [  270/  748]\n",
      "loss: 0.139341  [  360/  748]\n",
      "loss: 0.089089  [  450/  748]\n",
      "loss: 0.025889  [  540/  748]\n",
      "loss: 0.091596  [  630/  748]\n",
      "loss: 0.061130  [  720/  748]\n",
      "loss: 0.157823  [  252/  748]\n",
      "Training Loss (Epoch): 0.093106\n",
      "Validating...\n",
      "Validation Loss: 0.548625, Validation Accuracy: 87.23%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 11/25\n",
      "loss: 0.026897  [   90/  748]\n",
      "loss: 0.067106  [  180/  748]\n",
      "loss: 0.109138  [  270/  748]\n",
      "loss: 0.113791  [  360/  748]\n",
      "loss: 0.078045  [  450/  748]\n",
      "loss: 0.049798  [  540/  748]\n",
      "loss: 0.124284  [  630/  748]\n",
      "loss: 0.059583  [  720/  748]\n",
      "loss: 0.007011  [  252/  748]\n",
      "Training Loss (Epoch): 0.070628\n",
      "Validating...\n",
      "Validation Loss: 0.541757, Validation Accuracy: 86.70%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 12/25\n",
      "loss: 0.084918  [   90/  748]\n",
      "loss: 0.027378  [  180/  748]\n",
      "loss: 0.040423  [  270/  748]\n",
      "loss: 0.062094  [  360/  748]\n",
      "loss: 0.065792  [  450/  748]\n",
      "loss: 0.072002  [  540/  748]\n",
      "loss: 0.134034  [  630/  748]\n",
      "loss: 0.084807  [  720/  748]\n",
      "loss: 0.107866  [  252/  748]\n",
      "Training Loss (Epoch): 0.075479\n",
      "Validating...\n",
      "Validation Loss: 0.528315, Validation Accuracy: 86.70%\n",
      "Learning Rate: [1e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 6\n",
      "Epoch 1/25\n",
      "loss: 2.480422  [   90/  658]\n",
      "loss: 2.387698  [  180/  658]\n",
      "loss: 2.341720  [  270/  658]\n",
      "loss: 2.285296  [  360/  658]\n",
      "loss: 2.215276  [  450/  658]\n",
      "loss: 2.069993  [  540/  658]\n",
      "loss: 2.083191  [  630/  658]\n",
      "loss: 1.976243  [  224/  658]\n",
      "Training Loss (Epoch): 2.229980\n",
      "Validating...\n",
      "Validation Loss: 2.165938, Validation Accuracy: 18.18%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/25\n",
      "loss: 2.115095  [   90/  658]\n",
      "loss: 2.023047  [  180/  658]\n",
      "loss: 1.878639  [  270/  658]\n",
      "loss: 1.543592  [  360/  658]\n",
      "loss: 1.330802  [  450/  658]\n",
      "loss: 1.320493  [  540/  658]\n",
      "loss: 2.288142  [  630/  658]\n",
      "loss: 1.725506  [  224/  658]\n",
      "Training Loss (Epoch): 1.778165\n",
      "Validating...\n",
      "Validation Loss: 1.474103, Validation Accuracy: 50.30%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/25\n",
      "loss: 1.479662  [   90/  658]\n",
      "loss: 1.364507  [  180/  658]\n",
      "loss: 1.233407  [  270/  658]\n",
      "loss: 1.359087  [  360/  658]\n",
      "loss: 1.239856  [  450/  658]\n",
      "loss: 0.895979  [  540/  658]\n",
      "loss: 1.106290  [  630/  658]\n",
      "loss: 1.447730  [  224/  658]\n",
      "Training Loss (Epoch): 1.265815\n",
      "Validating...\n",
      "Validation Loss: 1.173006, Validation Accuracy: 60.61%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/25\n",
      "loss: 0.530310  [   90/  658]\n",
      "loss: 1.421412  [  180/  658]\n",
      "loss: 0.947639  [  270/  658]\n",
      "loss: 0.776098  [  360/  658]\n",
      "loss: 0.816519  [  450/  658]\n",
      "loss: 0.895748  [  540/  658]\n",
      "loss: 1.097307  [  630/  658]\n",
      "loss: 0.842394  [  224/  658]\n",
      "Training Loss (Epoch): 0.915928\n",
      "Validating...\n",
      "Validation Loss: 0.844694, Validation Accuracy: 67.88%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/25\n",
      "loss: 0.931711  [   90/  658]\n",
      "loss: 0.689350  [  180/  658]\n",
      "loss: 0.521636  [  270/  658]\n",
      "loss: 0.492583  [  360/  658]\n",
      "loss: 0.561135  [  450/  658]\n",
      "loss: 0.562600  [  540/  658]\n",
      "loss: 0.532634  [  630/  658]\n",
      "loss: 1.077445  [  224/  658]\n",
      "Training Loss (Epoch): 0.671137\n",
      "Validating...\n",
      "Validation Loss: 0.578892, Validation Accuracy: 81.82%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/25\n",
      "loss: 0.404861  [   90/  658]\n",
      "loss: 0.372721  [  180/  658]\n",
      "loss: 0.658370  [  270/  658]\n",
      "loss: 0.293203  [  360/  658]\n",
      "loss: 0.491457  [  450/  658]\n",
      "loss: 0.406250  [  540/  658]\n",
      "loss: 0.333586  [  630/  658]\n",
      "loss: 0.277093  [  224/  658]\n",
      "Training Loss (Epoch): 0.404693\n",
      "Validating...\n",
      "Validation Loss: 0.635541, Validation Accuracy: 78.79%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 7/25\n",
      "loss: 0.251608  [   90/  658]\n",
      "loss: 0.353516  [  180/  658]\n",
      "loss: 0.166420  [  270/  658]\n",
      "loss: 0.387506  [  360/  658]\n",
      "loss: 0.305417  [  450/  658]\n",
      "loss: 0.257546  [  540/  658]\n",
      "loss: 0.426014  [  630/  658]\n",
      "loss: 0.213104  [  224/  658]\n",
      "Training Loss (Epoch): 0.295141\n",
      "Validating...\n",
      "Validation Loss: 0.623150, Validation Accuracy: 79.39%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 8/25\n",
      "loss: 0.370829  [   90/  658]\n",
      "loss: 0.313435  [  180/  658]\n",
      "loss: 0.220496  [  270/  658]\n",
      "loss: 0.256302  [  360/  658]\n",
      "loss: 0.162690  [  450/  658]\n",
      "loss: 0.452480  [  540/  658]\n",
      "loss: 0.135720  [  630/  658]\n",
      "loss: 0.304935  [  224/  658]\n",
      "Training Loss (Epoch): 0.277111\n",
      "Validating...\n",
      "Validation Loss: 0.326884, Validation Accuracy: 88.48%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 9/25\n",
      "loss: 0.205547  [   90/  658]\n",
      "loss: 0.244468  [  180/  658]\n",
      "loss: 0.117867  [  270/  658]\n",
      "loss: 0.234780  [  360/  658]\n",
      "loss: 0.179297  [  450/  658]\n",
      "loss: 0.264377  [  540/  658]\n",
      "loss: 0.133970  [  630/  658]\n",
      "loss: 0.312465  [  224/  658]\n",
      "Training Loss (Epoch): 0.211596\n",
      "Validating...\n",
      "Validation Loss: 0.303759, Validation Accuracy: 90.91%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 10/25\n",
      "loss: 0.171314  [   90/  658]\n",
      "loss: 0.116993  [  180/  658]\n",
      "loss: 0.225590  [  270/  658]\n",
      "loss: 0.129052  [  360/  658]\n",
      "loss: 0.182412  [  450/  658]\n",
      "loss: 0.150298  [  540/  658]\n",
      "loss: 0.193235  [  630/  658]\n",
      "loss: 0.068810  [  224/  658]\n",
      "Training Loss (Epoch): 0.154713\n",
      "Validating...\n",
      "Validation Loss: 0.303676, Validation Accuracy: 90.91%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 11/25\n",
      "loss: 0.228585  [   90/  658]\n",
      "loss: 0.142851  [  180/  658]\n",
      "loss: 0.121743  [  270/  658]\n",
      "loss: 0.189369  [  360/  658]\n",
      "loss: 0.167795  [  450/  658]\n",
      "loss: 0.196165  [  540/  658]\n",
      "loss: 0.094618  [  630/  658]\n",
      "loss: 0.191119  [  224/  658]\n",
      "Training Loss (Epoch): 0.166531\n",
      "Validating...\n",
      "Validation Loss: 0.297951, Validation Accuracy: 90.91%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 12/25\n",
      "loss: 0.218678  [   90/  658]\n",
      "loss: 0.134286  [  180/  658]\n",
      "loss: 0.172225  [  270/  658]\n",
      "loss: 0.167794  [  360/  658]\n",
      "loss: 0.090491  [  450/  658]\n",
      "loss: 0.193323  [  540/  658]\n",
      "loss: 0.126839  [  630/  658]\n",
      "loss: 0.014919  [  224/  658]\n",
      "Training Loss (Epoch): 0.139819\n",
      "Validating...\n",
      "Validation Loss: 0.296862, Validation Accuracy: 90.91%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 13/25\n",
      "loss: 0.100674  [   90/  658]\n",
      "loss: 0.206396  [  180/  658]\n",
      "loss: 0.131319  [  270/  658]\n",
      "loss: 0.161758  [  360/  658]\n",
      "loss: 0.141594  [  450/  658]\n",
      "loss: 0.191057  [  540/  658]\n",
      "loss: 0.124508  [  630/  658]\n",
      "loss: 0.232886  [  224/  658]\n",
      "Training Loss (Epoch): 0.161274\n",
      "Validating...\n",
      "Validation Loss: 0.296184, Validation Accuracy: 90.30%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 14/25\n",
      "loss: 0.054536  [   90/  658]\n",
      "loss: 0.153226  [  180/  658]\n",
      "loss: 0.211859  [  270/  658]\n",
      "loss: 0.161207  [  360/  658]\n",
      "loss: 0.169594  [  450/  658]\n",
      "loss: 0.127145  [  540/  658]\n",
      "loss: 0.117101  [  630/  658]\n",
      "loss: 0.364417  [  224/  658]\n",
      "Training Loss (Epoch): 0.169886\n",
      "Validating...\n",
      "Validation Loss: 0.295453, Validation Accuracy: 90.30%\n",
      "Learning Rate: [1e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 7\n",
      "Epoch 1/25\n",
      "loss: 2.442672  [   90/  670]\n",
      "loss: 2.400580  [  180/  670]\n",
      "loss: 2.215564  [  270/  670]\n",
      "loss: 2.242438  [  360/  670]\n",
      "loss: 2.073943  [  450/  670]\n",
      "loss: 2.036684  [  540/  670]\n",
      "loss: 1.899392  [  630/  670]\n",
      "loss: 1.956895  [  320/  670]\n",
      "Training Loss (Epoch): 2.158521\n",
      "Validating...\n",
      "Validation Loss: 2.085044, Validation Accuracy: 39.88%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/25\n",
      "loss: 2.051892  [   90/  670]\n",
      "loss: 1.861360  [  180/  670]\n",
      "loss: 1.645059  [  270/  670]\n",
      "loss: 1.345082  [  360/  670]\n",
      "loss: 1.312291  [  450/  670]\n",
      "loss: 1.547129  [  540/  670]\n",
      "loss: 1.161724  [  630/  670]\n",
      "loss: 1.394283  [  320/  670]\n",
      "Training Loss (Epoch): 1.539852\n",
      "Validating...\n",
      "Validation Loss: 1.157721, Validation Accuracy: 63.10%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/25\n",
      "loss: 0.998332  [   90/  670]\n",
      "loss: 1.024957  [  180/  670]\n",
      "loss: 0.931698  [  270/  670]\n",
      "loss: 0.717717  [  360/  670]\n",
      "loss: 0.823141  [  450/  670]\n",
      "loss: 0.792568  [  540/  670]\n",
      "loss: 0.996850  [  630/  670]\n",
      "loss: 0.764389  [  320/  670]\n",
      "Training Loss (Epoch): 0.881207\n",
      "Validating...\n",
      "Validation Loss: 1.215471, Validation Accuracy: 60.12%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/25\n",
      "loss: 0.966306  [   90/  670]\n",
      "loss: 0.571720  [  180/  670]\n",
      "loss: 0.905169  [  270/  670]\n",
      "loss: 0.929819  [  360/  670]\n",
      "loss: 0.970127  [  450/  670]\n",
      "loss: 0.666264  [  540/  670]\n",
      "loss: 0.636734  [  630/  670]\n",
      "loss: 0.617124  [  320/  670]\n",
      "Training Loss (Epoch): 0.782908\n",
      "Validating...\n",
      "Validation Loss: 0.802427, Validation Accuracy: 72.62%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 5/25\n",
      "loss: 0.505107  [   90/  670]\n",
      "loss: 0.342580  [  180/  670]\n",
      "loss: 0.474974  [  270/  670]\n",
      "loss: 0.413229  [  360/  670]\n",
      "loss: 0.618040  [  450/  670]\n",
      "loss: 0.465205  [  540/  670]\n",
      "loss: 0.333213  [  630/  670]\n",
      "loss: 0.836859  [  320/  670]\n",
      "Training Loss (Epoch): 0.498651\n",
      "Validating...\n",
      "Validation Loss: 0.557356, Validation Accuracy: 77.98%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 6/25\n",
      "loss: 0.351234  [   90/  670]\n",
      "loss: 0.409332  [  180/  670]\n",
      "loss: 0.327253  [  270/  670]\n",
      "loss: 0.411688  [  360/  670]\n",
      "loss: 0.351147  [  450/  670]\n",
      "loss: 0.288047  [  540/  670]\n",
      "loss: 0.334377  [  630/  670]\n",
      "loss: 0.418356  [  320/  670]\n",
      "Training Loss (Epoch): 0.361429\n",
      "Validating...\n",
      "Validation Loss: 0.484766, Validation Accuracy: 80.95%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 7/25\n",
      "loss: 0.293838  [   90/  670]\n",
      "loss: 0.287611  [  180/  670]\n",
      "loss: 0.294703  [  270/  670]\n",
      "loss: 0.297055  [  360/  670]\n",
      "loss: 0.282230  [  450/  670]\n",
      "loss: 0.200416  [  540/  670]\n",
      "loss: 0.267454  [  630/  670]\n",
      "loss: 0.310168  [  320/  670]\n",
      "Training Loss (Epoch): 0.279184\n",
      "Validating...\n",
      "Validation Loss: 0.564801, Validation Accuracy: 82.74%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 8/25\n",
      "loss: 0.207334  [   90/  670]\n",
      "loss: 0.140691  [  180/  670]\n",
      "loss: 0.193323  [  270/  670]\n",
      "loss: 0.199312  [  360/  670]\n",
      "loss: 0.283404  [  450/  670]\n",
      "loss: 0.267480  [  540/  670]\n",
      "loss: 0.228842  [  630/  670]\n",
      "loss: 0.461095  [  320/  670]\n",
      "Training Loss (Epoch): 0.247685\n",
      "Validating...\n",
      "Validation Loss: 0.499100, Validation Accuracy: 84.52%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 9/25\n",
      "loss: 0.243681  [   90/  670]\n",
      "loss: 0.102266  [  180/  670]\n",
      "loss: 0.180481  [  270/  670]\n",
      "loss: 0.180227  [  360/  670]\n",
      "loss: 0.221840  [  450/  670]\n",
      "loss: 0.169479  [  540/  670]\n",
      "loss: 0.204788  [  630/  670]\n",
      "loss: 0.351683  [  320/  670]\n",
      "Training Loss (Epoch): 0.206806\n",
      "Validating...\n",
      "Validation Loss: 0.509686, Validation Accuracy: 82.14%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 8\n",
      "Epoch 1/25\n",
      "loss: 2.446386  [   90/  644]\n",
      "loss: 2.323192  [  180/  644]\n",
      "loss: 2.242292  [  270/  644]\n",
      "loss: 2.382055  [  360/  644]\n",
      "loss: 2.287979  [  450/  644]\n",
      "loss: 2.247993  [  540/  644]\n",
      "loss: 2.119457  [  630/  644]\n",
      "loss: 2.136231  [  112/  644]\n",
      "Training Loss (Epoch): 2.273198\n",
      "Validating...\n",
      "Validation Loss: 2.192192, Validation Accuracy: 16.05%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/25\n",
      "loss: 2.142704  [   90/  644]\n",
      "loss: 2.058408  [  180/  644]\n",
      "loss: 1.854066  [  270/  644]\n",
      "loss: 1.728938  [  360/  644]\n",
      "loss: 1.611232  [  450/  644]\n",
      "loss: 1.791504  [  540/  644]\n",
      "loss: 1.685577  [  630/  644]\n",
      "loss: 1.145999  [  112/  644]\n",
      "Training Loss (Epoch): 1.752303\n",
      "Validating...\n",
      "Validation Loss: 1.842498, Validation Accuracy: 37.65%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/25\n",
      "loss: 1.339493  [   90/  644]\n",
      "loss: 1.476897  [  180/  644]\n",
      "loss: 1.404249  [  270/  644]\n",
      "loss: 1.253493  [  360/  644]\n",
      "loss: 1.149008  [  450/  644]\n",
      "loss: 1.215856  [  540/  644]\n",
      "loss: 0.899154  [  630/  644]\n",
      "loss: 1.495333  [  112/  644]\n",
      "Training Loss (Epoch): 1.279185\n",
      "Validating...\n",
      "Validation Loss: 2.298679, Validation Accuracy: 40.12%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/25\n",
      "loss: 2.219882  [   90/  644]\n",
      "loss: 0.888262  [  180/  644]\n",
      "loss: 0.882869  [  270/  644]\n",
      "loss: 1.138612  [  360/  644]\n",
      "loss: 1.239166  [  450/  644]\n",
      "loss: 1.172056  [  540/  644]\n",
      "loss: 1.022754  [  630/  644]\n",
      "loss: 1.375921  [  112/  644]\n",
      "Training Loss (Epoch): 1.242440\n",
      "Validating...\n",
      "Validation Loss: 1.022896, Validation Accuracy: 64.20%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/25\n",
      "loss: 0.751754  [   90/  644]\n",
      "loss: 0.809565  [  180/  644]\n",
      "loss: 0.611389  [  270/  644]\n",
      "loss: 0.781767  [  360/  644]\n",
      "loss: 0.452104  [  450/  644]\n",
      "loss: 0.678699  [  540/  644]\n",
      "loss: 0.556459  [  630/  644]\n",
      "loss: 0.701593  [  112/  644]\n",
      "Training Loss (Epoch): 0.667916\n",
      "Validating...\n",
      "Validation Loss: 0.783262, Validation Accuracy: 79.01%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/25\n",
      "loss: 0.403395  [   90/  644]\n",
      "loss: 0.725206  [  180/  644]\n",
      "loss: 0.589667  [  270/  644]\n",
      "loss: 0.327537  [  360/  644]\n",
      "loss: 0.649154  [  450/  644]\n",
      "loss: 0.538544  [  540/  644]\n",
      "loss: 0.615034  [  630/  644]\n",
      "loss: 1.269580  [  112/  644]\n",
      "Training Loss (Epoch): 0.639765\n",
      "Validating...\n",
      "Validation Loss: 0.675511, Validation Accuracy: 72.84%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 7/25\n",
      "loss: 0.649111  [   90/  644]\n",
      "loss: 0.409249  [  180/  644]\n",
      "loss: 0.535790  [  270/  644]\n",
      "loss: 0.446378  [  360/  644]\n",
      "loss: 0.494553  [  450/  644]\n",
      "loss: 0.268525  [  540/  644]\n",
      "loss: 0.377765  [  630/  644]\n",
      "loss: 0.428883  [  112/  644]\n",
      "Training Loss (Epoch): 0.451282\n",
      "Validating...\n",
      "Validation Loss: 0.544671, Validation Accuracy: 82.72%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 8/25\n",
      "loss: 0.275343  [   90/  644]\n",
      "loss: 0.313344  [  180/  644]\n",
      "loss: 0.283144  [  270/  644]\n",
      "loss: 0.177023  [  360/  644]\n",
      "loss: 0.310068  [  450/  644]\n",
      "loss: 0.420696  [  540/  644]\n",
      "loss: 0.206053  [  630/  644]\n",
      "loss: 0.088793  [  112/  644]\n",
      "Training Loss (Epoch): 0.259308\n",
      "Validating...\n",
      "Validation Loss: 0.414714, Validation Accuracy: 85.80%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 9/25\n",
      "loss: 0.230694  [   90/  644]\n",
      "loss: 0.228228  [  180/  644]\n",
      "loss: 0.121607  [  270/  644]\n",
      "loss: 0.183757  [  360/  644]\n",
      "loss: 0.142338  [  450/  644]\n",
      "loss: 0.340599  [  540/  644]\n",
      "loss: 0.165638  [  630/  644]\n",
      "loss: 0.184363  [  112/  644]\n",
      "Training Loss (Epoch): 0.199653\n",
      "Validating...\n",
      "Validation Loss: 0.404629, Validation Accuracy: 86.42%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 10/25\n",
      "loss: 0.118063  [   90/  644]\n",
      "loss: 0.158232  [  180/  644]\n",
      "loss: 0.219455  [  270/  644]\n",
      "loss: 0.202422  [  360/  644]\n",
      "loss: 0.129540  [  450/  644]\n",
      "loss: 0.143772  [  540/  644]\n",
      "loss: 0.112788  [  630/  644]\n",
      "loss: 0.223641  [  112/  644]\n",
      "Training Loss (Epoch): 0.163489\n",
      "Validating...\n",
      "Validation Loss: 0.390551, Validation Accuracy: 85.80%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 11/25\n",
      "loss: 0.140687  [   90/  644]\n",
      "loss: 0.203447  [  180/  644]\n",
      "loss: 0.128537  [  270/  644]\n",
      "loss: 0.182097  [  360/  644]\n",
      "loss: 0.154367  [  450/  644]\n",
      "loss: 0.189492  [  540/  644]\n",
      "loss: 0.145919  [  630/  644]\n",
      "loss: 0.544927  [  112/  644]\n",
      "Training Loss (Epoch): 0.211184\n",
      "Validating...\n",
      "Validation Loss: 0.367057, Validation Accuracy: 88.27%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 12/25\n",
      "loss: 0.248827  [   90/  644]\n",
      "loss: 0.111278  [  180/  644]\n",
      "loss: 0.081046  [  270/  644]\n",
      "loss: 0.166967  [  360/  644]\n",
      "loss: 0.076781  [  450/  644]\n",
      "loss: 0.087308  [  540/  644]\n",
      "loss: 0.202048  [  630/  644]\n",
      "loss: 0.223401  [  112/  644]\n",
      "Training Loss (Epoch): 0.149707\n",
      "Validating...\n",
      "Validation Loss: 0.367250, Validation Accuracy: 88.27%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 13/25\n",
      "loss: 0.189766  [   90/  644]\n",
      "loss: 0.169119  [  180/  644]\n",
      "loss: 0.117139  [  270/  644]\n",
      "loss: 0.130273  [  360/  644]\n",
      "loss: 0.108463  [  450/  644]\n",
      "loss: 0.133459  [  540/  644]\n",
      "loss: 0.126182  [  630/  644]\n",
      "loss: 0.168953  [  112/  644]\n",
      "Training Loss (Epoch): 0.142919\n",
      "Validating...\n",
      "Validation Loss: 0.367094, Validation Accuracy: 88.89%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 14/25\n",
      "loss: 0.190729  [   90/  644]\n",
      "loss: 0.139390  [  180/  644]\n",
      "loss: 0.164858  [  270/  644]\n",
      "loss: 0.117194  [  360/  644]\n",
      "loss: 0.220011  [  450/  644]\n",
      "loss: 0.133854  [  540/  644]\n",
      "loss: 0.107756  [  630/  644]\n",
      "loss: 0.139586  [  112/  644]\n",
      "Training Loss (Epoch): 0.151672\n",
      "Validating...\n",
      "Validation Loss: 0.366412, Validation Accuracy: 88.89%\n",
      "Learning Rate: [1e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 9\n",
      "Epoch 1/25\n",
      "loss: 2.441516  [   90/  652]\n",
      "loss: 2.285738  [  180/  652]\n",
      "loss: 2.263248  [  270/  652]\n",
      "loss: 2.072619  [  360/  652]\n",
      "loss: 2.081652  [  450/  652]\n",
      "loss: 1.985914  [  540/  652]\n",
      "loss: 1.897464  [  630/  652]\n",
      "loss: 1.604900  [  176/  652]\n",
      "Training Loss (Epoch): 2.079131\n",
      "Validating...\n",
      "Validation Loss: 1.997595, Validation Accuracy: 56.71%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/25\n",
      "loss: 2.079502  [   90/  652]\n",
      "loss: 1.778338  [  180/  652]\n",
      "loss: 1.311827  [  270/  652]\n",
      "loss: 1.078448  [  360/  652]\n",
      "loss: 1.361081  [  450/  652]\n",
      "loss: 1.201344  [  540/  652]\n",
      "loss: 1.212879  [  630/  652]\n",
      "loss: 1.958486  [  176/  652]\n",
      "Training Loss (Epoch): 1.497738\n",
      "Validating...\n",
      "Validation Loss: 1.148563, Validation Accuracy: 57.93%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/25\n",
      "loss: 1.116727  [   90/  652]\n",
      "loss: 1.318756  [  180/  652]\n",
      "loss: 1.376944  [  270/  652]\n",
      "loss: 1.139955  [  360/  652]\n",
      "loss: 0.948899  [  450/  652]\n",
      "loss: 0.711124  [  540/  652]\n",
      "loss: 0.894756  [  630/  652]\n",
      "loss: 0.547653  [  176/  652]\n",
      "Training Loss (Epoch): 1.006852\n",
      "Validating...\n",
      "Validation Loss: 0.920069, Validation Accuracy: 71.34%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/25\n",
      "loss: 0.914573  [   90/  652]\n",
      "loss: 0.508627  [  180/  652]\n",
      "loss: 0.952957  [  270/  652]\n",
      "loss: 0.539907  [  360/  652]\n",
      "loss: 0.780530  [  450/  652]\n",
      "loss: 0.552869  [  540/  652]\n",
      "loss: 0.700289  [  630/  652]\n",
      "loss: 1.420298  [  176/  652]\n",
      "Training Loss (Epoch): 0.796256\n",
      "Validating...\n",
      "Validation Loss: 0.795513, Validation Accuracy: 70.12%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/25\n",
      "loss: 0.624291  [   90/  652]\n",
      "loss: 0.546536  [  180/  652]\n",
      "loss: 0.378320  [  270/  652]\n",
      "loss: 0.396611  [  360/  652]\n",
      "loss: 0.558217  [  450/  652]\n",
      "loss: 0.796615  [  540/  652]\n",
      "loss: 0.416314  [  630/  652]\n",
      "loss: 0.313169  [  176/  652]\n",
      "Training Loss (Epoch): 0.503759\n",
      "Validating...\n",
      "Validation Loss: 0.492940, Validation Accuracy: 84.15%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/25\n",
      "loss: 0.346940  [   90/  652]\n",
      "loss: 0.262139  [  180/  652]\n",
      "loss: 0.579769  [  270/  652]\n",
      "loss: 0.299619  [  360/  652]\n",
      "loss: 0.374019  [  450/  652]\n",
      "loss: 0.346552  [  540/  652]\n",
      "loss: 0.454265  [  630/  652]\n",
      "loss: 0.259218  [  176/  652]\n",
      "Training Loss (Epoch): 0.365315\n",
      "Validating...\n",
      "Validation Loss: 0.358202, Validation Accuracy: 87.80%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 7/25\n",
      "loss: 0.284072  [   90/  652]\n",
      "loss: 0.206343  [  180/  652]\n",
      "loss: 0.257189  [  270/  652]\n",
      "loss: 0.303239  [  360/  652]\n",
      "loss: 0.181111  [  450/  652]\n",
      "loss: 0.180622  [  540/  652]\n",
      "loss: 0.172455  [  630/  652]\n",
      "loss: 0.254793  [  176/  652]\n",
      "Training Loss (Epoch): 0.229978\n",
      "Validating...\n",
      "Validation Loss: 0.353746, Validation Accuracy: 84.76%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 8/25\n",
      "loss: 0.188258  [   90/  652]\n",
      "loss: 0.132496  [  180/  652]\n",
      "loss: 0.153247  [  270/  652]\n",
      "loss: 0.180827  [  360/  652]\n",
      "loss: 0.156005  [  450/  652]\n",
      "loss: 0.174081  [  540/  652]\n",
      "loss: 0.156321  [  630/  652]\n",
      "loss: 0.043675  [  176/  652]\n",
      "Training Loss (Epoch): 0.148114\n",
      "Validating...\n",
      "Validation Loss: 0.322005, Validation Accuracy: 87.20%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 9/25\n",
      "loss: 0.097610  [   90/  652]\n",
      "loss: 0.155820  [  180/  652]\n",
      "loss: 0.166067  [  270/  652]\n",
      "loss: 0.078817  [  360/  652]\n",
      "loss: 0.108686  [  450/  652]\n",
      "loss: 0.085626  [  540/  652]\n",
      "loss: 0.115542  [  630/  652]\n",
      "loss: 0.079060  [  176/  652]\n",
      "Training Loss (Epoch): 0.110903\n",
      "Validating...\n",
      "Validation Loss: 0.314226, Validation Accuracy: 90.24%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 10/25\n",
      "loss: 0.059010  [   90/  652]\n",
      "loss: 0.109300  [  180/  652]\n",
      "loss: 0.133176  [  270/  652]\n",
      "loss: 0.114027  [  360/  652]\n",
      "loss: 0.062896  [  450/  652]\n",
      "loss: 0.106733  [  540/  652]\n",
      "loss: 0.065180  [  630/  652]\n",
      "loss: 0.108220  [  176/  652]\n",
      "Training Loss (Epoch): 0.094818\n",
      "Validating...\n",
      "Validation Loss: 0.311079, Validation Accuracy: 90.24%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 11/25\n",
      "loss: 0.058940  [   90/  652]\n",
      "loss: 0.113862  [  180/  652]\n",
      "loss: 0.108932  [  270/  652]\n",
      "loss: 0.050374  [  360/  652]\n",
      "loss: 0.092003  [  450/  652]\n",
      "loss: 0.091494  [  540/  652]\n",
      "loss: 0.098674  [  630/  652]\n",
      "loss: 0.078425  [  176/  652]\n",
      "Training Loss (Epoch): 0.086588\n",
      "Validating...\n",
      "Validation Loss: 0.303566, Validation Accuracy: 90.24%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 12/25\n",
      "loss: 0.065566  [   90/  652]\n",
      "loss: 0.108044  [  180/  652]\n",
      "loss: 0.080219  [  270/  652]\n",
      "loss: 0.098065  [  360/  652]\n",
      "loss: 0.068990  [  450/  652]\n",
      "loss: 0.142919  [  540/  652]\n",
      "loss: 0.027789  [  630/  652]\n",
      "loss: 0.155082  [  176/  652]\n",
      "Training Loss (Epoch): 0.093334\n",
      "Validating...\n",
      "Validation Loss: 0.303524, Validation Accuracy: 90.24%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 13/25\n",
      "loss: 0.038234  [   90/  652]\n",
      "loss: 0.083132  [  180/  652]\n",
      "loss: 0.086336  [  270/  652]\n",
      "loss: 0.170547  [  360/  652]\n",
      "loss: 0.058415  [  450/  652]\n",
      "loss: 0.079442  [  540/  652]\n",
      "loss: 0.064001  [  630/  652]\n",
      "loss: 0.083400  [  176/  652]\n",
      "Training Loss (Epoch): 0.082938\n",
      "Validating...\n",
      "Validation Loss: 0.303121, Validation Accuracy: 90.24%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 14/25\n",
      "loss: 0.116911  [   90/  652]\n",
      "loss: 0.096691  [  180/  652]\n",
      "loss: 0.037526  [  270/  652]\n",
      "loss: 0.109837  [  360/  652]\n",
      "loss: 0.087307  [  450/  652]\n",
      "loss: 0.038228  [  540/  652]\n",
      "loss: 0.089148  [  630/  652]\n",
      "loss: 0.073627  [  176/  652]\n",
      "Training Loss (Epoch): 0.081159\n",
      "Validating...\n",
      "Validation Loss: 0.303078, Validation Accuracy: 90.24%\n",
      "Learning Rate: [1e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 10\n",
      "Epoch 1/25\n",
      "loss: 2.366863  [   90/  669]\n",
      "loss: 2.281436  [  180/  669]\n",
      "loss: 2.331274  [  270/  669]\n",
      "loss: 2.223038  [  360/  669]\n",
      "loss: 2.082799  [  450/  669]\n",
      "loss: 2.056964  [  540/  669]\n",
      "loss: 2.059032  [  630/  669]\n",
      "loss: 2.096273  [  312/  669]\n",
      "Training Loss (Epoch): 2.187210\n",
      "Validating...\n",
      "Validation Loss: 2.079493, Validation Accuracy: 36.90%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/25\n",
      "loss: 2.092246  [   90/  669]\n",
      "loss: 1.837864  [  180/  669]\n",
      "loss: 1.828006  [  270/  669]\n",
      "loss: 1.446622  [  360/  669]\n",
      "loss: 1.233796  [  450/  669]\n",
      "loss: 1.714031  [  540/  669]\n",
      "loss: 1.114075  [  630/  669]\n",
      "loss: 1.427907  [  312/  669]\n",
      "Training Loss (Epoch): 1.586818\n",
      "Validating...\n",
      "Validation Loss: 1.096672, Validation Accuracy: 63.10%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/25\n",
      "loss: 1.180609  [   90/  669]\n",
      "loss: 1.108736  [  180/  669]\n",
      "loss: 1.104523  [  270/  669]\n",
      "loss: 1.084452  [  360/  669]\n",
      "loss: 0.970873  [  450/  669]\n",
      "loss: 0.985576  [  540/  669]\n",
      "loss: 0.839755  [  630/  669]\n",
      "loss: 0.500046  [  312/  669]\n",
      "Training Loss (Epoch): 0.971821\n",
      "Validating...\n",
      "Validation Loss: 1.067704, Validation Accuracy: 67.86%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/25\n",
      "loss: 0.953631  [   90/  669]\n",
      "loss: 0.885835  [  180/  669]\n",
      "loss: 0.782862  [  270/  669]\n",
      "loss: 0.685457  [  360/  669]\n",
      "loss: 0.697590  [  450/  669]\n",
      "loss: 0.659611  [  540/  669]\n",
      "loss: 0.765427  [  630/  669]\n",
      "loss: 0.710372  [  312/  669]\n",
      "Training Loss (Epoch): 0.767598\n",
      "Validating...\n",
      "Validation Loss: 0.654226, Validation Accuracy: 78.57%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/25\n",
      "loss: 0.470272  [   90/  669]\n",
      "loss: 0.618059  [  180/  669]\n",
      "loss: 0.532656  [  270/  669]\n",
      "loss: 0.535015  [  360/  669]\n",
      "loss: 0.440443  [  450/  669]\n",
      "loss: 0.666892  [  540/  669]\n",
      "loss: 0.480847  [  630/  669]\n",
      "loss: 0.591166  [  312/  669]\n",
      "Training Loss (Epoch): 0.541919\n",
      "Validating...\n",
      "Validation Loss: 0.490922, Validation Accuracy: 80.95%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/25\n",
      "loss: 0.468904  [   90/  669]\n",
      "loss: 0.543227  [  180/  669]\n",
      "loss: 0.342040  [  270/  669]\n",
      "loss: 0.341276  [  360/  669]\n",
      "loss: 0.462898  [  450/  669]\n",
      "loss: 0.450321  [  540/  669]\n",
      "loss: 0.305203  [  630/  669]\n",
      "loss: 0.506265  [  312/  669]\n",
      "Training Loss (Epoch): 0.427517\n",
      "Validating...\n",
      "Validation Loss: 0.472681, Validation Accuracy: 83.93%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 7/25\n",
      "loss: 0.391039  [   90/  669]\n",
      "loss: 0.514392  [  180/  669]\n",
      "loss: 0.356482  [  270/  669]\n",
      "loss: 0.316008  [  360/  669]\n",
      "loss: 0.251579  [  450/  669]\n",
      "loss: 0.317907  [  540/  669]\n",
      "loss: 0.271303  [  630/  669]\n",
      "loss: 0.358447  [  312/  669]\n",
      "Training Loss (Epoch): 0.347145\n",
      "Validating...\n",
      "Validation Loss: 0.372557, Validation Accuracy: 86.31%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 8/25\n",
      "loss: 0.355417  [   90/  669]\n",
      "loss: 0.338741  [  180/  669]\n",
      "loss: 0.249362  [  270/  669]\n",
      "loss: 0.222178  [  360/  669]\n",
      "loss: 0.265132  [  450/  669]\n",
      "loss: 0.301210  [  540/  669]\n",
      "loss: 0.303089  [  630/  669]\n",
      "loss: 0.369851  [  312/  669]\n",
      "Training Loss (Epoch): 0.300623\n",
      "Validating...\n",
      "Validation Loss: 0.356216, Validation Accuracy: 86.31%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 9/25\n",
      "loss: 0.268928  [   90/  669]\n",
      "loss: 0.337501  [  180/  669]\n",
      "loss: 0.287491  [  270/  669]\n",
      "loss: 0.238571  [  360/  669]\n",
      "loss: 0.329232  [  450/  669]\n",
      "loss: 0.257632  [  540/  669]\n",
      "loss: 0.230979  [  630/  669]\n",
      "loss: 0.066495  [  312/  669]\n",
      "Training Loss (Epoch): 0.252104\n",
      "Validating...\n",
      "Validation Loss: 0.334500, Validation Accuracy: 85.71%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 10/25\n",
      "loss: 0.241968  [   90/  669]\n",
      "loss: 0.251075  [  180/  669]\n",
      "loss: 0.208303  [  270/  669]\n",
      "loss: 0.244858  [  360/  669]\n",
      "loss: 0.335452  [  450/  669]\n",
      "loss: 0.213836  [  540/  669]\n",
      "loss: 0.209241  [  630/  669]\n",
      "loss: 0.361271  [  312/  669]\n",
      "Training Loss (Epoch): 0.258250\n",
      "Validating...\n",
      "Validation Loss: 0.325296, Validation Accuracy: 85.71%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 11/25\n",
      "loss: 0.182623  [   90/  669]\n",
      "loss: 0.208564  [  180/  669]\n",
      "loss: 0.387018  [  270/  669]\n",
      "loss: 0.246886  [  360/  669]\n",
      "loss: 0.183330  [  450/  669]\n",
      "loss: 0.240307  [  540/  669]\n",
      "loss: 0.256260  [  630/  669]\n",
      "loss: 0.270685  [  312/  669]\n",
      "Training Loss (Epoch): 0.246959\n",
      "Validating...\n",
      "Validation Loss: 0.324712, Validation Accuracy: 86.90%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 12/25\n",
      "loss: 0.096482  [   90/  669]\n",
      "loss: 0.353188  [  180/  669]\n",
      "loss: 0.221455  [  270/  669]\n",
      "loss: 0.249841  [  360/  669]\n",
      "loss: 0.220723  [  450/  669]\n",
      "loss: 0.371783  [  540/  669]\n",
      "loss: 0.243254  [  630/  669]\n",
      "loss: 0.125160  [  312/  669]\n",
      "Training Loss (Epoch): 0.235236\n",
      "Validating...\n",
      "Validation Loss: 0.320466, Validation Accuracy: 87.50%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 13/25\n",
      "loss: 0.174018  [   90/  669]\n",
      "loss: 0.091679  [  180/  669]\n",
      "loss: 0.412531  [  270/  669]\n",
      "loss: 0.338435  [  360/  669]\n",
      "loss: 0.264892  [  450/  669]\n",
      "loss: 0.303913  [  540/  669]\n",
      "loss: 0.165280  [  630/  669]\n",
      "loss: 0.107705  [  312/  669]\n",
      "Training Loss (Epoch): 0.232307\n",
      "Validating...\n",
      "Validation Loss: 0.319094, Validation Accuracy: 87.50%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 14/25\n",
      "loss: 0.315661  [   90/  669]\n",
      "loss: 0.215010  [  180/  669]\n",
      "loss: 0.299816  [  270/  669]\n",
      "loss: 0.232720  [  360/  669]\n",
      "loss: 0.205903  [  450/  669]\n",
      "loss: 0.169533  [  540/  669]\n",
      "loss: 0.287922  [  630/  669]\n",
      "loss: 0.145525  [  312/  669]\n",
      "Training Loss (Epoch): 0.234011\n",
      "Validating...\n",
      "Validation Loss: 0.317616, Validation Accuracy: 87.50%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 15/25\n",
      "loss: 0.160218  [   90/  669]\n",
      "loss: 0.194080  [  180/  669]\n",
      "loss: 0.218981  [  270/  669]\n",
      "loss: 0.259529  [  360/  669]\n",
      "loss: 0.257321  [  450/  669]\n",
      "loss: 0.365908  [  540/  669]\n",
      "loss: 0.241258  [  630/  669]\n",
      "loss: 0.193296  [  312/  669]\n",
      "Training Loss (Epoch): 0.236324\n",
      "Validating...\n",
      "Validation Loss: 0.316063, Validation Accuracy: 87.50%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 16/25\n",
      "loss: 0.253783  [   90/  669]\n",
      "loss: 0.304569  [  180/  669]\n",
      "loss: 0.238933  [  270/  669]\n",
      "loss: 0.208895  [  360/  669]\n",
      "loss: 0.208206  [  450/  669]\n",
      "loss: 0.218781  [  540/  669]\n",
      "loss: 0.316708  [  630/  669]\n",
      "loss: 0.057751  [  312/  669]\n",
      "Training Loss (Epoch): 0.225953\n",
      "Validating...\n",
      "Validation Loss: 0.315120, Validation Accuracy: 87.50%\n",
      "Learning Rate: [1e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "\n",
      "Cross-Validation Results:\n",
      "Avg Training Loss: 0.594600\n",
      "Avg Validation Loss: 0.741242\n",
      "Avg Validation Accuracy: 87.88%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5946000657280446, 0.7412422964003469, 0.8788498316821757)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_tune(layer = 1, lr = 2e-4, weight_decay = 0.2, weights = \"DEFAULT\", drop = 0.8, batch_size = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1\n",
      "Epoch 1/25\n",
      "loss: 2.365685  [   70/  698]\n",
      "loss: 2.189179  [  210/  698]\n",
      "loss: 2.114712  [  350/  698]\n",
      "loss: 1.928397  [  490/  698]\n",
      "loss: 1.905750  [  630/  698]\n",
      "Training Loss (Epoch): 2.133061\n",
      "Validating...\n",
      "Validation Loss: 2.016626, Validation Accuracy: 40.00%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/25\n",
      "loss: 1.969156  [   70/  698]\n",
      "loss: 1.638966  [  210/  698]\n",
      "loss: 1.609162  [  350/  698]\n",
      "loss: 1.331521  [  490/  698]\n",
      "loss: 1.083152  [  630/  698]\n",
      "Training Loss (Epoch): 1.420270\n",
      "Validating...\n",
      "Validation Loss: 0.999652, Validation Accuracy: 68.57%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/25\n",
      "loss: 0.991948  [   70/  698]\n",
      "loss: 1.032357  [  210/  698]\n",
      "loss: 1.248400  [  350/  698]\n",
      "loss: 0.785337  [  490/  698]\n",
      "loss: 0.951132  [  630/  698]\n",
      "Training Loss (Epoch): 0.936630\n",
      "Validating...\n",
      "Validation Loss: 0.963571, Validation Accuracy: 67.43%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/25\n",
      "loss: 0.700760  [   70/  698]\n",
      "loss: 0.686056  [  210/  698]\n",
      "loss: 0.610208  [  350/  698]\n",
      "loss: 0.382017  [  490/  698]\n",
      "loss: 0.503731  [  630/  698]\n",
      "Training Loss (Epoch): 0.565402\n",
      "Validating...\n",
      "Validation Loss: 0.507500, Validation Accuracy: 85.71%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/25\n",
      "loss: 0.327314  [   70/  698]\n",
      "loss: 0.403102  [  210/  698]\n",
      "loss: 0.307863  [  350/  698]\n",
      "loss: 0.375139  [  490/  698]\n",
      "loss: 0.488152  [  630/  698]\n",
      "Training Loss (Epoch): 0.331876\n",
      "Validating...\n",
      "Validation Loss: 0.420497, Validation Accuracy: 85.14%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/25\n",
      "loss: 0.270647  [   70/  698]\n",
      "loss: 0.225824  [  210/  698]\n",
      "loss: 0.154205  [  350/  698]\n",
      "loss: 0.231866  [  490/  698]\n",
      "loss: 0.155965  [  630/  698]\n",
      "Training Loss (Epoch): 0.220592\n",
      "Validating...\n",
      "Validation Loss: 0.456202, Validation Accuracy: 87.43%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 7/25\n",
      "loss: 0.219525  [   70/  698]\n",
      "loss: 0.066873  [  210/  698]\n",
      "loss: 0.103644  [  350/  698]\n",
      "loss: 0.219705  [  490/  698]\n",
      "loss: 0.076526  [  630/  698]\n",
      "Training Loss (Epoch): 0.132918\n",
      "Validating...\n",
      "Validation Loss: 0.273338, Validation Accuracy: 91.43%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 8/25\n",
      "loss: 0.058421  [   70/  698]\n",
      "loss: 0.075821  [  210/  698]\n",
      "loss: 0.089496  [  350/  698]\n",
      "loss: 0.181916  [  490/  698]\n",
      "loss: 0.041161  [  630/  698]\n",
      "Training Loss (Epoch): 0.090512\n",
      "Validating...\n",
      "Validation Loss: 0.276253, Validation Accuracy: 92.00%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 9/25\n",
      "loss: 0.025138  [   70/  698]\n",
      "loss: 0.026499  [  210/  698]\n",
      "loss: 0.094472  [  350/  698]\n",
      "loss: 0.075149  [  490/  698]\n",
      "loss: 0.071548  [  630/  698]\n",
      "Training Loss (Epoch): 0.070249\n",
      "Validating...\n",
      "Validation Loss: 0.263909, Validation Accuracy: 94.29%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 10/25\n",
      "loss: 0.063605  [   70/  698]\n",
      "loss: 0.076776  [  210/  698]\n",
      "loss: 0.008429  [  350/  698]\n",
      "loss: 0.042496  [  490/  698]\n",
      "loss: 0.014609  [  630/  698]\n",
      "Training Loss (Epoch): 0.062083\n",
      "Validating...\n",
      "Validation Loss: 0.255523, Validation Accuracy: 94.86%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 11/25\n",
      "loss: 0.074930  [   70/  698]\n",
      "loss: 0.075868  [  210/  698]\n",
      "loss: 0.013197  [  350/  698]\n",
      "loss: 0.108913  [  490/  698]\n",
      "loss: 0.065353  [  630/  698]\n",
      "Training Loss (Epoch): 0.059386\n",
      "Validating...\n",
      "Validation Loss: 0.254719, Validation Accuracy: 94.86%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 12/25\n",
      "loss: 0.019111  [   70/  698]\n",
      "loss: 0.027263  [  210/  698]\n",
      "loss: 0.032280  [  350/  698]\n",
      "loss: 0.087630  [  490/  698]\n",
      "loss: 0.081995  [  630/  698]\n",
      "Training Loss (Epoch): 0.058714\n",
      "Validating...\n",
      "Validation Loss: 0.254014, Validation Accuracy: 94.86%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 13/25\n",
      "loss: 0.035659  [   70/  698]\n",
      "loss: 0.067500  [  210/  698]\n",
      "loss: 0.039218  [  350/  698]\n",
      "loss: 0.047861  [  490/  698]\n",
      "loss: 0.055706  [  630/  698]\n",
      "Training Loss (Epoch): 0.057928\n",
      "Validating...\n",
      "Validation Loss: 0.253955, Validation Accuracy: 94.86%\n",
      "Learning Rate: [1e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 2\n",
      "Epoch 1/25\n",
      "loss: 2.310000  [   70/  710]\n",
      "loss: 2.159396  [  210/  710]\n",
      "loss: 2.054110  [  350/  710]\n",
      "loss: 1.917632  [  490/  710]\n",
      "loss: 1.839936  [  630/  710]\n",
      "loss: 1.963120  [  110/  710]\n",
      "Training Loss (Epoch): 2.028247\n",
      "Validating...\n",
      "Validation Loss: 1.856586, Validation Accuracy: 41.01%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/25\n",
      "loss: 1.827595  [   70/  710]\n",
      "loss: 1.362023  [  210/  710]\n",
      "loss: 1.106452  [  350/  710]\n",
      "loss: 0.896788  [  490/  710]\n",
      "loss: 1.208392  [  630/  710]\n",
      "loss: 1.117727  [  110/  710]\n",
      "Training Loss (Epoch): 1.214550\n",
      "Validating...\n",
      "Validation Loss: 1.198230, Validation Accuracy: 57.30%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/25\n",
      "loss: 1.136775  [   70/  710]\n",
      "loss: 0.742546  [  210/  710]\n",
      "loss: 0.636133  [  350/  710]\n",
      "loss: 0.608355  [  490/  710]\n",
      "loss: 0.611393  [  630/  710]\n",
      "loss: 0.747930  [  110/  710]\n",
      "Training Loss (Epoch): 0.777013\n",
      "Validating...\n",
      "Validation Loss: 0.735507, Validation Accuracy: 76.40%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/25\n",
      "loss: 0.507505  [   70/  710]\n",
      "loss: 0.420180  [  210/  710]\n",
      "loss: 0.492385  [  350/  710]\n",
      "loss: 0.503735  [  490/  710]\n",
      "loss: 0.384934  [  630/  710]\n",
      "loss: 0.846941  [  110/  710]\n",
      "Training Loss (Epoch): 0.486571\n",
      "Validating...\n",
      "Validation Loss: 0.905084, Validation Accuracy: 74.16%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/25\n",
      "loss: 0.478680  [   70/  710]\n",
      "loss: 0.470477  [  210/  710]\n",
      "loss: 0.587413  [  350/  710]\n",
      "loss: 0.637807  [  490/  710]\n",
      "loss: 0.533758  [  630/  710]\n",
      "loss: 0.869606  [  110/  710]\n",
      "Training Loss (Epoch): 0.556893\n",
      "Validating...\n",
      "Validation Loss: 0.580815, Validation Accuracy: 84.83%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 6/25\n",
      "loss: 0.223051  [   70/  710]\n",
      "loss: 0.469109  [  210/  710]\n",
      "loss: 0.419975  [  350/  710]\n",
      "loss: 0.211057  [  490/  710]\n",
      "loss: 0.196872  [  630/  710]\n",
      "loss: 0.038274  [  110/  710]\n",
      "Training Loss (Epoch): 0.289126\n",
      "Validating...\n",
      "Validation Loss: 0.481052, Validation Accuracy: 84.83%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 7/25\n",
      "loss: 0.309904  [   70/  710]\n",
      "loss: 0.213899  [  210/  710]\n",
      "loss: 0.142003  [  350/  710]\n",
      "loss: 0.181152  [  490/  710]\n",
      "loss: 0.057359  [  630/  710]\n",
      "loss: 0.557177  [  110/  710]\n",
      "Training Loss (Epoch): 0.205772\n",
      "Validating...\n",
      "Validation Loss: 0.374670, Validation Accuracy: 88.20%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 8/25\n",
      "loss: 0.084333  [   70/  710]\n",
      "loss: 0.142311  [  210/  710]\n",
      "loss: 0.273550  [  350/  710]\n",
      "loss: 0.222080  [  490/  710]\n",
      "loss: 0.093261  [  630/  710]\n",
      "loss: 0.021927  [  110/  710]\n",
      "Training Loss (Epoch): 0.143902\n",
      "Validating...\n",
      "Validation Loss: 0.568654, Validation Accuracy: 85.39%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 9/25\n",
      "loss: 0.056823  [   70/  710]\n",
      "loss: 0.348122  [  210/  710]\n",
      "loss: 0.128567  [  350/  710]\n",
      "loss: 0.124982  [  490/  710]\n",
      "loss: 0.127788  [  630/  710]\n",
      "loss: 0.021979  [  110/  710]\n",
      "Training Loss (Epoch): 0.142486\n",
      "Validating...\n",
      "Validation Loss: 0.423514, Validation Accuracy: 89.33%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 10/25\n",
      "loss: 0.092627  [   70/  710]\n",
      "loss: 0.075382  [  210/  710]\n",
      "loss: 0.195679  [  350/  710]\n",
      "loss: 0.149950  [  490/  710]\n",
      "loss: 0.082101  [  630/  710]\n",
      "loss: 0.002394  [  110/  710]\n",
      "Training Loss (Epoch): 0.092196\n",
      "Validating...\n",
      "Validation Loss: 0.374737, Validation Accuracy: 89.33%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 3\n",
      "Epoch 1/25\n",
      "loss: 2.564353  [   70/  740]\n",
      "loss: 2.370490  [  210/  740]\n",
      "loss: 2.314558  [  350/  740]\n",
      "loss: 2.163841  [  490/  740]\n",
      "loss: 2.039603  [  630/  740]\n",
      "loss: 2.026014  [  440/  740]\n",
      "Training Loss (Epoch): 2.190233\n",
      "Validating...\n",
      "Validation Loss: 2.005213, Validation Accuracy: 34.05%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/25\n",
      "loss: 1.799840  [   70/  740]\n",
      "loss: 1.632132  [  210/  740]\n",
      "loss: 1.286124  [  350/  740]\n",
      "loss: 1.537900  [  490/  740]\n",
      "loss: 1.282231  [  630/  740]\n",
      "loss: 0.841743  [  440/  740]\n",
      "Training Loss (Epoch): 1.401082\n",
      "Validating...\n",
      "Validation Loss: 1.240391, Validation Accuracy: 54.59%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/25\n",
      "loss: 0.630106  [   70/  740]\n",
      "loss: 0.700791  [  210/  740]\n",
      "loss: 0.734684  [  350/  740]\n",
      "loss: 0.689054  [  490/  740]\n",
      "loss: 0.821808  [  630/  740]\n",
      "loss: 0.788845  [  440/  740]\n",
      "Training Loss (Epoch): 0.782385\n",
      "Validating...\n",
      "Validation Loss: 0.750795, Validation Accuracy: 73.51%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/25\n",
      "loss: 0.524609  [   70/  740]\n",
      "loss: 0.375179  [  210/  740]\n",
      "loss: 0.806758  [  350/  740]\n",
      "loss: 0.525249  [  490/  740]\n",
      "loss: 0.644035  [  630/  740]\n",
      "loss: 0.417669  [  440/  740]\n",
      "Training Loss (Epoch): 0.534078\n",
      "Validating...\n",
      "Validation Loss: 0.626888, Validation Accuracy: 78.38%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/25\n",
      "loss: 0.576827  [   70/  740]\n",
      "loss: 0.501346  [  210/  740]\n",
      "loss: 0.410222  [  350/  740]\n",
      "loss: 0.234061  [  490/  740]\n",
      "loss: 0.287585  [  630/  740]\n",
      "loss: 0.437257  [  440/  740]\n",
      "Training Loss (Epoch): 0.344179\n",
      "Validating...\n",
      "Validation Loss: 0.707717, Validation Accuracy: 77.30%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 6/25\n",
      "loss: 0.178428  [   70/  740]\n",
      "loss: 0.256652  [  210/  740]\n",
      "loss: 0.201723  [  350/  740]\n",
      "loss: 0.221718  [  490/  740]\n",
      "loss: 0.185788  [  630/  740]\n",
      "loss: 0.213291  [  440/  740]\n",
      "Training Loss (Epoch): 0.223911\n",
      "Validating...\n",
      "Validation Loss: 0.461355, Validation Accuracy: 84.86%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 7/25\n",
      "loss: 0.167635  [   70/  740]\n",
      "loss: 0.080823  [  210/  740]\n",
      "loss: 0.214550  [  350/  740]\n",
      "loss: 0.085360  [  490/  740]\n",
      "loss: 0.076341  [  630/  740]\n",
      "loss: 0.038529  [  440/  740]\n",
      "Training Loss (Epoch): 0.151117\n",
      "Validating...\n",
      "Validation Loss: 0.496895, Validation Accuracy: 84.86%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 8/25\n",
      "loss: 0.235029  [   70/  740]\n",
      "loss: 0.061268  [  210/  740]\n",
      "loss: 0.157526  [  350/  740]\n",
      "loss: 0.138880  [  490/  740]\n",
      "loss: 0.037300  [  630/  740]\n",
      "loss: 0.072116  [  440/  740]\n",
      "Training Loss (Epoch): 0.122174\n",
      "Validating...\n",
      "Validation Loss: 0.444174, Validation Accuracy: 84.86%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 9/25\n",
      "loss: 0.087691  [   70/  740]\n",
      "loss: 0.035448  [  210/  740]\n",
      "loss: 0.145932  [  350/  740]\n",
      "loss: 0.027084  [  490/  740]\n",
      "loss: 0.125297  [  630/  740]\n",
      "loss: 0.130862  [  440/  740]\n",
      "Training Loss (Epoch): 0.105177\n",
      "Validating...\n",
      "Validation Loss: 0.381955, Validation Accuracy: 84.86%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 10/25\n",
      "loss: 0.076444  [   70/  740]\n",
      "loss: 0.167986  [  210/  740]\n",
      "loss: 0.038264  [  350/  740]\n",
      "loss: 0.085237  [  490/  740]\n",
      "loss: 0.028847  [  630/  740]\n",
      "loss: 0.164546  [  440/  740]\n",
      "Training Loss (Epoch): 0.083884\n",
      "Validating...\n",
      "Validation Loss: 0.367788, Validation Accuracy: 87.03%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 11/25\n",
      "loss: 0.157402  [   70/  740]\n",
      "loss: 0.071763  [  210/  740]\n",
      "loss: 0.060237  [  350/  740]\n",
      "loss: 0.045531  [  490/  740]\n",
      "loss: 0.073884  [  630/  740]\n",
      "loss: 0.017830  [  440/  740]\n",
      "Training Loss (Epoch): 0.081291\n",
      "Validating...\n",
      "Validation Loss: 0.368391, Validation Accuracy: 87.03%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 12/25\n",
      "loss: 0.114183  [   70/  740]\n",
      "loss: 0.126002  [  210/  740]\n",
      "loss: 0.033582  [  350/  740]\n",
      "loss: 0.140805  [  490/  740]\n",
      "loss: 0.084571  [  630/  740]\n",
      "loss: 0.253585  [  440/  740]\n",
      "Training Loss (Epoch): 0.088184\n",
      "Validating...\n",
      "Validation Loss: 0.365439, Validation Accuracy: 87.57%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 13/25\n",
      "loss: 0.090664  [   70/  740]\n",
      "loss: 0.060280  [  210/  740]\n",
      "loss: 0.058954  [  350/  740]\n",
      "loss: 0.081150  [  490/  740]\n",
      "loss: 0.081929  [  630/  740]\n",
      "loss: 0.233063  [  440/  740]\n",
      "Training Loss (Epoch): 0.091173\n",
      "Validating...\n",
      "Validation Loss: 0.361775, Validation Accuracy: 87.03%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 14/25\n",
      "loss: 0.044510  [   70/  740]\n",
      "loss: 0.038249  [  210/  740]\n",
      "loss: 0.082460  [  350/  740]\n",
      "loss: 0.082586  [  490/  740]\n",
      "loss: 0.110291  [  630/  740]\n",
      "loss: 0.021575  [  440/  740]\n",
      "Training Loss (Epoch): 0.072406\n",
      "Validating...\n",
      "Validation Loss: 0.359235, Validation Accuracy: 87.03%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 15/25\n",
      "loss: 0.084803  [   70/  740]\n",
      "loss: 0.142691  [  210/  740]\n",
      "loss: 0.064634  [  350/  740]\n",
      "loss: 0.042144  [  490/  740]\n",
      "loss: 0.107984  [  630/  740]\n",
      "loss: 0.093913  [  440/  740]\n",
      "Training Loss (Epoch): 0.087308\n",
      "Validating...\n",
      "Validation Loss: 0.357035, Validation Accuracy: 87.03%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 16/25\n",
      "loss: 0.036040  [   70/  740]\n",
      "loss: 0.047765  [  210/  740]\n",
      "loss: 0.067503  [  350/  740]\n",
      "loss: 0.252029  [  490/  740]\n",
      "loss: 0.064326  [  630/  740]\n",
      "loss: 0.010865  [  440/  740]\n",
      "Training Loss (Epoch): 0.077382\n",
      "Validating...\n",
      "Validation Loss: 0.355668, Validation Accuracy: 87.03%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 17/25\n",
      "loss: 0.107763  [   70/  740]\n",
      "loss: 0.030642  [  210/  740]\n",
      "loss: 0.069606  [  350/  740]\n",
      "loss: 0.071669  [  490/  740]\n",
      "loss: 0.024099  [  630/  740]\n",
      "loss: 0.042938  [  440/  740]\n",
      "Training Loss (Epoch): 0.075120\n",
      "Validating...\n",
      "Validation Loss: 0.354712, Validation Accuracy: 87.03%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 18/25\n",
      "loss: 0.076395  [   70/  740]\n",
      "loss: 0.080962  [  210/  740]\n",
      "loss: 0.029025  [  350/  740]\n",
      "loss: 0.011543  [  490/  740]\n",
      "loss: 0.073656  [  630/  740]\n",
      "loss: 0.113710  [  440/  740]\n",
      "Training Loss (Epoch): 0.069374\n",
      "Validating...\n",
      "Validation Loss: 0.353707, Validation Accuracy: 87.03%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 19/25\n",
      "loss: 0.058893  [   70/  740]\n",
      "loss: 0.080538  [  210/  740]\n",
      "loss: 0.109867  [  350/  740]\n",
      "loss: 0.071268  [  490/  740]\n",
      "loss: 0.057501  [  630/  740]\n",
      "loss: 0.096225  [  440/  740]\n",
      "Training Loss (Epoch): 0.075330\n",
      "Validating...\n",
      "Validation Loss: 0.351652, Validation Accuracy: 87.03%\n",
      "Learning Rate: [1e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 4\n",
      "Epoch 1/25\n",
      "loss: 2.456805  [   70/  792]\n",
      "loss: 2.243653  [  210/  792]\n",
      "loss: 2.228524  [  350/  792]\n",
      "loss: 2.088194  [  490/  792]\n",
      "loss: 1.931070  [  630/  792]\n",
      "loss: 1.926513  [  770/  792]\n",
      "Training Loss (Epoch): 2.161577\n",
      "Validating...\n",
      "Validation Loss: 1.851650, Validation Accuracy: 47.47%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/25\n",
      "loss: 1.837451  [   70/  792]\n",
      "loss: 1.592613  [  210/  792]\n",
      "loss: 1.093803  [  350/  792]\n",
      "loss: 1.187320  [  490/  792]\n",
      "loss: 1.226725  [  630/  792]\n",
      "loss: 1.060079  [  770/  792]\n",
      "Training Loss (Epoch): 1.355832\n",
      "Validating...\n",
      "Validation Loss: 0.853946, Validation Accuracy: 70.71%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/25\n",
      "loss: 0.890163  [   70/  792]\n",
      "loss: 0.806939  [  210/  792]\n",
      "loss: 0.808244  [  350/  792]\n",
      "loss: 1.038687  [  490/  792]\n",
      "loss: 1.022973  [  630/  792]\n",
      "loss: 0.676681  [  770/  792]\n",
      "Training Loss (Epoch): 0.808884\n",
      "Validating...\n",
      "Validation Loss: 0.640785, Validation Accuracy: 76.26%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/25\n",
      "loss: 0.720638  [   70/  792]\n",
      "loss: 0.616395  [  210/  792]\n",
      "loss: 0.535972  [  350/  792]\n",
      "loss: 0.360667  [  490/  792]\n",
      "loss: 0.497192  [  630/  792]\n",
      "loss: 0.539138  [  770/  792]\n",
      "Training Loss (Epoch): 0.628923\n",
      "Validating...\n",
      "Validation Loss: 0.657937, Validation Accuracy: 78.28%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 5/25\n",
      "loss: 0.416381  [   70/  792]\n",
      "loss: 0.837867  [  210/  792]\n",
      "loss: 0.463623  [  350/  792]\n",
      "loss: 0.327735  [  490/  792]\n",
      "loss: 0.418594  [  630/  792]\n",
      "loss: 0.257880  [  770/  792]\n",
      "Training Loss (Epoch): 0.445511\n",
      "Validating...\n",
      "Validation Loss: 0.465845, Validation Accuracy: 83.33%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 6/25\n",
      "loss: 0.307832  [   70/  792]\n",
      "loss: 0.248748  [  210/  792]\n",
      "loss: 0.237770  [  350/  792]\n",
      "loss: 0.310607  [  490/  792]\n",
      "loss: 0.177836  [  630/  792]\n",
      "loss: 0.238900  [  770/  792]\n",
      "Training Loss (Epoch): 0.256636\n",
      "Validating...\n",
      "Validation Loss: 0.368995, Validation Accuracy: 86.36%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 7/25\n",
      "loss: 0.138680  [   70/  792]\n",
      "loss: 0.183129  [  210/  792]\n",
      "loss: 0.236847  [  350/  792]\n",
      "loss: 0.173834  [  490/  792]\n",
      "loss: 0.259781  [  630/  792]\n",
      "loss: 0.117679  [  770/  792]\n",
      "Training Loss (Epoch): 0.158724\n",
      "Validating...\n",
      "Validation Loss: 0.335680, Validation Accuracy: 90.40%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 8/25\n",
      "loss: 0.263746  [   70/  792]\n",
      "loss: 0.073490  [  210/  792]\n",
      "loss: 0.083924  [  350/  792]\n",
      "loss: 0.130331  [  490/  792]\n",
      "loss: 0.060066  [  630/  792]\n",
      "loss: 0.078209  [  770/  792]\n",
      "Training Loss (Epoch): 0.103032\n",
      "Validating...\n",
      "Validation Loss: 0.340840, Validation Accuracy: 91.41%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 9/25\n",
      "loss: 0.094852  [   70/  792]\n",
      "loss: 0.085194  [  210/  792]\n",
      "loss: 0.087073  [  350/  792]\n",
      "loss: 0.048537  [  490/  792]\n",
      "loss: 0.090083  [  630/  792]\n",
      "loss: 0.096185  [  770/  792]\n",
      "Training Loss (Epoch): 0.096160\n",
      "Validating...\n",
      "Validation Loss: 0.315172, Validation Accuracy: 91.41%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 10/25\n",
      "loss: 0.096868  [   70/  792]\n",
      "loss: 0.064607  [  210/  792]\n",
      "loss: 0.054155  [  350/  792]\n",
      "loss: 0.135813  [  490/  792]\n",
      "loss: 0.071791  [  630/  792]\n",
      "loss: 0.027821  [  770/  792]\n",
      "Training Loss (Epoch): 0.084386\n",
      "Validating...\n",
      "Validation Loss: 0.313637, Validation Accuracy: 91.41%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 11/25\n",
      "loss: 0.083710  [   70/  792]\n",
      "loss: 0.069793  [  210/  792]\n",
      "loss: 0.143794  [  350/  792]\n",
      "loss: 0.112758  [  490/  792]\n",
      "loss: 0.020254  [  630/  792]\n",
      "loss: 0.077489  [  770/  792]\n",
      "Training Loss (Epoch): 0.075310\n",
      "Validating...\n",
      "Validation Loss: 0.311589, Validation Accuracy: 91.41%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 12/25\n",
      "loss: 0.093366  [   70/  792]\n",
      "loss: 0.125831  [  210/  792]\n",
      "loss: 0.032424  [  350/  792]\n",
      "loss: 0.071983  [  490/  792]\n",
      "loss: 0.095549  [  630/  792]\n",
      "loss: 0.052219  [  770/  792]\n",
      "Training Loss (Epoch): 0.073799\n",
      "Validating...\n",
      "Validation Loss: 0.309254, Validation Accuracy: 91.92%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 13/25\n",
      "loss: 0.040440  [   70/  792]\n",
      "loss: 0.025286  [  210/  792]\n",
      "loss: 0.035230  [  350/  792]\n",
      "loss: 0.078649  [  490/  792]\n",
      "loss: 0.086174  [  630/  792]\n",
      "loss: 0.070254  [  770/  792]\n",
      "Training Loss (Epoch): 0.090924\n",
      "Validating...\n",
      "Validation Loss: 0.309096, Validation Accuracy: 91.41%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 14/25\n",
      "loss: 0.087828  [   70/  792]\n",
      "loss: 0.045000  [  210/  792]\n",
      "loss: 0.160629  [  350/  792]\n",
      "loss: 0.046947  [  490/  792]\n",
      "loss: 0.125497  [  630/  792]\n",
      "loss: 0.025898  [  770/  792]\n",
      "Training Loss (Epoch): 0.069936\n",
      "Validating...\n",
      "Validation Loss: 0.310832, Validation Accuracy: 91.41%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 15/25\n",
      "loss: 0.059746  [   70/  792]\n",
      "loss: 0.029792  [  210/  792]\n",
      "loss: 0.085568  [  350/  792]\n",
      "loss: 0.075491  [  490/  792]\n",
      "loss: 0.132553  [  630/  792]\n",
      "loss: 0.077070  [  770/  792]\n",
      "Training Loss (Epoch): 0.078602\n",
      "Validating...\n",
      "Validation Loss: 0.310185, Validation Accuracy: 91.41%\n",
      "Learning Rate: [1e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 5\n",
      "Epoch 1/25\n",
      "loss: 2.499359  [   70/  748]\n",
      "loss: 2.245328  [  210/  748]\n",
      "loss: 2.129537  [  350/  748]\n",
      "loss: 2.154988  [  490/  748]\n",
      "loss: 2.022820  [  630/  748]\n",
      "loss: 2.031310  [  528/  748]\n",
      "Training Loss (Epoch): 2.193323\n",
      "Validating...\n",
      "Validation Loss: 2.100205, Validation Accuracy: 33.51%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/25\n",
      "loss: 2.113674  [   70/  748]\n",
      "loss: 1.840467  [  210/  748]\n",
      "loss: 1.515243  [  350/  748]\n",
      "loss: 1.334429  [  490/  748]\n",
      "loss: 1.522267  [  630/  748]\n",
      "loss: 1.185312  [  528/  748]\n",
      "Training Loss (Epoch): 1.576384\n",
      "Validating...\n",
      "Validation Loss: 1.441447, Validation Accuracy: 60.64%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/25\n",
      "loss: 0.908972  [   70/  748]\n",
      "loss: 1.291892  [  210/  748]\n",
      "loss: 0.898264  [  350/  748]\n",
      "loss: 0.797062  [  490/  748]\n",
      "loss: 0.834199  [  630/  748]\n",
      "loss: 0.698412  [  528/  748]\n",
      "Training Loss (Epoch): 0.905111\n",
      "Validating...\n",
      "Validation Loss: 0.969769, Validation Accuracy: 71.28%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/25\n",
      "loss: 0.599531  [   70/  748]\n",
      "loss: 0.490472  [  210/  748]\n",
      "loss: 1.063171  [  350/  748]\n",
      "loss: 1.373912  [  490/  748]\n",
      "loss: 1.013565  [  630/  748]\n",
      "loss: 0.880216  [  528/  748]\n",
      "Training Loss (Epoch): 0.930647\n",
      "Validating...\n",
      "Validation Loss: 0.946256, Validation Accuracy: 68.62%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/25\n",
      "loss: 0.670145  [   70/  748]\n",
      "loss: 0.402250  [  210/  748]\n",
      "loss: 0.540084  [  350/  748]\n",
      "loss: 0.663669  [  490/  748]\n",
      "loss: 0.460976  [  630/  748]\n",
      "loss: 0.635304  [  528/  748]\n",
      "Training Loss (Epoch): 0.544800\n",
      "Validating...\n",
      "Validation Loss: 0.742723, Validation Accuracy: 76.60%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 6/25\n",
      "loss: 0.421253  [   70/  748]\n",
      "loss: 0.379647  [  210/  748]\n",
      "loss: 0.316604  [  350/  748]\n",
      "loss: 0.312416  [  490/  748]\n",
      "loss: 0.272092  [  630/  748]\n",
      "loss: 0.254926  [  528/  748]\n",
      "Training Loss (Epoch): 0.362391\n",
      "Validating...\n",
      "Validation Loss: 0.673072, Validation Accuracy: 79.26%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 7/25\n",
      "loss: 0.288052  [   70/  748]\n",
      "loss: 0.105173  [  210/  748]\n",
      "loss: 0.272331  [  350/  748]\n",
      "loss: 0.221834  [  490/  748]\n",
      "loss: 0.233984  [  630/  748]\n",
      "loss: 0.245871  [  528/  748]\n",
      "Training Loss (Epoch): 0.276518\n",
      "Validating...\n",
      "Validation Loss: 0.518388, Validation Accuracy: 84.04%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 8/25\n",
      "loss: 0.166553  [   70/  748]\n",
      "loss: 0.214450  [  210/  748]\n",
      "loss: 0.275904  [  350/  748]\n",
      "loss: 0.298679  [  490/  748]\n",
      "loss: 0.265590  [  630/  748]\n",
      "loss: 0.206944  [  528/  748]\n",
      "Training Loss (Epoch): 0.228434\n",
      "Validating...\n",
      "Validation Loss: 0.497027, Validation Accuracy: 84.04%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 9/25\n",
      "loss: 0.132847  [   70/  748]\n",
      "loss: 0.299572  [  210/  748]\n",
      "loss: 0.177452  [  350/  748]\n",
      "loss: 0.245495  [  490/  748]\n",
      "loss: 0.137813  [  630/  748]\n",
      "loss: 0.344166  [  528/  748]\n",
      "Training Loss (Epoch): 0.201727\n",
      "Validating...\n",
      "Validation Loss: 0.475125, Validation Accuracy: 85.64%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 10/25\n",
      "loss: 0.150104  [   70/  748]\n",
      "loss: 0.080337  [  210/  748]\n",
      "loss: 0.173319  [  350/  748]\n",
      "loss: 0.241948  [  490/  748]\n",
      "loss: 0.083330  [  630/  748]\n",
      "loss: 0.210883  [  528/  748]\n",
      "Training Loss (Epoch): 0.173925\n",
      "Validating...\n",
      "Validation Loss: 0.442457, Validation Accuracy: 86.17%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 11/25\n",
      "loss: 0.143691  [   70/  748]\n",
      "loss: 0.165689  [  210/  748]\n",
      "loss: 0.138552  [  350/  748]\n",
      "loss: 0.261461  [  490/  748]\n",
      "loss: 0.134863  [  630/  748]\n",
      "loss: 0.130242  [  528/  748]\n",
      "Training Loss (Epoch): 0.162797\n",
      "Validating...\n",
      "Validation Loss: 0.423211, Validation Accuracy: 87.23%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 12/25\n",
      "loss: 0.162970  [   70/  748]\n",
      "loss: 0.232931  [  210/  748]\n",
      "loss: 0.191285  [  350/  748]\n",
      "loss: 0.158204  [  490/  748]\n",
      "loss: 0.131404  [  630/  748]\n",
      "loss: 0.109081  [  528/  748]\n",
      "Training Loss (Epoch): 0.155562\n",
      "Validating...\n",
      "Validation Loss: 0.422211, Validation Accuracy: 87.23%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 13/25\n",
      "loss: 0.248459  [   70/  748]\n",
      "loss: 0.132991  [  210/  748]\n",
      "loss: 0.127829  [  350/  748]\n",
      "loss: 0.159129  [  490/  748]\n",
      "loss: 0.108273  [  630/  748]\n",
      "loss: 0.097015  [  528/  748]\n",
      "Training Loss (Epoch): 0.159051\n",
      "Validating...\n",
      "Validation Loss: 0.417111, Validation Accuracy: 86.17%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 14/25\n",
      "loss: 0.207487  [   70/  748]\n",
      "loss: 0.124001  [  210/  748]\n",
      "loss: 0.147659  [  350/  748]\n",
      "loss: 0.275821  [  490/  748]\n",
      "loss: 0.215354  [  630/  748]\n",
      "loss: 0.058413  [  528/  748]\n",
      "Training Loss (Epoch): 0.154043\n",
      "Validating...\n",
      "Validation Loss: 0.416641, Validation Accuracy: 86.17%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 15/25\n",
      "loss: 0.172090  [   70/  748]\n",
      "loss: 0.125562  [  210/  748]\n",
      "loss: 0.116336  [  350/  748]\n",
      "loss: 0.127055  [  490/  748]\n",
      "loss: 0.196499  [  630/  748]\n",
      "loss: 0.230677  [  528/  748]\n",
      "Training Loss (Epoch): 0.154451\n",
      "Validating...\n",
      "Validation Loss: 0.417286, Validation Accuracy: 86.17%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 16/25\n",
      "loss: 0.094326  [   70/  748]\n",
      "loss: 0.294866  [  210/  748]\n",
      "loss: 0.137979  [  350/  748]\n",
      "loss: 0.159190  [  490/  748]\n",
      "loss: 0.148152  [  630/  748]\n",
      "loss: 0.106329  [  528/  748]\n",
      "Training Loss (Epoch): 0.149142\n",
      "Validating...\n",
      "Validation Loss: 0.418879, Validation Accuracy: 86.17%\n",
      "Learning Rate: [1e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 6\n",
      "Epoch 1/25\n",
      "loss: 2.461817  [   70/  658]\n",
      "loss: 2.457612  [  210/  658]\n",
      "loss: 2.306444  [  350/  658]\n",
      "loss: 2.138582  [  490/  658]\n",
      "loss: 2.061532  [  630/  658]\n",
      "Training Loss (Epoch): 2.225389\n",
      "Validating...\n",
      "Validation Loss: 2.121774, Validation Accuracy: 23.64%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/25\n",
      "loss: 2.168803  [   70/  658]\n",
      "loss: 1.641897  [  210/  658]\n",
      "loss: 1.593822  [  350/  658]\n",
      "loss: 1.249726  [  490/  658]\n",
      "loss: 1.484321  [  630/  658]\n",
      "Training Loss (Epoch): 1.547209\n",
      "Validating...\n",
      "Validation Loss: 1.343591, Validation Accuracy: 52.73%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/25\n",
      "loss: 1.215941  [   70/  658]\n",
      "loss: 1.103976  [  210/  658]\n",
      "loss: 0.823543  [  350/  658]\n",
      "loss: 0.845526  [  490/  658]\n",
      "loss: 0.910832  [  630/  658]\n",
      "Training Loss (Epoch): 1.027266\n",
      "Validating...\n",
      "Validation Loss: 1.172782, Validation Accuracy: 67.27%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/25\n",
      "loss: 0.762916  [   70/  658]\n",
      "loss: 1.086755  [  210/  658]\n",
      "loss: 1.073329  [  350/  658]\n",
      "loss: 0.647521  [  490/  658]\n",
      "loss: 0.806371  [  630/  658]\n",
      "Training Loss (Epoch): 0.867639\n",
      "Validating...\n",
      "Validation Loss: 0.760525, Validation Accuracy: 70.91%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/25\n",
      "loss: 0.546211  [   70/  658]\n",
      "loss: 0.520838  [  210/  658]\n",
      "loss: 0.482704  [  350/  658]\n",
      "loss: 0.494432  [  490/  658]\n",
      "loss: 0.489285  [  630/  658]\n",
      "Training Loss (Epoch): 0.506643\n",
      "Validating...\n",
      "Validation Loss: 0.538057, Validation Accuracy: 81.82%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/25\n",
      "loss: 0.301347  [   70/  658]\n",
      "loss: 0.477124  [  210/  658]\n",
      "loss: 0.273617  [  350/  658]\n",
      "loss: 0.577841  [  490/  658]\n",
      "loss: 0.411567  [  630/  658]\n",
      "Training Loss (Epoch): 0.387956\n",
      "Validating...\n",
      "Validation Loss: 0.458695, Validation Accuracy: 84.24%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 7/25\n",
      "loss: 0.376115  [   70/  658]\n",
      "loss: 0.274529  [  210/  658]\n",
      "loss: 0.333192  [  350/  658]\n",
      "loss: 0.261898  [  490/  658]\n",
      "loss: 0.252002  [  630/  658]\n",
      "Training Loss (Epoch): 0.291153\n",
      "Validating...\n",
      "Validation Loss: 0.464622, Validation Accuracy: 84.85%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 8/25\n",
      "loss: 0.310811  [   70/  658]\n",
      "loss: 0.253107  [  210/  658]\n",
      "loss: 0.251663  [  350/  658]\n",
      "loss: 0.127364  [  490/  658]\n",
      "loss: 0.182466  [  630/  658]\n",
      "Training Loss (Epoch): 0.205270\n",
      "Validating...\n",
      "Validation Loss: 0.425296, Validation Accuracy: 85.45%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 9/25\n",
      "loss: 0.345211  [   70/  658]\n",
      "loss: 0.199582  [  210/  658]\n",
      "loss: 0.215522  [  350/  658]\n",
      "loss: 0.135366  [  490/  658]\n",
      "loss: 0.104552  [  630/  658]\n",
      "Training Loss (Epoch): 0.156215\n",
      "Validating...\n",
      "Validation Loss: 0.418584, Validation Accuracy: 89.09%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 10/25\n",
      "loss: 0.205203  [   70/  658]\n",
      "loss: 0.072847  [  210/  658]\n",
      "loss: 0.140628  [  350/  658]\n",
      "loss: 0.152830  [  490/  658]\n",
      "loss: 0.175879  [  630/  658]\n",
      "Training Loss (Epoch): 0.131521\n",
      "Validating...\n",
      "Validation Loss: 0.387935, Validation Accuracy: 87.88%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 11/25\n",
      "loss: 0.065757  [   70/  658]\n",
      "loss: 0.066528  [  210/  658]\n",
      "loss: 0.065102  [  350/  658]\n",
      "loss: 0.125640  [  490/  658]\n",
      "loss: 0.281764  [  630/  658]\n",
      "Training Loss (Epoch): 0.108236\n",
      "Validating...\n",
      "Validation Loss: 0.365893, Validation Accuracy: 88.48%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 12/25\n",
      "loss: 0.100213  [   70/  658]\n",
      "loss: 0.102440  [  210/  658]\n",
      "loss: 0.069920  [  350/  658]\n",
      "loss: 0.104258  [  490/  658]\n",
      "loss: 0.142909  [  630/  658]\n",
      "Training Loss (Epoch): 0.102007\n",
      "Validating...\n",
      "Validation Loss: 0.364656, Validation Accuracy: 88.48%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 13/25\n",
      "loss: 0.049156  [   70/  658]\n",
      "loss: 0.083351  [  210/  658]\n",
      "loss: 0.153421  [  350/  658]\n",
      "loss: 0.079164  [  490/  658]\n",
      "loss: 0.200310  [  630/  658]\n",
      "Training Loss (Epoch): 0.105477\n",
      "Validating...\n",
      "Validation Loss: 0.363702, Validation Accuracy: 88.48%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 14/25\n",
      "loss: 0.146281  [   70/  658]\n",
      "loss: 0.043312  [  210/  658]\n",
      "loss: 0.042449  [  350/  658]\n",
      "loss: 0.125992  [  490/  658]\n",
      "loss: 0.121366  [  630/  658]\n",
      "Training Loss (Epoch): 0.105785\n",
      "Validating...\n",
      "Validation Loss: 0.363370, Validation Accuracy: 88.48%\n",
      "Learning Rate: [1e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 7\n",
      "Epoch 1/25\n",
      "loss: 2.372267  [   70/  670]\n",
      "loss: 2.178993  [  210/  670]\n",
      "loss: 2.120753  [  350/  670]\n",
      "loss: 1.934822  [  490/  670]\n",
      "loss: 1.821555  [  630/  670]\n",
      "Training Loss (Epoch): 2.072694\n",
      "Validating...\n",
      "Validation Loss: 1.970459, Validation Accuracy: 35.71%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/25\n",
      "loss: 1.867286  [   70/  670]\n",
      "loss: 1.555676  [  210/  670]\n",
      "loss: 1.307475  [  350/  670]\n",
      "loss: 1.344383  [  490/  670]\n",
      "loss: 1.372498  [  630/  670]\n",
      "Training Loss (Epoch): 1.358655\n",
      "Validating...\n",
      "Validation Loss: 1.085829, Validation Accuracy: 61.90%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/25\n",
      "loss: 0.965241  [   70/  670]\n",
      "loss: 0.858171  [  210/  670]\n",
      "loss: 0.839021  [  350/  670]\n",
      "loss: 0.728641  [  490/  670]\n",
      "loss: 0.624615  [  630/  670]\n",
      "Training Loss (Epoch): 0.779184\n",
      "Validating...\n",
      "Validation Loss: 0.876171, Validation Accuracy: 69.05%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/25\n",
      "loss: 0.515061  [   70/  670]\n",
      "loss: 0.512540  [  210/  670]\n",
      "loss: 0.278059  [  350/  670]\n",
      "loss: 0.782717  [  490/  670]\n",
      "loss: 0.718319  [  630/  670]\n",
      "Training Loss (Epoch): 0.542744\n",
      "Validating...\n",
      "Validation Loss: 1.022054, Validation Accuracy: 75.60%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/25\n",
      "loss: 0.529342  [   70/  670]\n",
      "loss: 0.374656  [  210/  670]\n",
      "loss: 0.306007  [  350/  670]\n",
      "loss: 0.238942  [  490/  670]\n",
      "loss: 0.324970  [  630/  670]\n",
      "Training Loss (Epoch): 0.384023\n",
      "Validating...\n",
      "Validation Loss: 1.084421, Validation Accuracy: 70.83%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/25\n",
      "loss: 0.401050  [   70/  670]\n",
      "loss: 0.229354  [  210/  670]\n",
      "loss: 0.376494  [  350/  670]\n",
      "loss: 0.369109  [  490/  670]\n",
      "loss: 0.388568  [  630/  670]\n",
      "Training Loss (Epoch): 0.398149\n",
      "Validating...\n",
      "Validation Loss: 0.528538, Validation Accuracy: 79.17%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 7/25\n",
      "loss: 0.371413  [   70/  670]\n",
      "loss: 0.458652  [  210/  670]\n",
      "loss: 0.313211  [  350/  670]\n",
      "loss: 0.289552  [  490/  670]\n",
      "loss: 0.274034  [  630/  670]\n",
      "Training Loss (Epoch): 0.302695\n",
      "Validating...\n",
      "Validation Loss: 0.604203, Validation Accuracy: 80.36%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 8/25\n",
      "loss: 0.145347  [   70/  670]\n",
      "loss: 0.176785  [  210/  670]\n",
      "loss: 0.158857  [  350/  670]\n",
      "loss: 0.143540  [  490/  670]\n",
      "loss: 0.158576  [  630/  670]\n",
      "Training Loss (Epoch): 0.152634\n",
      "Validating...\n",
      "Validation Loss: 0.735192, Validation Accuracy: 81.55%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 9/25\n",
      "loss: 0.145076  [   70/  670]\n",
      "loss: 0.096771  [  210/  670]\n",
      "loss: 0.067121  [  350/  670]\n",
      "loss: 0.187289  [  490/  670]\n",
      "loss: 0.144766  [  630/  670]\n",
      "Training Loss (Epoch): 0.112763\n",
      "Validating...\n",
      "Validation Loss: 0.746894, Validation Accuracy: 81.55%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 8\n",
      "Epoch 1/25\n",
      "loss: 2.514101  [   70/  644]\n",
      "loss: 2.298059  [  210/  644]\n",
      "loss: 2.093833  [  350/  644]\n",
      "loss: 2.043283  [  490/  644]\n",
      "loss: 1.988149  [  630/  644]\n",
      "Training Loss (Epoch): 2.161297\n",
      "Validating...\n",
      "Validation Loss: 2.092233, Validation Accuracy: 36.42%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/25\n",
      "loss: 2.038471  [   70/  644]\n",
      "loss: 1.880461  [  210/  644]\n",
      "loss: 1.566576  [  350/  644]\n",
      "loss: 1.437723  [  490/  644]\n",
      "loss: 1.709565  [  630/  644]\n",
      "Training Loss (Epoch): 1.624972\n",
      "Validating...\n",
      "Validation Loss: 1.540553, Validation Accuracy: 45.06%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/25\n",
      "loss: 1.375837  [   70/  644]\n",
      "loss: 1.373535  [  210/  644]\n",
      "loss: 0.960031  [  350/  644]\n",
      "loss: 1.045126  [  490/  644]\n",
      "loss: 0.838666  [  630/  644]\n",
      "Training Loss (Epoch): 1.122648\n",
      "Validating...\n",
      "Validation Loss: 2.137532, Validation Accuracy: 40.74%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 4/25\n",
      "loss: 1.242606  [   70/  644]\n",
      "loss: 0.891193  [  210/  644]\n",
      "loss: 0.552942  [  350/  644]\n",
      "loss: 0.896596  [  490/  644]\n",
      "loss: 0.690210  [  630/  644]\n",
      "Training Loss (Epoch): 0.903284\n",
      "Validating...\n",
      "Validation Loss: 0.782098, Validation Accuracy: 71.60%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 5/25\n",
      "loss: 0.640253  [   70/  644]\n",
      "loss: 0.632326  [  210/  644]\n",
      "loss: 0.600190  [  350/  644]\n",
      "loss: 0.432077  [  490/  644]\n",
      "loss: 0.674828  [  630/  644]\n",
      "Training Loss (Epoch): 0.564323\n",
      "Validating...\n",
      "Validation Loss: 0.699231, Validation Accuracy: 73.46%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 6/25\n",
      "loss: 0.687293  [   70/  644]\n",
      "loss: 0.421627  [  210/  644]\n",
      "loss: 0.374178  [  350/  644]\n",
      "loss: 0.402236  [  490/  644]\n",
      "loss: 0.312324  [  630/  644]\n",
      "Training Loss (Epoch): 0.450576\n",
      "Validating...\n",
      "Validation Loss: 0.556566, Validation Accuracy: 77.16%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 7/25\n",
      "loss: 0.286486  [   70/  644]\n",
      "loss: 0.255353  [  210/  644]\n",
      "loss: 0.295881  [  350/  644]\n",
      "loss: 0.321247  [  490/  644]\n",
      "loss: 0.291428  [  630/  644]\n",
      "Training Loss (Epoch): 0.335314\n",
      "Validating...\n",
      "Validation Loss: 0.530229, Validation Accuracy: 78.40%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 8/25\n",
      "loss: 0.341736  [   70/  644]\n",
      "loss: 0.274130  [  210/  644]\n",
      "loss: 0.397304  [  350/  644]\n",
      "loss: 0.219962  [  490/  644]\n",
      "loss: 0.253674  [  630/  644]\n",
      "Training Loss (Epoch): 0.272601\n",
      "Validating...\n",
      "Validation Loss: 0.468699, Validation Accuracy: 84.57%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 9/25\n",
      "loss: 0.314963  [   70/  644]\n",
      "loss: 0.236171  [  210/  644]\n",
      "loss: 0.300099  [  350/  644]\n",
      "loss: 0.254736  [  490/  644]\n",
      "loss: 0.246686  [  630/  644]\n",
      "Training Loss (Epoch): 0.277630\n",
      "Validating...\n",
      "Validation Loss: 0.455854, Validation Accuracy: 83.95%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 10/25\n",
      "loss: 0.312682  [   70/  644]\n",
      "loss: 0.190023  [  210/  644]\n",
      "loss: 0.178566  [  350/  644]\n",
      "loss: 0.212687  [  490/  644]\n",
      "loss: 0.155719  [  630/  644]\n",
      "Training Loss (Epoch): 0.332211\n",
      "Validating...\n",
      "Validation Loss: 0.453955, Validation Accuracy: 80.86%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 11/25\n",
      "loss: 0.121034  [   70/  644]\n",
      "loss: 0.220169  [  210/  644]\n",
      "loss: 0.177335  [  350/  644]\n",
      "loss: 0.135041  [  490/  644]\n",
      "loss: 0.171948  [  630/  644]\n",
      "Training Loss (Epoch): 0.194582\n",
      "Validating...\n",
      "Validation Loss: 0.456462, Validation Accuracy: 79.63%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 12/25\n",
      "loss: 0.191007  [   70/  644]\n",
      "loss: 0.208436  [  210/  644]\n",
      "loss: 0.248699  [  350/  644]\n",
      "loss: 0.228054  [  490/  644]\n",
      "loss: 0.164520  [  630/  644]\n",
      "Training Loss (Epoch): 0.196985\n",
      "Validating...\n",
      "Validation Loss: 0.447037, Validation Accuracy: 84.57%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 13/25\n",
      "loss: 0.121360  [   70/  644]\n",
      "loss: 0.330724  [  210/  644]\n",
      "loss: 0.211595  [  350/  644]\n",
      "loss: 0.248835  [  490/  644]\n",
      "loss: 0.134684  [  630/  644]\n",
      "Training Loss (Epoch): 0.204570\n",
      "Validating...\n",
      "Validation Loss: 0.442146, Validation Accuracy: 83.95%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 14/25\n",
      "loss: 0.232512  [   70/  644]\n",
      "loss: 0.142566  [  210/  644]\n",
      "loss: 0.185482  [  350/  644]\n",
      "loss: 0.222475  [  490/  644]\n",
      "loss: 0.226730  [  630/  644]\n",
      "Training Loss (Epoch): 0.192824\n",
      "Validating...\n",
      "Validation Loss: 0.437951, Validation Accuracy: 83.33%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 15/25\n",
      "loss: 0.152617  [   70/  644]\n",
      "loss: 0.184535  [  210/  644]\n",
      "loss: 0.152427  [  350/  644]\n",
      "loss: 0.096362  [  490/  644]\n",
      "loss: 0.159430  [  630/  644]\n",
      "Training Loss (Epoch): 0.187191\n",
      "Validating...\n",
      "Validation Loss: 0.434158, Validation Accuracy: 83.33%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 16/25\n",
      "loss: 0.263636  [   70/  644]\n",
      "loss: 0.235608  [  210/  644]\n",
      "loss: 0.171981  [  350/  644]\n",
      "loss: 0.202324  [  490/  644]\n",
      "loss: 0.112121  [  630/  644]\n",
      "Training Loss (Epoch): 0.196690\n",
      "Validating...\n",
      "Validation Loss: 0.434292, Validation Accuracy: 80.86%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 17/25\n",
      "loss: 0.183058  [   70/  644]\n",
      "loss: 0.146788  [  210/  644]\n",
      "loss: 0.172164  [  350/  644]\n",
      "loss: 0.152615  [  490/  644]\n",
      "loss: 0.137488  [  630/  644]\n",
      "Training Loss (Epoch): 0.212477\n",
      "Validating...\n",
      "Validation Loss: 0.427908, Validation Accuracy: 84.57%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 18/25\n",
      "loss: 0.151847  [   70/  644]\n",
      "loss: 0.246542  [  210/  644]\n",
      "loss: 0.149251  [  350/  644]\n",
      "loss: 0.140461  [  490/  644]\n",
      "loss: 0.241119  [  630/  644]\n",
      "Training Loss (Epoch): 0.196553\n",
      "Validating...\n",
      "Validation Loss: 0.422723, Validation Accuracy: 83.95%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 19/25\n",
      "loss: 0.138123  [   70/  644]\n",
      "loss: 0.166332  [  210/  644]\n",
      "loss: 0.201127  [  350/  644]\n",
      "loss: 0.136123  [  490/  644]\n",
      "loss: 0.216926  [  630/  644]\n",
      "Training Loss (Epoch): 0.178047\n",
      "Validating...\n",
      "Validation Loss: 0.416677, Validation Accuracy: 84.57%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 20/25\n",
      "loss: 0.114794  [   70/  644]\n",
      "loss: 0.417726  [  210/  644]\n",
      "loss: 0.237388  [  350/  644]\n",
      "loss: 0.205625  [  490/  644]\n",
      "loss: 0.160646  [  630/  644]\n",
      "Training Loss (Epoch): 0.177360\n",
      "Validating...\n",
      "Validation Loss: 0.416255, Validation Accuracy: 83.95%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 21/25\n",
      "loss: 0.150593  [   70/  644]\n",
      "loss: 0.188621  [  210/  644]\n",
      "loss: 0.245198  [  350/  644]\n",
      "loss: 0.157662  [  490/  644]\n",
      "loss: 0.256001  [  630/  644]\n",
      "Training Loss (Epoch): 0.189724\n",
      "Validating...\n",
      "Validation Loss: 0.414750, Validation Accuracy: 83.95%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 22/25\n",
      "loss: 0.210765  [   70/  644]\n",
      "loss: 0.189517  [  210/  644]\n",
      "loss: 0.149214  [  350/  644]\n",
      "loss: 0.128390  [  490/  644]\n",
      "loss: 0.289572  [  630/  644]\n",
      "Training Loss (Epoch): 0.228219\n",
      "Validating...\n",
      "Validation Loss: 0.414945, Validation Accuracy: 83.95%\n",
      "Learning Rate: [1e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 9\n",
      "Epoch 1/25\n",
      "loss: 2.487134  [   70/  652]\n",
      "loss: 2.337820  [  210/  652]\n",
      "loss: 2.160842  [  350/  652]\n",
      "loss: 1.943941  [  490/  652]\n",
      "loss: 1.910222  [  630/  652]\n",
      "Training Loss (Epoch): 2.119032\n",
      "Validating...\n",
      "Validation Loss: 1.949757, Validation Accuracy: 53.05%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/25\n",
      "loss: 1.887977  [   70/  652]\n",
      "loss: 1.453404  [  210/  652]\n",
      "loss: 1.275350  [  350/  652]\n",
      "loss: 1.026600  [  490/  652]\n",
      "loss: 0.978115  [  630/  652]\n",
      "Training Loss (Epoch): 1.294263\n",
      "Validating...\n",
      "Validation Loss: 1.310085, Validation Accuracy: 59.15%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/25\n",
      "loss: 1.496499  [   70/  652]\n",
      "loss: 0.835169  [  210/  652]\n",
      "loss: 0.783871  [  350/  652]\n",
      "loss: 0.877469  [  490/  652]\n",
      "loss: 0.672328  [  630/  652]\n",
      "Training Loss (Epoch): 0.867242\n",
      "Validating...\n",
      "Validation Loss: 0.616321, Validation Accuracy: 79.27%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/25\n",
      "loss: 0.441714  [   70/  652]\n",
      "loss: 0.714793  [  210/  652]\n",
      "loss: 0.353351  [  350/  652]\n",
      "loss: 0.568876  [  490/  652]\n",
      "loss: 0.338146  [  630/  652]\n",
      "Training Loss (Epoch): 0.548352\n",
      "Validating...\n",
      "Validation Loss: 1.062821, Validation Accuracy: 69.51%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/25\n",
      "loss: 0.552572  [   70/  652]\n",
      "loss: 0.371565  [  210/  652]\n",
      "loss: 0.605478  [  350/  652]\n",
      "loss: 0.427956  [  490/  652]\n",
      "loss: 0.385642  [  630/  652]\n",
      "Training Loss (Epoch): 0.489121\n",
      "Validating...\n",
      "Validation Loss: 0.555985, Validation Accuracy: 80.49%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 6/25\n",
      "loss: 0.201462  [   70/  652]\n",
      "loss: 0.366432  [  210/  652]\n",
      "loss: 0.269622  [  350/  652]\n",
      "loss: 0.177181  [  490/  652]\n",
      "loss: 0.197980  [  630/  652]\n",
      "Training Loss (Epoch): 0.290681\n",
      "Validating...\n",
      "Validation Loss: 0.492173, Validation Accuracy: 84.15%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 7/25\n",
      "loss: 0.127871  [   70/  652]\n",
      "loss: 0.160825  [  210/  652]\n",
      "loss: 0.101263  [  350/  652]\n",
      "loss: 0.121259  [  490/  652]\n",
      "loss: 0.172219  [  630/  652]\n",
      "Training Loss (Epoch): 0.166908\n",
      "Validating...\n",
      "Validation Loss: 0.466035, Validation Accuracy: 87.80%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 8/25\n",
      "loss: 0.120998  [   70/  652]\n",
      "loss: 0.195767  [  210/  652]\n",
      "loss: 0.136506  [  350/  652]\n",
      "loss: 0.166810  [  490/  652]\n",
      "loss: 0.156485  [  630/  652]\n",
      "Training Loss (Epoch): 0.139618\n",
      "Validating...\n",
      "Validation Loss: 0.450126, Validation Accuracy: 87.80%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 9/25\n",
      "loss: 0.127355  [   70/  652]\n",
      "loss: 0.135007  [  210/  652]\n",
      "loss: 0.130543  [  350/  652]\n",
      "loss: 0.074329  [  490/  652]\n",
      "loss: 0.138412  [  630/  652]\n",
      "Training Loss (Epoch): 0.123272\n",
      "Validating...\n",
      "Validation Loss: 0.445960, Validation Accuracy: 87.20%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 10/25\n",
      "loss: 0.076271  [   70/  652]\n",
      "loss: 0.114860  [  210/  652]\n",
      "loss: 0.105740  [  350/  652]\n",
      "loss: 0.152846  [  490/  652]\n",
      "loss: 0.129015  [  630/  652]\n",
      "Training Loss (Epoch): 0.121319\n",
      "Validating...\n",
      "Validation Loss: 0.444280, Validation Accuracy: 87.20%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 11/25\n",
      "loss: 0.135683  [   70/  652]\n",
      "loss: 0.150480  [  210/  652]\n",
      "loss: 0.108939  [  350/  652]\n",
      "loss: 0.090574  [  490/  652]\n",
      "loss: 0.085109  [  630/  652]\n",
      "Training Loss (Epoch): 0.117760\n",
      "Validating...\n",
      "Validation Loss: 0.443230, Validation Accuracy: 87.20%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 12/25\n",
      "loss: 0.144602  [   70/  652]\n",
      "loss: 0.138171  [  210/  652]\n",
      "loss: 0.116121  [  350/  652]\n",
      "loss: 0.080633  [  490/  652]\n",
      "loss: 0.168208  [  630/  652]\n",
      "Training Loss (Epoch): 0.105845\n",
      "Validating...\n",
      "Validation Loss: 0.443920, Validation Accuracy: 87.80%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 13/25\n",
      "loss: 0.132081  [   70/  652]\n",
      "loss: 0.157672  [  210/  652]\n",
      "loss: 0.110770  [  350/  652]\n",
      "loss: 0.101571  [  490/  652]\n",
      "loss: 0.072004  [  630/  652]\n",
      "Training Loss (Epoch): 0.115134\n",
      "Validating...\n",
      "Validation Loss: 0.443966, Validation Accuracy: 87.80%\n",
      "Learning Rate: [1e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 10\n",
      "Epoch 1/25\n",
      "loss: 2.500578  [   70/  669]\n",
      "loss: 2.247483  [  210/  669]\n",
      "loss: 2.190589  [  350/  669]\n",
      "loss: 2.007785  [  490/  669]\n",
      "loss: 1.831276  [  630/  669]\n",
      "Training Loss (Epoch): 2.142061\n",
      "Validating...\n",
      "Validation Loss: 1.903333, Validation Accuracy: 44.64%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/25\n",
      "loss: 1.876819  [   70/  669]\n",
      "loss: 1.550547  [  210/  669]\n",
      "loss: 1.365069  [  350/  669]\n",
      "loss: 1.293211  [  490/  669]\n",
      "loss: 0.927742  [  630/  669]\n",
      "Training Loss (Epoch): 1.378384\n",
      "Validating...\n",
      "Validation Loss: 1.138557, Validation Accuracy: 59.52%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/25\n",
      "loss: 1.108463  [   70/  669]\n",
      "loss: 0.887965  [  210/  669]\n",
      "loss: 1.206914  [  350/  669]\n",
      "loss: 0.794516  [  490/  669]\n",
      "loss: 0.980676  [  630/  669]\n",
      "Training Loss (Epoch): 0.951942\n",
      "Validating...\n",
      "Validation Loss: 0.853652, Validation Accuracy: 75.60%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/25\n",
      "loss: 0.700657  [   70/  669]\n",
      "loss: 0.658153  [  210/  669]\n",
      "loss: 0.840041  [  350/  669]\n",
      "loss: 0.619231  [  490/  669]\n",
      "loss: 0.641799  [  630/  669]\n",
      "Training Loss (Epoch): 0.697581\n",
      "Validating...\n",
      "Validation Loss: 0.667971, Validation Accuracy: 79.17%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/25\n",
      "loss: 0.630019  [   70/  669]\n",
      "loss: 0.648777  [  210/  669]\n",
      "loss: 0.539793  [  350/  669]\n",
      "loss: 0.604874  [  490/  669]\n",
      "loss: 0.590965  [  630/  669]\n",
      "Training Loss (Epoch): 0.581889\n",
      "Validating...\n",
      "Validation Loss: 0.552089, Validation Accuracy: 83.33%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 6/25\n",
      "loss: 0.341853  [   70/  669]\n",
      "loss: 0.469701  [  210/  669]\n",
      "loss: 0.329749  [  350/  669]\n",
      "loss: 0.445510  [  490/  669]\n",
      "loss: 0.261286  [  630/  669]\n",
      "Training Loss (Epoch): 0.400892\n",
      "Validating...\n",
      "Validation Loss: 0.421163, Validation Accuracy: 83.93%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 7/25\n",
      "loss: 0.307735  [   70/  669]\n",
      "loss: 0.283734  [  210/  669]\n",
      "loss: 0.208099  [  350/  669]\n",
      "loss: 0.341145  [  490/  669]\n",
      "loss: 0.352190  [  630/  669]\n",
      "Training Loss (Epoch): 0.330589\n",
      "Validating...\n",
      "Validation Loss: 0.368141, Validation Accuracy: 86.31%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 8/25\n",
      "loss: 0.336186  [   70/  669]\n",
      "loss: 0.259464  [  210/  669]\n",
      "loss: 0.388655  [  350/  669]\n",
      "loss: 0.230317  [  490/  669]\n",
      "loss: 0.231614  [  630/  669]\n",
      "Training Loss (Epoch): 0.282776\n",
      "Validating...\n",
      "Validation Loss: 0.348031, Validation Accuracy: 88.10%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 9/25\n",
      "loss: 0.252017  [   70/  669]\n",
      "loss: 0.352806  [  210/  669]\n",
      "loss: 0.202959  [  350/  669]\n",
      "loss: 0.280485  [  490/  669]\n",
      "loss: 0.268633  [  630/  669]\n",
      "Training Loss (Epoch): 0.246627\n",
      "Validating...\n",
      "Validation Loss: 0.333388, Validation Accuracy: 88.69%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 10/25\n",
      "loss: 0.344742  [   70/  669]\n",
      "loss: 0.153692  [  210/  669]\n",
      "loss: 0.182753  [  350/  669]\n",
      "loss: 0.094694  [  490/  669]\n",
      "loss: 0.311287  [  630/  669]\n",
      "Training Loss (Epoch): 0.222054\n",
      "Validating...\n",
      "Validation Loss: 0.338187, Validation Accuracy: 88.69%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 11/25\n",
      "loss: 0.255771  [   70/  669]\n",
      "loss: 0.267197  [  210/  669]\n",
      "loss: 0.160366  [  350/  669]\n",
      "loss: 0.234552  [  490/  669]\n",
      "loss: 0.244735  [  630/  669]\n",
      "Training Loss (Epoch): 0.208059\n",
      "Validating...\n",
      "Validation Loss: 0.344357, Validation Accuracy: 88.69%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 12/25\n",
      "loss: 0.121212  [   70/  669]\n",
      "loss: 0.287326  [  210/  669]\n",
      "loss: 0.129555  [  350/  669]\n",
      "loss: 0.122904  [  490/  669]\n",
      "loss: 0.200814  [  630/  669]\n",
      "Training Loss (Epoch): 0.209234\n",
      "Validating...\n",
      "Validation Loss: 0.343042, Validation Accuracy: 88.10%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "\n",
      "Cross-Validation Results:\n",
      "Avg Training Loss: 0.521263\n",
      "Avg Validation Loss: 0.674410\n",
      "Avg Validation Accuracy: 87.87%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5212631433530196, 0.6744096205120895, 0.8786775677213348)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_tune(layer = 1, lr = 2e-4, weight_decay = 0.1, weights = \"DEFAULT\", drop = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchaudio\n",
    "\n",
    "# audio_path = \"./UrbanSound8k/audio/fold1/137156-9-0-30.wav\"\n",
    "# waveform, sample_rate = torchaudio.load(audio_path)\n",
    "# print(f\"Shape: {waveform.shape}, Sample Rate: {sample_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_stereogram(spectrogram):\n",
    "    # Convert to numpy\n",
    "    spectrogram_np = spectrogram.numpy()  # Shape: (2, Freq, Time)\n",
    "\n",
    "    # Plot left and right channels\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(6, 6), constrained_layout=True)\n",
    "\n",
    "    axs[0].imshow(spectrogram_np[0], aspect='auto', origin='lower', cmap='magma')\n",
    "    axs[0].set_title(f\"Spectrogram {i+1} - Left Channel\")\n",
    "    axs[0].set_ylabel(\"Frequency Bins\")\n",
    "    axs[0].set_xlabel(\"Time Frames\")\n",
    "\n",
    "    axs[1].imshow(spectrogram_np[1], aspect='auto', origin='lower', cmap='magma')\n",
    "    axs[1].set_title(f\"Spectrogram {i+1} - Right Channel\")\n",
    "    axs[1].set_ylabel(\"Frequency Bins\")\n",
    "    axs[1].set_xlabel(\"Time Frames\")\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "urbad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
