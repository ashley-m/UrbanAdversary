{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "mBSFTJ5M_z-H"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n",
    "from torch.cuda import manual_seed_all\n",
    "from torch import manual_seed as torch_manual_seed\n",
    "from torch.backends import cudnn\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3uDKfjRHMuxk"
   },
   "outputs": [],
   "source": [
    "# pre spectrogram augmentations\n",
    "# these are examples and can be changed based on domain knowledge\n",
    "\n",
    "time_stretch = T.TimeStretch()\n",
    "def stretch_waveform(waveform, rate=1.2):\n",
    "    # `rate > 1.0` speeds up, `rate < 1.0` slows down\n",
    "    return time_stretch(waveform, rate)\n",
    "\n",
    "pitch_shift = T.PitchShift(sample_rate=44100, n_steps=2)  # Shift up by 2 semitones\n",
    "def shift_pitch(waveform, sample_rate):\n",
    "    return pitch_shift(waveform)\n",
    "\n",
    "def scale_volume(waveform, factor=1.5):\n",
    "    return waveform * factor  # Amplifies waveform by factor\n",
    "\n",
    "def crop_waveform(waveform, crop_size):\n",
    "    start = torch.randint(0, max(1, waveform.size(-1) - crop_size), (1,)).item()\n",
    "    return waveform[:, start:start + crop_size]\n",
    "\n",
    "def apply_reverb(waveform):\n",
    "    reverb = T.Reverberate()\n",
    "    return reverb(waveform)\n",
    "\n",
    "def time_shift(waveform, shift):\n",
    "    return torch.roll(waveform, shifts=shift, dims=-1)\n",
    "\n",
    "def add_noise(waveform, noise_level=0.005):\n",
    "    noise = torch.randn_like(waveform) * noise_level\n",
    "    return waveform + noise\n",
    "\n",
    "# Augment on-the-fly stochastically\n",
    "# again these are just examples and do not necessarily utilize the methods above\n",
    "def augment_waveform(data):\n",
    "    waveform, sample_rate = data\n",
    "    if torch.rand(1).item() > 0.5:\n",
    "        waveform += torch.randn_like(waveform) * 0.005\n",
    "    if torch.rand(1).item() > 0.5:\n",
    "        waveform = torch.roll(waveform, shifts=torch.randint(-5000, 5000, (1,)).item(), dims=-1)\n",
    "    if torch.rand(1).item() > 0.5:\n",
    "        waveform *= torch.FloatTensor(1).uniform_(0.8, 1.5).item()\n",
    "    return waveform, sample_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Ww8OMV8nNZcf"
   },
   "outputs": [],
   "source": [
    "# Create a MelSpectrogram transformation\n",
    "mel_spectrogram_transform = T.MelSpectrogram(\n",
    "    sample_rate=44100,         # Default sample rate, change if needed\n",
    "    n_fft=1024,                # Number of FFT bins\n",
    "    hop_length=512,            # Hop length between windows\n",
    "    n_mels=64                  # Number of Mel bands\n",
    ")\n",
    "\n",
    "def waveform_to_spectrogram(data):\n",
    "    waveform, sample_rate = data\n",
    "    spectrogram = mel_spectrogram_transform(waveform)  # Apply the spectrogram transformation\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "khV1u_wUIR-o"
   },
   "outputs": [],
   "source": [
    "# post spectrogram augmentations\n",
    "\n",
    "# Example augmentations, could add more\n",
    "time_mask = T.TimeMasking(time_mask_param=10)\n",
    "\n",
    "freq_mask = T.FrequencyMasking(freq_mask_param=8)\n",
    "\n",
    "# hybridizes two sounds\n",
    "def mixup(spectrogram1, spectrogram2, alpha=0.2):\n",
    "    lam = torch.FloatTensor(1).uniform_(0, alpha).item()\n",
    "    return lam * spectrogram1 + (1 - lam) * spectrogram2\n",
    "\n",
    "# should probably implement a randomization process like above\n",
    "def augment_spectrogram(spectrogram):\n",
    "    augmented = time_mask(spectrogram)  # Apply time masking\n",
    "    augmented = freq_mask(augmented)   # Apply frequency masking\n",
    "    return augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2U9n6Z-fPiwY"
   },
   "outputs": [],
   "source": [
    "# Decode audio files\n",
    "def decode_audio(file_tuple):\n",
    "    file_path, file = file_tuple\n",
    "    waveform, sample_rate = torchaudio.load(file_path)\n",
    "    return waveform, sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "class UrbanSoundDataset(Dataset):\n",
    "    def __init__(self, audio_path, fold, csv_path, transform=None):\n",
    "        self.audio_path = os.path.join(audio_path, f\"fold{fold}\")\n",
    "        self.file_list = [os.path.join(self.audio_path, f) for f in os.listdir(self.audio_path) if f.endswith(\".wav\")]\n",
    "        self.transform = transform\n",
    "\n",
    "        # Load the metadata CSV file\n",
    "        self.metadata = pd.read_csv(csv_path)\n",
    "\n",
    "    def get_label(self, file_name):\n",
    "        \"\"\"Fetch the class label for a given file name from the metadata.\"\"\"\n",
    "        label_row = self.metadata.loc[self.metadata['slice_file_name'] == file_name, 'class']\n",
    "        if not label_row.empty:\n",
    "            return label_row.values[0]\n",
    "        else:\n",
    "            raise ValueError(f\"File name {file_name} not found in metadata CSV.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load the audio file\n",
    "        file_path = self.file_list[idx]\n",
    "        waveform, sample_rate = torchaudio.load(file_path)\n",
    "\n",
    "        # Convert mono to stereo if necessary\n",
    "        if waveform.size(0) == 1:  # If mono\n",
    "            waveform = waveform.repeat(2, 1)\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            waveform = self.transform(waveform)\n",
    "\n",
    "        # Extract the file name from the path\n",
    "        file_name = os.path.basename(file_path)\n",
    "\n",
    "        # Get the corresponding label for the file\n",
    "        label = self.get_label(file_name)\n",
    "\n",
    "        return waveform, label\n",
    "\n",
    "# class UrbanSoundDataset(Dataset):\n",
    "#     def __init__(self, audio_path, fold, transform=None):\n",
    "#         self.audio_path = os.path.join(audio_path, f\"fold{fold}\")\n",
    "#         self.norm_path = os.path.normpath(self.audio_path)\n",
    "#         self.file_list = [os.path.join(self.norm_path, f) for f in os.listdir(self.norm_path) if f.endswith(\".wav\")]\n",
    "#         self.transform = transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.file_list)\n",
    "\n",
    "#     # def __getitem__(self, idx):\n",
    "#     #     # Load the audio file\n",
    "#     #     file_path = self.file_list[idx]\n",
    "#     #     waveform, sample_rate = torchaudio.load(file_path)\n",
    "\n",
    "#     #     # Convert mono to stereo if necessary\n",
    "#     #     if waveform.size(0) == 1:\n",
    "#     #         waveform = waveform.repeat(2, 1)\n",
    "\n",
    "        \n",
    "#     #     # Apply any transformations (e.g., augmentations, spectrogram)\n",
    "#     #     if self.transform:\n",
    "#     #         waveform = self.transform(waveform)\n",
    "        \n",
    "#     #     return waveform\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#     file_path = self.file_list[idx]\n",
    "#     waveform, sample_rate = torchaudio.load(file_path)\n",
    "    \n",
    "#     # Convert mono to stereo if necessary\n",
    "#     if waveform.size(0) == 1:\n",
    "#         waveform = waveform.repeat(2, 1)\n",
    "    \n",
    "#     # Apply transformations\n",
    "#     if self.transform:\n",
    "#         waveform = self.transform(waveform)\n",
    "\n",
    "#     # Make sure to return both X (waveform) and y (label)\n",
    "#     label = self.get_label(file_path)  # Replace with your method to get labels\n",
    "#     return waveform, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asm2fe/.local/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torchaudio.transforms as T\n",
    "\n",
    "# Example transformations\n",
    "def augment_waveform(waveform):\n",
    "    # Add your augmentation logic here (e.g., noise addition, time stretch, etc.)\n",
    "    return waveform\n",
    "\n",
    "waveform_to_spectrogram = T.MelSpectrogram(sample_rate=16000, n_mels=128)\n",
    "augment_spectrogram = T.AmplitudeToDB()\n",
    "\n",
    "# Combine transformations into a callable function\n",
    "def transform_pipeline(waveform):\n",
    "    waveform = augment_waveform(waveform)\n",
    "    spectrogram = waveform_to_spectrogram(waveform)\n",
    "    spectrogram = augment_spectrogram(spectrogram)\n",
    "    return spectrogram\n",
    "\n",
    "def pad_with_noise(spectrogram, max_time, noise_std=0.01):\n",
    "    \"\"\"\n",
    "    Pads a spectrogram with Gaussian noise instead of zeros.\n",
    "\n",
    "    Args:\n",
    "        spectrogram (Tensor): Shape (channels, freq_bins, time_steps)\n",
    "        max_time (int): Target time dimension\n",
    "        noise_std (float): Standard deviation of the Gaussian noise\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Padded spectrogram with noise\n",
    "    \"\"\"\n",
    "    # Compute how much padding is needed\n",
    "    pad_amount = max_time - spectrogram.size(2)\n",
    "    \n",
    "    if pad_amount > 0:\n",
    "        # Generate random noise matching the shape of missing time steps\n",
    "        noise = torch.randn((spectrogram.size(0), spectrogram.size(1), pad_amount)) * noise_std\n",
    "        \n",
    "        # Concatenate noise along the time axis\n",
    "        spectrogram = torch.cat([spectrogram, noise], dim=2)\n",
    "    \n",
    "    return spectrogram\n",
    "\n",
    "def convert_to_three_channels(spectrogram):\n",
    "    # Convert [2, 224, 224] to [3, 224, 224]\n",
    "    if spectrogram.size(0) == 2:\n",
    "        # Duplicate the first channel to create a third channel\n",
    "        return torch.cat((spectrogram, spectrogram[0:1, :, :]), dim=0)\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "class densenet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    DenseNet Class, derived from Pytorch. Intended for model manipulation (i.e. unfreezing layers, etc.)\n",
    "    To use model, try (densenet).model(data)\n",
    "    May change to reflect manual implementation of densenet161.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()  # Initialize the nn.Module base class\n",
    "        self.model = torchvision.models.densenet161()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)  # Delegate forward pass to the original DenseNet\n",
    "\n",
    "    def layer_change(self):\n",
    "        \"\"\"\n",
    "        Unfreeze layers of DenseNet model per specifications\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and testing loops\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, scheduler = None, epochs=1):\n",
    "    model.train()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        size = len(dataloader.dataset)\n",
    "        total_loss = 0  # Initialize variable to accumulate loss per epoch\n",
    "        total_batches = len(dataloader)\n",
    "\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            # Compute prediction and loss\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate loss\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "\n",
    "            total_batches = len(dataloader)\n",
    "            if batch % (total_batches // 5) == 0:  # Prints 5 times per epoch\n",
    "                current = (batch + 1) * len(X)\n",
    "                print(f\"loss: {loss.item():>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        # Average loss for this epoch\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Training Loss (Epoch): {avg_loss:>7f}\")\n",
    "    return avg_loss  # Return the average loss for the last epoch\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    # Average loss and accuracy for this fold\n",
    "    avg_test_loss = test_loss / num_batches\n",
    "    accuracy = correct / size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*accuracy):>0.1f}%, Avg loss: {avg_test_loss:>8f} \\n\")\n",
    "    return avg_test_loss, accuracy  # Return both average loss and accuracy for this fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "BLCzmvxcHvKs"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Resize and normalize for DenseNet\n",
    "resize_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize for DenseNet\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Standard ImageNet normalization\n",
    "])\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    inputs, labels = zip(*batch)  # Separate inputs and labels\n",
    "    max_time = max(spectrogram.size(2) for spectrogram in inputs)\n",
    "\n",
    "    # Pad inputs to the same length along the time dimension\n",
    "    padded_inputs = [\n",
    "        torch.nn.functional.pad(input, (0, max_time - input.size(2)))\n",
    "        for input in inputs\n",
    "    ]\n",
    "\n",
    "    # Convert to 3 channels and resize\n",
    "    resized_inputs = [resize_transform(convert_to_three_channels(input)) for input in padded_inputs]\n",
    "    \n",
    "    # Map labels to numeric class IDs\n",
    "    class_mapping = {\n",
    "        \"air_conditioner\": 0,\n",
    "        \"car_horn\": 1,\n",
    "        \"children_playing\": 2,\n",
    "        \"dog_bark\": 3,\n",
    "        \"drilling\": 4,\n",
    "        \"engine_idling\": 5,\n",
    "        \"gun_shot\": 6,\n",
    "        \"jackhammer\": 7,\n",
    "        \"siren\": 8,\n",
    "        \"street_music\": 9\n",
    "    }\n",
    "\n",
    "    numeric_labels = [class_mapping[label] for label in labels]\n",
    "\n",
    "    # Stack inputs and labels\n",
    "    return torch.stack(resized_inputs), torch.tensor(numeric_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sfs/gpfs/tardis/home/asm2fe/UrbanAdversary\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1\n",
      "Epoch 1/20\n",
      "loss: 7.014059  [   64/  698]\n",
      "loss: 3.600421  [  192/  698]\n",
      "loss: 1.725978  [  320/  698]\n",
      "loss: 1.395375  [  448/  698]\n",
      "loss: 1.517347  [  576/  698]\n",
      "loss: 1.551700  [  638/  698]\n",
      "Training Loss (Epoch): 2.635453\n",
      "Epoch 2/20\n",
      "loss: 1.518900  [   64/  698]\n",
      "loss: 1.456610  [  192/  698]\n",
      "loss: 1.138530  [  320/  698]\n",
      "loss: 1.181764  [  448/  698]\n",
      "loss: 1.280517  [  576/  698]\n",
      "loss: 1.148436  [  638/  698]\n",
      "Training Loss (Epoch): 1.281892\n",
      "Epoch 3/20\n",
      "loss: 1.082554  [   64/  698]\n",
      "loss: 0.990879  [  192/  698]\n",
      "loss: 1.262527  [  320/  698]\n",
      "loss: 1.057591  [  448/  698]\n",
      "loss: 1.010648  [  576/  698]\n",
      "loss: 0.873514  [  638/  698]\n",
      "Training Loss (Epoch): 1.044794\n",
      "Epoch 4/20\n",
      "loss: 0.754652  [   64/  698]\n",
      "loss: 0.750141  [  192/  698]\n",
      "loss: 0.782680  [  320/  698]\n",
      "loss: 0.997096  [  448/  698]\n",
      "loss: 0.812159  [  576/  698]\n",
      "loss: 0.915061  [  638/  698]\n",
      "Training Loss (Epoch): 0.845733\n",
      "Epoch 5/20\n",
      "loss: 0.673269  [   64/  698]\n",
      "loss: 0.697129  [  192/  698]\n",
      "loss: 0.654542  [  320/  698]\n",
      "loss: 0.820791  [  448/  698]\n",
      "loss: 0.527932  [  576/  698]\n",
      "loss: 0.770451  [  638/  698]\n",
      "Training Loss (Epoch): 0.671530\n",
      "Epoch 6/20\n",
      "loss: 0.468106  [   64/  698]\n",
      "loss: 0.501270  [  192/  698]\n",
      "loss: 0.627922  [  320/  698]\n",
      "loss: 0.461332  [  448/  698]\n",
      "loss: 0.501534  [  576/  698]\n",
      "loss: 0.438612  [  638/  698]\n",
      "Training Loss (Epoch): 0.540392\n",
      "Epoch 7/20\n",
      "loss: 0.354942  [   64/  698]\n",
      "loss: 0.387107  [  192/  698]\n",
      "loss: 0.514252  [  320/  698]\n",
      "loss: 0.336180  [  448/  698]\n",
      "loss: 0.416500  [  576/  698]\n",
      "loss: 0.350138  [  638/  698]\n",
      "Training Loss (Epoch): 0.421213\n",
      "Epoch 8/20\n",
      "loss: 0.392257  [   64/  698]\n",
      "loss: 0.347821  [  192/  698]\n",
      "loss: 0.378698  [  320/  698]\n",
      "loss: 0.320573  [  448/  698]\n",
      "loss: 0.325960  [  576/  698]\n",
      "loss: 0.295660  [  638/  698]\n",
      "Training Loss (Epoch): 0.364011\n",
      "Epoch 9/20\n",
      "loss: 0.335979  [   64/  698]\n",
      "loss: 0.213416  [  192/  698]\n",
      "loss: 0.229235  [  320/  698]\n",
      "loss: 0.235263  [  448/  698]\n",
      "loss: 0.282375  [  576/  698]\n",
      "loss: 0.368774  [  638/  698]\n",
      "Training Loss (Epoch): 0.278222\n",
      "Epoch 10/20\n",
      "loss: 0.194569  [   64/  698]\n",
      "loss: 0.214328  [  192/  698]\n",
      "loss: 0.263224  [  320/  698]\n",
      "loss: 0.196732  [  448/  698]\n",
      "loss: 0.141604  [  576/  698]\n",
      "loss: 0.290969  [  638/  698]\n",
      "Training Loss (Epoch): 0.225128\n",
      "Epoch 11/20\n",
      "loss: 0.133174  [   64/  698]\n",
      "loss: 0.166367  [  192/  698]\n",
      "loss: 0.138087  [  320/  698]\n",
      "loss: 0.141762  [  448/  698]\n",
      "loss: 0.153899  [  576/  698]\n",
      "loss: 0.120648  [  638/  698]\n",
      "Training Loss (Epoch): 0.134796\n",
      "Epoch 12/20\n",
      "loss: 0.121649  [   64/  698]\n",
      "loss: 0.153704  [  192/  698]\n",
      "loss: 0.123992  [  320/  698]\n",
      "loss: 0.113593  [  448/  698]\n",
      "loss: 0.128281  [  576/  698]\n",
      "loss: 0.186864  [  638/  698]\n",
      "Training Loss (Epoch): 0.129198\n",
      "Epoch 13/20\n",
      "loss: 0.125950  [   64/  698]\n",
      "loss: 0.087152  [  192/  698]\n",
      "loss: 0.114098  [  320/  698]\n",
      "loss: 0.087452  [  448/  698]\n",
      "loss: 0.091707  [  576/  698]\n",
      "loss: 0.136591  [  638/  698]\n",
      "Training Loss (Epoch): 0.111746\n",
      "Epoch 14/20\n",
      "loss: 0.156442  [   64/  698]\n",
      "loss: 0.105675  [  192/  698]\n",
      "loss: 0.067831  [  320/  698]\n",
      "loss: 0.125218  [  448/  698]\n",
      "loss: 0.094368  [  576/  698]\n",
      "loss: 0.056735  [  638/  698]\n",
      "Training Loss (Epoch): 0.096203\n",
      "Epoch 15/20\n",
      "loss: 0.068255  [   64/  698]\n",
      "loss: 0.072236  [  192/  698]\n",
      "loss: 0.079886  [  320/  698]\n",
      "loss: 0.080822  [  448/  698]\n",
      "loss: 0.066408  [  576/  698]\n",
      "loss: 0.057806  [  638/  698]\n",
      "Training Loss (Epoch): 0.078816\n",
      "Epoch 16/20\n",
      "loss: 0.071541  [   64/  698]\n",
      "loss: 0.064138  [  192/  698]\n",
      "loss: 0.099809  [  320/  698]\n",
      "loss: 0.075333  [  448/  698]\n",
      "loss: 0.065328  [  576/  698]\n",
      "loss: 0.103663  [  638/  698]\n",
      "Training Loss (Epoch): 0.076899\n",
      "Epoch 17/20\n",
      "loss: 0.111504  [   64/  698]\n",
      "loss: 0.077573  [  192/  698]\n",
      "loss: 0.080981  [  320/  698]\n",
      "loss: 0.061261  [  448/  698]\n",
      "loss: 0.142793  [  576/  698]\n",
      "loss: 0.111274  [  638/  698]\n",
      "Training Loss (Epoch): 0.087689\n",
      "Epoch 18/20\n",
      "loss: 0.058875  [   64/  698]\n",
      "loss: 0.042409  [  192/  698]\n",
      "loss: 0.111102  [  320/  698]\n",
      "loss: 0.091862  [  448/  698]\n",
      "loss: 0.056155  [  576/  698]\n",
      "loss: 0.071330  [  638/  698]\n",
      "Training Loss (Epoch): 0.077037\n",
      "Epoch 19/20\n",
      "loss: 0.049438  [   64/  698]\n",
      "loss: 0.093932  [  192/  698]\n",
      "loss: 0.077433  [  320/  698]\n",
      "loss: 0.059403  [  448/  698]\n",
      "loss: 0.059803  [  576/  698]\n",
      "loss: 0.087303  [  638/  698]\n",
      "Training Loss (Epoch): 0.077303\n",
      "Epoch 20/20\n",
      "loss: 0.106867  [   64/  698]\n",
      "loss: 0.097333  [  192/  698]\n",
      "loss: 0.065715  [  320/  698]\n",
      "loss: 0.077107  [  448/  698]\n",
      "loss: 0.051506  [  576/  698]\n",
      "loss: 0.142250  [  638/  698]\n",
      "Training Loss (Epoch): 0.091709\n",
      "Test Error: \n",
      " Accuracy: 93.7%, Avg loss: 0.242238 \n",
      "\n",
      "Processing Fold 2\n",
      "Epoch 1/20\n",
      "loss: 1.301074  [   64/  710]\n",
      "loss: 2.457359  [  192/  710]\n",
      "loss: 1.804820  [  320/  710]\n",
      "loss: 1.935482  [  448/  710]\n",
      "loss: 1.582613  [  576/  710]\n",
      "loss: 1.352411  [  704/  710]\n",
      "Training Loss (Epoch): 2.002333\n",
      "Epoch 2/20\n",
      "loss: 1.237181  [   64/  710]\n",
      "loss: 1.274616  [  192/  710]\n",
      "loss: 1.313810  [  320/  710]\n",
      "loss: 1.084968  [  448/  710]\n",
      "loss: 1.278368  [  576/  710]\n",
      "loss: 1.649125  [  704/  710]\n",
      "Training Loss (Epoch): 1.388327\n",
      "Epoch 3/20\n",
      "loss: 1.251241  [   64/  710]\n",
      "loss: 1.240916  [  192/  710]\n",
      "loss: 1.020646  [  320/  710]\n",
      "loss: 1.402193  [  448/  710]\n",
      "loss: 0.949476  [  576/  710]\n",
      "loss: 1.027248  [  704/  710]\n",
      "Training Loss (Epoch): 1.165919\n",
      "Epoch 4/20\n",
      "loss: 1.006304  [   64/  710]\n",
      "loss: 0.978944  [  192/  710]\n",
      "loss: 1.236304  [  320/  710]\n",
      "loss: 1.026191  [  448/  710]\n",
      "loss: 0.996742  [  576/  710]\n",
      "loss: 0.864925  [  704/  710]\n",
      "Training Loss (Epoch): 1.161751\n",
      "Epoch 5/20\n",
      "loss: 0.881820  [   64/  710]\n",
      "loss: 0.849815  [  192/  710]\n",
      "loss: 1.337458  [  320/  710]\n",
      "loss: 0.949659  [  448/  710]\n",
      "loss: 0.871866  [  576/  710]\n",
      "loss: 0.929468  [  704/  710]\n",
      "Training Loss (Epoch): 0.985102\n",
      "Epoch 6/20\n",
      "loss: 0.853679  [   64/  710]\n",
      "loss: 1.171893  [  192/  710]\n",
      "loss: 0.858829  [  320/  710]\n",
      "loss: 0.960729  [  448/  710]\n",
      "loss: 0.743512  [  576/  710]\n",
      "loss: 1.073195  [  704/  710]\n",
      "Training Loss (Epoch): 0.993394\n",
      "Epoch 7/20\n",
      "loss: 0.746271  [   64/  710]\n",
      "loss: 0.839279  [  192/  710]\n",
      "loss: 0.830034  [  320/  710]\n",
      "loss: 0.729523  [  448/  710]\n",
      "loss: 0.775425  [  576/  710]\n",
      "loss: 0.833938  [  704/  710]\n",
      "Training Loss (Epoch): 0.792377\n",
      "Epoch 8/20\n",
      "loss: 0.597903  [   64/  710]\n",
      "loss: 1.171412  [  192/  710]\n",
      "loss: 0.592560  [  320/  710]\n",
      "loss: 0.717953  [  448/  710]\n",
      "loss: 0.665884  [  576/  710]\n",
      "loss: 0.601996  [  704/  710]\n",
      "Training Loss (Epoch): 0.724332\n",
      "Epoch 9/20\n",
      "loss: 0.668284  [   64/  710]\n",
      "loss: 0.437817  [  192/  710]\n",
      "loss: 0.530819  [  320/  710]\n",
      "loss: 0.779253  [  448/  710]\n",
      "loss: 0.604758  [  576/  710]\n",
      "loss: 0.621651  [  704/  710]\n",
      "Training Loss (Epoch): 0.675004\n",
      "Epoch 10/20\n",
      "loss: 0.538104  [   64/  710]\n",
      "loss: 0.614700  [  192/  710]\n",
      "loss: 0.719049  [  320/  710]\n",
      "loss: 0.605385  [  448/  710]\n",
      "loss: 0.475698  [  576/  710]\n",
      "loss: 0.470817  [  704/  710]\n",
      "Training Loss (Epoch): 0.608325\n",
      "Epoch 11/20\n",
      "loss: 0.521514  [   64/  710]\n",
      "loss: 0.436079  [  192/  710]\n",
      "loss: 0.454100  [  320/  710]\n",
      "loss: 0.534329  [  448/  710]\n",
      "loss: 0.528652  [  576/  710]\n",
      "loss: 0.383325  [  704/  710]\n",
      "Training Loss (Epoch): 0.521391\n",
      "Epoch 12/20\n",
      "loss: 0.602102  [   64/  710]\n",
      "loss: 0.389031  [  192/  710]\n",
      "loss: 0.650652  [  320/  710]\n",
      "loss: 0.342631  [  448/  710]\n",
      "loss: 0.359921  [  576/  710]\n",
      "loss: 0.468184  [  704/  710]\n",
      "Training Loss (Epoch): 0.728088\n",
      "Epoch 13/20\n",
      "loss: 0.319508  [   64/  710]\n",
      "loss: 0.477205  [  192/  710]\n",
      "loss: 0.376769  [  320/  710]\n",
      "loss: 0.467645  [  448/  710]\n",
      "loss: 0.411747  [  576/  710]\n",
      "loss: 0.519637  [  704/  710]\n",
      "Training Loss (Epoch): 0.498959\n",
      "Epoch 14/20\n",
      "loss: 0.434092  [   64/  710]\n",
      "loss: 0.442620  [  192/  710]\n",
      "loss: 0.430576  [  320/  710]\n",
      "loss: 0.476152  [  448/  710]\n",
      "loss: 0.858826  [  576/  710]\n",
      "loss: 0.329812  [  704/  710]\n",
      "Training Loss (Epoch): 0.576608\n",
      "Epoch 15/20\n",
      "loss: 0.404998  [   64/  710]\n",
      "loss: 0.571135  [  192/  710]\n",
      "loss: 0.533737  [  320/  710]\n",
      "loss: 0.480526  [  448/  710]\n",
      "loss: 0.471679  [  576/  710]\n",
      "loss: 0.370799  [  704/  710]\n",
      "Training Loss (Epoch): 0.460962\n",
      "Epoch 16/20\n",
      "loss: 0.367250  [   64/  710]\n",
      "loss: 0.514701  [  192/  710]\n",
      "loss: 0.723637  [  320/  710]\n",
      "loss: 0.471508  [  448/  710]\n",
      "loss: 0.527843  [  576/  710]\n",
      "loss: 0.295826  [  704/  710]\n",
      "Training Loss (Epoch): 0.462905\n",
      "Epoch 17/20\n",
      "loss: 0.525441  [   64/  710]\n",
      "loss: 0.615254  [  192/  710]\n",
      "loss: 0.453848  [  320/  710]\n",
      "loss: 0.505044  [  448/  710]\n",
      "loss: 0.630165  [  576/  710]\n",
      "loss: 0.398771  [  704/  710]\n",
      "Training Loss (Epoch): 0.482093\n",
      "Epoch 18/20\n",
      "loss: 0.382296  [   64/  710]\n",
      "loss: 0.354426  [  192/  710]\n",
      "loss: 0.556709  [  320/  710]\n",
      "loss: 0.591124  [  448/  710]\n",
      "loss: 0.537180  [  576/  710]\n",
      "loss: 0.332234  [  704/  710]\n",
      "Training Loss (Epoch): 0.472015\n",
      "Epoch 19/20\n",
      "loss: 0.363524  [   64/  710]\n",
      "loss: 0.449053  [  192/  710]\n",
      "loss: 0.481600  [  320/  710]\n",
      "loss: 0.455764  [  448/  710]\n",
      "loss: 0.317324  [  576/  710]\n",
      "loss: 0.432462  [  704/  710]\n",
      "Training Loss (Epoch): 0.523316\n",
      "Epoch 20/20\n",
      "loss: 0.376279  [   64/  710]\n",
      "loss: 0.391339  [  192/  710]\n",
      "loss: 0.635695  [  320/  710]\n",
      "loss: 0.423199  [  448/  710]\n",
      "loss: 0.493668  [  576/  710]\n",
      "loss: 0.519075  [  704/  710]\n",
      "Training Loss (Epoch): 0.538959\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 0.823515 \n",
      "\n",
      "Processing Fold 3\n",
      "Epoch 1/20\n",
      "loss: 2.263769  [   64/  740]\n",
      "loss: 3.416896  [  192/  740]\n",
      "loss: 1.937978  [  320/  740]\n",
      "loss: 1.988580  [  448/  740]\n",
      "loss: 2.011918  [  576/  740]\n",
      "loss: 1.488131  [  704/  740]\n",
      "Training Loss (Epoch): 2.066554\n",
      "Epoch 2/20\n",
      "loss: 1.662666  [   64/  740]\n",
      "loss: 1.344048  [  192/  740]\n",
      "loss: 1.585954  [  320/  740]\n",
      "loss: 1.473895  [  448/  740]\n",
      "loss: 1.395630  [  576/  740]\n",
      "loss: 1.586122  [  704/  740]\n",
      "Training Loss (Epoch): 1.497009\n",
      "Epoch 3/20\n",
      "loss: 1.481346  [   64/  740]\n",
      "loss: 1.627550  [  192/  740]\n",
      "loss: 1.192322  [  320/  740]\n",
      "loss: 1.538693  [  448/  740]\n",
      "loss: 1.310720  [  576/  740]\n",
      "loss: 1.513196  [  704/  740]\n",
      "Training Loss (Epoch): 1.354219\n",
      "Epoch 4/20\n",
      "loss: 1.300636  [   64/  740]\n",
      "loss: 1.254529  [  192/  740]\n",
      "loss: 1.491604  [  320/  740]\n",
      "loss: 1.209541  [  448/  740]\n",
      "loss: 1.206167  [  576/  740]\n",
      "loss: 1.284383  [  704/  740]\n",
      "Training Loss (Epoch): 1.296752\n",
      "Epoch 5/20\n",
      "loss: 1.263417  [   64/  740]\n",
      "loss: 1.266089  [  192/  740]\n",
      "loss: 1.147370  [  320/  740]\n",
      "loss: 1.314318  [  448/  740]\n",
      "loss: 1.026063  [  576/  740]\n",
      "loss: 1.215815  [  704/  740]\n",
      "Training Loss (Epoch): 1.193941\n",
      "Epoch 6/20\n",
      "loss: 1.236820  [   64/  740]\n",
      "loss: 1.260386  [  192/  740]\n",
      "loss: 1.081371  [  320/  740]\n",
      "loss: 1.032938  [  448/  740]\n",
      "loss: 1.062905  [  576/  740]\n",
      "loss: 1.237371  [  704/  740]\n",
      "Training Loss (Epoch): 1.133791\n",
      "Epoch 7/20\n",
      "loss: 0.853985  [   64/  740]\n",
      "loss: 1.143162  [  192/  740]\n",
      "loss: 0.951882  [  320/  740]\n",
      "loss: 1.088453  [  448/  740]\n",
      "loss: 0.908647  [  576/  740]\n",
      "loss: 1.057305  [  704/  740]\n",
      "Training Loss (Epoch): 1.017043\n",
      "Epoch 8/20\n",
      "loss: 0.821273  [   64/  740]\n",
      "loss: 0.936518  [  192/  740]\n",
      "loss: 0.902172  [  320/  740]\n",
      "loss: 0.974971  [  448/  740]\n",
      "loss: 1.047196  [  576/  740]\n",
      "loss: 0.994709  [  704/  740]\n",
      "Training Loss (Epoch): 0.944447\n",
      "Epoch 9/20\n",
      "loss: 0.853002  [   64/  740]\n",
      "loss: 0.852323  [  192/  740]\n",
      "loss: 0.889427  [  320/  740]\n",
      "loss: 1.018849  [  448/  740]\n",
      "loss: 0.896210  [  576/  740]\n",
      "loss: 0.969741  [  704/  740]\n",
      "Training Loss (Epoch): 0.876611\n",
      "Epoch 10/20\n",
      "loss: 0.790347  [   64/  740]\n",
      "loss: 0.935276  [  192/  740]\n",
      "loss: 0.666304  [  320/  740]\n",
      "loss: 0.691992  [  448/  740]\n",
      "loss: 0.809667  [  576/  740]\n",
      "loss: 0.703071  [  704/  740]\n",
      "Training Loss (Epoch): 0.767718\n",
      "Epoch 11/20\n",
      "loss: 0.554076  [   64/  740]\n",
      "loss: 0.923042  [  192/  740]\n",
      "loss: 0.516177  [  320/  740]\n",
      "loss: 0.595316  [  448/  740]\n",
      "loss: 0.709815  [  576/  740]\n",
      "loss: 0.885853  [  704/  740]\n",
      "Training Loss (Epoch): 0.699188\n",
      "Epoch 12/20\n",
      "loss: 0.753440  [   64/  740]\n",
      "loss: 0.815539  [  192/  740]\n",
      "loss: 0.592166  [  320/  740]\n",
      "loss: 0.494347  [  448/  740]\n",
      "loss: 0.545583  [  576/  740]\n",
      "loss: 0.687618  [  704/  740]\n",
      "Training Loss (Epoch): 0.671123\n",
      "Epoch 13/20\n",
      "loss: 0.625351  [   64/  740]\n",
      "loss: 0.635886  [  192/  740]\n",
      "loss: 0.549451  [  320/  740]\n",
      "loss: 0.641586  [  448/  740]\n",
      "loss: 0.697572  [  576/  740]\n",
      "loss: 0.664270  [  704/  740]\n",
      "Training Loss (Epoch): 0.657128\n",
      "Epoch 14/20\n",
      "loss: 0.643034  [   64/  740]\n",
      "loss: 0.631067  [  192/  740]\n",
      "loss: 0.759324  [  320/  740]\n",
      "loss: 0.495073  [  448/  740]\n",
      "loss: 0.611620  [  576/  740]\n",
      "loss: 0.565754  [  704/  740]\n",
      "Training Loss (Epoch): 0.622409\n",
      "Epoch 15/20\n",
      "loss: 0.511951  [   64/  740]\n",
      "loss: 0.629636  [  192/  740]\n",
      "loss: 0.672143  [  320/  740]\n",
      "loss: 0.480439  [  448/  740]\n",
      "loss: 0.678593  [  576/  740]\n",
      "loss: 0.563985  [  704/  740]\n",
      "Training Loss (Epoch): 0.593296\n",
      "Epoch 16/20\n",
      "loss: 0.745997  [   64/  740]\n",
      "loss: 0.529827  [  192/  740]\n",
      "loss: 0.670095  [  320/  740]\n",
      "loss: 0.617376  [  448/  740]\n",
      "loss: 0.677211  [  576/  740]\n",
      "loss: 0.541764  [  704/  740]\n",
      "Training Loss (Epoch): 0.600434\n",
      "Epoch 17/20\n",
      "loss: 0.361846  [   64/  740]\n",
      "loss: 0.590985  [  192/  740]\n",
      "loss: 0.797831  [  320/  740]\n",
      "loss: 0.556145  [  448/  740]\n",
      "loss: 0.685004  [  576/  740]\n",
      "loss: 0.561103  [  704/  740]\n",
      "Training Loss (Epoch): 0.591936\n",
      "Epoch 18/20\n",
      "loss: 0.455442  [   64/  740]\n",
      "loss: 0.750689  [  192/  740]\n",
      "loss: 0.558668  [  320/  740]\n",
      "loss: 0.607940  [  448/  740]\n",
      "loss: 0.515169  [  576/  740]\n",
      "loss: 0.658241  [  704/  740]\n",
      "Training Loss (Epoch): 0.599915\n",
      "Epoch 19/20\n",
      "loss: 0.635788  [   64/  740]\n",
      "loss: 0.735612  [  192/  740]\n",
      "loss: 0.564281  [  320/  740]\n",
      "loss: 0.733140  [  448/  740]\n",
      "loss: 0.679565  [  576/  740]\n",
      "loss: 0.410985  [  704/  740]\n",
      "Training Loss (Epoch): 0.613842\n",
      "Epoch 20/20\n",
      "loss: 0.591036  [   64/  740]\n",
      "loss: 0.665930  [  192/  740]\n",
      "loss: 0.602276  [  320/  740]\n",
      "loss: 0.423010  [  448/  740]\n",
      "loss: 0.645908  [  576/  740]\n",
      "loss: 0.657276  [  704/  740]\n",
      "Training Loss (Epoch): 0.600488\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.617756 \n",
      "\n",
      "Processing Fold 4\n",
      "Epoch 1/20\n",
      "loss: 2.333189  [   64/  792]\n",
      "loss: 1.903763  [  192/  792]\n",
      "loss: 1.872635  [  320/  792]\n",
      "loss: 1.653484  [  448/  792]\n",
      "loss: 1.254276  [  576/  792]\n",
      "loss: 1.561293  [  704/  792]\n",
      "loss: 1.529315  [  312/  792]\n",
      "Training Loss (Epoch): 1.732516\n",
      "Epoch 2/20\n",
      "loss: 1.368356  [   64/  792]\n",
      "loss: 1.479930  [  192/  792]\n",
      "loss: 1.207411  [  320/  792]\n",
      "loss: 1.506545  [  448/  792]\n",
      "loss: 1.143516  [  576/  792]\n",
      "loss: 1.281555  [  704/  792]\n",
      "loss: 1.125624  [  312/  792]\n",
      "Training Loss (Epoch): 1.267593\n",
      "Epoch 3/20\n",
      "loss: 1.122435  [   64/  792]\n",
      "loss: 1.156672  [  192/  792]\n",
      "loss: 1.250154  [  320/  792]\n",
      "loss: 1.088732  [  448/  792]\n",
      "loss: 1.047182  [  576/  792]\n",
      "loss: 1.238993  [  704/  792]\n",
      "loss: 1.224816  [  312/  792]\n",
      "Training Loss (Epoch): 1.114271\n",
      "Epoch 4/20\n",
      "loss: 0.913031  [   64/  792]\n",
      "loss: 1.154584  [  192/  792]\n",
      "loss: 0.948673  [  320/  792]\n",
      "loss: 1.027123  [  448/  792]\n",
      "loss: 1.040404  [  576/  792]\n",
      "loss: 0.888938  [  704/  792]\n",
      "loss: 1.161254  [  312/  792]\n",
      "Training Loss (Epoch): 1.018039\n",
      "Epoch 5/20\n",
      "loss: 0.839680  [   64/  792]\n",
      "loss: 0.955371  [  192/  792]\n",
      "loss: 0.916896  [  320/  792]\n",
      "loss: 0.889724  [  448/  792]\n",
      "loss: 0.895855  [  576/  792]\n",
      "loss: 1.233633  [  704/  792]\n",
      "loss: 1.510653  [  312/  792]\n",
      "Training Loss (Epoch): 0.975645\n",
      "Epoch 6/20\n",
      "loss: 0.921860  [   64/  792]\n",
      "loss: 0.998886  [  192/  792]\n",
      "loss: 0.775540  [  320/  792]\n",
      "loss: 0.898578  [  448/  792]\n",
      "loss: 0.955966  [  576/  792]\n",
      "loss: 0.882574  [  704/  792]\n",
      "loss: 0.808394  [  312/  792]\n",
      "Training Loss (Epoch): 0.861844\n",
      "Epoch 7/20\n",
      "loss: 0.782064  [   64/  792]\n",
      "loss: 0.831465  [  192/  792]\n",
      "loss: 0.661023  [  320/  792]\n",
      "loss: 0.852107  [  448/  792]\n",
      "loss: 0.733753  [  576/  792]\n",
      "loss: 0.949794  [  704/  792]\n",
      "loss: 1.202870  [  312/  792]\n",
      "Training Loss (Epoch): 0.828571\n",
      "Epoch 8/20\n",
      "loss: 0.759761  [   64/  792]\n",
      "loss: 0.683151  [  192/  792]\n",
      "loss: 0.763796  [  320/  792]\n",
      "loss: 0.808991  [  448/  792]\n",
      "loss: 0.736026  [  576/  792]\n",
      "loss: 0.569348  [  704/  792]\n",
      "loss: 0.654504  [  312/  792]\n",
      "Training Loss (Epoch): 0.725063\n",
      "Epoch 9/20\n",
      "loss: 0.606523  [   64/  792]\n",
      "loss: 0.696095  [  192/  792]\n",
      "loss: 1.536298  [  320/  792]\n",
      "loss: 0.731285  [  448/  792]\n",
      "loss: 0.774137  [  576/  792]\n",
      "loss: 0.657935  [  704/  792]\n",
      "loss: 0.880669  [  312/  792]\n",
      "Training Loss (Epoch): 0.760068\n",
      "Epoch 10/20\n",
      "loss: 0.642570  [   64/  792]\n",
      "loss: 0.590883  [  192/  792]\n",
      "loss: 0.705941  [  320/  792]\n",
      "loss: 0.676101  [  448/  792]\n",
      "loss: 0.592884  [  576/  792]\n",
      "loss: 0.886376  [  704/  792]\n",
      "loss: 0.624630  [  312/  792]\n",
      "Training Loss (Epoch): 0.666573\n",
      "Epoch 11/20\n",
      "loss: 0.497962  [   64/  792]\n",
      "loss: 0.749175  [  192/  792]\n",
      "loss: 0.483534  [  320/  792]\n",
      "loss: 0.591794  [  448/  792]\n",
      "loss: 0.643491  [  576/  792]\n",
      "loss: 0.489709  [  704/  792]\n",
      "loss: 1.041687  [  312/  792]\n",
      "Training Loss (Epoch): 0.612711\n",
      "Epoch 12/20\n",
      "loss: 0.444422  [   64/  792]\n",
      "loss: 0.568078  [  192/  792]\n",
      "loss: 0.542038  [  320/  792]\n",
      "loss: 0.711028  [  448/  792]\n",
      "loss: 0.705692  [  576/  792]\n",
      "loss: 0.499789  [  704/  792]\n",
      "loss: 0.711064  [  312/  792]\n",
      "Training Loss (Epoch): 0.560637\n",
      "Epoch 13/20\n",
      "loss: 0.567557  [   64/  792]\n",
      "loss: 0.483961  [  192/  792]\n",
      "loss: 0.742446  [  320/  792]\n",
      "loss: 0.509759  [  448/  792]\n",
      "loss: 0.564301  [  576/  792]\n",
      "loss: 0.545870  [  704/  792]\n",
      "loss: 0.454910  [  312/  792]\n",
      "Training Loss (Epoch): 0.531265\n",
      "Epoch 14/20\n",
      "loss: 0.489931  [   64/  792]\n",
      "loss: 0.537598  [  192/  792]\n",
      "loss: 0.606813  [  320/  792]\n",
      "loss: 0.636601  [  448/  792]\n",
      "loss: 0.674120  [  576/  792]\n",
      "loss: 0.451029  [  704/  792]\n",
      "loss: 0.396165  [  312/  792]\n",
      "Training Loss (Epoch): 0.504679\n",
      "Epoch 15/20\n",
      "loss: 0.639273  [   64/  792]\n",
      "loss: 0.382074  [  192/  792]\n",
      "loss: 0.559000  [  320/  792]\n",
      "loss: 0.492657  [  448/  792]\n",
      "loss: 0.450851  [  576/  792]\n",
      "loss: 0.537432  [  704/  792]\n",
      "loss: 1.305713  [  312/  792]\n",
      "Training Loss (Epoch): 0.573211\n",
      "Epoch 16/20\n",
      "loss: 0.547260  [   64/  792]\n",
      "loss: 0.536647  [  192/  792]\n",
      "loss: 0.397277  [  320/  792]\n",
      "loss: 0.500992  [  448/  792]\n",
      "loss: 0.575722  [  576/  792]\n",
      "loss: 0.534008  [  704/  792]\n",
      "loss: 0.511972  [  312/  792]\n",
      "Training Loss (Epoch): 0.506106\n",
      "Epoch 17/20\n",
      "loss: 0.389323  [   64/  792]\n",
      "loss: 0.553322  [  192/  792]\n",
      "loss: 0.582903  [  320/  792]\n",
      "loss: 0.397800  [  448/  792]\n",
      "loss: 0.478850  [  576/  792]\n",
      "loss: 0.570431  [  704/  792]\n",
      "loss: 1.204991  [  312/  792]\n",
      "Training Loss (Epoch): 0.556802\n",
      "Epoch 18/20\n",
      "loss: 0.485901  [   64/  792]\n",
      "loss: 0.581226  [  192/  792]\n",
      "loss: 0.435033  [  320/  792]\n",
      "loss: 0.521743  [  448/  792]\n",
      "loss: 0.703840  [  576/  792]\n",
      "loss: 0.544841  [  704/  792]\n",
      "loss: 0.522106  [  312/  792]\n",
      "Training Loss (Epoch): 0.514352\n",
      "Epoch 19/20\n",
      "loss: 0.580163  [   64/  792]\n",
      "loss: 0.498477  [  192/  792]\n",
      "loss: 0.503877  [  320/  792]\n",
      "loss: 0.489376  [  448/  792]\n",
      "loss: 0.465087  [  576/  792]\n",
      "loss: 0.576983  [  704/  792]\n",
      "loss: 0.547760  [  312/  792]\n",
      "Training Loss (Epoch): 0.539683\n",
      "Epoch 20/20\n",
      "loss: 0.590471  [   64/  792]\n",
      "loss: 0.507860  [  192/  792]\n",
      "loss: 0.490427  [  320/  792]\n",
      "loss: 0.428821  [  448/  792]\n",
      "loss: 0.425957  [  576/  792]\n",
      "loss: 0.443312  [  704/  792]\n",
      "loss: 0.420741  [  312/  792]\n",
      "Training Loss (Epoch): 0.492303\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.646821 \n",
      "\n",
      "Processing Fold 5\n",
      "Epoch 1/20\n",
      "loss: 2.136650  [   64/  748]\n",
      "loss: 1.545361  [  192/  748]\n",
      "loss: 1.953743  [  320/  748]\n",
      "loss: 1.615608  [  448/  748]\n",
      "loss: 1.402461  [  576/  748]\n",
      "loss: 1.326050  [  704/  748]\n",
      "Training Loss (Epoch): 1.628115\n",
      "Epoch 2/20\n",
      "loss: 1.314564  [   64/  748]\n",
      "loss: 1.193685  [  192/  748]\n",
      "loss: 1.293119  [  320/  748]\n",
      "loss: 1.201558  [  448/  748]\n",
      "loss: 1.601934  [  576/  748]\n",
      "loss: 1.018648  [  704/  748]\n",
      "Training Loss (Epoch): 1.278225\n",
      "Epoch 3/20\n",
      "loss: 1.073704  [   64/  748]\n",
      "loss: 0.956622  [  192/  748]\n",
      "loss: 0.961156  [  320/  748]\n",
      "loss: 1.090229  [  448/  748]\n",
      "loss: 1.101697  [  576/  748]\n",
      "loss: 1.015651  [  704/  748]\n",
      "Training Loss (Epoch): 1.047528\n",
      "Epoch 4/20\n",
      "loss: 1.053628  [   64/  748]\n",
      "loss: 0.863511  [  192/  748]\n",
      "loss: 1.127726  [  320/  748]\n",
      "loss: 1.040313  [  448/  748]\n",
      "loss: 0.919533  [  576/  748]\n",
      "loss: 0.843915  [  704/  748]\n",
      "Training Loss (Epoch): 0.949270\n",
      "Epoch 5/20\n",
      "loss: 0.901058  [   64/  748]\n",
      "loss: 0.929684  [  192/  748]\n",
      "loss: 0.810272  [  320/  748]\n",
      "loss: 0.726054  [  448/  748]\n",
      "loss: 1.074343  [  576/  748]\n",
      "loss: 0.977700  [  704/  748]\n",
      "Training Loss (Epoch): 0.903371\n",
      "Epoch 6/20\n",
      "loss: 0.879390  [   64/  748]\n",
      "loss: 0.873613  [  192/  748]\n",
      "loss: 0.706083  [  320/  748]\n",
      "loss: 0.783245  [  448/  748]\n",
      "loss: 0.888847  [  576/  748]\n",
      "loss: 0.989211  [  704/  748]\n",
      "Training Loss (Epoch): 0.790738\n",
      "Epoch 7/20\n",
      "loss: 0.748468  [   64/  748]\n",
      "loss: 0.629244  [  192/  748]\n",
      "loss: 0.851569  [  320/  748]\n",
      "loss: 0.805516  [  448/  748]\n",
      "loss: 0.701753  [  576/  748]\n",
      "loss: 0.747860  [  704/  748]\n",
      "Training Loss (Epoch): 0.727054\n",
      "Epoch 8/20\n",
      "loss: 0.673635  [   64/  748]\n",
      "loss: 0.691359  [  192/  748]\n",
      "loss: 0.850185  [  320/  748]\n",
      "loss: 0.613340  [  448/  748]\n",
      "loss: 0.631858  [  576/  748]\n",
      "loss: 0.501299  [  704/  748]\n",
      "Training Loss (Epoch): 0.652171\n",
      "Epoch 9/20\n",
      "loss: 0.671228  [   64/  748]\n",
      "loss: 0.583042  [  192/  748]\n",
      "loss: 0.671230  [  320/  748]\n",
      "loss: 0.626680  [  448/  748]\n",
      "loss: 0.699425  [  576/  748]\n",
      "loss: 0.388134  [  704/  748]\n",
      "Training Loss (Epoch): 0.580671\n",
      "Epoch 10/20\n",
      "loss: 0.505876  [   64/  748]\n",
      "loss: 0.487524  [  192/  748]\n",
      "loss: 0.564272  [  320/  748]\n",
      "loss: 0.428871  [  448/  748]\n",
      "loss: 0.536267  [  576/  748]\n",
      "loss: 0.581262  [  704/  748]\n",
      "Training Loss (Epoch): 0.536198\n",
      "Epoch 11/20\n",
      "loss: 0.531875  [   64/  748]\n",
      "loss: 1.043415  [  192/  748]\n",
      "loss: 0.598822  [  320/  748]\n",
      "loss: 0.419181  [  448/  748]\n",
      "loss: 0.348375  [  576/  748]\n",
      "loss: 0.786196  [  704/  748]\n",
      "Training Loss (Epoch): 0.575914\n",
      "Epoch 12/20\n",
      "loss: 0.315599  [   64/  748]\n",
      "loss: 0.401974  [  192/  748]\n",
      "loss: 0.431550  [  320/  748]\n",
      "loss: 0.576070  [  448/  748]\n",
      "loss: 1.145864  [  576/  748]\n",
      "loss: 0.463183  [  704/  748]\n",
      "Training Loss (Epoch): 0.548241\n",
      "Epoch 13/20\n",
      "loss: 0.770018  [   64/  748]\n",
      "loss: 0.427699  [  192/  748]\n",
      "loss: 1.055138  [  320/  748]\n",
      "loss: 0.492509  [  448/  748]\n",
      "loss: 0.475375  [  576/  748]\n",
      "loss: 0.403416  [  704/  748]\n",
      "Training Loss (Epoch): 0.533604\n",
      "Epoch 14/20\n",
      "loss: 0.578236  [   64/  748]\n",
      "loss: 0.542675  [  192/  748]\n",
      "loss: 0.334711  [  320/  748]\n",
      "loss: 0.419718  [  448/  748]\n",
      "loss: 0.314351  [  576/  748]\n",
      "loss: 0.471849  [  704/  748]\n",
      "Training Loss (Epoch): 0.439860\n",
      "Epoch 15/20\n",
      "loss: 0.492169  [   64/  748]\n",
      "loss: 0.354372  [  192/  748]\n",
      "loss: 0.473164  [  320/  748]\n",
      "loss: 0.649051  [  448/  748]\n",
      "loss: 0.425167  [  576/  748]\n",
      "loss: 0.694548  [  704/  748]\n",
      "Training Loss (Epoch): 0.503950\n",
      "Epoch 16/20\n",
      "loss: 0.377710  [   64/  748]\n",
      "loss: 0.346892  [  192/  748]\n",
      "loss: 0.497271  [  320/  748]\n",
      "loss: 0.372881  [  448/  748]\n",
      "loss: 0.536678  [  576/  748]\n",
      "loss: 0.438062  [  704/  748]\n",
      "Training Loss (Epoch): 0.450926\n",
      "Epoch 17/20\n",
      "loss: 0.516588  [   64/  748]\n",
      "loss: 0.476555  [  192/  748]\n",
      "loss: 0.476211  [  320/  748]\n",
      "loss: 0.403644  [  448/  748]\n",
      "loss: 0.461715  [  576/  748]\n",
      "loss: 0.348890  [  704/  748]\n",
      "Training Loss (Epoch): 0.450365\n",
      "Epoch 18/20\n",
      "loss: 0.457594  [   64/  748]\n",
      "loss: 0.451799  [  192/  748]\n",
      "loss: 0.383742  [  320/  748]\n",
      "loss: 0.393140  [  448/  748]\n",
      "loss: 0.360619  [  576/  748]\n",
      "loss: 0.426003  [  704/  748]\n",
      "Training Loss (Epoch): 0.458814\n",
      "Epoch 19/20\n",
      "loss: 0.379621  [   64/  748]\n",
      "loss: 0.396889  [  192/  748]\n",
      "loss: 0.427457  [  320/  748]\n",
      "loss: 0.346875  [  448/  748]\n",
      "loss: 0.409383  [  576/  748]\n",
      "loss: 0.466866  [  704/  748]\n",
      "Training Loss (Epoch): 0.457340\n",
      "Epoch 20/20\n",
      "loss: 0.466383  [   64/  748]\n",
      "loss: 0.316260  [  192/  748]\n",
      "loss: 0.476177  [  320/  748]\n",
      "loss: 0.454643  [  448/  748]\n",
      "loss: 0.664601  [  576/  748]\n",
      "loss: 0.430489  [  704/  748]\n",
      "Training Loss (Epoch): 0.452096\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.700545 \n",
      "\n",
      "Processing Fold 6\n",
      "Epoch 1/20\n",
      "loss: 1.724509  [   64/  658]\n",
      "loss: 3.336118  [  192/  658]\n",
      "loss: 1.842339  [  320/  658]\n",
      "loss: 1.760107  [  448/  658]\n",
      "loss: 1.628900  [  576/  658]\n",
      "loss: 1.573919  [  198/  658]\n",
      "Training Loss (Epoch): 1.985817\n",
      "Epoch 2/20\n",
      "loss: 1.755591  [   64/  658]\n",
      "loss: 1.454078  [  192/  658]\n",
      "loss: 1.534535  [  320/  658]\n",
      "loss: 1.467230  [  448/  658]\n",
      "loss: 1.457705  [  576/  658]\n",
      "loss: 2.025037  [  198/  658]\n",
      "Training Loss (Epoch): 1.521820\n",
      "Epoch 3/20\n",
      "loss: 1.533605  [   64/  658]\n",
      "loss: 1.842401  [  192/  658]\n",
      "loss: 1.353351  [  320/  658]\n",
      "loss: 1.343332  [  448/  658]\n",
      "loss: 1.322800  [  576/  658]\n",
      "loss: 1.493734  [  198/  658]\n",
      "Training Loss (Epoch): 1.396742\n",
      "Epoch 4/20\n",
      "loss: 1.174553  [   64/  658]\n",
      "loss: 1.390929  [  192/  658]\n",
      "loss: 1.351400  [  320/  658]\n",
      "loss: 1.355501  [  448/  658]\n",
      "loss: 1.355699  [  576/  658]\n",
      "loss: 1.037694  [  198/  658]\n",
      "Training Loss (Epoch): 1.263445\n",
      "Epoch 5/20\n",
      "loss: 1.157426  [   64/  658]\n",
      "loss: 1.222578  [  192/  658]\n",
      "loss: 1.373166  [  320/  658]\n",
      "loss: 1.139203  [  448/  658]\n",
      "loss: 1.487984  [  576/  658]\n",
      "loss: 1.121389  [  198/  658]\n",
      "Training Loss (Epoch): 1.181090\n",
      "Epoch 6/20\n",
      "loss: 1.234547  [   64/  658]\n",
      "loss: 1.156818  [  192/  658]\n",
      "loss: 1.097062  [  320/  658]\n",
      "loss: 1.226565  [  448/  658]\n",
      "loss: 1.005151  [  576/  658]\n",
      "loss: 1.003788  [  198/  658]\n",
      "Training Loss (Epoch): 1.130405\n",
      "Epoch 7/20\n",
      "loss: 0.967051  [   64/  658]\n",
      "loss: 1.120977  [  192/  658]\n",
      "loss: 1.156117  [  320/  658]\n",
      "loss: 1.120117  [  448/  658]\n",
      "loss: 1.022112  [  576/  658]\n",
      "loss: 0.964049  [  198/  658]\n",
      "Training Loss (Epoch): 1.028935\n",
      "Epoch 8/20\n",
      "loss: 1.111146  [   64/  658]\n",
      "loss: 1.076017  [  192/  658]\n",
      "loss: 1.055022  [  320/  658]\n",
      "loss: 0.868011  [  448/  658]\n",
      "loss: 0.799027  [  576/  658]\n",
      "loss: 1.204019  [  198/  658]\n",
      "Training Loss (Epoch): 0.977606\n",
      "Epoch 9/20\n",
      "loss: 0.908051  [   64/  658]\n",
      "loss: 0.862298  [  192/  658]\n",
      "loss: 0.999750  [  320/  658]\n",
      "loss: 0.957514  [  448/  658]\n",
      "loss: 0.894441  [  576/  658]\n",
      "loss: 1.055958  [  198/  658]\n",
      "Training Loss (Epoch): 0.926010\n",
      "Epoch 10/20\n",
      "loss: 0.764229  [   64/  658]\n",
      "loss: 0.741090  [  192/  658]\n",
      "loss: 0.968665  [  320/  658]\n",
      "loss: 0.770759  [  448/  658]\n",
      "loss: 0.944319  [  576/  658]\n",
      "loss: 0.810792  [  198/  658]\n",
      "Training Loss (Epoch): 0.825963\n",
      "Epoch 11/20\n",
      "loss: 0.657689  [   64/  658]\n",
      "loss: 0.645350  [  192/  658]\n",
      "loss: 0.652817  [  320/  658]\n",
      "loss: 0.629282  [  448/  658]\n",
      "loss: 1.118819  [  576/  658]\n",
      "loss: 0.847930  [  198/  658]\n",
      "Training Loss (Epoch): 0.818884\n",
      "Epoch 12/20\n",
      "loss: 0.712355  [   64/  658]\n",
      "loss: 0.660918  [  192/  658]\n",
      "loss: 0.673794  [  320/  658]\n",
      "loss: 0.720271  [  448/  658]\n",
      "loss: 0.739690  [  576/  658]\n",
      "loss: 1.216780  [  198/  658]\n",
      "Training Loss (Epoch): 0.787232\n",
      "Epoch 13/20\n",
      "loss: 0.681136  [   64/  658]\n",
      "loss: 0.687837  [  192/  658]\n",
      "loss: 0.628968  [  320/  658]\n",
      "loss: 0.694462  [  448/  658]\n",
      "loss: 0.590077  [  576/  658]\n",
      "loss: 0.732364  [  198/  658]\n",
      "Training Loss (Epoch): 0.706389\n",
      "Epoch 14/20\n",
      "loss: 0.634381  [   64/  658]\n",
      "loss: 0.678764  [  192/  658]\n",
      "loss: 1.035083  [  320/  658]\n",
      "loss: 0.694489  [  448/  658]\n",
      "loss: 0.718148  [  576/  658]\n",
      "loss: 1.483493  [  198/  658]\n",
      "Training Loss (Epoch): 0.801191\n",
      "Epoch 15/20\n",
      "loss: 0.684548  [   64/  658]\n",
      "loss: 0.637995  [  192/  658]\n",
      "loss: 0.775833  [  320/  658]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 50\u001b[39m\n\u001b[32m     47\u001b[39m scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones = [\u001b[32m1\u001b[39m, \u001b[32m10\u001b[39m, \u001b[32m15\u001b[39m, \u001b[32m16\u001b[39m, \u001b[32m17\u001b[39m, \u001b[32m19\u001b[39m], gamma=\u001b[32m0.1\u001b[39m)\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# Train and validate\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m train_loss = \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m val_loss, val_accuracy = test_loop(val_dataloader, model, loss_fn)\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# Aggregate metrics\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mtrain_loop\u001b[39m\u001b[34m(dataloader, model, loss_fn, optimizer, scheduler, epochs)\u001b[39m\n\u001b[32m      9\u001b[39m total_loss = \u001b[32m0\u001b[39m  \u001b[38;5;66;03m# Initialize variable to accumulate loss per epoch\u001b[39;00m\n\u001b[32m     10\u001b[39m total_batches = \u001b[38;5;28mlen\u001b[39m(dataloader)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Compute prediction and loss\u001b[39;49;00m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_collation:\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataset, \u001b[33m\"\u001b[39m\u001b[33m__getitems__\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__:\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     52\u001b[39m         data = [\u001b[38;5;28mself\u001b[39m.dataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/utils/data/dataset.py:420\u001b[39m, in \u001b[36mSubset.__getitems__\u001b[39m\u001b[34m(self, indices)\u001b[39m\n\u001b[32m    418\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__([\u001b[38;5;28mself\u001b[39m.indices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/utils/data/dataset.py:420\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    418\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__([\u001b[38;5;28mself\u001b[39m.indices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mUrbanSoundDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[32m     27\u001b[39m     \u001b[38;5;66;03m# Load the audio file\u001b[39;00m\n\u001b[32m     28\u001b[39m     file_path = \u001b[38;5;28mself\u001b[39m.file_list[idx]\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     waveform, sample_rate = \u001b[43mtorchaudio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     \u001b[38;5;66;03m# Convert mono to stereo if necessary\u001b[39;00m\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m waveform.size(\u001b[32m0\u001b[39m) == \u001b[32m1\u001b[39m:  \u001b[38;5;66;03m# If mono\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torchaudio/_backend/utils.py:205\u001b[39m, in \u001b[36mget_load_func.<locals>.load\u001b[39m\u001b[34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size, backend)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Load audio data from source.\u001b[39;00m\n\u001b[32m    129\u001b[39m \n\u001b[32m    130\u001b[39m \u001b[33;03mBy default (``normalize=True``, ``channels_first=True``), this function returns Tensor with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    202\u001b[39m \u001b[33;03m        `[channel, time]` else `[time, channel]`.\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    204\u001b[39m backend = dispatcher(uri, \u001b[38;5;28mformat\u001b[39m, backend)\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torchaudio/_backend/ffmpeg.py:297\u001b[39m, in \u001b[36mFFmpegBackend.load\u001b[39m\u001b[34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\n\u001b[32m    289\u001b[39m     uri: InputType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    295\u001b[39m     buffer_size: \u001b[38;5;28mint\u001b[39m = \u001b[32m4096\u001b[39m,\n\u001b[32m    296\u001b[39m ) -> Tuple[torch.Tensor, \u001b[38;5;28mint\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torchaudio/_backend/ffmpeg.py:88\u001b[39m, in \u001b[36mload_audio\u001b[39m\u001b[34m(src, frame_offset, num_frames, convert, channels_first, format, buffer_size)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(src, \u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33mvorbis\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     87\u001b[39m     \u001b[38;5;28mformat\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mogg\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m s = \u001b[43mtorchaudio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mStreamReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m sample_rate = \u001b[38;5;28mint\u001b[39m(s.get_src_stream_info(s.default_audio_stream).sample_rate)\n\u001b[32m     90\u001b[39m \u001b[38;5;28mfilter\u001b[39m = _get_load_filter(frame_offset, num_frames, convert)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torio/io/_streaming_media_decoder.py:526\u001b[39m, in \u001b[36mStreamingMediaDecoder.__init__\u001b[39m\u001b[34m(self, src, format, option, buffer_size)\u001b[39m\n\u001b[32m    524\u001b[39m     \u001b[38;5;28mself\u001b[39m._be = ffmpeg_ext.StreamingMediaDecoderFileObj(src, \u001b[38;5;28mformat\u001b[39m, option, buffer_size)\n\u001b[32m    525\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m     \u001b[38;5;28mself\u001b[39m._be = \u001b[43mffmpeg_ext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mStreamingMediaDecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnormpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moption\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    528\u001b[39m i = \u001b[38;5;28mself\u001b[39m._be.find_best_audio_stream()\n\u001b[32m    529\u001b[39m \u001b[38;5;28mself\u001b[39m._default_audio_stream = \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m i < \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m i\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "pwd = os.getcwd()\n",
    "# Specify paths and batch size\n",
    "AUDIO_PATH = \"./UrbanSound8K/audio\"\n",
    "CSV_PATH = \"./UrbanSound8K/metadata/UrbanSound8K.csv\"\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "\n",
    "def setup_seed(seed):\n",
    "    torch_manual_seed(seed)\n",
    "    manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    cudnn.deterministic = True\n",
    "\n",
    "SEED = 666\n",
    "setup_seed(SEED)\n",
    "\n",
    "\n",
    "fold_losses = []\n",
    "fold_accuracies = []\n",
    "\n",
    "model = densenet()\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Loop through folds\n",
    "# Variables to accumulate metrics across folds\n",
    "fold_losses = []\n",
    "fold_accuracies = []\n",
    "\n",
    "# Loop through folds\n",
    "for fold in range(1, 11):\n",
    "    print(f\"Processing Fold {fold}\")\n",
    "\n",
    "    # Initialize dataset and DataLoader\n",
    "    dataset = UrbanSoundDataset(audio_path=AUDIO_PATH, fold=fold, transform=transform_pipeline, csv_path=CSV_PATH)\n",
    "    train_indices, val_indices = train_test_split(list(range(len(dataset))), test_size=0.2, random_state=666)\n",
    "    \n",
    "    train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "    val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones = [1, 10, 15, 16, 17, 19], gamma=0.1)\n",
    "\n",
    "    # Train and validate\n",
    "    train_loss = train_loop(train_dataloader, model, loss_fn, optimizer, scheduler, epochs=epochs)\n",
    "    val_loss, val_accuracy = test_loop(val_dataloader, model, loss_fn)\n",
    "\n",
    "    # Aggregate metrics\n",
    "    fold_losses.append(val_loss)\n",
    "    fold_accuracies.append(val_accuracy)\n",
    "\n",
    "# Compute average loss and accuracy across folds\n",
    "mean_loss = sum(fold_losses) / len(fold_losses)\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "\n",
    "print(f\"\\nCross-Validation Results:\")\n",
    "print(f\"Avg Loss: {mean_loss:.6f}, Avg Accuracy: {(100 * mean_accuracy):.2f}%\")\n",
    "\n",
    "# Compute average loss and accuracy across folds\n",
    "mean_loss = sum(fold_losses) / len(fold_losses)\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "\n",
    "print(f\"\\nCross-Validation Results:\")\n",
    "print(f\"Avg Loss: {mean_loss:.6f}, Avg Accuracy: {(100 * mean_accuracy):.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchaudio\n",
    "\n",
    "# audio_path = \"./UrbanSound8k/audio/fold1/137156-9-0-30.wav\"\n",
    "# waveform, sample_rate = torchaudio.load(audio_path)\n",
    "# print(f\"Shape: {waveform.shape}, Sample Rate: {sample_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_stereogram(spectrogram):\n",
    "    # Convert to numpy\n",
    "    spectrogram_np = spectrogram.numpy()  # Shape: (2, Freq, Time)\n",
    "\n",
    "    # Plot left and right channels\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(6, 6), constrained_layout=True)\n",
    "\n",
    "    axs[0].imshow(spectrogram_np[0], aspect='auto', origin='lower', cmap='magma')\n",
    "    axs[0].set_title(f\"Spectrogram {i+1} - Left Channel\")\n",
    "    axs[0].set_ylabel(\"Frequency Bins\")\n",
    "    axs[0].set_xlabel(\"Time Frames\")\n",
    "\n",
    "    axs[1].imshow(spectrogram_np[1], aspect='auto', origin='lower', cmap='magma')\n",
    "    axs[1].set_title(f\"Spectrogram {i+1} - Right Channel\")\n",
    "    axs[1].set_ylabel(\"Frequency Bins\")\n",
    "    axs[1].set_xlabel(\"Time Frames\")\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
