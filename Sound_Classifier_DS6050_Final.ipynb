{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mBSFTJ5M_z-H"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n",
    "from torch.cuda import manual_seed_all\n",
    "from torch import manual_seed as torch_manual_seed\n",
    "from torch.backends import cudnn\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3uDKfjRHMuxk"
   },
   "outputs": [],
   "source": [
    "# pre spectrogram augmentations\n",
    "# these are examples and can be changed based on domain knowledge\n",
    "\n",
    "def stretch_waveform(waveform, rate=1.2):\n",
    "    time_stretch = T.TimeStretch()\n",
    "    # `rate > 1.0` speeds up, `rate < 1.0` slows down\n",
    "    return time_stretch(waveform, rate)\n",
    "\n",
    "def shift_pitch(waveform, sample_rate=44100, n_steps = 2):\n",
    "    pitch_shift = T.PitchShift(sample_rate, n_steps)  # Shift up by 2 semitones\n",
    "    return pitch_shift(waveform)\n",
    "\n",
    "def scale_volume(waveform, factor = None):\n",
    "    if factor is None:\n",
    "        waveform *= torch.FloatTensor(1).uniform_(0.8, 1.5).item()  # Amplifies waveform by random factor\n",
    "    else:\n",
    "        waveform *= factor\n",
    "    return waveform\n",
    "\n",
    "def crop_waveform(waveform, crop_size):\n",
    "    start = torch.randint(0, max(1, waveform.size(-1) - crop_size), (1,)).item()\n",
    "    return waveform[:, start:start + crop_size]\n",
    "\n",
    "def apply_reverb(waveform):\n",
    "    reverb = T.Reverberate()\n",
    "    return reverb(waveform)\n",
    "\n",
    "def time_shift(waveform, shift):\n",
    "    return torch.roll(waveform, shifts=shift, dims=-1)\n",
    "\n",
    "def add_noise(waveform, noise_level=0.005):\n",
    "    noise = torch.randn_like(waveform) * noise_level\n",
    "    return waveform + noise\n",
    "\n",
    "# Augment on-the-fly stochastically\n",
    "# again these are just examples and do not necessarily utilize the methods above\n",
    "def augment_waveform(data):\n",
    "    waveform, sample_rate = data\n",
    "    if torch.rand(1).item() > 0.9:\n",
    "        waveform = add_noise(waveform)\n",
    "    if torch.rand(1).item() > 0.9:\n",
    "        waveform = time_shift(waveform, shifts=torch.randint(-waveform.size(-1) // 2, waveform.size(-1) // 2, (1,)).item())\n",
    "    if torch.rand(1).item() > 0.9:\n",
    "        waveform = scale_volume(waveform)\n",
    "    if torch.rand(1).item() > 0.9:\n",
    "        waveform = apply_reverb(waveform)\n",
    "    if torch.rand(1).item() > 0.9:\n",
    "        waveform = shift_pitch(waveform, sample_rate, n_steps= torch.randint(-12, 12, (1,)).item())\n",
    "    if torch.rand(1).item() > 0.9:\n",
    "        waveform = stretch_waveform(waveform, rate= torch.FloatTensor(1).uniform_(0.5, 1.5).item())\n",
    "    return waveform, sample_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Ww8OMV8nNZcf"
   },
   "outputs": [],
   "source": [
    "# Create a MelSpectrogram transformation\n",
    "mel_spectrogram_transform = T.MelSpectrogram(\n",
    "    sample_rate=44100,         # Default sample rate, change if needed\n",
    "    n_fft=1024,                # Number of FFT bins\n",
    "    hop_length=512,            # Hop length between windows\n",
    "    n_mels=64                  # Number of Mel bands\n",
    ")\n",
    "\n",
    "def waveform_to_spectrogram(data):\n",
    "    waveform, sample_rate = data\n",
    "    spectrogram = mel_spectrogram_transform(waveform)  # Apply the spectrogram transformation\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "khV1u_wUIR-o"
   },
   "outputs": [],
   "source": [
    "# post spectrogram augmentations\n",
    "\n",
    "# Example augmentations, could add more\n",
    "time_mask = T.TimeMasking(time_mask_param=10)\n",
    "\n",
    "freq_mask = T.FrequencyMasking(freq_mask_param=8)\n",
    "\n",
    "# hybridizes two sounds\n",
    "def mixup(spectrogram1, spectrogram2, alpha=0.2):\n",
    "    lam = torch.FloatTensor(1).uniform_(0, alpha).item()\n",
    "    return lam * spectrogram1 + (1 - lam) * spectrogram2\n",
    "\n",
    "# should probably implement a randomization process like above\n",
    "def augment_spectrogram(spectrogram):\n",
    "    augmented = time_mask(spectrogram)  # Apply time masking\n",
    "    augmented = freq_mask(augmented)   # Apply frequency masking\n",
    "    return augmented\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2U9n6Z-fPiwY"
   },
   "outputs": [],
   "source": [
    "# Decode audio files\n",
    "def decode_audio(file_tuple):\n",
    "    file_path, file = file_tuple\n",
    "    waveform, sample_rate = torchaudio.load(file_path)\n",
    "    return waveform, sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "class UrbanSoundDataset(Dataset):\n",
    "    def __init__(self, audio_path, fold, csv_path, transform=None):\n",
    "        self.audio_path = os.path.join(audio_path, f\"fold{fold}\")\n",
    "        self.file_list = [os.path.join(self.audio_path, f) for f in os.listdir(self.audio_path) if f.endswith(\".wav\")]\n",
    "        self.transform = transform\n",
    "\n",
    "        # Load the metadata CSV file\n",
    "        self.metadata = pd.read_csv(csv_path)\n",
    "\n",
    "    def get_label(self, file_name):\n",
    "        \"\"\"Fetch the class label for a given file name from the metadata.\"\"\"\n",
    "        label_row = self.metadata.loc[self.metadata['slice_file_name'] == file_name, 'class']\n",
    "        if not label_row.empty:\n",
    "            return label_row.values[0]\n",
    "        else:\n",
    "            raise ValueError(f\"File name {file_name} not found in metadata CSV.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load the audio file\n",
    "        file_path = self.file_list[idx]\n",
    "        waveform, sample_rate = torchaudio.load(file_path)\n",
    "\n",
    "        # Convert mono to stereo if necessary\n",
    "        if waveform.size(0) == 1:  # If mono\n",
    "            waveform = waveform.repeat(3, 1)\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            waveform = self.transform(waveform)\n",
    "\n",
    "        # Extract the file name from the path\n",
    "        file_name = os.path.basename(file_path)\n",
    "\n",
    "        # Get the corresponding label for the file\n",
    "        label = self.get_label(file_name)\n",
    "\n",
    "        return waveform, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asm2fe/.local/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torchaudio.transforms as T\n",
    "\n",
    "# Example transformations\n",
    "def augment_waveform(waveform):\n",
    "    # Add your augmentation logic here (e.g., noise addition, time stretch, etc.)\n",
    "    return waveform\n",
    "\n",
    "waveform_to_spectrogram = T.MelSpectrogram(sample_rate=16000, n_mels=128)\n",
    "augment_spectrogram = T.AmplitudeToDB()\n",
    "\n",
    "# Combine transformations into a callable function\n",
    "def transform_pipeline(waveform):\n",
    "    waveform = augment_waveform(waveform)\n",
    "    spectrogram = waveform_to_spectrogram(waveform)\n",
    "    # spectrogram = augment_spectrogram(spectrogram)\n",
    "    return spectrogram\n",
    "\n",
    "def pad_with_noise(spectrogram, max_time, noise_std=0.01):\n",
    "    \"\"\"\n",
    "    Pads a spectrogram with Gaussian noise instead of zeros.\n",
    "\n",
    "    Args:\n",
    "        spectrogram (Tensor): Shape (channels, freq_bins, time_steps)\n",
    "        max_time (int): Target time dimension\n",
    "        noise_std (float): Standard deviation of the Gaussian noise\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Padded spectrogram with noise\n",
    "    \"\"\"\n",
    "    # Compute how much padding is needed\n",
    "    pad_amount = max_time - spectrogram.size(2)\n",
    "    \n",
    "    if pad_amount > 0:\n",
    "        # Generate random noise matching the shape of missing time steps\n",
    "        noise = torch.randn((spectrogram.size(0), spectrogram.size(1), pad_amount)) * noise_std\n",
    "        \n",
    "        # Concatenate noise along the time axis\n",
    "        spectrogram = torch.cat([spectrogram, noise], dim=2)\n",
    "    \n",
    "    return spectrogram\n",
    "\n",
    "# def convert_to_three_channels(spectrogram):\n",
    "#     # Convert [2, 224, 224] to [3, 224, 224]\n",
    "#     if spectrogram.size(0) == 2:\n",
    "#         # Duplicate the first channel to create a third channel\n",
    "#         return torch.cat((spectrogram, spectrogram[0:1, :, :]), dim=0)\n",
    "#     return spectrogram\n",
    "\n",
    "def convert_to_three_channels(spectrogram):\n",
    "    # Convert [2, 224, 224] to [3, 224, 224]\n",
    "    if spectrogram.size(0) == 2:\n",
    "        # Calculate the mean of the two channels\n",
    "        mean_channel = torch.mean(spectrogram, dim=0, keepdim=True)\n",
    "        # Concatenate the mean channel as the third channel\n",
    "        return torch.cat((spectrogram, mean_channel), dim=0)\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "\n",
    "class densenet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    DenseNet Class, derived from Pytorch. Intended for model manipulation (i.e. unfreezing layers, etc.)\n",
    "    To use model, try (densenet).model(data)\n",
    "    May change to reflect manual implementation of densenet161.\n",
    "    \"\"\"\n",
    "    def __init__(self, weights = \"DEFAULT\", drop = 0.5):\n",
    "        super().__init__()  # Initialize the nn.Module base class\n",
    "        self.model = torchvision.models.densenet161(weights = weights)\n",
    "        \n",
    "        num_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Dropout(drop),  # Add dropout with 50% probability\n",
    "            nn.Linear(num_features, 10)  # Adjust for 10 output classes (UrbanSound8k)\n",
    "        )\n",
    "        \n",
    "        # Ensure classifier is trainable\n",
    "        for param in self.model.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)  # Delegate forward pass to the original DenseNet\n",
    "\n",
    "    def layer_change(self, layer=0):\n",
    "        if layer > 0:    \n",
    "            # Freeze earlier layers (optional)\n",
    "            for name, param in self.model.features.named_parameters():\n",
    "                if \"conv0\" in name or \"denseblock1\" in name:  # Freeze initial layers and denseblock1\n",
    "                    param.requires_grad = False\n",
    "        if layer > 1:    \n",
    "            # Freeze earlier layers (optional)\n",
    "            for name, param in self.model.features.named_parameters():\n",
    "                if \"denseblock2\" in name:  # Freeze initial layers and denseblock2\n",
    "                    param.requires_grad = False\n",
    "        if layer > 2:    \n",
    "            # Freeze earlier layers (optional)\n",
    "            for name, param in self.model.features.named_parameters():\n",
    "                if \"denseblock3\" in name:  # Freeze initial layers and denseblock3\n",
    "                    param.requires_grad = False\n",
    "        if layer > 3:    \n",
    "            # Freeze earlier layers (optional)\n",
    "            for name, param in self.model.features.named_parameters():\n",
    "                if \"denseblock4\" in name:  # Freeze initial layers and denseblock4\n",
    "                    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = densenet()\n",
    "# for param in model.model.features.named_parameters():\n",
    "#     print(param[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and testing loops\n",
    "\n",
    "def train_loop(train_dataloader, val_dataloader, model, loss_fn, optimizer, scheduler=None, epochs=1):\n",
    "    model.train()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Store metrics\n",
    "    epoch_train_losses = []  # Track training loss across epochs\n",
    "    epoch_val_losses = []  # Track validation loss across epochs\n",
    "    epoch_val_accuracies = []  # Track validation accuracy across epochs\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        size = len(train_dataloader.dataset)\n",
    "        total_loss = 0  # Initialize variable to accumulate training loss\n",
    "\n",
    "        for batch, (X, y) in enumerate(train_dataloader):\n",
    "            # Compute prediction and loss\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Print progress periodically\n",
    "            total_batches = len(train_dataloader)\n",
    "            if batch % (total_batches // 5) == 0:  # Prints 5 times per epoch\n",
    "                current = (batch + 1) * len(X)\n",
    "                print(f\"loss: {loss.item():>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "        # Average training loss for the epoch\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "        print(f\"Training Loss (Epoch): {avg_train_loss:>7f}\")\n",
    "        epoch_train_losses.append(avg_train_loss)\n",
    "\n",
    "        # **Validation Step**\n",
    "        print(\"Validating...\")\n",
    "        avg_val_loss, val_accuracy = test_loop(val_dataloader, model, loss_fn, verbose=False)\n",
    "        print(f\"Validation Loss: {avg_val_loss:.6f}, Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "\n",
    "        # Track validation metrics\n",
    "        epoch_val_losses.append(avg_val_loss)\n",
    "        epoch_val_accuracies.append(val_accuracy)\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(val_accuracy)\n",
    "            print(f\"Learning Rate: {scheduler.get_last_lr()}\")\n",
    "\n",
    "    # Return metrics for tracking/aggregation across folds\n",
    "    return epoch_train_losses, epoch_val_losses, epoch_val_accuracies\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn, verbose=True):\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    # Average loss and accuracy for this fold\n",
    "    avg_test_loss = test_loss / num_batches\n",
    "    accuracy = correct / size\n",
    "    if verbose:\n",
    "        print(f\"Test Error: \\n Accuracy: {(100*accuracy):>0.1f}%, Avg loss: {avg_test_loss:>8f} \\n\")\n",
    "    return avg_test_loss, accuracy  # Return both average loss and accuracy for this fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "BLCzmvxcHvKs"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    # Resize and normalize for DenseNet\n",
    "    resize_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize for DenseNet\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Standard ImageNet normalization\n",
    "    ])\n",
    "    \n",
    "    inputs, labels = zip(*batch)  # Separate inputs and labels\n",
    "    max_time = max(spectrogram.size(2) for spectrogram in inputs)\n",
    "\n",
    "    # Pad inputs to the same length along the time dimension\n",
    "    padded_inputs = [\n",
    "        torch.nn.functional.pad(input, (0, max_time - input.size(2)))\n",
    "        for input in inputs\n",
    "    ]\n",
    "\n",
    "    # Convert to 3 channels and resize\n",
    "    resized_inputs = [resize_transform(convert_to_three_channels(input)) for input in padded_inputs]\n",
    "    \n",
    "    # Map labels to numeric class IDs\n",
    "    class_mapping = {\n",
    "        \"air_conditioner\": 0,\n",
    "        \"car_horn\": 1,\n",
    "        \"children_playing\": 2,\n",
    "        \"dog_bark\": 3,\n",
    "        \"drilling\": 4,\n",
    "        \"engine_idling\": 5,\n",
    "        \"gun_shot\": 6,\n",
    "        \"jackhammer\": 7,\n",
    "        \"siren\": 8,\n",
    "        \"street_music\": 9\n",
    "    }\n",
    "\n",
    "    numeric_labels = [class_mapping[label] for label in labels]\n",
    "\n",
    "    # Stack inputs and labels\n",
    "    return torch.stack(resized_inputs), torch.tensor(numeric_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sfs/gpfs/tardis/home/asm2fe/UrbanAdversary\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# Specify paths and batch size\n",
    "AUDIO_PATH = \"./UrbanSound8K/audio\"\n",
    "CSV_PATH = \"./UrbanSound8K/metadata/UrbanSound8K.csv\"\n",
    "batch_size = 70\n",
    "epochs = 25\n",
    "\n",
    "def setup_seed(seed):\n",
    "    torch_manual_seed(seed)\n",
    "    manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    cudnn.deterministic = True\n",
    "\n",
    "def dense_tune(layer = 0, lr = 2e-4, weight_decay = 0.2, weights = \"DEFAULT\", drop = 0.5, SEED = 666):\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    setup_seed(SEED)\n",
    "\n",
    "    # Variables to accumulate metrics across folds\n",
    "    fold_train_losses = []\n",
    "    fold_val_losses = []\n",
    "    fold_val_accuracies = []\n",
    "\n",
    "    # Loop through folds\n",
    "    for fold in range(1, 11):\n",
    "        model = densenet(weights = weights, drop = drop)\n",
    "        model.layer_change(layer = layer) # freeze first conv and dense block(s) if desired\n",
    "\n",
    "        print(f\"Processing Fold {fold}\")\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay = weight_decay)\n",
    "        # optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001, weight_decay = 0.01, momentum = 0.9)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='max', factor=0.5, patience=0, threshold_mode = 'abs', threshold= 0.01, min_lr=1e-9)\n",
    "\n",
    "        # Initialize dataset and DataLoader\n",
    "        dataset = UrbanSoundDataset(audio_path=AUDIO_PATH, fold=fold, transform=transform_pipeline, csv_path=CSV_PATH)\n",
    "        train_indices, val_indices = train_test_split(list(range(len(dataset))), test_size=0.2, random_state=42)\n",
    "\n",
    "        train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "        val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
    "\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "        val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "        # Train and validate (over multiple epochs per fold)\n",
    "        epoch_train_losses, epoch_val_losses, epoch_val_accuracies = train_loop(\n",
    "            train_dataloader, val_dataloader, model, loss_fn, optimizer, scheduler, epochs=epochs\n",
    "        )\n",
    "\n",
    "        # Aggregate fold-level metrics (e.g., last epoch metrics)\n",
    "        fold_train_losses.append(epoch_train_losses[-1])  # Last epoch's training loss\n",
    "        fold_val_losses.append(epoch_val_losses[-1])  # Last epoch's validation loss\n",
    "        fold_val_accuracies.append(epoch_val_accuracies[-1])  # Last epoch's validation accuracy\n",
    "\n",
    "    # Compute average metrics across folds\n",
    "    mean_train_loss = sum(fold_train_losses) / len(fold_train_losses)\n",
    "    mean_val_loss = sum(fold_val_losses) / len(fold_val_losses)\n",
    "    mean_val_accuracy = sum(fold_val_accuracies) / len(fold_val_accuracies)\n",
    "\n",
    "    print(f\"\\nCross-Validation Results:\")\n",
    "    print(f\"Avg Training Loss: {mean_train_loss:.6f}\")\n",
    "    print(f\"Avg Validation Loss: {mean_val_loss:.6f}\")\n",
    "    print(f\"Avg Validation Accuracy: {mean_val_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1\n",
      "Epoch 1/25\n",
      "loss: 2.331131  [   70/  698]\n",
      "loss: 2.014276  [  210/  698]\n",
      "loss: 1.880963  [  350/  698]\n",
      "loss: 1.672783  [  490/  698]\n",
      "loss: 1.541667  [  630/  698]\n",
      "Training Loss (Epoch): 1.889011\n",
      "Validating...\n",
      "Validation Loss: 1.856203, Validation Accuracy: 45.14%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/25\n",
      "loss: 1.809719  [   70/  698]\n",
      "loss: 1.277156  [  210/  698]\n",
      "loss: 1.275134  [  350/  698]\n",
      "loss: 1.094460  [  490/  698]\n",
      "loss: 0.964627  [  630/  698]\n",
      "Training Loss (Epoch): 1.189580\n",
      "Validating...\n",
      "Validation Loss: 0.775463, Validation Accuracy: 69.14%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/25\n",
      "loss: 0.608593  [   70/  698]\n",
      "loss: 0.521410  [  210/  698]\n",
      "loss: 0.532534  [  350/  698]\n",
      "loss: 0.507833  [  490/  698]\n",
      "loss: 0.704651  [  630/  698]\n",
      "Training Loss (Epoch): 0.627951\n",
      "Validating...\n",
      "Validation Loss: 0.766771, Validation Accuracy: 72.57%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/25\n",
      "loss: 0.471835  [   70/  698]\n",
      "loss: 0.624454  [  210/  698]\n",
      "loss: 0.316563  [  350/  698]\n",
      "loss: 0.503466  [  490/  698]\n",
      "loss: 0.427389  [  630/  698]\n",
      "Training Loss (Epoch): 0.489168\n",
      "Validating...\n",
      "Validation Loss: 0.565463, Validation Accuracy: 80.57%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/25\n",
      "loss: 0.383851  [   70/  698]\n",
      "loss: 0.316962  [  210/  698]\n",
      "loss: 0.284427  [  350/  698]\n",
      "loss: 0.350476  [  490/  698]\n",
      "loss: 0.392345  [  630/  698]\n",
      "Training Loss (Epoch): 0.292045\n",
      "Validating...\n",
      "Validation Loss: 0.516031, Validation Accuracy: 80.00%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 6/25\n",
      "loss: 0.339740  [   70/  698]\n",
      "loss: 0.257916  [  210/  698]\n",
      "loss: 0.158750  [  350/  698]\n",
      "loss: 0.274708  [  490/  698]\n",
      "loss: 0.198259  [  630/  698]\n",
      "Training Loss (Epoch): 0.237407\n",
      "Validating...\n",
      "Validation Loss: 0.383137, Validation Accuracy: 87.43%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 7/25\n",
      "loss: 0.240907  [   70/  698]\n",
      "loss: 0.045635  [  210/  698]\n",
      "loss: 0.086860  [  350/  698]\n",
      "loss: 0.167958  [  490/  698]\n",
      "loss: 0.065972  [  630/  698]\n",
      "Training Loss (Epoch): 0.121449\n",
      "Validating...\n",
      "Validation Loss: 0.248317, Validation Accuracy: 92.00%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 8/25\n",
      "loss: 0.042890  [   70/  698]\n",
      "loss: 0.156348  [  210/  698]\n",
      "loss: 0.051001  [  350/  698]\n",
      "loss: 0.221175  [  490/  698]\n",
      "loss: 0.046393  [  630/  698]\n",
      "Training Loss (Epoch): 0.094762\n",
      "Validating...\n",
      "Validation Loss: 0.304033, Validation Accuracy: 89.14%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 9/25\n",
      "loss: 0.014413  [   70/  698]\n",
      "loss: 0.041531  [  210/  698]\n",
      "loss: 0.074550  [  350/  698]\n",
      "loss: 0.086942  [  490/  698]\n",
      "loss: 0.055735  [  630/  698]\n",
      "Training Loss (Epoch): 0.065234\n",
      "Validating...\n",
      "Validation Loss: 0.272135, Validation Accuracy: 92.00%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 10/25\n",
      "loss: 0.076673  [   70/  698]\n",
      "loss: 0.068713  [  210/  698]\n",
      "loss: 0.014537  [  350/  698]\n",
      "loss: 0.039802  [  490/  698]\n",
      "loss: 0.002572  [  630/  698]\n",
      "Training Loss (Epoch): 0.052361\n",
      "Validating...\n",
      "Validation Loss: 0.250495, Validation Accuracy: 90.29%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 11/25\n",
      "loss: 0.054349  [   70/  698]\n",
      "loss: 0.043426  [  210/  698]\n",
      "loss: 0.012490  [  350/  698]\n",
      "loss: 0.080776  [  490/  698]\n",
      "loss: 0.043698  [  630/  698]\n",
      "Training Loss (Epoch): 0.043451\n",
      "Validating...\n",
      "Validation Loss: 0.243244, Validation Accuracy: 92.57%\n",
      "Learning Rate: [6.25e-06]\n",
      "Epoch 12/25\n",
      "loss: 0.005491  [   70/  698]\n",
      "loss: 0.021067  [  210/  698]\n",
      "loss: 0.021182  [  350/  698]\n",
      "loss: 0.044102  [  490/  698]\n",
      "loss: 0.063344  [  630/  698]\n",
      "Training Loss (Epoch): 0.041496\n",
      "Validating...\n",
      "Validation Loss: 0.240357, Validation Accuracy: 93.14%\n",
      "Learning Rate: [6.25e-06]\n",
      "Epoch 13/25\n",
      "loss: 0.027773  [   70/  698]\n",
      "loss: 0.051483  [  210/  698]\n",
      "loss: 0.016225  [  350/  698]\n",
      "loss: 0.029011  [  490/  698]\n",
      "loss: 0.048642  [  630/  698]\n",
      "Training Loss (Epoch): 0.040558\n",
      "Validating...\n",
      "Validation Loss: 0.242435, Validation Accuracy: 93.71%\n",
      "Learning Rate: [3.125e-06]\n",
      "Epoch 14/25\n",
      "loss: 0.040663  [   70/  698]\n",
      "loss: 0.093903  [  210/  698]\n",
      "loss: 0.040860  [  350/  698]\n",
      "loss: 0.035669  [  490/  698]\n",
      "loss: 0.019557  [  630/  698]\n",
      "Training Loss (Epoch): 0.039950\n",
      "Validating...\n",
      "Validation Loss: 0.243091, Validation Accuracy: 93.71%\n",
      "Learning Rate: [1.5625e-06]\n",
      "Epoch 15/25\n",
      "loss: 0.010809  [   70/  698]\n",
      "loss: 0.019140  [  210/  698]\n",
      "loss: 0.104051  [  350/  698]\n",
      "loss: 0.075562  [  490/  698]\n",
      "loss: 0.035539  [  630/  698]\n",
      "Training Loss (Epoch): 0.039564\n",
      "Validating...\n",
      "Validation Loss: 0.243636, Validation Accuracy: 93.71%\n",
      "Learning Rate: [7.8125e-07]\n",
      "Epoch 16/25\n",
      "loss: 0.514900  [   70/  698]\n",
      "loss: 0.074490  [  210/  698]\n",
      "loss: 0.028862  [  350/  698]\n",
      "loss: 0.044893  [  490/  698]\n",
      "loss: 0.036481  [  630/  698]\n",
      "Training Loss (Epoch): 0.089210\n",
      "Validating...\n",
      "Validation Loss: 0.239846, Validation Accuracy: 93.14%\n",
      "Learning Rate: [3.90625e-07]\n",
      "Epoch 17/25\n",
      "loss: 0.020514  [   70/  698]\n",
      "loss: 0.005515  [  210/  698]\n",
      "loss: 0.149957  [  350/  698]\n",
      "loss: 0.033147  [  490/  698]\n",
      "loss: 0.025884  [  630/  698]\n",
      "Training Loss (Epoch): 0.039472\n",
      "Validating...\n",
      "Validation Loss: 0.239434, Validation Accuracy: 92.57%\n",
      "Learning Rate: [1.953125e-07]\n",
      "Epoch 18/25\n",
      "loss: 0.027405  [   70/  698]\n",
      "loss: 0.075469  [  210/  698]\n",
      "loss: 0.051276  [  350/  698]\n",
      "loss: 0.022806  [  490/  698]\n",
      "loss: 0.062717  [  630/  698]\n",
      "Training Loss (Epoch): 0.039580\n",
      "Validating...\n",
      "Validation Loss: 0.239449, Validation Accuracy: 92.57%\n",
      "Learning Rate: [9.765625e-08]\n",
      "Epoch 19/25\n",
      "loss: 0.023409  [   70/  698]\n",
      "loss: 0.059307  [  210/  698]\n",
      "loss: 0.025942  [  350/  698]\n",
      "loss: 0.135513  [  490/  698]\n",
      "loss: 0.018237  [  630/  698]\n",
      "Training Loss (Epoch): 0.039522\n",
      "Validating...\n",
      "Validation Loss: 0.239431, Validation Accuracy: 92.57%\n",
      "Learning Rate: [4.8828125e-08]\n",
      "Epoch 20/25\n",
      "loss: 0.019657  [   70/  698]\n",
      "loss: 0.021979  [  210/  698]\n",
      "loss: 0.044369  [  350/  698]\n",
      "loss: 0.023848  [  490/  698]\n",
      "loss: 0.050554  [  630/  698]\n",
      "Training Loss (Epoch): 0.039586\n",
      "Validating...\n",
      "Validation Loss: 0.239467, Validation Accuracy: 92.57%\n",
      "Learning Rate: [2.44140625e-08]\n",
      "Epoch 21/25\n",
      "loss: 0.068808  [   70/  698]\n",
      "loss: 0.001467  [  210/  698]\n",
      "loss: 0.029208  [  350/  698]\n",
      "loss: 0.077412  [  490/  698]\n",
      "loss: 0.041670  [  630/  698]\n",
      "Training Loss (Epoch): 0.039454\n",
      "Validating...\n",
      "Validation Loss: 0.239505, Validation Accuracy: 92.57%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 22/25\n",
      "loss: 0.028433  [   70/  698]\n",
      "loss: 0.056212  [  210/  698]\n",
      "loss: 0.068852  [  350/  698]\n",
      "loss: 0.002438  [  490/  698]\n",
      "loss: 0.016884  [  630/  698]\n",
      "Training Loss (Epoch): 0.039602\n",
      "Validating...\n",
      "Validation Loss: 0.239485, Validation Accuracy: 92.57%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 23/25\n",
      "loss: 0.033582  [   70/  698]\n",
      "loss: 0.028471  [  210/  698]\n",
      "loss: 0.048357  [  350/  698]\n",
      "loss: 0.040180  [  490/  698]\n",
      "loss: 0.021341  [  630/  698]\n",
      "Training Loss (Epoch): 0.039447\n",
      "Validating...\n",
      "Validation Loss: 0.239542, Validation Accuracy: 92.57%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 24/25\n",
      "loss: 0.028172  [   70/  698]\n",
      "loss: 0.081241  [  210/  698]\n",
      "loss: 0.014276  [  350/  698]\n",
      "loss: 0.063967  [  490/  698]\n",
      "loss: 0.032531  [  630/  698]\n",
      "Training Loss (Epoch): 0.039471\n",
      "Validating...\n",
      "Validation Loss: 0.239539, Validation Accuracy: 92.57%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 25/25\n",
      "loss: 0.057459  [   70/  698]\n",
      "loss: 0.035883  [  210/  698]\n",
      "loss: 0.020463  [  350/  698]\n",
      "loss: 0.018379  [  490/  698]\n",
      "loss: 0.018645  [  630/  698]\n",
      "Training Loss (Epoch): 0.039541\n",
      "Validating...\n",
      "Validation Loss: 0.239500, Validation Accuracy: 92.57%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Processing Fold 2\n",
      "Epoch 1/25\n",
      "loss: 2.324147  [   70/  710]\n",
      "loss: 2.126844  [  210/  710]\n",
      "loss: 1.878817  [  350/  710]\n",
      "loss: 1.750072  [  490/  710]\n",
      "loss: 1.484145  [  630/  710]\n",
      "loss: 1.342728  [  110/  710]\n",
      "Training Loss (Epoch): 1.801871\n",
      "Validating...\n",
      "Validation Loss: 1.751807, Validation Accuracy: 47.75%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/25\n",
      "loss: 1.734865  [   70/  710]\n",
      "loss: 1.292042  [  210/  710]\n",
      "loss: 1.221029  [  350/  710]\n",
      "loss: 1.070334  [  490/  710]\n",
      "loss: 1.119073  [  630/  710]\n",
      "loss: 0.864347  [  110/  710]\n",
      "Training Loss (Epoch): 1.162102\n",
      "Validating...\n",
      "Validation Loss: 1.401471, Validation Accuracy: 53.37%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/25\n",
      "loss: 1.154592  [   70/  710]\n",
      "loss: 0.726432  [  210/  710]\n",
      "loss: 0.737774  [  350/  710]\n",
      "loss: 0.721227  [  490/  710]\n",
      "loss: 0.839718  [  630/  710]\n",
      "loss: 1.232608  [  110/  710]\n",
      "Training Loss (Epoch): 0.929219\n",
      "Validating...\n",
      "Validation Loss: 1.028697, Validation Accuracy: 67.98%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/25\n",
      "loss: 0.933430  [   70/  710]\n",
      "loss: 0.696192  [  210/  710]\n",
      "loss: 0.790000  [  350/  710]\n",
      "loss: 0.575761  [  490/  710]\n",
      "loss: 0.413658  [  630/  710]\n",
      "loss: 1.075502  [  110/  710]\n",
      "Training Loss (Epoch): 0.735764\n",
      "Validating...\n",
      "Validation Loss: 0.842841, Validation Accuracy: 75.28%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/25\n",
      "loss: 0.447476  [   70/  710]\n",
      "loss: 0.493053  [  210/  710]\n",
      "loss: 0.508829  [  350/  710]\n",
      "loss: 0.514476  [  490/  710]\n",
      "loss: 0.331967  [  630/  710]\n",
      "loss: 0.664474  [  110/  710]\n",
      "Training Loss (Epoch): 0.518207\n",
      "Validating...\n",
      "Validation Loss: 0.574815, Validation Accuracy: 82.58%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/25\n",
      "loss: 0.384077  [   70/  710]\n",
      "loss: 0.719211  [  210/  710]\n",
      "loss: 0.623708  [  350/  710]\n",
      "loss: 0.295058  [  490/  710]\n",
      "loss: 0.283936  [  630/  710]\n",
      "loss: 0.283764  [  110/  710]\n",
      "Training Loss (Epoch): 0.392382\n",
      "Validating...\n",
      "Validation Loss: 0.813469, Validation Accuracy: 79.78%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 7/25\n",
      "loss: 0.534763  [   70/  710]\n",
      "loss: 0.090518  [  210/  710]\n",
      "loss: 0.342553  [  350/  710]\n",
      "loss: 0.226800  [  490/  710]\n",
      "loss: 0.343670  [  630/  710]\n",
      "loss: 0.211439  [  110/  710]\n",
      "Training Loss (Epoch): 0.295597\n",
      "Validating...\n",
      "Validation Loss: 0.620277, Validation Accuracy: 85.39%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 8/25\n",
      "loss: 0.232941  [   70/  710]\n",
      "loss: 0.204651  [  210/  710]\n",
      "loss: 0.184824  [  350/  710]\n",
      "loss: 0.333584  [  490/  710]\n",
      "loss: 0.105316  [  630/  710]\n",
      "loss: 0.466975  [  110/  710]\n",
      "Training Loss (Epoch): 0.208839\n",
      "Validating...\n",
      "Validation Loss: 0.704447, Validation Accuracy: 85.39%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 9/25\n",
      "loss: 0.090059  [   70/  710]\n",
      "loss: 0.123210  [  210/  710]\n",
      "loss: 0.298003  [  350/  710]\n",
      "loss: 0.179299  [  490/  710]\n",
      "loss: 0.106585  [  630/  710]\n",
      "loss: 0.027424  [  110/  710]\n",
      "Training Loss (Epoch): 0.122354\n",
      "Validating...\n",
      "Validation Loss: 0.484286, Validation Accuracy: 89.89%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 10/25\n",
      "loss: 0.081459  [   70/  710]\n",
      "loss: 0.102311  [  210/  710]\n",
      "loss: 0.142293  [  350/  710]\n",
      "loss: 0.043415  [  490/  710]\n",
      "loss: 0.096615  [  630/  710]\n",
      "loss: 0.066273  [  110/  710]\n",
      "Training Loss (Epoch): 0.080265\n",
      "Validating...\n",
      "Validation Loss: 0.554474, Validation Accuracy: 89.33%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 11/25\n",
      "loss: 0.077609  [   70/  710]\n",
      "loss: 0.025128  [  210/  710]\n",
      "loss: 0.037204  [  350/  710]\n",
      "loss: 0.024339  [  490/  710]\n",
      "loss: 0.060091  [  630/  710]\n",
      "loss: 0.011406  [  110/  710]\n",
      "Training Loss (Epoch): 0.054090\n",
      "Validating...\n",
      "Validation Loss: 0.598976, Validation Accuracy: 89.89%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 12/25\n",
      "loss: 0.063204  [   70/  710]\n",
      "loss: 0.088129  [  210/  710]\n",
      "loss: 0.060084  [  350/  710]\n",
      "loss: 0.105781  [  490/  710]\n",
      "loss: 0.013116  [  630/  710]\n",
      "loss: 0.009909  [  110/  710]\n",
      "Training Loss (Epoch): 0.049698\n",
      "Validating...\n",
      "Validation Loss: 0.638713, Validation Accuracy: 89.89%\n",
      "Learning Rate: [6.25e-06]\n",
      "Epoch 13/25\n",
      "loss: 0.090905  [   70/  710]\n",
      "loss: 0.006201  [  210/  710]\n",
      "loss: 0.051960  [  350/  710]\n",
      "loss: 0.059089  [  490/  710]\n",
      "loss: 0.063070  [  630/  710]\n",
      "loss: 0.000289  [  110/  710]\n",
      "Training Loss (Epoch): 0.038200\n",
      "Validating...\n",
      "Validation Loss: 0.651344, Validation Accuracy: 90.45%\n",
      "Learning Rate: [3.125e-06]\n",
      "Epoch 14/25\n",
      "loss: 0.090607  [   70/  710]\n",
      "loss: 0.012311  [  210/  710]\n",
      "loss: 0.017087  [  350/  710]\n",
      "loss: 0.060888  [  490/  710]\n",
      "loss: 0.026479  [  630/  710]\n",
      "loss: 0.025658  [  110/  710]\n",
      "Training Loss (Epoch): 0.042262\n",
      "Validating...\n",
      "Validation Loss: 0.654620, Validation Accuracy: 90.45%\n",
      "Learning Rate: [1.5625e-06]\n",
      "Epoch 15/25\n",
      "loss: 0.116680  [   70/  710]\n",
      "loss: 0.039003  [  210/  710]\n",
      "loss: 0.063980  [  350/  710]\n",
      "loss: 0.014194  [  490/  710]\n",
      "loss: 0.056277  [  630/  710]\n",
      "loss: 0.000876  [  110/  710]\n",
      "Training Loss (Epoch): 0.042129\n",
      "Validating...\n",
      "Validation Loss: 0.657777, Validation Accuracy: 90.45%\n",
      "Learning Rate: [7.8125e-07]\n",
      "Epoch 16/25\n",
      "loss: 0.055734  [   70/  710]\n",
      "loss: 0.039188  [  210/  710]\n",
      "loss: 0.018687  [  350/  710]\n",
      "loss: 0.013185  [  490/  710]\n",
      "loss: 0.094292  [  630/  710]\n",
      "loss: 0.011101  [  110/  710]\n",
      "Training Loss (Epoch): 0.038045\n",
      "Validating...\n",
      "Validation Loss: 0.657894, Validation Accuracy: 90.45%\n",
      "Learning Rate: [3.90625e-07]\n",
      "Epoch 17/25\n",
      "loss: 0.042988  [   70/  710]\n",
      "loss: 0.158711  [  210/  710]\n",
      "loss: 0.036194  [  350/  710]\n",
      "loss: 0.021708  [  490/  710]\n",
      "loss: 0.037666  [  630/  710]\n",
      "loss: 0.186267  [  110/  710]\n",
      "Training Loss (Epoch): 0.062463\n",
      "Validating...\n",
      "Validation Loss: 0.660505, Validation Accuracy: 90.45%\n",
      "Learning Rate: [1.953125e-07]\n",
      "Epoch 18/25\n",
      "loss: 0.015437  [   70/  710]\n",
      "loss: 0.036536  [  210/  710]\n",
      "loss: 0.066732  [  350/  710]\n",
      "loss: 0.038186  [  490/  710]\n",
      "loss: 0.036942  [  630/  710]\n",
      "loss: 0.025547  [  110/  710]\n",
      "Training Loss (Epoch): 0.034866\n",
      "Validating...\n",
      "Validation Loss: 0.660617, Validation Accuracy: 90.45%\n",
      "Learning Rate: [9.765625e-08]\n",
      "Epoch 19/25\n",
      "loss: 0.023304  [   70/  710]\n",
      "loss: 0.063811  [  210/  710]\n",
      "loss: 0.039596  [  350/  710]\n",
      "loss: 0.035949  [  490/  710]\n",
      "loss: 0.017760  [  630/  710]\n",
      "loss: 0.002118  [  110/  710]\n",
      "Training Loss (Epoch): 0.036242\n",
      "Validating...\n",
      "Validation Loss: 0.660316, Validation Accuracy: 90.45%\n",
      "Learning Rate: [4.8828125e-08]\n",
      "Epoch 20/25\n",
      "loss: 0.037545  [   70/  710]\n",
      "loss: 0.022353  [  210/  710]\n",
      "loss: 0.034061  [  350/  710]\n",
      "loss: 0.029356  [  490/  710]\n",
      "loss: 0.030057  [  630/  710]\n",
      "loss: 0.016056  [  110/  710]\n",
      "Training Loss (Epoch): 0.035376\n",
      "Validating...\n",
      "Validation Loss: 0.659982, Validation Accuracy: 90.45%\n",
      "Learning Rate: [2.44140625e-08]\n",
      "Epoch 21/25\n",
      "loss: 0.011573  [   70/  710]\n",
      "loss: 0.084095  [  210/  710]\n",
      "loss: 0.023883  [  350/  710]\n",
      "loss: 0.071515  [  490/  710]\n",
      "loss: 0.022357  [  630/  710]\n",
      "loss: 0.060682  [  110/  710]\n",
      "Training Loss (Epoch): 0.047951\n",
      "Validating...\n",
      "Validation Loss: 0.660023, Validation Accuracy: 90.45%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 22/25\n",
      "loss: 0.048797  [   70/  710]\n",
      "loss: 0.058432  [  210/  710]\n",
      "loss: 0.045996  [  350/  710]\n",
      "loss: 0.010108  [  490/  710]\n",
      "loss: 0.061211  [  630/  710]\n",
      "loss: 0.033592  [  110/  710]\n",
      "Training Loss (Epoch): 0.036413\n",
      "Validating...\n",
      "Validation Loss: 0.660066, Validation Accuracy: 90.45%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 23/25\n",
      "loss: 0.021330  [   70/  710]\n",
      "loss: 0.023412  [  210/  710]\n",
      "loss: 0.072792  [  350/  710]\n",
      "loss: 0.093634  [  490/  710]\n",
      "loss: 0.011133  [  630/  710]\n",
      "loss: 0.023715  [  110/  710]\n",
      "Training Loss (Epoch): 0.035575\n",
      "Validating...\n",
      "Validation Loss: 0.660067, Validation Accuracy: 90.45%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 24/25\n",
      "loss: 0.039040  [   70/  710]\n",
      "loss: 0.022765  [  210/  710]\n",
      "loss: 0.012667  [  350/  710]\n",
      "loss: 0.045728  [  490/  710]\n",
      "loss: 0.006825  [  630/  710]\n",
      "loss: 0.088247  [  110/  710]\n",
      "Training Loss (Epoch): 0.040372\n",
      "Validating...\n",
      "Validation Loss: 0.659983, Validation Accuracy: 90.45%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 25/25\n",
      "loss: 0.075738  [   70/  710]\n",
      "loss: 0.019476  [  210/  710]\n",
      "loss: 0.021859  [  350/  710]\n",
      "loss: 0.025858  [  490/  710]\n",
      "loss: 0.088433  [  630/  710]\n",
      "loss: 0.033981  [  110/  710]\n",
      "Training Loss (Epoch): 0.040116\n",
      "Validating...\n",
      "Validation Loss: 0.659962, Validation Accuracy: 90.45%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Processing Fold 3\n",
      "Epoch 1/25\n",
      "loss: 2.359405  [   70/  740]\n",
      "loss: 2.169508  [  210/  740]\n",
      "loss: 1.967548  [  350/  740]\n",
      "loss: 1.728688  [  490/  740]\n",
      "loss: 1.494381  [  630/  740]\n",
      "loss: 1.516063  [  440/  740]\n",
      "Training Loss (Epoch): 1.846697\n",
      "Validating...\n",
      "Validation Loss: 1.636536, Validation Accuracy: 52.43%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/25\n",
      "loss: 1.455866  [   70/  740]\n",
      "loss: 1.104195  [  210/  740]\n",
      "loss: 1.293432  [  350/  740]\n",
      "loss: 1.408371  [  490/  740]\n",
      "loss: 0.777992  [  630/  740]\n",
      "loss: 0.666110  [  440/  740]\n",
      "Training Loss (Epoch): 1.136678\n",
      "Validating...\n",
      "Validation Loss: 1.084973, Validation Accuracy: 60.00%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/25\n",
      "loss: 0.739978  [   70/  740]\n",
      "loss: 0.901213  [  210/  740]\n",
      "loss: 0.582727  [  350/  740]\n",
      "loss: 0.506001  [  490/  740]\n",
      "loss: 0.687853  [  630/  740]\n",
      "loss: 0.320088  [  440/  740]\n",
      "Training Loss (Epoch): 0.716630\n",
      "Validating...\n",
      "Validation Loss: 0.935952, Validation Accuracy: 67.03%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/25\n",
      "loss: 0.395864  [   70/  740]\n",
      "loss: 0.636716  [  210/  740]\n",
      "loss: 0.528887  [  350/  740]\n",
      "loss: 0.551350  [  490/  740]\n",
      "loss: 0.739026  [  630/  740]\n",
      "loss: 0.523165  [  440/  740]\n",
      "Training Loss (Epoch): 0.623550\n",
      "Validating...\n",
      "Validation Loss: 0.780245, Validation Accuracy: 71.89%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/25\n",
      "loss: 0.364411  [   70/  740]\n",
      "loss: 0.456462  [  210/  740]\n",
      "loss: 0.486659  [  350/  740]\n",
      "loss: 0.422379  [  490/  740]\n",
      "loss: 0.323357  [  630/  740]\n",
      "loss: 0.221552  [  440/  740]\n",
      "Training Loss (Epoch): 0.420997\n",
      "Validating...\n",
      "Validation Loss: 0.523392, Validation Accuracy: 80.00%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/25\n",
      "loss: 0.284507  [   70/  740]\n",
      "loss: 0.312766  [  210/  740]\n",
      "loss: 0.521833  [  350/  740]\n",
      "loss: 0.195688  [  490/  740]\n",
      "loss: 0.256027  [  630/  740]\n",
      "loss: 0.208680  [  440/  740]\n",
      "Training Loss (Epoch): 0.288569\n",
      "Validating...\n",
      "Validation Loss: 0.469405, Validation Accuracy: 85.95%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 7/25\n",
      "loss: 0.403540  [   70/  740]\n",
      "loss: 0.138417  [  210/  740]\n",
      "loss: 0.132188  [  350/  740]\n",
      "loss: 0.247044  [  490/  740]\n",
      "loss: 0.269255  [  630/  740]\n",
      "loss: 0.290565  [  440/  740]\n",
      "Training Loss (Epoch): 0.238223\n",
      "Validating...\n",
      "Validation Loss: 0.508264, Validation Accuracy: 79.46%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 8/25\n",
      "loss: 0.283787  [   70/  740]\n",
      "loss: 0.333005  [  210/  740]\n",
      "loss: 0.255381  [  350/  740]\n",
      "loss: 0.168508  [  490/  740]\n",
      "loss: 0.135800  [  630/  740]\n",
      "loss: 0.176923  [  440/  740]\n",
      "Training Loss (Epoch): 0.230329\n",
      "Validating...\n",
      "Validation Loss: 0.508892, Validation Accuracy: 85.41%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 9/25\n",
      "loss: 0.160460  [   70/  740]\n",
      "loss: 0.179106  [  210/  740]\n",
      "loss: 0.091584  [  350/  740]\n",
      "loss: 0.168484  [  490/  740]\n",
      "loss: 0.141593  [  630/  740]\n",
      "loss: 0.026647  [  440/  740]\n",
      "Training Loss (Epoch): 0.130524\n",
      "Validating...\n",
      "Validation Loss: 0.328414, Validation Accuracy: 87.57%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 10/25\n",
      "loss: 0.161229  [   70/  740]\n",
      "loss: 0.079401  [  210/  740]\n",
      "loss: 0.116163  [  350/  740]\n",
      "loss: 0.100149  [  490/  740]\n",
      "loss: 0.148569  [  630/  740]\n",
      "loss: 0.021337  [  440/  740]\n",
      "Training Loss (Epoch): 0.089520\n",
      "Validating...\n",
      "Validation Loss: 0.384620, Validation Accuracy: 89.73%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 11/25\n",
      "loss: 0.090572  [   70/  740]\n",
      "loss: 0.052189  [  210/  740]\n",
      "loss: 0.016510  [  350/  740]\n",
      "loss: 0.055603  [  490/  740]\n",
      "loss: 0.039554  [  630/  740]\n",
      "loss: 0.017520  [  440/  740]\n",
      "Training Loss (Epoch): 0.055885\n",
      "Validating...\n",
      "Validation Loss: 0.330777, Validation Accuracy: 89.19%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 12/25\n",
      "loss: 0.043531  [   70/  740]\n",
      "loss: 0.060534  [  210/  740]\n",
      "loss: 0.042056  [  350/  740]\n",
      "loss: 0.053301  [  490/  740]\n",
      "loss: 0.106070  [  630/  740]\n",
      "loss: 0.008042  [  440/  740]\n",
      "Training Loss (Epoch): 0.048193\n",
      "Validating...\n",
      "Validation Loss: 0.344507, Validation Accuracy: 89.73%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 13/25\n",
      "loss: 0.053545  [   70/  740]\n",
      "loss: 0.027608  [  210/  740]\n",
      "loss: 0.003328  [  350/  740]\n",
      "loss: 0.042904  [  490/  740]\n",
      "loss: 0.035611  [  630/  740]\n",
      "loss: 0.153155  [  440/  740]\n",
      "Training Loss (Epoch): 0.053081\n",
      "Validating...\n",
      "Validation Loss: 0.328795, Validation Accuracy: 90.27%\n",
      "Learning Rate: [6.25e-06]\n",
      "Epoch 14/25\n",
      "loss: 0.075120  [   70/  740]\n",
      "loss: 0.045923  [  210/  740]\n",
      "loss: 0.049603  [  350/  740]\n",
      "loss: 0.075521  [  490/  740]\n",
      "loss: 0.030447  [  630/  740]\n",
      "loss: 0.034660  [  440/  740]\n",
      "Training Loss (Epoch): 0.044746\n",
      "Validating...\n",
      "Validation Loss: 0.330645, Validation Accuracy: 91.35%\n",
      "Learning Rate: [6.25e-06]\n",
      "Epoch 15/25\n",
      "loss: 0.018759  [   70/  740]\n",
      "loss: 0.028647  [  210/  740]\n",
      "loss: 0.050369  [  350/  740]\n",
      "loss: 0.094171  [  490/  740]\n",
      "loss: 0.029688  [  630/  740]\n",
      "loss: 0.058016  [  440/  740]\n",
      "Training Loss (Epoch): 0.042239\n",
      "Validating...\n",
      "Validation Loss: 0.337048, Validation Accuracy: 90.81%\n",
      "Learning Rate: [3.125e-06]\n",
      "Epoch 16/25\n",
      "loss: 0.029609  [   70/  740]\n",
      "loss: 0.032770  [  210/  740]\n",
      "loss: 0.067169  [  350/  740]\n",
      "loss: 0.046159  [  490/  740]\n",
      "loss: 0.016371  [  630/  740]\n",
      "loss: 0.044515  [  440/  740]\n",
      "Training Loss (Epoch): 0.037939\n",
      "Validating...\n",
      "Validation Loss: 0.337494, Validation Accuracy: 90.81%\n",
      "Learning Rate: [1.5625e-06]\n",
      "Epoch 17/25\n",
      "loss: 0.024942  [   70/  740]\n",
      "loss: 0.049704  [  210/  740]\n",
      "loss: 0.006992  [  350/  740]\n",
      "loss: 0.047566  [  490/  740]\n",
      "loss: 0.030407  [  630/  740]\n",
      "loss: 0.081245  [  440/  740]\n",
      "Training Loss (Epoch): 0.039634\n",
      "Validating...\n",
      "Validation Loss: 0.335720, Validation Accuracy: 90.27%\n",
      "Learning Rate: [7.8125e-07]\n",
      "Epoch 18/25\n",
      "loss: 0.092056  [   70/  740]\n",
      "loss: 0.029196  [  210/  740]\n",
      "loss: 0.040672  [  350/  740]\n",
      "loss: 0.048012  [  490/  740]\n",
      "loss: 0.020552  [  630/  740]\n",
      "loss: 0.024894  [  440/  740]\n",
      "Training Loss (Epoch): 0.038419\n",
      "Validating...\n",
      "Validation Loss: 0.335094, Validation Accuracy: 90.27%\n",
      "Learning Rate: [3.90625e-07]\n",
      "Epoch 19/25\n",
      "loss: 0.020255  [   70/  740]\n",
      "loss: 0.033760  [  210/  740]\n",
      "loss: 0.013976  [  350/  740]\n",
      "loss: 0.028848  [  490/  740]\n",
      "loss: 0.052832  [  630/  740]\n",
      "loss: 0.031803  [  440/  740]\n",
      "Training Loss (Epoch): 0.036408\n",
      "Validating...\n",
      "Validation Loss: 0.335524, Validation Accuracy: 90.27%\n",
      "Learning Rate: [1.953125e-07]\n",
      "Epoch 20/25\n",
      "loss: 0.092267  [   70/  740]\n",
      "loss: 0.047793  [  210/  740]\n",
      "loss: 0.029260  [  350/  740]\n",
      "loss: 0.046002  [  490/  740]\n",
      "loss: 0.005416  [  630/  740]\n",
      "loss: 0.001155  [  440/  740]\n",
      "Training Loss (Epoch): 0.036632\n",
      "Validating...\n",
      "Validation Loss: 0.335406, Validation Accuracy: 90.27%\n",
      "Learning Rate: [9.765625e-08]\n",
      "Epoch 21/25\n",
      "loss: 0.034774  [   70/  740]\n",
      "loss: 0.042320  [  210/  740]\n",
      "loss: 0.040436  [  350/  740]\n",
      "loss: 0.019843  [  490/  740]\n",
      "loss: 0.001472  [  630/  740]\n",
      "loss: 0.034111  [  440/  740]\n",
      "Training Loss (Epoch): 0.036934\n",
      "Validating...\n",
      "Validation Loss: 0.335275, Validation Accuracy: 90.27%\n",
      "Learning Rate: [4.8828125e-08]\n",
      "Epoch 22/25\n",
      "loss: 0.022898  [   70/  740]\n",
      "loss: 0.031911  [  210/  740]\n",
      "loss: 0.073111  [  350/  740]\n",
      "loss: 0.028990  [  490/  740]\n",
      "loss: 0.047495  [  630/  740]\n",
      "loss: 0.002120  [  440/  740]\n",
      "Training Loss (Epoch): 0.036414\n",
      "Validating...\n",
      "Validation Loss: 0.335290, Validation Accuracy: 90.27%\n",
      "Learning Rate: [2.44140625e-08]\n",
      "Epoch 23/25\n",
      "loss: 0.037425  [   70/  740]\n",
      "loss: 0.076194  [  210/  740]\n",
      "loss: 0.012602  [  350/  740]\n",
      "loss: 0.050102  [  490/  740]\n",
      "loss: 0.059374  [  630/  740]\n",
      "loss: 0.018523  [  440/  740]\n",
      "Training Loss (Epoch): 0.036889\n",
      "Validating...\n",
      "Validation Loss: 0.335249, Validation Accuracy: 90.27%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 24/25\n",
      "loss: 0.051125  [   70/  740]\n",
      "loss: 0.040168  [  210/  740]\n",
      "loss: 0.022653  [  350/  740]\n",
      "loss: 0.029037  [  490/  740]\n",
      "loss: 0.037157  [  630/  740]\n",
      "loss: 0.068334  [  440/  740]\n",
      "Training Loss (Epoch): 0.035434\n",
      "Validating...\n",
      "Validation Loss: 0.335236, Validation Accuracy: 90.27%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 25/25\n",
      "loss: 0.052146  [   70/  740]\n",
      "loss: 0.030743  [  210/  740]\n",
      "loss: 0.020914  [  350/  740]\n",
      "loss: 0.012241  [  490/  740]\n",
      "loss: 0.020267  [  630/  740]\n",
      "loss: 0.038090  [  440/  740]\n",
      "Training Loss (Epoch): 0.037867\n",
      "Validating...\n",
      "Validation Loss: 0.335229, Validation Accuracy: 90.27%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Processing Fold 4\n",
      "Epoch 1/25\n",
      "loss: 2.330706  [   70/  792]\n",
      "loss: 2.176523  [  210/  792]\n",
      "loss: 2.057385  [  350/  792]\n",
      "loss: 1.775079  [  490/  792]\n",
      "loss: 1.755274  [  630/  792]\n",
      "loss: 1.572264  [  770/  792]\n",
      "Training Loss (Epoch): 1.925446\n",
      "Validating...\n",
      "Validation Loss: 1.628207, Validation Accuracy: 62.12%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/25\n",
      "loss: 1.591287  [   70/  792]\n",
      "loss: 1.316407  [  210/  792]\n",
      "loss: 1.052491  [  350/  792]\n",
      "loss: 1.915580  [  490/  792]\n",
      "loss: 1.463362  [  630/  792]\n",
      "loss: 1.090845  [  770/  792]\n",
      "Training Loss (Epoch): 1.443084\n",
      "Validating...\n",
      "Validation Loss: 0.937054, Validation Accuracy: 64.14%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/25\n",
      "loss: 0.902853  [   70/  792]\n",
      "loss: 0.694125  [  210/  792]\n",
      "loss: 1.217924  [  350/  792]\n",
      "loss: 0.958104  [  490/  792]\n",
      "loss: 0.861355  [  630/  792]\n",
      "loss: 0.732769  [  770/  792]\n",
      "Training Loss (Epoch): 0.921778\n",
      "Validating...\n",
      "Validation Loss: 0.982661, Validation Accuracy: 64.65%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 4/25\n",
      "loss: 1.001769  [   70/  792]\n",
      "loss: 0.615705  [  210/  792]\n",
      "loss: 0.513435  [  350/  792]\n",
      "loss: 0.497921  [  490/  792]\n",
      "loss: 0.496481  [  630/  792]\n",
      "loss: 0.691878  [  770/  792]\n",
      "Training Loss (Epoch): 0.540809\n",
      "Validating...\n",
      "Validation Loss: 0.433659, Validation Accuracy: 85.86%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 5/25\n",
      "loss: 0.445915  [   70/  792]\n",
      "loss: 0.429689  [  210/  792]\n",
      "loss: 0.422509  [  350/  792]\n",
      "loss: 0.564786  [  490/  792]\n",
      "loss: 0.245033  [  630/  792]\n",
      "loss: 0.273448  [  770/  792]\n",
      "Training Loss (Epoch): 0.466028\n",
      "Validating...\n",
      "Validation Loss: 0.489634, Validation Accuracy: 81.31%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 6/25\n",
      "loss: 0.349751  [   70/  792]\n",
      "loss: 0.485241  [  210/  792]\n",
      "loss: 0.336419  [  350/  792]\n",
      "loss: 0.225591  [  490/  792]\n",
      "loss: 0.556814  [  630/  792]\n",
      "loss: 0.496671  [  770/  792]\n",
      "Training Loss (Epoch): 0.385236\n",
      "Validating...\n",
      "Validation Loss: 0.399597, Validation Accuracy: 85.35%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 7/25\n",
      "loss: 0.415095  [   70/  792]\n",
      "loss: 0.225826  [  210/  792]\n",
      "loss: 0.291486  [  350/  792]\n",
      "loss: 0.203760  [  490/  792]\n",
      "loss: 0.283648  [  630/  792]\n",
      "loss: 0.168145  [  770/  792]\n",
      "Training Loss (Epoch): 0.240472\n",
      "Validating...\n",
      "Validation Loss: 0.344653, Validation Accuracy: 89.90%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 8/25\n",
      "loss: 0.250027  [   70/  792]\n",
      "loss: 0.231703  [  210/  792]\n",
      "loss: 0.240639  [  350/  792]\n",
      "loss: 0.234854  [  490/  792]\n",
      "loss: 0.196885  [  630/  792]\n",
      "loss: 0.136697  [  770/  792]\n",
      "Training Loss (Epoch): 0.174493\n",
      "Validating...\n",
      "Validation Loss: 0.337200, Validation Accuracy: 90.40%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 9/25\n",
      "loss: 0.173976  [   70/  792]\n",
      "loss: 0.185576  [  210/  792]\n",
      "loss: 0.056797  [  350/  792]\n",
      "loss: 0.124253  [  490/  792]\n",
      "loss: 0.139369  [  630/  792]\n",
      "loss: 0.148159  [  770/  792]\n",
      "Training Loss (Epoch): 0.144480\n",
      "Validating...\n",
      "Validation Loss: 0.314910, Validation Accuracy: 91.41%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 10/25\n",
      "loss: 0.056037  [   70/  792]\n",
      "loss: 0.058531  [  210/  792]\n",
      "loss: 0.144495  [  350/  792]\n",
      "loss: 0.124999  [  490/  792]\n",
      "loss: 0.067407  [  630/  792]\n",
      "loss: 0.063229  [  770/  792]\n",
      "Training Loss (Epoch): 0.135800\n",
      "Validating...\n",
      "Validation Loss: 0.302472, Validation Accuracy: 91.92%\n",
      "Learning Rate: [6.25e-06]\n",
      "Epoch 11/25\n",
      "loss: 0.127892  [   70/  792]\n",
      "loss: 0.108034  [  210/  792]\n",
      "loss: 0.248285  [  350/  792]\n",
      "loss: 0.087327  [  490/  792]\n",
      "loss: 0.056788  [  630/  792]\n",
      "loss: 0.040333  [  770/  792]\n",
      "Training Loss (Epoch): 0.099268\n",
      "Validating...\n",
      "Validation Loss: 0.292297, Validation Accuracy: 91.92%\n",
      "Learning Rate: [3.125e-06]\n",
      "Epoch 12/25\n",
      "loss: 0.062920  [   70/  792]\n",
      "loss: 0.176249  [  210/  792]\n",
      "loss: 0.086939  [  350/  792]\n",
      "loss: 0.071803  [  490/  792]\n",
      "loss: 0.042574  [  630/  792]\n",
      "loss: 0.092479  [  770/  792]\n",
      "Training Loss (Epoch): 0.091358\n",
      "Validating...\n",
      "Validation Loss: 0.285981, Validation Accuracy: 91.92%\n",
      "Learning Rate: [1.5625e-06]\n",
      "Epoch 13/25\n",
      "loss: 0.084380  [   70/  792]\n",
      "loss: 0.074081  [  210/  792]\n",
      "loss: 0.093649  [  350/  792]\n",
      "loss: 0.148357  [  490/  792]\n",
      "loss: 0.127846  [  630/  792]\n",
      "loss: 0.071210  [  770/  792]\n",
      "Training Loss (Epoch): 0.086429\n",
      "Validating...\n",
      "Validation Loss: 0.285316, Validation Accuracy: 91.92%\n",
      "Learning Rate: [7.8125e-07]\n",
      "Epoch 14/25\n",
      "loss: 0.033200  [   70/  792]\n",
      "loss: 0.142806  [  210/  792]\n",
      "loss: 0.054204  [  350/  792]\n",
      "loss: 0.127507  [  490/  792]\n",
      "loss: 0.019252  [  630/  792]\n",
      "loss: 0.129334  [  770/  792]\n",
      "Training Loss (Epoch): 0.081567\n",
      "Validating...\n",
      "Validation Loss: 0.285082, Validation Accuracy: 93.43%\n",
      "Learning Rate: [7.8125e-07]\n",
      "Epoch 15/25\n",
      "loss: 0.051805  [   70/  792]\n",
      "loss: 0.051870  [  210/  792]\n",
      "loss: 0.098697  [  350/  792]\n",
      "loss: 0.035569  [  490/  792]\n",
      "loss: 0.133651  [  630/  792]\n",
      "loss: 0.066942  [  770/  792]\n",
      "Training Loss (Epoch): 0.092617\n",
      "Validating...\n",
      "Validation Loss: 0.284934, Validation Accuracy: 93.43%\n",
      "Learning Rate: [3.90625e-07]\n",
      "Epoch 16/25\n",
      "loss: 0.073645  [   70/  792]\n",
      "loss: 0.114498  [  210/  792]\n",
      "loss: 0.089633  [  350/  792]\n",
      "loss: 0.065150  [  490/  792]\n",
      "loss: 0.093026  [  630/  792]\n",
      "loss: 0.082963  [  770/  792]\n",
      "Training Loss (Epoch): 0.080802\n",
      "Validating...\n",
      "Validation Loss: 0.284635, Validation Accuracy: 93.43%\n",
      "Learning Rate: [1.953125e-07]\n",
      "Epoch 17/25\n",
      "loss: 0.071763  [   70/  792]\n",
      "loss: 0.065027  [  210/  792]\n",
      "loss: 0.066118  [  350/  792]\n",
      "loss: 0.046197  [  490/  792]\n",
      "loss: 0.125928  [  630/  792]\n",
      "loss: 0.085336  [  770/  792]\n",
      "Training Loss (Epoch): 0.078811\n",
      "Validating...\n",
      "Validation Loss: 0.284611, Validation Accuracy: 93.43%\n",
      "Learning Rate: [9.765625e-08]\n",
      "Epoch 18/25\n",
      "loss: 0.021025  [   70/  792]\n",
      "loss: 0.137332  [  210/  792]\n",
      "loss: 0.045551  [  350/  792]\n",
      "loss: 0.041013  [  490/  792]\n",
      "loss: 0.093729  [  630/  792]\n",
      "loss: 0.087944  [  770/  792]\n",
      "Training Loss (Epoch): 0.092757\n",
      "Validating...\n",
      "Validation Loss: 0.284573, Validation Accuracy: 93.43%\n",
      "Learning Rate: [4.8828125e-08]\n",
      "Epoch 19/25\n",
      "loss: 0.055342  [   70/  792]\n",
      "loss: 0.024045  [  210/  792]\n",
      "loss: 0.035741  [  350/  792]\n",
      "loss: 0.104160  [  490/  792]\n",
      "loss: 0.084135  [  630/  792]\n",
      "loss: 0.184272  [  770/  792]\n",
      "Training Loss (Epoch): 0.079735\n",
      "Validating...\n",
      "Validation Loss: 0.284625, Validation Accuracy: 93.43%\n",
      "Learning Rate: [2.44140625e-08]\n",
      "Epoch 20/25\n",
      "loss: 0.173964  [   70/  792]\n",
      "loss: 0.097205  [  210/  792]\n",
      "loss: 0.043307  [  350/  792]\n",
      "loss: 0.091840  [  490/  792]\n",
      "loss: 0.095001  [  630/  792]\n",
      "loss: 0.098417  [  770/  792]\n",
      "Training Loss (Epoch): 0.084862\n",
      "Validating...\n",
      "Validation Loss: 0.284629, Validation Accuracy: 93.43%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 21/25\n",
      "loss: 0.121940  [   70/  792]\n",
      "loss: 0.088543  [  210/  792]\n",
      "loss: 0.075366  [  350/  792]\n",
      "loss: 0.172848  [  490/  792]\n",
      "loss: 0.115283  [  630/  792]\n",
      "loss: 0.035080  [  770/  792]\n",
      "Training Loss (Epoch): 0.082290\n",
      "Validating...\n",
      "Validation Loss: 0.284597, Validation Accuracy: 93.43%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 22/25\n",
      "loss: 0.115804  [   70/  792]\n",
      "loss: 0.046866  [  210/  792]\n",
      "loss: 0.056646  [  350/  792]\n",
      "loss: 0.076948  [  490/  792]\n",
      "loss: 0.042024  [  630/  792]\n",
      "loss: 0.134744  [  770/  792]\n",
      "Training Loss (Epoch): 0.078242\n",
      "Validating...\n",
      "Validation Loss: 0.284594, Validation Accuracy: 93.43%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 23/25\n",
      "loss: 0.051179  [   70/  792]\n",
      "loss: 0.110157  [  210/  792]\n",
      "loss: 0.092562  [  350/  792]\n",
      "loss: 0.075077  [  490/  792]\n",
      "loss: 0.083574  [  630/  792]\n",
      "loss: 0.060525  [  770/  792]\n",
      "Training Loss (Epoch): 0.085539\n",
      "Validating...\n",
      "Validation Loss: 0.284591, Validation Accuracy: 93.43%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 24/25\n",
      "loss: 0.052291  [   70/  792]\n",
      "loss: 0.130486  [  210/  792]\n",
      "loss: 0.043655  [  350/  792]\n",
      "loss: 0.096554  [  490/  792]\n",
      "loss: 0.101933  [  630/  792]\n",
      "loss: 0.063865  [  770/  792]\n",
      "Training Loss (Epoch): 0.090001\n",
      "Validating...\n",
      "Validation Loss: 0.284583, Validation Accuracy: 93.43%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 25/25\n",
      "loss: 0.053614  [   70/  792]\n",
      "loss: 0.074701  [  210/  792]\n",
      "loss: 0.061317  [  350/  792]\n",
      "loss: 0.087984  [  490/  792]\n",
      "loss: 0.122903  [  630/  792]\n",
      "loss: 0.062953  [  770/  792]\n",
      "Training Loss (Epoch): 0.079227\n",
      "Validating...\n",
      "Validation Loss: 0.284559, Validation Accuracy: 93.43%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Processing Fold 5\n",
      "Epoch 1/25\n",
      "loss: 2.351445  [   70/  748]\n",
      "loss: 2.154093  [  210/  748]\n",
      "loss: 2.005580  [  350/  748]\n",
      "loss: 1.813904  [  490/  748]\n",
      "loss: 1.783811  [  630/  748]\n",
      "loss: 1.642190  [  528/  748]\n",
      "Training Loss (Epoch): 1.949467\n",
      "Validating...\n",
      "Validation Loss: 1.752536, Validation Accuracy: 50.00%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/25\n",
      "loss: 1.693507  [   70/  748]\n",
      "loss: 1.112429  [  210/  748]\n",
      "loss: 1.110625  [  350/  748]\n",
      "loss: 1.711058  [  490/  748]\n",
      "loss: 1.490246  [  630/  748]\n",
      "loss: 1.565678  [  528/  748]\n",
      "Training Loss (Epoch): 1.495392\n",
      "Validating...\n",
      "Validation Loss: 1.594617, Validation Accuracy: 51.60%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/25\n",
      "loss: 1.436673  [   70/  748]\n",
      "loss: 1.196024  [  210/  748]\n",
      "loss: 0.952043  [  350/  748]\n",
      "loss: 0.804905  [  490/  748]\n",
      "loss: 0.972158  [  630/  748]\n",
      "loss: 0.732514  [  528/  748]\n",
      "Training Loss (Epoch): 1.042972\n",
      "Validating...\n",
      "Validation Loss: 1.106954, Validation Accuracy: 60.11%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/25\n",
      "loss: 0.851007  [   70/  748]\n",
      "loss: 0.829307  [  210/  748]\n",
      "loss: 0.667450  [  350/  748]\n",
      "loss: 0.680620  [  490/  748]\n",
      "loss: 0.444793  [  630/  748]\n",
      "loss: 0.635850  [  528/  748]\n",
      "Training Loss (Epoch): 0.665956\n",
      "Validating...\n",
      "Validation Loss: 0.909818, Validation Accuracy: 71.28%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/25\n",
      "loss: 0.736014  [   70/  748]\n",
      "loss: 0.457402  [  210/  748]\n",
      "loss: 0.534346  [  350/  748]\n",
      "loss: 0.389452  [  490/  748]\n",
      "loss: 0.417022  [  630/  748]\n",
      "loss: 0.269034  [  528/  748]\n",
      "Training Loss (Epoch): 0.450758\n",
      "Validating...\n",
      "Validation Loss: 0.701498, Validation Accuracy: 76.60%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/25\n",
      "loss: 0.318671  [   70/  748]\n",
      "loss: 0.311456  [  210/  748]\n",
      "loss: 0.279207  [  350/  748]\n",
      "loss: 0.231161  [  490/  748]\n",
      "loss: 0.404709  [  630/  748]\n",
      "loss: 0.074966  [  528/  748]\n",
      "Training Loss (Epoch): 0.310514\n",
      "Validating...\n",
      "Validation Loss: 0.694047, Validation Accuracy: 81.91%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 7/25\n",
      "loss: 0.243940  [   70/  748]\n",
      "loss: 0.268460  [  210/  748]\n",
      "loss: 0.263708  [  350/  748]\n",
      "loss: 0.260064  [  490/  748]\n",
      "loss: 0.402514  [  630/  748]\n",
      "loss: 0.393847  [  528/  748]\n",
      "Training Loss (Epoch): 0.306437\n",
      "Validating...\n",
      "Validation Loss: 0.808372, Validation Accuracy: 78.72%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 8/25\n",
      "loss: 0.198962  [   70/  748]\n",
      "loss: 0.207803  [  210/  748]\n",
      "loss: 0.248415  [  350/  748]\n",
      "loss: 0.138120  [  490/  748]\n",
      "loss: 0.205374  [  630/  748]\n",
      "loss: 0.171344  [  528/  748]\n",
      "Training Loss (Epoch): 0.216434\n",
      "Validating...\n",
      "Validation Loss: 0.631086, Validation Accuracy: 82.45%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 9/25\n",
      "loss: 0.140209  [   70/  748]\n",
      "loss: 0.145688  [  210/  748]\n",
      "loss: 0.127311  [  350/  748]\n",
      "loss: 0.084664  [  490/  748]\n",
      "loss: 0.199644  [  630/  748]\n",
      "loss: 0.305978  [  528/  748]\n",
      "Training Loss (Epoch): 0.170506\n",
      "Validating...\n",
      "Validation Loss: 0.515228, Validation Accuracy: 85.64%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 10/25\n",
      "loss: 0.135247  [   70/  748]\n",
      "loss: 0.192990  [  210/  748]\n",
      "loss: 0.148016  [  350/  748]\n",
      "loss: 0.142783  [  490/  748]\n",
      "loss: 0.166817  [  630/  748]\n",
      "loss: 0.009500  [  528/  748]\n",
      "Training Loss (Epoch): 0.139080\n",
      "Validating...\n",
      "Validation Loss: 0.514993, Validation Accuracy: 88.83%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 11/25\n",
      "loss: 0.142696  [   70/  748]\n",
      "loss: 0.143147  [  210/  748]\n",
      "loss: 0.150093  [  350/  748]\n",
      "loss: 0.152331  [  490/  748]\n",
      "loss: 0.131388  [  630/  748]\n",
      "loss: 0.030970  [  528/  748]\n",
      "Training Loss (Epoch): 0.114343\n",
      "Validating...\n",
      "Validation Loss: 0.506832, Validation Accuracy: 88.30%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 12/25\n",
      "loss: 0.108299  [   70/  748]\n",
      "loss: 0.100650  [  210/  748]\n",
      "loss: 0.078344  [  350/  748]\n",
      "loss: 0.067444  [  490/  748]\n",
      "loss: 0.092480  [  630/  748]\n",
      "loss: 0.095321  [  528/  748]\n",
      "Training Loss (Epoch): 0.097883\n",
      "Validating...\n",
      "Validation Loss: 0.508390, Validation Accuracy: 88.30%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 13/25\n",
      "loss: 0.071270  [   70/  748]\n",
      "loss: 0.102674  [  210/  748]\n",
      "loss: 0.049851  [  350/  748]\n",
      "loss: 0.150938  [  490/  748]\n",
      "loss: 0.097114  [  630/  748]\n",
      "loss: 0.020687  [  528/  748]\n",
      "Training Loss (Epoch): 0.095315\n",
      "Validating...\n",
      "Validation Loss: 0.548260, Validation Accuracy: 86.17%\n",
      "Learning Rate: [6.25e-06]\n",
      "Epoch 14/25\n",
      "loss: 0.088158  [   70/  748]\n",
      "loss: 0.047748  [  210/  748]\n",
      "loss: 0.034789  [  350/  748]\n",
      "loss: 0.174459  [  490/  748]\n",
      "loss: 0.088602  [  630/  748]\n",
      "loss: 0.023626  [  528/  748]\n",
      "Training Loss (Epoch): 0.076538\n",
      "Validating...\n",
      "Validation Loss: 0.534091, Validation Accuracy: 87.23%\n",
      "Learning Rate: [3.125e-06]\n",
      "Epoch 15/25\n",
      "loss: 0.041249  [   70/  748]\n",
      "loss: 0.090036  [  210/  748]\n",
      "loss: 0.076428  [  350/  748]\n",
      "loss: 0.096196  [  490/  748]\n",
      "loss: 0.084937  [  630/  748]\n",
      "loss: 0.097408  [  528/  748]\n",
      "Training Loss (Epoch): 0.074459\n",
      "Validating...\n",
      "Validation Loss: 0.524881, Validation Accuracy: 87.23%\n",
      "Learning Rate: [1.5625e-06]\n",
      "Epoch 16/25\n",
      "loss: 0.117679  [   70/  748]\n",
      "loss: 0.028621  [  210/  748]\n",
      "loss: 0.009559  [  350/  748]\n",
      "loss: 0.096177  [  490/  748]\n",
      "loss: 0.048788  [  630/  748]\n",
      "loss: 0.103525  [  528/  748]\n",
      "Training Loss (Epoch): 0.074760\n",
      "Validating...\n",
      "Validation Loss: 0.520906, Validation Accuracy: 87.77%\n",
      "Learning Rate: [7.8125e-07]\n",
      "Epoch 17/25\n",
      "loss: 0.073509  [   70/  748]\n",
      "loss: 0.025320  [  210/  748]\n",
      "loss: 0.008871  [  350/  748]\n",
      "loss: 0.123817  [  490/  748]\n",
      "loss: 0.098392  [  630/  748]\n",
      "loss: 0.014903  [  528/  748]\n",
      "Training Loss (Epoch): 0.071365\n",
      "Validating...\n",
      "Validation Loss: 0.518583, Validation Accuracy: 87.77%\n",
      "Learning Rate: [3.90625e-07]\n",
      "Epoch 18/25\n",
      "loss: 0.044831  [   70/  748]\n",
      "loss: 0.123005  [  210/  748]\n",
      "loss: 0.007730  [  350/  748]\n",
      "loss: 0.098429  [  490/  748]\n",
      "loss: 0.078755  [  630/  748]\n",
      "loss: 0.039246  [  528/  748]\n",
      "Training Loss (Epoch): 0.068937\n",
      "Validating...\n",
      "Validation Loss: 0.517938, Validation Accuracy: 87.77%\n",
      "Learning Rate: [1.953125e-07]\n",
      "Epoch 19/25\n",
      "loss: 0.061355  [   70/  748]\n",
      "loss: 0.056494  [  210/  748]\n",
      "loss: 0.096044  [  350/  748]\n",
      "loss: 0.142783  [  490/  748]\n",
      "loss: 0.030979  [  630/  748]\n",
      "loss: 0.098395  [  528/  748]\n",
      "Training Loss (Epoch): 0.070320\n",
      "Validating...\n",
      "Validation Loss: 0.517714, Validation Accuracy: 87.77%\n",
      "Learning Rate: [9.765625e-08]\n",
      "Epoch 20/25\n",
      "loss: 0.054658  [   70/  748]\n",
      "loss: 0.085445  [  210/  748]\n",
      "loss: 0.056893  [  350/  748]\n",
      "loss: 0.076651  [  490/  748]\n",
      "loss: 0.102510  [  630/  748]\n",
      "loss: 0.083957  [  528/  748]\n",
      "Training Loss (Epoch): 0.069745\n",
      "Validating...\n",
      "Validation Loss: 0.517538, Validation Accuracy: 87.77%\n",
      "Learning Rate: [4.8828125e-08]\n",
      "Epoch 21/25\n",
      "loss: 0.064257  [   70/  748]\n",
      "loss: 0.097716  [  210/  748]\n",
      "loss: 0.058180  [  350/  748]\n",
      "loss: 0.088150  [  490/  748]\n",
      "loss: 0.029991  [  630/  748]\n",
      "loss: 0.186036  [  528/  748]\n",
      "Training Loss (Epoch): 0.072777\n",
      "Validating...\n",
      "Validation Loss: 0.517563, Validation Accuracy: 87.77%\n",
      "Learning Rate: [2.44140625e-08]\n",
      "Epoch 22/25\n",
      "loss: 0.072479  [   70/  748]\n",
      "loss: 0.023391  [  210/  748]\n",
      "loss: 0.128523  [  350/  748]\n",
      "loss: 0.053508  [  490/  748]\n",
      "loss: 0.054206  [  630/  748]\n",
      "loss: 0.068026  [  528/  748]\n",
      "Training Loss (Epoch): 0.070902\n",
      "Validating...\n",
      "Validation Loss: 0.517551, Validation Accuracy: 87.77%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 23/25\n",
      "loss: 0.096214  [   70/  748]\n",
      "loss: 0.062199  [  210/  748]\n",
      "loss: 0.064333  [  350/  748]\n",
      "loss: 0.031419  [  490/  748]\n",
      "loss: 0.055330  [  630/  748]\n",
      "loss: 0.103103  [  528/  748]\n",
      "Training Loss (Epoch): 0.070165\n",
      "Validating...\n",
      "Validation Loss: 0.517565, Validation Accuracy: 87.77%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 24/25\n",
      "loss: 0.078625  [   70/  748]\n",
      "loss: 0.072477  [  210/  748]\n",
      "loss: 0.111623  [  350/  748]\n",
      "loss: 0.052685  [  490/  748]\n",
      "loss: 0.110315  [  630/  748]\n",
      "loss: 0.042112  [  528/  748]\n",
      "Training Loss (Epoch): 0.068407\n",
      "Validating...\n",
      "Validation Loss: 0.517545, Validation Accuracy: 87.77%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 25/25\n",
      "loss: 0.184702  [   70/  748]\n",
      "loss: 0.073771  [  210/  748]\n",
      "loss: 0.077511  [  350/  748]\n",
      "loss: 0.067258  [  490/  748]\n",
      "loss: 0.033605  [  630/  748]\n",
      "loss: 0.067431  [  528/  748]\n",
      "Training Loss (Epoch): 0.076866\n",
      "Validating...\n",
      "Validation Loss: 0.517538, Validation Accuracy: 87.77%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Processing Fold 6\n",
      "Epoch 1/25\n",
      "loss: 2.370173  [   70/  658]\n",
      "loss: 2.135021  [  210/  658]\n",
      "loss: 1.845811  [  350/  658]\n",
      "loss: 1.842329  [  490/  658]\n",
      "loss: 1.671840  [  630/  658]\n",
      "Training Loss (Epoch): 1.931033\n",
      "Validating...\n",
      "Validation Loss: 1.811007, Validation Accuracy: 36.36%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/25\n",
      "loss: 1.766980  [   70/  658]\n",
      "loss: 1.262138  [  210/  658]\n",
      "loss: 1.238258  [  350/  658]\n",
      "loss: 1.297022  [  490/  658]\n",
      "loss: 0.984892  [  630/  658]\n",
      "Training Loss (Epoch): 1.318654\n",
      "Validating...\n",
      "Validation Loss: 1.043331, Validation Accuracy: 67.88%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/25\n",
      "loss: 0.927027  [   70/  658]\n",
      "loss: 0.730420  [  210/  658]\n",
      "loss: 0.751652  [  350/  658]\n",
      "loss: 0.725613  [  490/  658]\n",
      "loss: 0.743589  [  630/  658]\n",
      "Training Loss (Epoch): 0.816048\n",
      "Validating...\n",
      "Validation Loss: 1.054889, Validation Accuracy: 67.88%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 4/25\n",
      "loss: 0.910002  [   70/  658]\n",
      "loss: 0.564245  [  210/  658]\n",
      "loss: 0.403043  [  350/  658]\n",
      "loss: 0.435658  [  490/  658]\n",
      "loss: 0.606045  [  630/  658]\n",
      "Training Loss (Epoch): 0.608041\n",
      "Validating...\n",
      "Validation Loss: 0.754190, Validation Accuracy: 77.58%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 5/25\n",
      "loss: 0.554649  [   70/  658]\n",
      "loss: 0.399658  [  210/  658]\n",
      "loss: 0.483962  [  350/  658]\n",
      "loss: 0.620324  [  490/  658]\n",
      "loss: 0.309059  [  630/  658]\n",
      "Training Loss (Epoch): 0.451523\n",
      "Validating...\n",
      "Validation Loss: 0.553751, Validation Accuracy: 83.03%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 6/25\n",
      "loss: 0.359255  [   70/  658]\n",
      "loss: 0.321824  [  210/  658]\n",
      "loss: 0.336361  [  350/  658]\n",
      "loss: 0.414518  [  490/  658]\n",
      "loss: 0.293367  [  630/  658]\n",
      "Training Loss (Epoch): 0.304827\n",
      "Validating...\n",
      "Validation Loss: 0.591513, Validation Accuracy: 84.24%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 7/25\n",
      "loss: 0.235958  [   70/  658]\n",
      "loss: 0.225279  [  210/  658]\n",
      "loss: 0.178762  [  350/  658]\n",
      "loss: 0.296983  [  490/  658]\n",
      "loss: 0.427708  [  630/  658]\n",
      "Training Loss (Epoch): 0.336689\n",
      "Validating...\n",
      "Validation Loss: 0.553243, Validation Accuracy: 83.64%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 8/25\n",
      "loss: 0.215112  [   70/  658]\n",
      "loss: 0.250502  [  210/  658]\n",
      "loss: 0.309296  [  350/  658]\n",
      "loss: 0.237969  [  490/  658]\n",
      "loss: 0.167098  [  630/  658]\n",
      "Training Loss (Epoch): 0.227295\n",
      "Validating...\n",
      "Validation Loss: 0.488524, Validation Accuracy: 85.45%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 9/25\n",
      "loss: 0.199066  [   70/  658]\n",
      "loss: 0.187579  [  210/  658]\n",
      "loss: 0.209235  [  350/  658]\n",
      "loss: 0.068874  [  490/  658]\n",
      "loss: 0.121931  [  630/  658]\n",
      "Training Loss (Epoch): 0.165204\n",
      "Validating...\n",
      "Validation Loss: 0.467567, Validation Accuracy: 87.88%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 10/25\n",
      "loss: 0.099211  [   70/  658]\n",
      "loss: 0.175096  [  210/  658]\n",
      "loss: 0.130645  [  350/  658]\n",
      "loss: 0.194953  [  490/  658]\n",
      "loss: 0.077958  [  630/  658]\n",
      "Training Loss (Epoch): 0.134749\n",
      "Validating...\n",
      "Validation Loss: 0.425377, Validation Accuracy: 88.48%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 11/25\n",
      "loss: 0.134870  [   70/  658]\n",
      "loss: 0.085706  [  210/  658]\n",
      "loss: 0.091423  [  350/  658]\n",
      "loss: 0.137277  [  490/  658]\n",
      "loss: 0.158025  [  630/  658]\n",
      "Training Loss (Epoch): 0.095393\n",
      "Validating...\n",
      "Validation Loss: 0.431110, Validation Accuracy: 89.70%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 12/25\n",
      "loss: 0.049410  [   70/  658]\n",
      "loss: 0.055375  [  210/  658]\n",
      "loss: 0.086653  [  350/  658]\n",
      "loss: 0.127949  [  490/  658]\n",
      "loss: 0.167969  [  630/  658]\n",
      "Training Loss (Epoch): 0.098499\n",
      "Validating...\n",
      "Validation Loss: 0.454664, Validation Accuracy: 90.30%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 13/25\n",
      "loss: 0.130576  [   70/  658]\n",
      "loss: 0.088903  [  210/  658]\n",
      "loss: 0.079032  [  350/  658]\n",
      "loss: 0.078058  [  490/  658]\n",
      "loss: 0.068042  [  630/  658]\n",
      "Training Loss (Epoch): 0.074533\n",
      "Validating...\n",
      "Validation Loss: 0.456545, Validation Accuracy: 89.09%\n",
      "Learning Rate: [6.25e-06]\n",
      "Epoch 14/25\n",
      "loss: 0.111033  [   70/  658]\n",
      "loss: 0.090218  [  210/  658]\n",
      "loss: 0.055307  [  350/  658]\n",
      "loss: 0.063878  [  490/  658]\n",
      "loss: 0.036879  [  630/  658]\n",
      "Training Loss (Epoch): 0.074065\n",
      "Validating...\n",
      "Validation Loss: 0.434793, Validation Accuracy: 90.30%\n",
      "Learning Rate: [3.125e-06]\n",
      "Epoch 15/25\n",
      "loss: 0.134504  [   70/  658]\n",
      "loss: 0.054176  [  210/  658]\n",
      "loss: 0.065885  [  350/  658]\n",
      "loss: 0.063850  [  490/  658]\n",
      "loss: 0.064210  [  630/  658]\n",
      "Training Loss (Epoch): 0.066592\n",
      "Validating...\n",
      "Validation Loss: 0.435497, Validation Accuracy: 91.52%\n",
      "Learning Rate: [3.125e-06]\n",
      "Epoch 16/25\n",
      "loss: 0.052199  [   70/  658]\n",
      "loss: 0.102038  [  210/  658]\n",
      "loss: 0.049300  [  350/  658]\n",
      "loss: 0.057737  [  490/  658]\n",
      "loss: 0.042398  [  630/  658]\n",
      "Training Loss (Epoch): 0.064623\n",
      "Validating...\n",
      "Validation Loss: 0.435648, Validation Accuracy: 90.91%\n",
      "Learning Rate: [1.5625e-06]\n",
      "Epoch 17/25\n",
      "loss: 0.037868  [   70/  658]\n",
      "loss: 0.018265  [  210/  658]\n",
      "loss: 0.010213  [  350/  658]\n",
      "loss: 0.091556  [  490/  658]\n",
      "loss: 0.069065  [  630/  658]\n",
      "Training Loss (Epoch): 0.061663\n",
      "Validating...\n",
      "Validation Loss: 0.435632, Validation Accuracy: 90.91%\n",
      "Learning Rate: [7.8125e-07]\n",
      "Epoch 18/25\n",
      "loss: 0.030745  [   70/  658]\n",
      "loss: 0.055610  [  210/  658]\n",
      "loss: 0.077222  [  350/  658]\n",
      "loss: 0.082710  [  490/  658]\n",
      "loss: 0.036814  [  630/  658]\n",
      "Training Loss (Epoch): 0.067013\n",
      "Validating...\n",
      "Validation Loss: 0.436342, Validation Accuracy: 90.91%\n",
      "Learning Rate: [3.90625e-07]\n",
      "Epoch 19/25\n",
      "loss: 0.020003  [   70/  658]\n",
      "loss: 0.065939  [  210/  658]\n",
      "loss: 0.020592  [  350/  658]\n",
      "loss: 0.024813  [  490/  658]\n",
      "loss: 0.092005  [  630/  658]\n",
      "Training Loss (Epoch): 0.064504\n",
      "Validating...\n",
      "Validation Loss: 0.436621, Validation Accuracy: 90.91%\n",
      "Learning Rate: [1.953125e-07]\n",
      "Epoch 20/25\n",
      "loss: 0.083211  [   70/  658]\n",
      "loss: 0.071483  [  210/  658]\n",
      "loss: 0.083688  [  350/  658]\n",
      "loss: 0.031937  [  490/  658]\n",
      "loss: 0.052089  [  630/  658]\n",
      "Training Loss (Epoch): 0.059159\n",
      "Validating...\n",
      "Validation Loss: 0.436714, Validation Accuracy: 90.91%\n",
      "Learning Rate: [9.765625e-08]\n",
      "Epoch 21/25\n",
      "loss: 0.095050  [   70/  658]\n",
      "loss: 0.119402  [  210/  658]\n",
      "loss: 0.051434  [  350/  658]\n",
      "loss: 0.042570  [  490/  658]\n",
      "loss: 0.015847  [  630/  658]\n",
      "Training Loss (Epoch): 0.056724\n",
      "Validating...\n",
      "Validation Loss: 0.436924, Validation Accuracy: 90.91%\n",
      "Learning Rate: [4.8828125e-08]\n",
      "Epoch 22/25\n",
      "loss: 0.089475  [   70/  658]\n",
      "loss: 0.015036  [  210/  658]\n",
      "loss: 0.048649  [  350/  658]\n",
      "loss: 0.054158  [  490/  658]\n",
      "loss: 0.098629  [  630/  658]\n",
      "Training Loss (Epoch): 0.065426\n",
      "Validating...\n",
      "Validation Loss: 0.436936, Validation Accuracy: 90.91%\n",
      "Learning Rate: [2.44140625e-08]\n",
      "Epoch 23/25\n",
      "loss: 0.066170  [   70/  658]\n",
      "loss: 0.115567  [  210/  658]\n",
      "loss: 0.025325  [  350/  658]\n",
      "loss: 0.005413  [  490/  658]\n",
      "loss: 0.033702  [  630/  658]\n",
      "Training Loss (Epoch): 0.058409\n",
      "Validating...\n",
      "Validation Loss: 0.436959, Validation Accuracy: 90.91%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 24/25\n",
      "loss: 0.053892  [   70/  658]\n",
      "loss: 0.117056  [  210/  658]\n",
      "loss: 0.063359  [  350/  658]\n",
      "loss: 0.029917  [  490/  658]\n",
      "loss: 0.077485  [  630/  658]\n",
      "Training Loss (Epoch): 0.057823\n",
      "Validating...\n",
      "Validation Loss: 0.436971, Validation Accuracy: 90.91%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 25/25\n",
      "loss: 0.077856  [   70/  658]\n",
      "loss: 0.054425  [  210/  658]\n",
      "loss: 0.061108  [  350/  658]\n",
      "loss: 0.065092  [  490/  658]\n",
      "loss: 0.061070  [  630/  658]\n",
      "Training Loss (Epoch): 0.065235\n",
      "Validating...\n",
      "Validation Loss: 0.436943, Validation Accuracy: 90.91%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Processing Fold 7\n",
      "Epoch 1/25\n",
      "loss: 2.364202  [   70/  670]\n",
      "loss: 2.148409  [  210/  670]\n",
      "loss: 1.994182  [  350/  670]\n",
      "loss: 1.853081  [  490/  670]\n",
      "loss: 1.736678  [  630/  670]\n",
      "Training Loss (Epoch): 1.998184\n",
      "Validating...\n",
      "Validation Loss: 1.853318, Validation Accuracy: 45.24%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/25\n",
      "loss: 1.816828  [   70/  670]\n",
      "loss: 1.310760  [  210/  670]\n",
      "loss: 1.598824  [  350/  670]\n",
      "loss: 1.196942  [  490/  670]\n",
      "loss: 1.221637  [  630/  670]\n",
      "Training Loss (Epoch): 1.372446\n",
      "Validating...\n",
      "Validation Loss: 1.217760, Validation Accuracy: 55.95%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/25\n",
      "loss: 0.864249  [   70/  670]\n",
      "loss: 1.138472  [  210/  670]\n",
      "loss: 0.772154  [  350/  670]\n",
      "loss: 0.944993  [  490/  670]\n",
      "loss: 0.695161  [  630/  670]\n",
      "Training Loss (Epoch): 0.934201\n",
      "Validating...\n",
      "Validation Loss: 0.882939, Validation Accuracy: 72.62%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/25\n",
      "loss: 1.024773  [   70/  670]\n",
      "loss: 0.632717  [  210/  670]\n",
      "loss: 0.688937  [  350/  670]\n",
      "loss: 0.505711  [  490/  670]\n",
      "loss: 0.573691  [  630/  670]\n",
      "Training Loss (Epoch): 0.664184\n",
      "Validating...\n",
      "Validation Loss: 0.914693, Validation Accuracy: 71.43%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 5/25\n",
      "loss: 0.432327  [   70/  670]\n",
      "loss: 0.458277  [  210/  670]\n",
      "loss: 0.354820  [  350/  670]\n",
      "loss: 0.404429  [  490/  670]\n",
      "loss: 0.460522  [  630/  670]\n",
      "Training Loss (Epoch): 0.495767\n",
      "Validating...\n",
      "Validation Loss: 0.619186, Validation Accuracy: 80.36%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 6/25\n",
      "loss: 0.388886  [   70/  670]\n",
      "loss: 0.734457  [  210/  670]\n",
      "loss: 0.313421  [  350/  670]\n",
      "loss: 0.220597  [  490/  670]\n",
      "loss: 0.411515  [  630/  670]\n",
      "Training Loss (Epoch): 0.406128\n",
      "Validating...\n",
      "Validation Loss: 0.780298, Validation Accuracy: 76.79%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 7/25\n",
      "loss: 0.448905  [   70/  670]\n",
      "loss: 0.149399  [  210/  670]\n",
      "loss: 0.235141  [  350/  670]\n",
      "loss: 0.317049  [  490/  670]\n",
      "loss: 0.305075  [  630/  670]\n",
      "Training Loss (Epoch): 0.256213\n",
      "Validating...\n",
      "Validation Loss: 0.699263, Validation Accuracy: 80.36%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 8/25\n",
      "loss: 0.300669  [   70/  670]\n",
      "loss: 0.253236  [  210/  670]\n",
      "loss: 0.260311  [  350/  670]\n",
      "loss: 0.133895  [  490/  670]\n",
      "loss: 0.134877  [  630/  670]\n",
      "Training Loss (Epoch): 0.198640\n",
      "Validating...\n",
      "Validation Loss: 0.688544, Validation Accuracy: 79.17%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 9/25\n",
      "loss: 0.196593  [   70/  670]\n",
      "loss: 0.166619  [  210/  670]\n",
      "loss: 0.066153  [  350/  670]\n",
      "loss: 0.164400  [  490/  670]\n",
      "loss: 0.197761  [  630/  670]\n",
      "Training Loss (Epoch): 0.187674\n",
      "Validating...\n",
      "Validation Loss: 0.669036, Validation Accuracy: 80.36%\n",
      "Learning Rate: [6.25e-06]\n",
      "Epoch 10/25\n",
      "loss: 0.087656  [   70/  670]\n",
      "loss: 0.159019  [  210/  670]\n",
      "loss: 0.158453  [  350/  670]\n",
      "loss: 0.134868  [  490/  670]\n",
      "loss: 0.227189  [  630/  670]\n",
      "Training Loss (Epoch): 0.162566\n",
      "Validating...\n",
      "Validation Loss: 0.659134, Validation Accuracy: 80.95%\n",
      "Learning Rate: [3.125e-06]\n",
      "Epoch 11/25\n",
      "loss: 0.169376  [   70/  670]\n",
      "loss: 0.302968  [  210/  670]\n",
      "loss: 0.163651  [  350/  670]\n",
      "loss: 0.093387  [  490/  670]\n",
      "loss: 0.132590  [  630/  670]\n",
      "Training Loss (Epoch): 0.169238\n",
      "Validating...\n",
      "Validation Loss: 0.655722, Validation Accuracy: 80.95%\n",
      "Learning Rate: [1.5625e-06]\n",
      "Epoch 12/25\n",
      "loss: 0.193614  [   70/  670]\n",
      "loss: 0.159123  [  210/  670]\n",
      "loss: 0.185805  [  350/  670]\n",
      "loss: 0.060588  [  490/  670]\n",
      "loss: 0.151896  [  630/  670]\n",
      "Training Loss (Epoch): 0.145903\n",
      "Validating...\n",
      "Validation Loss: 0.662631, Validation Accuracy: 81.55%\n",
      "Learning Rate: [1.5625e-06]\n",
      "Epoch 13/25\n",
      "loss: 0.144171  [   70/  670]\n",
      "loss: 0.136575  [  210/  670]\n",
      "loss: 0.252655  [  350/  670]\n",
      "loss: 0.187288  [  490/  670]\n",
      "loss: 0.110714  [  630/  670]\n",
      "Training Loss (Epoch): 0.139545\n",
      "Validating...\n",
      "Validation Loss: 0.662489, Validation Accuracy: 81.55%\n",
      "Learning Rate: [7.8125e-07]\n",
      "Epoch 14/25\n",
      "loss: 0.108559  [   70/  670]\n",
      "loss: 0.292331  [  210/  670]\n",
      "loss: 0.233058  [  350/  670]\n",
      "loss: 0.116532  [  490/  670]\n",
      "loss: 0.064632  [  630/  670]\n",
      "Training Loss (Epoch): 0.142027\n",
      "Validating...\n",
      "Validation Loss: 0.657805, Validation Accuracy: 82.14%\n",
      "Learning Rate: [3.90625e-07]\n",
      "Epoch 15/25\n",
      "loss: 0.141985  [   70/  670]\n",
      "loss: 0.170677  [  210/  670]\n",
      "loss: 0.026590  [  350/  670]\n",
      "loss: 0.160729  [  490/  670]\n",
      "loss: 0.124395  [  630/  670]\n",
      "Training Loss (Epoch): 0.134431\n",
      "Validating...\n",
      "Validation Loss: 0.657089, Validation Accuracy: 82.74%\n",
      "Learning Rate: [3.90625e-07]\n",
      "Epoch 16/25\n",
      "loss: 0.143324  [   70/  670]\n",
      "loss: 0.173377  [  210/  670]\n",
      "loss: 0.213940  [  350/  670]\n",
      "loss: 0.116318  [  490/  670]\n",
      "loss: 0.114341  [  630/  670]\n",
      "Training Loss (Epoch): 0.155347\n",
      "Validating...\n",
      "Validation Loss: 0.652787, Validation Accuracy: 83.33%\n",
      "Learning Rate: [1.953125e-07]\n",
      "Epoch 17/25\n",
      "loss: 0.043083  [   70/  670]\n",
      "loss: 0.055265  [  210/  670]\n",
      "loss: 0.196347  [  350/  670]\n",
      "loss: 0.234893  [  490/  670]\n",
      "loss: 0.127831  [  630/  670]\n",
      "Training Loss (Epoch): 0.161431\n",
      "Validating...\n",
      "Validation Loss: 0.650782, Validation Accuracy: 83.33%\n",
      "Learning Rate: [9.765625e-08]\n",
      "Epoch 18/25\n",
      "loss: 0.156313  [   70/  670]\n",
      "loss: 0.066721  [  210/  670]\n",
      "loss: 0.094578  [  350/  670]\n",
      "loss: 0.129546  [  490/  670]\n",
      "loss: 0.190474  [  630/  670]\n",
      "Training Loss (Epoch): 0.151328\n",
      "Validating...\n",
      "Validation Loss: 0.649968, Validation Accuracy: 83.33%\n",
      "Learning Rate: [4.8828125e-08]\n",
      "Epoch 19/25\n",
      "loss: 0.237444  [   70/  670]\n",
      "loss: 0.075777  [  210/  670]\n",
      "loss: 0.089625  [  350/  670]\n",
      "loss: 0.103763  [  490/  670]\n",
      "loss: 0.177321  [  630/  670]\n",
      "Training Loss (Epoch): 0.139431\n",
      "Validating...\n",
      "Validation Loss: 0.649864, Validation Accuracy: 83.33%\n",
      "Learning Rate: [2.44140625e-08]\n",
      "Epoch 20/25\n",
      "loss: 0.107069  [   70/  670]\n",
      "loss: 0.111212  [  210/  670]\n",
      "loss: 0.189920  [  350/  670]\n",
      "loss: 0.234806  [  490/  670]\n",
      "loss: 0.143306  [  630/  670]\n",
      "Training Loss (Epoch): 0.158966\n",
      "Validating...\n",
      "Validation Loss: 0.649617, Validation Accuracy: 83.33%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 21/25\n",
      "loss: 0.071747  [   70/  670]\n",
      "loss: 0.163500  [  210/  670]\n",
      "loss: 0.156483  [  350/  670]\n",
      "loss: 0.106230  [  490/  670]\n",
      "loss: 0.093277  [  630/  670]\n",
      "Training Loss (Epoch): 0.167537\n",
      "Validating...\n",
      "Validation Loss: 0.649593, Validation Accuracy: 83.33%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 22/25\n",
      "loss: 0.181061  [   70/  670]\n",
      "loss: 0.141940  [  210/  670]\n",
      "loss: 0.096491  [  350/  670]\n",
      "loss: 0.161586  [  490/  670]\n",
      "loss: 0.181717  [  630/  670]\n",
      "Training Loss (Epoch): 0.134814\n",
      "Validating...\n",
      "Validation Loss: 0.649409, Validation Accuracy: 83.33%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 23/25\n",
      "loss: 0.202958  [   70/  670]\n",
      "loss: 0.131226  [  210/  670]\n",
      "loss: 0.114966  [  350/  670]\n",
      "loss: 0.118746  [  490/  670]\n",
      "loss: 0.166005  [  630/  670]\n",
      "Training Loss (Epoch): 0.154281\n",
      "Validating...\n",
      "Validation Loss: 0.649392, Validation Accuracy: 83.33%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 24/25\n",
      "loss: 0.188829  [   70/  670]\n",
      "loss: 0.095961  [  210/  670]\n",
      "loss: 0.111906  [  350/  670]\n",
      "loss: 0.357664  [  490/  670]\n",
      "loss: 0.171326  [  630/  670]\n",
      "Training Loss (Epoch): 0.158215\n",
      "Validating...\n",
      "Validation Loss: 0.649423, Validation Accuracy: 83.33%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 25/25\n",
      "loss: 0.149798  [   70/  670]\n",
      "loss: 0.060059  [  210/  670]\n",
      "loss: 0.222998  [  350/  670]\n",
      "loss: 0.072828  [  490/  670]\n",
      "loss: 0.043172  [  630/  670]\n",
      "Training Loss (Epoch): 0.136859\n",
      "Validating...\n",
      "Validation Loss: 0.649424, Validation Accuracy: 83.33%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Processing Fold 8\n",
      "Epoch 1/25\n",
      "loss: 2.374075  [   70/  644]\n",
      "loss: 2.201657  [  210/  644]\n",
      "loss: 1.955880  [  350/  644]\n",
      "loss: 1.829072  [  490/  644]\n",
      "loss: 1.628454  [  630/  644]\n",
      "Training Loss (Epoch): 1.974534\n",
      "Validating...\n",
      "Validation Loss: 1.938189, Validation Accuracy: 48.15%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/25\n",
      "loss: 1.909748  [   70/  644]\n",
      "loss: 1.266136  [  210/  644]\n",
      "loss: 1.335637  [  350/  644]\n",
      "loss: 1.761927  [  490/  644]\n",
      "loss: 1.626917  [  630/  644]\n",
      "Training Loss (Epoch): 1.576941\n",
      "Validating...\n",
      "Validation Loss: 1.330123, Validation Accuracy: 55.56%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/25\n",
      "loss: 1.127618  [   70/  644]\n",
      "loss: 1.020579  [  210/  644]\n",
      "loss: 1.132244  [  350/  644]\n",
      "loss: 1.073108  [  490/  644]\n",
      "loss: 0.984678  [  630/  644]\n",
      "Training Loss (Epoch): 1.250343\n",
      "Validating...\n",
      "Validation Loss: 1.361529, Validation Accuracy: 58.64%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/25\n",
      "loss: 1.094557  [   70/  644]\n",
      "loss: 1.122347  [  210/  644]\n",
      "loss: 1.096747  [  350/  644]\n",
      "loss: 0.956841  [  490/  644]\n",
      "loss: 0.692871  [  630/  644]\n",
      "Training Loss (Epoch): 0.880219\n",
      "Validating...\n",
      "Validation Loss: 0.774099, Validation Accuracy: 69.14%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/25\n",
      "loss: 0.535616  [   70/  644]\n",
      "loss: 0.575929  [  210/  644]\n",
      "loss: 0.681795  [  350/  644]\n",
      "loss: 0.516561  [  490/  644]\n",
      "loss: 0.604588  [  630/  644]\n",
      "Training Loss (Epoch): 0.588159\n",
      "Validating...\n",
      "Validation Loss: 0.702195, Validation Accuracy: 75.31%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/25\n",
      "loss: 0.431664  [   70/  644]\n",
      "loss: 0.369558  [  210/  644]\n",
      "loss: 0.675873  [  350/  644]\n",
      "loss: 0.314787  [  490/  644]\n",
      "loss: 0.291126  [  630/  644]\n",
      "Training Loss (Epoch): 0.397390\n",
      "Validating...\n",
      "Validation Loss: 0.692323, Validation Accuracy: 80.86%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 7/25\n",
      "loss: 0.523065  [   70/  644]\n",
      "loss: 0.296661  [  210/  644]\n",
      "loss: 0.413508  [  350/  644]\n",
      "loss: 0.303974  [  490/  644]\n",
      "loss: 0.454885  [  630/  644]\n",
      "Training Loss (Epoch): 0.391013\n",
      "Validating...\n",
      "Validation Loss: 0.872270, Validation Accuracy: 73.46%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 8/25\n",
      "loss: 0.612729  [   70/  644]\n",
      "loss: 0.156835  [  210/  644]\n",
      "loss: 0.186862  [  350/  644]\n",
      "loss: 0.202112  [  490/  644]\n",
      "loss: 0.308702  [  630/  644]\n",
      "Training Loss (Epoch): 0.328081\n",
      "Validating...\n",
      "Validation Loss: 0.572278, Validation Accuracy: 79.01%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 9/25\n",
      "loss: 0.418288  [   70/  644]\n",
      "loss: 0.416376  [  210/  644]\n",
      "loss: 0.259000  [  350/  644]\n",
      "loss: 0.163490  [  490/  644]\n",
      "loss: 0.084070  [  630/  644]\n",
      "Training Loss (Epoch): 0.272947\n",
      "Validating...\n",
      "Validation Loss: 0.405397, Validation Accuracy: 84.57%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 10/25\n",
      "loss: 0.203020  [   70/  644]\n",
      "loss: 0.190716  [  210/  644]\n",
      "loss: 0.116468  [  350/  644]\n",
      "loss: 0.128651  [  490/  644]\n",
      "loss: 0.079952  [  630/  644]\n",
      "Training Loss (Epoch): 0.173070\n",
      "Validating...\n",
      "Validation Loss: 0.346921, Validation Accuracy: 88.89%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 11/25\n",
      "loss: 0.107784  [   70/  644]\n",
      "loss: 0.202047  [  210/  644]\n",
      "loss: 0.094942  [  350/  644]\n",
      "loss: 0.175972  [  490/  644]\n",
      "loss: 0.077957  [  630/  644]\n",
      "Training Loss (Epoch): 0.123488\n",
      "Validating...\n",
      "Validation Loss: 0.396654, Validation Accuracy: 85.80%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 12/25\n",
      "loss: 0.056117  [   70/  644]\n",
      "loss: 0.141309  [  210/  644]\n",
      "loss: 0.094988  [  350/  644]\n",
      "loss: 0.061417  [  490/  644]\n",
      "loss: 0.092402  [  630/  644]\n",
      "Training Loss (Epoch): 0.101667\n",
      "Validating...\n",
      "Validation Loss: 0.381092, Validation Accuracy: 85.19%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 13/25\n",
      "loss: 0.086487  [   70/  644]\n",
      "loss: 0.046650  [  210/  644]\n",
      "loss: 0.090118  [  350/  644]\n",
      "loss: 0.076087  [  490/  644]\n",
      "loss: 0.069942  [  630/  644]\n",
      "Training Loss (Epoch): 0.092650\n",
      "Validating...\n",
      "Validation Loss: 0.331825, Validation Accuracy: 88.27%\n",
      "Learning Rate: [6.25e-06]\n",
      "Epoch 14/25\n",
      "loss: 0.039038  [   70/  644]\n",
      "loss: 0.050534  [  210/  644]\n",
      "loss: 0.062139  [  350/  644]\n",
      "loss: 0.145333  [  490/  644]\n",
      "loss: 0.022734  [  630/  644]\n",
      "Training Loss (Epoch): 0.066028\n",
      "Validating...\n",
      "Validation Loss: 0.325515, Validation Accuracy: 88.27%\n",
      "Learning Rate: [3.125e-06]\n",
      "Epoch 15/25\n",
      "loss: 0.076675  [   70/  644]\n",
      "loss: 0.070918  [  210/  644]\n",
      "loss: 0.026021  [  350/  644]\n",
      "loss: 0.060182  [  490/  644]\n",
      "loss: 0.110543  [  630/  644]\n",
      "Training Loss (Epoch): 0.060732\n",
      "Validating...\n",
      "Validation Loss: 0.322366, Validation Accuracy: 88.27%\n",
      "Learning Rate: [1.5625e-06]\n",
      "Epoch 16/25\n",
      "loss: 0.038105  [   70/  644]\n",
      "loss: 0.029493  [  210/  644]\n",
      "loss: 0.025172  [  350/  644]\n",
      "loss: 0.096374  [  490/  644]\n",
      "loss: 0.081985  [  630/  644]\n",
      "Training Loss (Epoch): 0.055018\n",
      "Validating...\n",
      "Validation Loss: 0.318646, Validation Accuracy: 87.65%\n",
      "Learning Rate: [7.8125e-07]\n",
      "Epoch 17/25\n",
      "loss: 0.079588  [   70/  644]\n",
      "loss: 0.039980  [  210/  644]\n",
      "loss: 0.091820  [  350/  644]\n",
      "loss: 0.120808  [  490/  644]\n",
      "loss: 0.075604  [  630/  644]\n",
      "Training Loss (Epoch): 0.052037\n",
      "Validating...\n",
      "Validation Loss: 0.318058, Validation Accuracy: 88.27%\n",
      "Learning Rate: [3.90625e-07]\n",
      "Epoch 18/25\n",
      "loss: 0.090076  [   70/  644]\n",
      "loss: 0.017492  [  210/  644]\n",
      "loss: 0.167956  [  350/  644]\n",
      "loss: 0.035262  [  490/  644]\n",
      "loss: 0.020163  [  630/  644]\n",
      "Training Loss (Epoch): 0.050000\n",
      "Validating...\n",
      "Validation Loss: 0.317848, Validation Accuracy: 88.27%\n",
      "Learning Rate: [1.953125e-07]\n",
      "Epoch 19/25\n",
      "loss: 0.054790  [   70/  644]\n",
      "loss: 0.030557  [  210/  644]\n",
      "loss: 0.025682  [  350/  644]\n",
      "loss: 0.143736  [  490/  644]\n",
      "loss: 0.032277  [  630/  644]\n",
      "Training Loss (Epoch): 0.068005\n",
      "Validating...\n",
      "Validation Loss: 0.317804, Validation Accuracy: 88.27%\n",
      "Learning Rate: [9.765625e-08]\n",
      "Epoch 20/25\n",
      "loss: 0.047228  [   70/  644]\n",
      "loss: 0.044537  [  210/  644]\n",
      "loss: 0.047105  [  350/  644]\n",
      "loss: 0.012917  [  490/  644]\n",
      "loss: 0.068518  [  630/  644]\n",
      "Training Loss (Epoch): 0.060208\n",
      "Validating...\n",
      "Validation Loss: 0.317879, Validation Accuracy: 88.27%\n",
      "Learning Rate: [4.8828125e-08]\n",
      "Epoch 21/25\n",
      "loss: 0.029370  [   70/  644]\n",
      "loss: 0.021415  [  210/  644]\n",
      "loss: 0.045035  [  350/  644]\n",
      "loss: 0.044600  [  490/  644]\n",
      "loss: 0.078877  [  630/  644]\n",
      "Training Loss (Epoch): 0.081145\n",
      "Validating...\n",
      "Validation Loss: 0.317860, Validation Accuracy: 88.27%\n",
      "Learning Rate: [2.44140625e-08]\n",
      "Epoch 22/25\n",
      "loss: 0.099211  [   70/  644]\n",
      "loss: 0.056253  [  210/  644]\n",
      "loss: 0.082731  [  350/  644]\n",
      "loss: 0.018479  [  490/  644]\n",
      "loss: 0.059946  [  630/  644]\n",
      "Training Loss (Epoch): 0.057046\n",
      "Validating...\n",
      "Validation Loss: 0.317895, Validation Accuracy: 88.27%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 23/25\n",
      "loss: 0.135386  [   70/  644]\n",
      "loss: 0.065118  [  210/  644]\n",
      "loss: 0.044988  [  350/  644]\n",
      "loss: 0.032697  [  490/  644]\n",
      "loss: 0.030499  [  630/  644]\n",
      "Training Loss (Epoch): 0.053580\n",
      "Validating...\n",
      "Validation Loss: 0.317916, Validation Accuracy: 88.27%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 24/25\n",
      "loss: 0.032070  [   70/  644]\n",
      "loss: 0.016823  [  210/  644]\n",
      "loss: 0.099511  [  350/  644]\n",
      "loss: 0.027368  [  490/  644]\n",
      "loss: 0.066842  [  630/  644]\n",
      "Training Loss (Epoch): 0.059050\n",
      "Validating...\n",
      "Validation Loss: 0.317893, Validation Accuracy: 88.27%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 25/25\n",
      "loss: 0.026719  [   70/  644]\n",
      "loss: 0.105629  [  210/  644]\n",
      "loss: 0.058938  [  350/  644]\n",
      "loss: 0.060484  [  490/  644]\n",
      "loss: 0.040760  [  630/  644]\n",
      "Training Loss (Epoch): 0.053149\n",
      "Validating...\n",
      "Validation Loss: 0.317877, Validation Accuracy: 88.27%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Processing Fold 9\n",
      "Epoch 1/25\n",
      "loss: 2.363458  [   70/  652]\n",
      "loss: 2.067416  [  210/  652]\n",
      "loss: 1.841611  [  350/  652]\n",
      "loss: 1.617871  [  490/  652]\n",
      "loss: 1.422529  [  630/  652]\n",
      "Training Loss (Epoch): 1.847881\n",
      "Validating...\n",
      "Validation Loss: 1.630347, Validation Accuracy: 62.80%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/25\n",
      "loss: 1.590923  [   70/  652]\n",
      "loss: 1.266373  [  210/  652]\n",
      "loss: 1.319218  [  350/  652]\n",
      "loss: 1.052385  [  490/  652]\n",
      "loss: 0.873199  [  630/  652]\n",
      "Training Loss (Epoch): 1.124411\n",
      "Validating...\n",
      "Validation Loss: 1.020069, Validation Accuracy: 68.29%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/25\n",
      "loss: 0.953331  [   70/  652]\n",
      "loss: 0.875268  [  210/  652]\n",
      "loss: 0.638119  [  350/  652]\n",
      "loss: 0.642593  [  490/  652]\n",
      "loss: 0.724537  [  630/  652]\n",
      "Training Loss (Epoch): 0.818536\n",
      "Validating...\n",
      "Validation Loss: 0.715356, Validation Accuracy: 81.71%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/25\n",
      "loss: 0.569451  [   70/  652]\n",
      "loss: 0.871819  [  210/  652]\n",
      "loss: 0.704810  [  350/  652]\n",
      "loss: 0.457006  [  490/  652]\n",
      "loss: 0.396321  [  630/  652]\n",
      "Training Loss (Epoch): 0.587975\n",
      "Validating...\n",
      "Validation Loss: 0.805764, Validation Accuracy: 79.27%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 5/25\n",
      "loss: 0.366119  [   70/  652]\n",
      "loss: 0.593332  [  210/  652]\n",
      "loss: 0.216132  [  350/  652]\n",
      "loss: 0.172999  [  490/  652]\n",
      "loss: 0.359792  [  630/  652]\n",
      "Training Loss (Epoch): 0.354882\n",
      "Validating...\n",
      "Validation Loss: 0.631011, Validation Accuracy: 89.63%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 6/25\n",
      "loss: 0.172210  [   70/  652]\n",
      "loss: 0.241753  [  210/  652]\n",
      "loss: 0.240653  [  350/  652]\n",
      "loss: 0.230753  [  490/  652]\n",
      "loss: 0.206818  [  630/  652]\n",
      "Training Loss (Epoch): 0.232017\n",
      "Validating...\n",
      "Validation Loss: 0.707923, Validation Accuracy: 90.24%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 7/25\n",
      "loss: 0.241119  [   70/  652]\n",
      "loss: 0.198491  [  210/  652]\n",
      "loss: 0.205992  [  350/  652]\n",
      "loss: 0.084416  [  490/  652]\n",
      "loss: 0.124254  [  630/  652]\n",
      "Training Loss (Epoch): 0.165424\n",
      "Validating...\n",
      "Validation Loss: 0.793448, Validation Accuracy: 85.98%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 8/25\n",
      "loss: 0.179223  [   70/  652]\n",
      "loss: 0.103655  [  210/  652]\n",
      "loss: 0.068303  [  350/  652]\n",
      "loss: 0.063095  [  490/  652]\n",
      "loss: 0.130730  [  630/  652]\n",
      "Training Loss (Epoch): 0.125364\n",
      "Validating...\n",
      "Validation Loss: 0.762443, Validation Accuracy: 88.41%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 9/25\n",
      "loss: 0.231869  [   70/  652]\n",
      "loss: 0.134857  [  210/  652]\n",
      "loss: 0.094687  [  350/  652]\n",
      "loss: 0.079120  [  490/  652]\n",
      "loss: 0.125117  [  630/  652]\n",
      "Training Loss (Epoch): 0.100653\n",
      "Validating...\n",
      "Validation Loss: 0.775468, Validation Accuracy: 88.41%\n",
      "Learning Rate: [6.25e-06]\n",
      "Epoch 10/25\n",
      "loss: 0.113745  [   70/  652]\n",
      "loss: 0.188100  [  210/  652]\n",
      "loss: 0.028530  [  350/  652]\n",
      "loss: 0.070120  [  490/  652]\n",
      "loss: 0.068999  [  630/  652]\n",
      "Training Loss (Epoch): 0.095511\n",
      "Validating...\n",
      "Validation Loss: 0.785617, Validation Accuracy: 88.41%\n",
      "Learning Rate: [3.125e-06]\n",
      "Epoch 11/25\n",
      "loss: 0.110046  [   70/  652]\n",
      "loss: 0.087241  [  210/  652]\n",
      "loss: 0.108385  [  350/  652]\n",
      "loss: 0.064899  [  490/  652]\n",
      "loss: 0.065407  [  630/  652]\n",
      "Training Loss (Epoch): 0.094143\n",
      "Validating...\n",
      "Validation Loss: 0.793243, Validation Accuracy: 88.41%\n",
      "Learning Rate: [1.5625e-06]\n",
      "Epoch 12/25\n",
      "loss: 0.190242  [   70/  652]\n",
      "loss: 0.063705  [  210/  652]\n",
      "loss: 0.026405  [  350/  652]\n",
      "loss: 0.116796  [  490/  652]\n",
      "loss: 0.057546  [  630/  652]\n",
      "Training Loss (Epoch): 0.087309\n",
      "Validating...\n",
      "Validation Loss: 0.796747, Validation Accuracy: 88.41%\n",
      "Learning Rate: [7.8125e-07]\n",
      "Epoch 13/25\n",
      "loss: 0.036342  [   70/  652]\n",
      "loss: 0.048172  [  210/  652]\n",
      "loss: 0.133479  [  350/  652]\n",
      "loss: 0.053247  [  490/  652]\n",
      "loss: 0.129649  [  630/  652]\n",
      "Training Loss (Epoch): 0.090009\n",
      "Validating...\n",
      "Validation Loss: 0.798497, Validation Accuracy: 88.41%\n",
      "Learning Rate: [3.90625e-07]\n",
      "Epoch 14/25\n",
      "loss: 0.081922  [   70/  652]\n",
      "loss: 0.039089  [  210/  652]\n",
      "loss: 0.080726  [  350/  652]\n",
      "loss: 0.118069  [  490/  652]\n",
      "loss: 0.067155  [  630/  652]\n",
      "Training Loss (Epoch): 0.109623\n",
      "Validating...\n",
      "Validation Loss: 0.799419, Validation Accuracy: 88.41%\n",
      "Learning Rate: [1.953125e-07]\n",
      "Epoch 15/25\n",
      "loss: 0.102482  [   70/  652]\n",
      "loss: 0.050933  [  210/  652]\n",
      "loss: 0.037940  [  350/  652]\n",
      "loss: 0.089495  [  490/  652]\n",
      "loss: 0.073234  [  630/  652]\n",
      "Training Loss (Epoch): 0.093418\n",
      "Validating...\n",
      "Validation Loss: 0.799795, Validation Accuracy: 88.41%\n",
      "Learning Rate: [9.765625e-08]\n",
      "Epoch 16/25\n",
      "loss: 0.079086  [   70/  652]\n",
      "loss: 0.115247  [  210/  652]\n",
      "loss: 0.089323  [  350/  652]\n",
      "loss: 0.104458  [  490/  652]\n",
      "loss: 0.117303  [  630/  652]\n",
      "Training Loss (Epoch): 0.084366\n",
      "Validating...\n",
      "Validation Loss: 0.800003, Validation Accuracy: 88.41%\n",
      "Learning Rate: [4.8828125e-08]\n",
      "Epoch 17/25\n",
      "loss: 0.132200  [   70/  652]\n",
      "loss: 0.082685  [  210/  652]\n",
      "loss: 0.082445  [  350/  652]\n",
      "loss: 0.100675  [  490/  652]\n",
      "loss: 0.072876  [  630/  652]\n",
      "Training Loss (Epoch): 0.118918\n",
      "Validating...\n",
      "Validation Loss: 0.800149, Validation Accuracy: 88.41%\n",
      "Learning Rate: [2.44140625e-08]\n",
      "Epoch 18/25\n",
      "loss: 0.108727  [   70/  652]\n",
      "loss: 0.097717  [  210/  652]\n",
      "loss: 0.092672  [  350/  652]\n",
      "loss: 0.076794  [  490/  652]\n",
      "loss: 0.142899  [  630/  652]\n",
      "Training Loss (Epoch): 0.097084\n",
      "Validating...\n",
      "Validation Loss: 0.800117, Validation Accuracy: 88.41%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 19/25\n",
      "loss: 0.096035  [   70/  652]\n",
      "loss: 0.043710  [  210/  652]\n",
      "loss: 0.129602  [  350/  652]\n",
      "loss: 0.030653  [  490/  652]\n",
      "loss: 0.077394  [  630/  652]\n",
      "Training Loss (Epoch): 0.091419\n",
      "Validating...\n",
      "Validation Loss: 0.800081, Validation Accuracy: 88.41%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 20/25\n",
      "loss: 0.151062  [   70/  652]\n",
      "loss: 0.091539  [  210/  652]\n",
      "loss: 0.089159  [  350/  652]\n",
      "loss: 0.074982  [  490/  652]\n",
      "loss: 0.092778  [  630/  652]\n",
      "Training Loss (Epoch): 0.090235\n",
      "Validating...\n",
      "Validation Loss: 0.800121, Validation Accuracy: 88.41%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 21/25\n",
      "loss: 0.095692  [   70/  652]\n",
      "loss: 0.096482  [  210/  652]\n",
      "loss: 0.091475  [  350/  652]\n",
      "loss: 0.104596  [  490/  652]\n",
      "loss: 0.083281  [  630/  652]\n",
      "Training Loss (Epoch): 0.091280\n",
      "Validating...\n",
      "Validation Loss: 0.800110, Validation Accuracy: 88.41%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 22/25\n",
      "loss: 0.015798  [   70/  652]\n",
      "loss: 0.132580  [  210/  652]\n",
      "loss: 0.120510  [  350/  652]\n",
      "loss: 0.031618  [  490/  652]\n",
      "loss: 0.068181  [  630/  652]\n",
      "Training Loss (Epoch): 0.100876\n",
      "Validating...\n",
      "Validation Loss: 0.800081, Validation Accuracy: 88.41%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 23/25\n",
      "loss: 0.155047  [   70/  652]\n",
      "loss: 0.118384  [  210/  652]\n",
      "loss: 0.114421  [  350/  652]\n",
      "loss: 0.003135  [  490/  652]\n",
      "loss: 0.046213  [  630/  652]\n",
      "Training Loss (Epoch): 0.083762\n",
      "Validating...\n",
      "Validation Loss: 0.800164, Validation Accuracy: 88.41%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 24/25\n",
      "loss: 0.072382  [   70/  652]\n",
      "loss: 0.102610  [  210/  652]\n",
      "loss: 0.135420  [  350/  652]\n",
      "loss: 0.084886  [  490/  652]\n",
      "loss: 0.057492  [  630/  652]\n",
      "Training Loss (Epoch): 0.086450\n",
      "Validating...\n",
      "Validation Loss: 0.800169, Validation Accuracy: 88.41%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 25/25\n",
      "loss: 0.161515  [   70/  652]\n",
      "loss: 0.100808  [  210/  652]\n",
      "loss: 0.064659  [  350/  652]\n",
      "loss: 0.083681  [  490/  652]\n",
      "loss: 0.042128  [  630/  652]\n",
      "Training Loss (Epoch): 0.106407\n",
      "Validating...\n",
      "Validation Loss: 0.800189, Validation Accuracy: 88.41%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Processing Fold 10\n",
      "Epoch 1/25\n",
      "loss: 2.381198  [   70/  669]\n",
      "loss: 2.101446  [  210/  669]\n",
      "loss: 1.972602  [  350/  669]\n",
      "loss: 1.672745  [  490/  669]\n",
      "loss: 1.507768  [  630/  669]\n",
      "Training Loss (Epoch): 1.900814\n",
      "Validating...\n",
      "Validation Loss: 1.678968, Validation Accuracy: 48.21%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/25\n",
      "loss: 1.735556  [   70/  669]\n",
      "loss: 1.336981  [  210/  669]\n",
      "loss: 1.262917  [  350/  669]\n",
      "loss: 0.978927  [  490/  669]\n",
      "loss: 1.053383  [  630/  669]\n",
      "Training Loss (Epoch): 1.262609\n",
      "Validating...\n",
      "Validation Loss: 1.065530, Validation Accuracy: 63.10%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/25\n",
      "loss: 1.010570  [   70/  669]\n",
      "loss: 0.890778  [  210/  669]\n",
      "loss: 0.926264  [  350/  669]\n",
      "loss: 0.857662  [  490/  669]\n",
      "loss: 0.626836  [  630/  669]\n",
      "Training Loss (Epoch): 0.830843\n",
      "Validating...\n",
      "Validation Loss: 0.932874, Validation Accuracy: 70.24%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/25\n",
      "loss: 0.957536  [   70/  669]\n",
      "loss: 0.638325  [  210/  669]\n",
      "loss: 0.935471  [  350/  669]\n",
      "loss: 0.696681  [  490/  669]\n",
      "loss: 0.736028  [  630/  669]\n",
      "Training Loss (Epoch): 0.714783\n",
      "Validating...\n",
      "Validation Loss: 0.658523, Validation Accuracy: 76.19%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/25\n",
      "loss: 0.760140  [   70/  669]\n",
      "loss: 0.775579  [  210/  669]\n",
      "loss: 0.426451  [  350/  669]\n",
      "loss: 0.643860  [  490/  669]\n",
      "loss: 0.707996  [  630/  669]\n",
      "Training Loss (Epoch): 0.599493\n",
      "Validating...\n",
      "Validation Loss: 0.604932, Validation Accuracy: 77.38%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/25\n",
      "loss: 0.449904  [   70/  669]\n",
      "loss: 0.381128  [  210/  669]\n",
      "loss: 0.326215  [  350/  669]\n",
      "loss: 0.563054  [  490/  669]\n",
      "loss: 0.425085  [  630/  669]\n",
      "Training Loss (Epoch): 0.450318\n",
      "Validating...\n",
      "Validation Loss: 0.788060, Validation Accuracy: 76.79%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 7/25\n",
      "loss: 0.642428  [   70/  669]\n",
      "loss: 0.663126  [  210/  669]\n",
      "loss: 0.423094  [  350/  669]\n",
      "loss: 0.271530  [  490/  669]\n",
      "loss: 0.417339  [  630/  669]\n",
      "Training Loss (Epoch): 0.419312\n",
      "Validating...\n",
      "Validation Loss: 0.515085, Validation Accuracy: 83.93%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 8/25\n",
      "loss: 0.230492  [   70/  669]\n",
      "loss: 0.344896  [  210/  669]\n",
      "loss: 0.286014  [  350/  669]\n",
      "loss: 0.320408  [  490/  669]\n",
      "loss: 0.479346  [  630/  669]\n",
      "Training Loss (Epoch): 0.306617\n",
      "Validating...\n",
      "Validation Loss: 0.508501, Validation Accuracy: 84.52%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 9/25\n",
      "loss: 0.277548  [   70/  669]\n",
      "loss: 0.134400  [  210/  669]\n",
      "loss: 0.191676  [  350/  669]\n",
      "loss: 0.416106  [  490/  669]\n",
      "loss: 0.305512  [  630/  669]\n",
      "Training Loss (Epoch): 0.247116\n",
      "Validating...\n",
      "Validation Loss: 0.464793, Validation Accuracy: 88.10%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 10/25\n",
      "loss: 0.121798  [   70/  669]\n",
      "loss: 0.141313  [  210/  669]\n",
      "loss: 0.192668  [  350/  669]\n",
      "loss: 0.153734  [  490/  669]\n",
      "loss: 0.316674  [  630/  669]\n",
      "Training Loss (Epoch): 0.202620\n",
      "Validating...\n",
      "Validation Loss: 0.456023, Validation Accuracy: 90.48%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 11/25\n",
      "loss: 0.227300  [   70/  669]\n",
      "loss: 0.088734  [  210/  669]\n",
      "loss: 0.127696  [  350/  669]\n",
      "loss: 0.274475  [  490/  669]\n",
      "loss: 0.257753  [  630/  669]\n",
      "Training Loss (Epoch): 0.175975\n",
      "Validating...\n",
      "Validation Loss: 0.492142, Validation Accuracy: 87.50%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 12/25\n",
      "loss: 0.115540  [   70/  669]\n",
      "loss: 0.166374  [  210/  669]\n",
      "loss: 0.126648  [  350/  669]\n",
      "loss: 0.261508  [  490/  669]\n",
      "loss: 0.060862  [  630/  669]\n",
      "Training Loss (Epoch): 0.149223\n",
      "Validating...\n",
      "Validation Loss: 0.461210, Validation Accuracy: 86.90%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 13/25\n",
      "loss: 0.075734  [   70/  669]\n",
      "loss: 0.233697  [  210/  669]\n",
      "loss: 0.054981  [  350/  669]\n",
      "loss: 0.132530  [  490/  669]\n",
      "loss: 0.190359  [  630/  669]\n",
      "Training Loss (Epoch): 0.132151\n",
      "Validating...\n",
      "Validation Loss: 0.460634, Validation Accuracy: 88.69%\n",
      "Learning Rate: [6.25e-06]\n",
      "Epoch 14/25\n",
      "loss: 0.037382  [   70/  669]\n",
      "loss: 0.213444  [  210/  669]\n",
      "loss: 0.224735  [  350/  669]\n",
      "loss: 0.100584  [  490/  669]\n",
      "loss: 0.073593  [  630/  669]\n",
      "Training Loss (Epoch): 0.128878\n",
      "Validating...\n",
      "Validation Loss: 0.473960, Validation Accuracy: 88.69%\n",
      "Learning Rate: [3.125e-06]\n",
      "Epoch 15/25\n",
      "loss: 0.175717  [   70/  669]\n",
      "loss: 0.119782  [  210/  669]\n",
      "loss: 0.098952  [  350/  669]\n",
      "loss: 0.045841  [  490/  669]\n",
      "loss: 0.145552  [  630/  669]\n",
      "Training Loss (Epoch): 0.118546\n",
      "Validating...\n",
      "Validation Loss: 0.479066, Validation Accuracy: 89.88%\n",
      "Learning Rate: [1.5625e-06]\n",
      "Epoch 16/25\n",
      "loss: 0.113994  [   70/  669]\n",
      "loss: 0.102071  [  210/  669]\n",
      "loss: 0.181946  [  350/  669]\n",
      "loss: 0.121019  [  490/  669]\n",
      "loss: 0.128081  [  630/  669]\n",
      "Training Loss (Epoch): 0.117782\n",
      "Validating...\n",
      "Validation Loss: 0.478719, Validation Accuracy: 89.29%\n",
      "Learning Rate: [7.8125e-07]\n",
      "Epoch 17/25\n",
      "loss: 0.046614  [   70/  669]\n",
      "loss: 0.080430  [  210/  669]\n",
      "loss: 0.118193  [  350/  669]\n",
      "loss: 0.168154  [  490/  669]\n",
      "loss: 0.176263  [  630/  669]\n",
      "Training Loss (Epoch): 0.111331\n",
      "Validating...\n",
      "Validation Loss: 0.478564, Validation Accuracy: 89.29%\n",
      "Learning Rate: [3.90625e-07]\n",
      "Epoch 18/25\n",
      "loss: 0.098810  [   70/  669]\n",
      "loss: 0.137864  [  210/  669]\n",
      "loss: 0.195796  [  350/  669]\n",
      "loss: 0.071266  [  490/  669]\n",
      "loss: 0.165908  [  630/  669]\n",
      "Training Loss (Epoch): 0.112396\n",
      "Validating...\n",
      "Validation Loss: 0.478619, Validation Accuracy: 89.29%\n",
      "Learning Rate: [1.953125e-07]\n",
      "Epoch 19/25\n",
      "loss: 0.084454  [   70/  669]\n",
      "loss: 0.055610  [  210/  669]\n",
      "loss: 0.101027  [  350/  669]\n",
      "loss: 0.230786  [  490/  669]\n",
      "loss: 0.051241  [  630/  669]\n",
      "Training Loss (Epoch): 0.114699\n",
      "Validating...\n",
      "Validation Loss: 0.478592, Validation Accuracy: 89.29%\n",
      "Learning Rate: [9.765625e-08]\n",
      "Epoch 20/25\n",
      "loss: 0.181514  [   70/  669]\n",
      "loss: 0.169804  [  210/  669]\n",
      "loss: 0.099201  [  350/  669]\n",
      "loss: 0.107416  [  490/  669]\n",
      "loss: 0.083890  [  630/  669]\n",
      "Training Loss (Epoch): 0.112064\n",
      "Validating...\n",
      "Validation Loss: 0.478629, Validation Accuracy: 89.29%\n",
      "Learning Rate: [4.8828125e-08]\n",
      "Epoch 21/25\n",
      "loss: 0.105955  [   70/  669]\n",
      "loss: 0.162414  [  210/  669]\n",
      "loss: 0.111584  [  350/  669]\n",
      "loss: 0.154492  [  490/  669]\n",
      "loss: 0.144950  [  630/  669]\n",
      "Training Loss (Epoch): 0.112687\n",
      "Validating...\n",
      "Validation Loss: 0.478703, Validation Accuracy: 89.29%\n",
      "Learning Rate: [2.44140625e-08]\n",
      "Epoch 22/25\n",
      "loss: 0.127031  [   70/  669]\n",
      "loss: 0.144249  [  210/  669]\n",
      "loss: 0.148433  [  350/  669]\n",
      "loss: 0.078509  [  490/  669]\n",
      "loss: 0.127209  [  630/  669]\n",
      "Training Loss (Epoch): 0.113776\n",
      "Validating...\n",
      "Validation Loss: 0.478773, Validation Accuracy: 89.29%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 23/25\n",
      "loss: 0.156642  [   70/  669]\n",
      "loss: 0.018443  [  210/  669]\n",
      "loss: 0.109949  [  350/  669]\n",
      "loss: 0.087310  [  490/  669]\n",
      "loss: 0.061203  [  630/  669]\n",
      "Training Loss (Epoch): 0.123293\n",
      "Validating...\n",
      "Validation Loss: 0.478736, Validation Accuracy: 89.29%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 24/25\n",
      "loss: 0.055672  [   70/  669]\n",
      "loss: 0.151681  [  210/  669]\n",
      "loss: 0.102066  [  350/  669]\n",
      "loss: 0.214523  [  490/  669]\n",
      "loss: 0.085196  [  630/  669]\n",
      "Training Loss (Epoch): 0.114310\n",
      "Validating...\n",
      "Validation Loss: 0.478669, Validation Accuracy: 89.29%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "Epoch 25/25\n",
      "loss: 0.135277  [   70/  669]\n",
      "loss: 0.136114  [  210/  669]\n",
      "loss: 0.127975  [  350/  669]\n",
      "loss: 0.133776  [  490/  669]\n",
      "loss: 0.121623  [  630/  669]\n",
      "Training Loss (Epoch): 0.115744\n",
      "Validating...\n",
      "Validation Loss: 0.478689, Validation Accuracy: 89.29%\n",
      "Learning Rate: [1.220703125e-08]\n",
      "\n",
      "Cross-Validation Results:\n",
      "Avg Training Loss: 0.075101\n",
      "Avg Validation Loss: 0.471991\n",
      "Avg Validation Accuracy: 89.47%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dense_tune(layer = 0, lr = 2e-4, weight_decay = 0.2, weights = \"DEFAULT\", drop = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1\n",
      "Epoch 1/25\n",
      "loss: 2.331131  [   70/  698]\n",
      "loss: 2.055089  [  210/  698]\n",
      "loss: 1.877670  [  350/  698]\n",
      "loss: 1.687566  [  490/  698]\n",
      "loss: 1.555803  [  630/  698]\n",
      "Training Loss (Epoch): 1.905555\n",
      "Validating...\n",
      "Validation Loss: 1.838341, Validation Accuracy: 38.86%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/25\n",
      "loss: 1.756370  [   70/  698]\n",
      "loss: 1.312833  [  210/  698]\n",
      "loss: 1.193984  [  350/  698]\n",
      "loss: 1.035488  [  490/  698]\n",
      "loss: 0.948568  [  630/  698]\n",
      "Training Loss (Epoch): 1.199020\n",
      "Validating...\n",
      "Validation Loss: 0.995627, Validation Accuracy: 58.86%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/25\n",
      "loss: 0.746033  [   70/  698]\n",
      "loss: 0.646298  [  210/  698]\n",
      "loss: 0.543342  [  350/  698]\n",
      "loss: 0.599732  [  490/  698]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdense_tune\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDEFAULT\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36mdense_tune\u001b[39m\u001b[34m(layer, lr, weight_decay, weights, drop, SEED)\u001b[39m\n\u001b[32m     45\u001b[39m val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m, collate_fn=custom_collate_fn)\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# Train and validate (over multiple epochs per fold)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m epoch_train_losses, epoch_val_losses, epoch_val_accuracies = \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# Aggregate fold-level metrics (e.g., last epoch metrics)\u001b[39;00m\n\u001b[32m     53\u001b[39m fold_train_losses.append(epoch_train_losses[-\u001b[32m1\u001b[39m])  \u001b[38;5;66;03m# Last epoch's training loss\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mtrain_loop\u001b[39m\u001b[34m(train_dataloader, val_dataloader, model, loss_fn, optimizer, scheduler, epochs)\u001b[39m\n\u001b[32m     28\u001b[39m optimizer.step()\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Accumulate loss\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m total_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Print progress periodically\u001b[39;00m\n\u001b[32m     34\u001b[39m total_batches = \u001b[38;5;28mlen\u001b[39m(train_dataloader)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "dense_tune(layer = 1, lr = 2e-4, weight_decay = 0.2, weights = \"DEFAULT\", drop = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dense_tune(layer = 2, lr = 2e-4, weight_decay = 0.2, weights = \"DEFAULT\", drop = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dense_tune(layer = 3, lr = 2e-4, weight_decay = 0.2, weights = \"DEFAULT\", drop = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dense_tune(layer = 4, lr = 2e-4, weight_decay = 0.2, weights = \"DEFAULT\", drop = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_tune(layer = 0, lr = 2e-3, weight_decay = 0.2, weights = None, drop = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchaudio\n",
    "\n",
    "# audio_path = \"./UrbanSound8k/audio/fold1/137156-9-0-30.wav\"\n",
    "# waveform, sample_rate = torchaudio.load(audio_path)\n",
    "# print(f\"Shape: {waveform.shape}, Sample Rate: {sample_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_stereogram(spectrogram):\n",
    "    # Convert to numpy\n",
    "    spectrogram_np = spectrogram.numpy()  # Shape: (2, Freq, Time)\n",
    "\n",
    "    # Plot left and right channels\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(6, 6), constrained_layout=True)\n",
    "\n",
    "    axs[0].imshow(spectrogram_np[0], aspect='auto', origin='lower', cmap='magma')\n",
    "    axs[0].set_title(f\"Spectrogram {i+1} - Left Channel\")\n",
    "    axs[0].set_ylabel(\"Frequency Bins\")\n",
    "    axs[0].set_xlabel(\"Time Frames\")\n",
    "\n",
    "    axs[1].imshow(spectrogram_np[1], aspect='auto', origin='lower', cmap='magma')\n",
    "    axs[1].set_title(f\"Spectrogram {i+1} - Right Channel\")\n",
    "    axs[1].set_ylabel(\"Frequency Bins\")\n",
    "    axs[1].set_xlabel(\"Time Frames\")\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "urbad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
