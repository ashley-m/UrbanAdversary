{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mBSFTJ5M_z-H"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n",
    "from torch.cuda import manual_seed_all\n",
    "from torch import manual_seed as torch_manual_seed\n",
    "from torch.backends import cudnn\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "3uDKfjRHMuxk"
   },
   "outputs": [],
   "source": [
    "# pre spectrogram augmentations\n",
    "# these are examples and can be changed based on domain knowledge\n",
    "\n",
    "def stretch_waveform(waveform, rate=1.2):\n",
    "    time_stretch = T.TimeStretch()\n",
    "    # `rate > 1.0` speeds up, `rate < 1.0` slows down\n",
    "    return time_stretch(waveform, rate)\n",
    "\n",
    "def shift_pitch(waveform, sample_rate=44100, n_steps = 2):\n",
    "    pitch_shift = T.PitchShift(sample_rate, n_steps)  # Shift up by 2 semitones\n",
    "    return pitch_shift(waveform)\n",
    "\n",
    "def scale_volume(waveform, factor = None):\n",
    "    if factor is None:\n",
    "        waveform *= torch.FloatTensor(1).uniform_(0.8, 1.5).item()  # Amplifies waveform by random factor\n",
    "    else:\n",
    "        waveform *= factor\n",
    "    return waveform\n",
    "\n",
    "def crop_waveform(waveform, crop_size):\n",
    "    start = torch.randint(0, max(1, waveform.size(-1) - crop_size), (1,)).item()\n",
    "    return waveform[:, start:start + crop_size]\n",
    "\n",
    "def apply_reverb(waveform):\n",
    "    reverb = T.Reverberate()\n",
    "    return reverb(waveform)\n",
    "\n",
    "def time_shift(waveform, shift):\n",
    "    return torch.roll(waveform, shifts=shift, dims=-1)\n",
    "\n",
    "def add_noise(waveform, noise_level=0.005):\n",
    "    noise = torch.randn_like(waveform) * noise_level\n",
    "    return waveform + noise\n",
    "\n",
    "# Augment on-the-fly stochastically\n",
    "# again these are just examples and do not necessarily utilize the methods above\n",
    "def augment_waveform(data):\n",
    "    waveform, sample_rate = data\n",
    "    if torch.rand(1).item() > 0.9:\n",
    "        waveform = add_noise(waveform)\n",
    "    if torch.rand(1).item() > 0.9:\n",
    "        waveform = time_shift(waveform, shifts=torch.randint(-waveform.size(-1) // 2, waveform.size(-1) // 2, (1,)).item())\n",
    "    if torch.rand(1).item() > 0.9:\n",
    "        waveform = scale_volume(waveform)\n",
    "    if torch.rand(1).item() > 0.9:\n",
    "        waveform = apply_reverb(waveform)\n",
    "    if torch.rand(1).item() > 0.9:\n",
    "        waveform = shift_pitch(waveform, sample_rate, n_steps= torch.randint(-12, 12, (1,)).item())\n",
    "    if torch.rand(1).item() > 0.9:\n",
    "        waveform = stretch_waveform(waveform, rate= torch.FloatTensor(1).uniform_(0.5, 1.5).item())\n",
    "    return waveform, sample_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Ww8OMV8nNZcf"
   },
   "outputs": [],
   "source": [
    "# Create a MelSpectrogram transformation\n",
    "mel_spectrogram_transform = T.MelSpectrogram(\n",
    "    sample_rate=44100,         # Default sample rate, change if needed\n",
    "    n_fft=1024,                # Number of FFT bins\n",
    "    hop_length=512,            # Hop length between windows\n",
    "    n_mels=64                  # Number of Mel bands\n",
    ")\n",
    "\n",
    "def waveform_to_spectrogram(data):\n",
    "    waveform, sample_rate = data\n",
    "    spectrogram = mel_spectrogram_transform(waveform)  # Apply the spectrogram transformation\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "khV1u_wUIR-o"
   },
   "outputs": [],
   "source": [
    "# post spectrogram augmentations\n",
    "\n",
    "# Example augmentations, could add more\n",
    "time_mask = T.TimeMasking(time_mask_param=10)\n",
    "\n",
    "freq_mask = T.FrequencyMasking(freq_mask_param=8)\n",
    "\n",
    "# hybridizes two sounds\n",
    "def mixup(spectrogram1, spectrogram2, alpha=0.2):\n",
    "    lam = torch.FloatTensor(1).uniform_(0, alpha).item()\n",
    "    return lam * spectrogram1 + (1 - lam) * spectrogram2\n",
    "\n",
    "# should probably implement a randomization process like above\n",
    "def augment_spectrogram(spectrogram):\n",
    "    augmented = time_mask(spectrogram)  # Apply time masking\n",
    "    augmented = freq_mask(augmented)   # Apply frequency masking\n",
    "    return augmented\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2U9n6Z-fPiwY"
   },
   "outputs": [],
   "source": [
    "# Decode audio files\n",
    "def decode_audio(file_tuple):\n",
    "    file_path, file = file_tuple\n",
    "    waveform, sample_rate = torchaudio.load(file_path)\n",
    "    return waveform, sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "class UrbanSoundDataset(Dataset):\n",
    "    def __init__(self, audio_path, fold, csv_path, transform=None):\n",
    "        self.audio_path = os.path.join(audio_path, f\"fold{fold}\")\n",
    "        self.file_list = [os.path.join(self.audio_path, f) for f in os.listdir(self.audio_path) if f.endswith(\".wav\")]\n",
    "        self.transform = transform\n",
    "\n",
    "        # Load the metadata CSV file\n",
    "        self.metadata = pd.read_csv(csv_path)\n",
    "\n",
    "    def get_label(self, file_name):\n",
    "        \"\"\"Fetch the class label for a given file name from the metadata.\"\"\"\n",
    "        label_row = self.metadata.loc[self.metadata['slice_file_name'] == file_name, 'class']\n",
    "        if not label_row.empty:\n",
    "            return label_row.values[0]\n",
    "        else:\n",
    "            raise ValueError(f\"File name {file_name} not found in metadata CSV.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load the audio file\n",
    "        file_path = self.file_list[idx]\n",
    "        waveform, sample_rate = torchaudio.load(file_path)\n",
    "\n",
    "        # Convert mono to stereo if necessary\n",
    "        if waveform.size(0) == 1:  # If mono\n",
    "            waveform = waveform.repeat(3, 1)\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            waveform = self.transform(waveform)\n",
    "\n",
    "        # Extract the file name from the path\n",
    "        file_name = os.path.basename(file_path)\n",
    "\n",
    "        # Get the corresponding label for the file\n",
    "        label = self.get_label(file_name)\n",
    "\n",
    "        return waveform, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asm2fe/.local/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torchaudio.transforms as T\n",
    "\n",
    "# Example transformations\n",
    "def augment_waveform(waveform):\n",
    "    # Add your augmentation logic here (e.g., noise addition, time stretch, etc.)\n",
    "    return waveform\n",
    "\n",
    "waveform_to_spectrogram = T.MelSpectrogram(sample_rate=16000, n_mels=128)\n",
    "augment_spectrogram = T.AmplitudeToDB()\n",
    "\n",
    "# Combine transformations into a callable function\n",
    "def transform_pipeline(waveform):\n",
    "    waveform = augment_waveform(waveform)\n",
    "    spectrogram = waveform_to_spectrogram(waveform)\n",
    "    # spectrogram = augment_spectrogram(spectrogram)\n",
    "    return spectrogram\n",
    "\n",
    "def pad_with_noise(spectrogram, max_time, noise_std=0.01):\n",
    "    \"\"\"\n",
    "    Pads a spectrogram with Gaussian noise instead of zeros.\n",
    "\n",
    "    Args:\n",
    "        spectrogram (Tensor): Shape (channels, freq_bins, time_steps)\n",
    "        max_time (int): Target time dimension\n",
    "        noise_std (float): Standard deviation of the Gaussian noise\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Padded spectrogram with noise\n",
    "    \"\"\"\n",
    "    # Compute how much padding is needed\n",
    "    pad_amount = max_time - spectrogram.size(2)\n",
    "    \n",
    "    if pad_amount > 0:\n",
    "        # Generate random noise matching the shape of missing time steps\n",
    "        noise = torch.randn((spectrogram.size(0), spectrogram.size(1), pad_amount)) * noise_std\n",
    "        \n",
    "        # Concatenate noise along the time axis\n",
    "        spectrogram = torch.cat([spectrogram, noise], dim=2)\n",
    "    \n",
    "    return spectrogram\n",
    "\n",
    "# def convert_to_three_channels(spectrogram):\n",
    "#     # Convert [2, 224, 224] to [3, 224, 224]\n",
    "#     if spectrogram.size(0) == 2:\n",
    "#         # Duplicate the first channel to create a third channel\n",
    "#         return torch.cat((spectrogram, spectrogram[0:1, :, :]), dim=0)\n",
    "#     return spectrogram\n",
    "\n",
    "def convert_to_three_channels(spectrogram):\n",
    "    # Convert [2, 224, 224] to [3, 224, 224]\n",
    "    if spectrogram.size(0) == 2:\n",
    "        # Calculate the mean of the two channels\n",
    "        mean_channel = torch.mean(spectrogram, dim=0, keepdim=True)\n",
    "        # Concatenate the mean channel as the third channel\n",
    "        return torch.cat((spectrogram, mean_channel), dim=0)\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "\n",
    "class densenet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    DenseNet Class, derived from Pytorch. Intended for model manipulation (i.e. unfreezing layers, etc.)\n",
    "    To use model, try (densenet).model(data)\n",
    "    May change to reflect manual implementation of densenet161.\n",
    "    \"\"\"\n",
    "    def __init__(self, weights = \"DEFAULT\", drop = 0.5):\n",
    "        super().__init__()  # Initialize the nn.Module base class\n",
    "        self.model = torchvision.models.densenet161(weights = weights)\n",
    "        \n",
    "        num_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Dropout(drop),  # Add dropout with 50% probability\n",
    "            nn.Linear(num_features, 10)  # Adjust for 10 output classes (UrbanSound8k)\n",
    "        )\n",
    "        \n",
    "        # Ensure classifier is trainable\n",
    "        for param in self.model.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)  # Delegate forward pass to the original DenseNet\n",
    "\n",
    "    def layer_change(self, layer=0):\n",
    "        if layer > 0:    \n",
    "            # Freeze earlier layers (optional)\n",
    "            for name, param in self.model.features.named_parameters():\n",
    "                if \"conv0\" in name or \"denseblock1\" in name:  # Freeze initial layers and denseblock1\n",
    "                    param.requires_grad = False\n",
    "        if layer > 1:    \n",
    "            # Freeze earlier layers (optional)\n",
    "            for name, param in self.model.features.named_parameters():\n",
    "                if \"denseblock2\" in name:  # Freeze initial layers and denseblock2\n",
    "                    param.requires_grad = False\n",
    "        if layer > 2:    \n",
    "            # Freeze earlier layers (optional)\n",
    "            for name, param in self.model.features.named_parameters():\n",
    "                if \"denseblock3\" in name:  # Freeze initial layers and denseblock3\n",
    "                    param.requires_grad = False\n",
    "        if layer > 3:    \n",
    "            # Freeze earlier layers (optional)\n",
    "            for name, param in self.model.features.named_parameters():\n",
    "                if \"denseblock4\" in name:  # Freeze initial layers and denseblock4\n",
    "                    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = densenet()\n",
    "# for param in model.model.features.named_parameters():\n",
    "#     print(param[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and testing loops\n",
    "\n",
    "def train_loop(train_dataloader, val_dataloader, model, loss_fn, optimizer, scheduler=None, epochs=1):\n",
    "    model.train()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Store metrics\n",
    "    epoch_train_losses = []  # Track training loss across epochs\n",
    "    epoch_val_losses = []  # Track validation loss across epochs\n",
    "    epoch_val_accuracies = []  # Track validation accuracy across epochs\n",
    "\n",
    "    # Training loop with early stopping\n",
    "    early_stopping = EarlyStopping(patience=5, min_delta=0.0001)\n",
    "    \n",
    "    early_stop_epoch = None\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        size = len(train_dataloader.dataset)\n",
    "        total_loss = 0  # Initialize variable to accumulate training loss\n",
    "        \n",
    "\n",
    "        for batch, (X, y) in enumerate(train_dataloader):\n",
    "            # Compute prediction and loss\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Print progress periodically\n",
    "            total_batches = len(train_dataloader)\n",
    "            if batch % (total_batches // 5) == 0:  # Prints 5 times per epoch\n",
    "                current = (batch + 1) * len(X)\n",
    "                print(f\"loss: {loss.item():>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "        # Average training loss for the epoch\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "        # print(len(train_dataloader))\n",
    "        print(f\"Training Loss (Epoch): {avg_train_loss:>7f}\")\n",
    "        epoch_train_losses.append(avg_train_loss)\n",
    "\n",
    "        # **Validation Step**\n",
    "        print(\"Validating...\")\n",
    "        avg_val_loss, val_accuracy = test_loop(val_dataloader, model, loss_fn, verbose=False)\n",
    "        print(f\"Validation Loss: {avg_val_loss:.6f}, Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "\n",
    "        # Track validation metrics\n",
    "        epoch_val_losses.append(avg_val_loss)\n",
    "        epoch_val_accuracies.append(val_accuracy)\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(val_accuracy)\n",
    "            print(f\"Learning Rate: {scheduler.get_last_lr()}\")\n",
    "        \n",
    "        # Check for early stopping\n",
    "        early_stopping(avg_val_loss)\n",
    "        if early_stopping.stop_training:\n",
    "            print(\"Early stopping triggered. Training stopped.\")\n",
    "            early_stop_epoch = epoch\n",
    "            break\n",
    "\n",
    "    # Return metrics for tracking/aggregation across folds\n",
    "    return epoch_train_losses, epoch_val_losses, epoch_val_accuracies, early_stop_epoch\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn, verbose=True):\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    # Average loss and accuracy for this fold\n",
    "    avg_test_loss = test_loss / num_batches\n",
    "    accuracy = correct / size\n",
    "    if verbose:\n",
    "        print(f\"Test Error: \\n Accuracy: {(100*accuracy):>0.1f}%, Avg loss: {avg_test_loss:>8f} \\n\")\n",
    "    return avg_test_loss, accuracy  # Return both average loss and accuracy for this fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "BLCzmvxcHvKs"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    # Resize and normalize for DenseNet\n",
    "    resize_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize for DenseNet\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Standard ImageNet normalization\n",
    "    ])\n",
    "    \n",
    "    inputs, labels = zip(*batch)  # Separate inputs and labels\n",
    "    max_time = max(spectrogram.size(2) for spectrogram in inputs)\n",
    "\n",
    "    # Pad inputs to the same length along the time dimension\n",
    "    padded_inputs = [\n",
    "        torch.nn.functional.pad(input, (0, max_time - input.size(2)))\n",
    "        for input in inputs\n",
    "    ]\n",
    "\n",
    "    # Convert to 3 channels and resize\n",
    "    resized_inputs = [resize_transform(convert_to_three_channels(input)) for input in padded_inputs]\n",
    "    \n",
    "    # Map labels to numeric class IDs\n",
    "    class_mapping = {\n",
    "        \"air_conditioner\": 0,\n",
    "        \"car_horn\": 1,\n",
    "        \"children_playing\": 2,\n",
    "        \"dog_bark\": 3,\n",
    "        \"drilling\": 4,\n",
    "        \"engine_idling\": 5,\n",
    "        \"gun_shot\": 6,\n",
    "        \"jackhammer\": 7,\n",
    "        \"siren\": 8,\n",
    "        \"street_music\": 9\n",
    "    }\n",
    "\n",
    "    numeric_labels = [class_mapping[label] for label in labels]\n",
    "\n",
    "    # Stack inputs and labels\n",
    "    return torch.stack(resized_inputs), torch.tensor(numeric_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3, min_delta=0.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How many epochs to wait for improvement.\n",
    "            min_delta (float): Minimum change in monitored value to qualify as improvement.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.stop_training = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None or val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.stop_training = True   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sfs/gpfs/tardis/home/asm2fe/UrbanAdversary\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# Specify paths and batch size\n",
    "AUDIO_PATH = \"./UrbanSound8K/audio\"\n",
    "CSV_PATH = \"./UrbanSound8K/metadata/UrbanSound8K.csv\"\n",
    "\n",
    "\n",
    "def setup_seed(seed):\n",
    "    torch_manual_seed(seed)\n",
    "    manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    cudnn.deterministic = True\n",
    "\n",
    "def dense_tune(layer = 0, lr = 2e-4, weight_decay = 0.1, weights = \"DEFAULT\", drop = 0.8, SEED = 666,\\\n",
    "     total_epochs = 20, batch_size = 70, folds = 10):\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    setup_seed(SEED)\n",
    "\n",
    "    # Variables to accumulate metrics across folds\n",
    "    fold_train_losses = []\n",
    "    fold_val_losses = []\n",
    "    fold_val_accuracies = []\n",
    "\n",
    "    # Loop through folds\n",
    "    for fold in range(1, folds+1):\n",
    "        model = densenet(weights = weights, drop = drop)\n",
    "        model.layer_change(layer = layer) # freeze first conv and dense block(s) if desired\n",
    "\n",
    "        print(f\"Processing Fold {fold}\")\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay = weight_decay)\n",
    "        # optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001, weight_decay = 0.01, momentum = 0.9)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='max', factor=0.2, patience=1, threshold_mode = 'abs', threshold= 0.1, min_lr=1e-6)\n",
    "\n",
    "        # Initialize dataset and DataLoader\n",
    "        dataset = UrbanSoundDataset(audio_path=AUDIO_PATH, fold=fold, transform=transform_pipeline, csv_path=CSV_PATH)\n",
    "        train_indices, val_indices = train_test_split(list(range(len(dataset))), test_size=0.2, random_state=42)\n",
    "\n",
    "        train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "        val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
    "\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "        val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "        # Train and validate (over multiple epochs per fold)\n",
    "        epoch_train_losses, epoch_val_losses, epoch_val_accuracies, early_stop_epoch = train_loop(\n",
    "            train_dataloader, val_dataloader, model, loss_fn, optimizer, scheduler, epochs=total_epochs\n",
    "        )\n",
    "\n",
    "        # # Aggregate metrics up to the stopping epoch\n",
    "        # if early_stop_epoch is not None:\n",
    "        #     print(early_stop_epoch+1)\n",
    "        #     fold_train_losses.append(sum(epoch_train_losses) / (early_stop_epoch+1))  # Mean up to early stop\n",
    "        #     fold_val_losses.append(sum(epoch_val_losses) / (early_stop_epoch+1))      # Mean up to early stop\n",
    "        #     fold_val_accuracies.append(sum(epoch_val_accuracies) / (early_stop_epoch+1))  # Mean up to early stop\n",
    "        # else:\n",
    "        #     # If no early stopping occurred, aggregate metrics across all epochs\n",
    "        #     fold_train_losses.append(sum(epoch_train_losses) / len(epoch_train_losses))\n",
    "        #     fold_val_losses.append(sum(epoch_val_losses) / len(epoch_val_losses))\n",
    "        #     fold_val_accuracies.append(sum(epoch_val_accuracies) / len(epoch_val_accuracies))\n",
    "\n",
    "        # Aggregate fold-level metrics (e.g., mean across all epochs)\n",
    "        fold_train_losses.append(sum(epoch_train_losses) / len(epoch_train_losses))  # Mean of training losses\n",
    "        fold_val_losses.append(sum(epoch_val_losses) / len(epoch_val_losses))        # Mean of validation losses\n",
    "        fold_val_accuracies.append(epoch_val_accuracies[-1])  # Last validation accuracy\n",
    "\n",
    "    # Compute average metrics across folds\n",
    "    mean_train_loss = sum(fold_train_losses) / len(fold_train_losses)\n",
    "    mean_val_loss = sum(fold_val_losses) / len(fold_val_losses)\n",
    "    mean_val_accuracy = sum(fold_val_accuracies) / len(fold_val_accuracies)\n",
    "\n",
    "    print(f\"\\nCross-Validation Results:\")\n",
    "    print(f\"Avg Training Loss: {mean_train_loss:.6f}\")\n",
    "    print(f\"Avg Validation Loss: {mean_val_loss:.6f}\")\n",
    "    print(f\"Avg Validation Accuracy: {mean_val_accuracy * 100:.2f}%\")\n",
    "    return mean_train_loss, mean_val_loss, mean_val_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def dense_grid_search(param_grid):\n",
    "    param_names = list(param_grid.keys())\n",
    "    param_combinations = list(itertools.product(*param_grid.values()))\n",
    "\n",
    "    best_params = None\n",
    "    best_score = -float('inf')  # For maximizing validation accuracy\n",
    "    all_results = []\n",
    "\n",
    "    for combination in param_combinations:\n",
    "        # Map combination to hyperparameters\n",
    "        params = dict(zip(param_names, combination))\n",
    "        print(f\"Testing combination: {params}\")\n",
    "\n",
    "        # Call dense_tune with the current parameter combination\n",
    "        mean_train_loss, mean_val_loss, mean_val_accuracy = dense_tune(\n",
    "            layer=params[\"layer\"],\n",
    "            lr=params[\"lr\"],\n",
    "            weight_decay=params[\"weight_decay\"],\n",
    "            drop=params[\"drop\"],\n",
    "            total_epochs=params[\"total_epochs\"],\n",
    "            batch_size =params[\"batch_size\"],\n",
    "            folds = 10\n",
    "        )\n",
    "\n",
    "        # Store results\n",
    "        result = {\n",
    "            \"params\": params,\n",
    "            \"train_loss\": mean_train_loss,\n",
    "            \"val_loss\": mean_val_loss,\n",
    "            \"val_accuracy\": mean_val_accuracy\n",
    "        }\n",
    "        all_results.append(result)\n",
    "\n",
    "        # Update best score and parameters\n",
    "        if mean_val_accuracy > best_score:\n",
    "            best_score = mean_val_accuracy\n",
    "            best_params = params\n",
    "    print(f\"Best parameters were: {best_params}\")\n",
    "    print(f\"Best score was: {best_score}\")\n",
    "    return best_params, best_score, all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"layer\": [1],              # Number of frozen layers\n",
    "    \"lr\": [3e-4, 2e-4],       # Learning rates\n",
    "    \"weight_decay\": [0.1, 0.15],     # Weight decay values\n",
    "    \"drop\": [0.8],             # Dropout rates\n",
    "    \"total_epochs\": [25],            # Total epochs\n",
    "    \"batch_size\": [100, 110]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params, best_score, all_results = dense_grid_search(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1\n",
      "Epoch 1/15\n",
      "loss: 2.371572  [   90/  698]\n",
      "loss: 2.266326  [  180/  698]\n",
      "loss: 2.135051  [  270/  698]\n",
      "loss: 1.981686  [  360/  698]\n",
      "loss: 2.052443  [  450/  698]\n",
      "loss: 1.797413  [  540/  698]\n",
      "loss: 1.748499  [  630/  698]\n",
      "loss: 1.832912  [  544/  698]\n",
      "Training Loss (Epoch): 2.023238\n",
      "Validating...\n",
      "Validation Loss: 1.984087, Validation Accuracy: 40.00%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/15\n",
      "loss: 1.941096  [   90/  698]\n",
      "loss: 1.704687  [  180/  698]\n",
      "loss: 1.418131  [  270/  698]\n",
      "loss: 1.455065  [  360/  698]\n",
      "loss: 1.249689  [  450/  698]\n",
      "loss: 1.134141  [  540/  698]\n",
      "loss: 1.181928  [  630/  698]\n",
      "loss: 1.049193  [  544/  698]\n",
      "Training Loss (Epoch): 1.391741\n",
      "Validating...\n",
      "Validation Loss: 0.923820, Validation Accuracy: 70.86%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/15\n",
      "loss: 0.893042  [   90/  698]\n",
      "loss: 0.892553  [  180/  698]\n",
      "loss: 0.716824  [  270/  698]\n",
      "loss: 0.610409  [  360/  698]\n",
      "loss: 0.627822  [  450/  698]\n",
      "loss: 0.625156  [  540/  698]\n",
      "loss: 0.660446  [  630/  698]\n",
      "loss: 0.527096  [  544/  698]\n",
      "Training Loss (Epoch): 0.694168\n",
      "Validating...\n",
      "Validation Loss: 0.507213, Validation Accuracy: 84.00%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/15\n",
      "loss: 0.332001  [   90/  698]\n",
      "loss: 0.365619  [  180/  698]\n",
      "loss: 0.439215  [  270/  698]\n",
      "loss: 0.352525  [  360/  698]\n",
      "loss: 0.280020  [  450/  698]\n",
      "loss: 0.364061  [  540/  698]\n",
      "loss: 0.333868  [  630/  698]\n",
      "loss: 0.269945  [  544/  698]\n",
      "Training Loss (Epoch): 0.342157\n",
      "Validating...\n",
      "Validation Loss: 0.456671, Validation Accuracy: 81.71%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/15\n",
      "loss: 0.122803  [   90/  698]\n",
      "loss: 0.346758  [  180/  698]\n",
      "loss: 0.169681  [  270/  698]\n",
      "loss: 0.329086  [  360/  698]\n",
      "loss: 0.179148  [  450/  698]\n",
      "loss: 0.443675  [  540/  698]\n",
      "loss: 0.373788  [  630/  698]\n",
      "loss: 0.441023  [  544/  698]\n",
      "Training Loss (Epoch): 0.300745\n",
      "Validating...\n",
      "Validation Loss: 1.021612, Validation Accuracy: 76.57%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 6/15\n",
      "loss: 0.773511  [   90/  698]\n",
      "loss: 0.411807  [  180/  698]\n",
      "loss: 0.153449  [  270/  698]\n",
      "loss: 0.248577  [  360/  698]\n",
      "loss: 0.170918  [  450/  698]\n",
      "loss: 0.318692  [  540/  698]\n",
      "loss: 0.241892  [  630/  698]\n",
      "loss: 0.219804  [  544/  698]\n",
      "Training Loss (Epoch): 0.317331\n",
      "Validating...\n",
      "Validation Loss: 0.462758, Validation Accuracy: 84.57%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 7/15\n",
      "loss: 0.224319  [   90/  698]\n",
      "loss: 0.196696  [  180/  698]\n",
      "loss: 0.123849  [  270/  698]\n",
      "loss: 0.144549  [  360/  698]\n",
      "loss: 0.135715  [  450/  698]\n",
      "loss: 0.168360  [  540/  698]\n",
      "loss: 0.109546  [  630/  698]\n",
      "loss: 0.151072  [  544/  698]\n",
      "Training Loss (Epoch): 0.156763\n",
      "Validating...\n",
      "Validation Loss: 0.281303, Validation Accuracy: 91.43%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 8/15\n",
      "loss: 0.080420  [   90/  698]\n",
      "loss: 0.102088  [  180/  698]\n",
      "loss: 0.065485  [  270/  698]\n",
      "loss: 0.094950  [  360/  698]\n",
      "loss: 0.159980  [  450/  698]\n",
      "loss: 0.147653  [  540/  698]\n",
      "loss: 0.020625  [  630/  698]\n",
      "loss: 0.073551  [  544/  698]\n",
      "Training Loss (Epoch): 0.093094\n",
      "Validating...\n",
      "Validation Loss: 0.268882, Validation Accuracy: 90.86%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 9/15\n",
      "loss: 0.057179  [   90/  698]\n",
      "loss: 0.073815  [  180/  698]\n",
      "loss: 0.118509  [  270/  698]\n",
      "loss: 0.087422  [  360/  698]\n",
      "loss: 0.052085  [  450/  698]\n",
      "loss: 0.075050  [  540/  698]\n",
      "loss: 0.077292  [  630/  698]\n",
      "loss: 0.092140  [  544/  698]\n",
      "Training Loss (Epoch): 0.079187\n",
      "Validating...\n",
      "Validation Loss: 0.258852, Validation Accuracy: 90.86%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 10/15\n",
      "loss: 0.098763  [   90/  698]\n",
      "loss: 0.051517  [  180/  698]\n",
      "loss: 0.093193  [  270/  698]\n",
      "loss: 0.016688  [  360/  698]\n",
      "loss: 0.139906  [  450/  698]\n",
      "loss: 0.066498  [  540/  698]\n",
      "loss: 0.051865  [  630/  698]\n",
      "loss: 0.040064  [  544/  698]\n",
      "Training Loss (Epoch): 0.069812\n",
      "Validating...\n",
      "Validation Loss: 0.258060, Validation Accuracy: 90.86%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 11/15\n",
      "loss: 0.071945  [   90/  698]\n",
      "loss: 0.108716  [  180/  698]\n",
      "loss: 0.062962  [  270/  698]\n",
      "loss: 0.024086  [  360/  698]\n",
      "loss: 0.089690  [  450/  698]\n",
      "loss: 0.089074  [  540/  698]\n",
      "loss: 0.067767  [  630/  698]\n",
      "loss: 0.027732  [  544/  698]\n",
      "Training Loss (Epoch): 0.067747\n",
      "Validating...\n",
      "Validation Loss: 0.257564, Validation Accuracy: 90.86%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 12/15\n",
      "loss: 0.033944  [   90/  698]\n",
      "loss: 0.068110  [  180/  698]\n",
      "loss: 0.069033  [  270/  698]\n",
      "loss: 0.034838  [  360/  698]\n",
      "loss: 0.075768  [  450/  698]\n",
      "loss: 0.079464  [  540/  698]\n",
      "loss: 0.094615  [  630/  698]\n",
      "loss: 0.089404  [  544/  698]\n",
      "Training Loss (Epoch): 0.068147\n",
      "Validating...\n",
      "Validation Loss: 0.257165, Validation Accuracy: 90.86%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 13/15\n",
      "loss: 0.049088  [   90/  698]\n",
      "loss: 0.106456  [  180/  698]\n",
      "loss: 0.035278  [  270/  698]\n",
      "loss: 0.049703  [  360/  698]\n",
      "loss: 0.097254  [  450/  698]\n",
      "loss: 0.057434  [  540/  698]\n",
      "loss: 0.052751  [  630/  698]\n",
      "loss: 0.088704  [  544/  698]\n",
      "Training Loss (Epoch): 0.067083\n",
      "Validating...\n",
      "Validation Loss: 0.256894, Validation Accuracy: 90.86%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 14/15\n",
      "loss: 0.116797  [   90/  698]\n",
      "loss: 0.115141  [  180/  698]\n",
      "loss: 0.074608  [  270/  698]\n",
      "loss: 0.069359  [  360/  698]\n",
      "loss: 0.034609  [  450/  698]\n",
      "loss: 0.029661  [  540/  698]\n",
      "loss: 0.043504  [  630/  698]\n",
      "loss: 0.031731  [  544/  698]\n",
      "Training Loss (Epoch): 0.064426\n",
      "Validating...\n",
      "Validation Loss: 0.256932, Validation Accuracy: 90.86%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 15/15\n",
      "loss: 0.036510  [   90/  698]\n",
      "loss: 0.074725  [  180/  698]\n",
      "loss: 0.062198  [  270/  698]\n",
      "loss: 0.103019  [  360/  698]\n",
      "loss: 0.066873  [  450/  698]\n",
      "loss: 0.076963  [  540/  698]\n",
      "loss: 0.052384  [  630/  698]\n",
      "loss: 0.035659  [  544/  698]\n",
      "Training Loss (Epoch): 0.063541\n",
      "Validating...\n",
      "Validation Loss: 0.256734, Validation Accuracy: 90.86%\n",
      "Learning Rate: [1e-06]\n",
      "Processing Fold 2\n",
      "Epoch 1/15\n",
      "loss: 2.443139  [   90/  710]\n",
      "loss: 2.276179  [  180/  710]\n",
      "loss: 2.191487  [  270/  710]\n",
      "loss: 2.100919  [  360/  710]\n",
      "loss: 2.006347  [  450/  710]\n",
      "loss: 1.955083  [  540/  710]\n",
      "loss: 1.774778  [  630/  710]\n",
      "loss: 1.666142  [  640/  710]\n",
      "Training Loss (Epoch): 2.051759\n",
      "Validating...\n",
      "Validation Loss: 2.066530, Validation Accuracy: 38.76%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/15\n",
      "loss: 1.944418  [   90/  710]\n",
      "loss: 1.673120  [  180/  710]\n",
      "loss: 1.348299  [  270/  710]\n",
      "loss: 1.272131  [  360/  710]\n",
      "loss: 1.038607  [  450/  710]\n",
      "loss: 1.201054  [  540/  710]\n",
      "loss: 1.110910  [  630/  710]\n",
      "loss: 0.847998  [  640/  710]\n",
      "Training Loss (Epoch): 1.304567\n",
      "Validating...\n",
      "Validation Loss: 1.068405, Validation Accuracy: 61.80%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/15\n",
      "loss: 0.863400  [   90/  710]\n",
      "loss: 0.545261  [  180/  710]\n",
      "loss: 0.689475  [  270/  710]\n",
      "loss: 0.674026  [  360/  710]\n",
      "loss: 0.470626  [  450/  710]\n",
      "loss: 0.646172  [  540/  710]\n",
      "loss: 0.436628  [  630/  710]\n",
      "loss: 0.505174  [  640/  710]\n",
      "Training Loss (Epoch): 0.603845\n",
      "Validating...\n",
      "Validation Loss: 0.707195, Validation Accuracy: 75.84%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/15\n",
      "loss: 0.339971  [   90/  710]\n",
      "loss: 0.447166  [  180/  710]\n",
      "loss: 0.183547  [  270/  710]\n",
      "loss: 0.426595  [  360/  710]\n",
      "loss: 0.384546  [  450/  710]\n",
      "loss: 0.289891  [  540/  710]\n",
      "loss: 0.362835  [  630/  710]\n",
      "loss: 0.515021  [  640/  710]\n",
      "Training Loss (Epoch): 0.368697\n",
      "Validating...\n",
      "Validation Loss: 0.698337, Validation Accuracy: 80.34%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/15\n",
      "loss: 0.411068  [   90/  710]\n",
      "loss: 0.248294  [  180/  710]\n",
      "loss: 0.383087  [  270/  710]\n",
      "loss: 0.214134  [  360/  710]\n",
      "loss: 0.382902  [  450/  710]\n",
      "loss: 0.306811  [  540/  710]\n",
      "loss: 0.127021  [  630/  710]\n",
      "loss: 0.116716  [  640/  710]\n",
      "Training Loss (Epoch): 0.273754\n",
      "Validating...\n",
      "Validation Loss: 0.662922, Validation Accuracy: 82.58%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 6/15\n",
      "loss: 0.256183  [   90/  710]\n",
      "loss: 0.235224  [  180/  710]\n",
      "loss: 0.107808  [  270/  710]\n",
      "loss: 0.094112  [  360/  710]\n",
      "loss: 0.082376  [  450/  710]\n",
      "loss: 0.063772  [  540/  710]\n",
      "loss: 0.077594  [  630/  710]\n",
      "loss: 0.106899  [  640/  710]\n",
      "Training Loss (Epoch): 0.127996\n",
      "Validating...\n",
      "Validation Loss: 0.594331, Validation Accuracy: 87.08%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 7/15\n",
      "loss: 0.042288  [   90/  710]\n",
      "loss: 0.136553  [  180/  710]\n",
      "loss: 0.112857  [  270/  710]\n",
      "loss: 0.078620  [  360/  710]\n",
      "loss: 0.036697  [  450/  710]\n",
      "loss: 0.118975  [  540/  710]\n",
      "loss: 0.039653  [  630/  710]\n",
      "loss: 0.083004  [  640/  710]\n",
      "Training Loss (Epoch): 0.081081\n",
      "Validating...\n",
      "Validation Loss: 0.567936, Validation Accuracy: 87.64%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 8/15\n",
      "loss: 0.053805  [   90/  710]\n",
      "loss: 0.044022  [  180/  710]\n",
      "loss: 0.048575  [  270/  710]\n",
      "loss: 0.088799  [  360/  710]\n",
      "loss: 0.083912  [  450/  710]\n",
      "loss: 0.008089  [  540/  710]\n",
      "loss: 0.033595  [  630/  710]\n",
      "loss: 0.063575  [  640/  710]\n",
      "Training Loss (Epoch): 0.053046\n",
      "Validating...\n",
      "Validation Loss: 0.610055, Validation Accuracy: 88.76%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 9/15\n",
      "loss: 0.040671  [   90/  710]\n",
      "loss: 0.018026  [  180/  710]\n",
      "loss: 0.021782  [  270/  710]\n",
      "loss: 0.064644  [  360/  710]\n",
      "loss: 0.018351  [  450/  710]\n",
      "loss: 0.043702  [  540/  710]\n",
      "loss: 0.038476  [  630/  710]\n",
      "loss: 0.046258  [  640/  710]\n",
      "Training Loss (Epoch): 0.036489\n",
      "Validating...\n",
      "Validation Loss: 0.619692, Validation Accuracy: 88.76%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 10/15\n",
      "loss: 0.022937  [   90/  710]\n",
      "loss: 0.032771  [  180/  710]\n",
      "loss: 0.040477  [  270/  710]\n",
      "loss: 0.008192  [  360/  710]\n",
      "loss: 0.039157  [  450/  710]\n",
      "loss: 0.025770  [  540/  710]\n",
      "loss: 0.062405  [  630/  710]\n",
      "loss: 0.033517  [  640/  710]\n",
      "Training Loss (Epoch): 0.033153\n",
      "Validating...\n",
      "Validation Loss: 0.606512, Validation Accuracy: 88.76%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 11/15\n",
      "loss: 0.011264  [   90/  710]\n",
      "loss: 0.078034  [  180/  710]\n",
      "loss: 0.015075  [  270/  710]\n",
      "loss: 0.030717  [  360/  710]\n",
      "loss: 0.012831  [  450/  710]\n",
      "loss: 0.054484  [  540/  710]\n",
      "loss: 0.014255  [  630/  710]\n",
      "loss: 0.062176  [  640/  710]\n",
      "Training Loss (Epoch): 0.034854\n",
      "Validating...\n",
      "Validation Loss: 0.601812, Validation Accuracy: 89.33%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 12/15\n",
      "loss: 0.030838  [   90/  710]\n",
      "loss: 0.025523  [  180/  710]\n",
      "loss: 0.014256  [  270/  710]\n",
      "loss: 0.052108  [  360/  710]\n",
      "loss: 0.039557  [  450/  710]\n",
      "loss: 0.031027  [  540/  710]\n",
      "loss: 0.029352  [  630/  710]\n",
      "loss: 0.100306  [  640/  710]\n",
      "Training Loss (Epoch): 0.040371\n",
      "Validating...\n",
      "Validation Loss: 0.594100, Validation Accuracy: 89.33%\n",
      "Learning Rate: [1e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 3\n",
      "Epoch 1/15\n",
      "loss: 2.360618  [   90/  740]\n",
      "loss: 2.332874  [  180/  740]\n",
      "loss: 2.245872  [  270/  740]\n",
      "loss: 2.087242  [  360/  740]\n",
      "loss: 2.010241  [  450/  740]\n",
      "loss: 1.967912  [  540/  740]\n",
      "loss: 1.853312  [  630/  740]\n",
      "loss: 1.636669  [  720/  740]\n",
      "loss: 1.906139  [  180/  740]\n",
      "Training Loss (Epoch): 2.044542\n",
      "Validating...\n",
      "Validation Loss: 2.008178, Validation Accuracy: 37.30%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/15\n",
      "loss: 1.850137  [   90/  740]\n",
      "loss: 1.757856  [  180/  740]\n",
      "loss: 1.358000  [  270/  740]\n",
      "loss: 1.241830  [  360/  740]\n",
      "loss: 1.417093  [  450/  740]\n",
      "loss: 1.113138  [  540/  740]\n",
      "loss: 1.141857  [  630/  740]\n",
      "loss: 0.971038  [  720/  740]\n",
      "loss: 1.010716  [  180/  740]\n",
      "Training Loss (Epoch): 1.317963\n",
      "Validating...\n",
      "Validation Loss: 1.115641, Validation Accuracy: 59.46%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/15\n",
      "loss: 0.947996  [   90/  740]\n",
      "loss: 1.338436  [  180/  740]\n",
      "loss: 0.925509  [  270/  740]\n",
      "loss: 1.055461  [  360/  740]\n",
      "loss: 0.857221  [  450/  740]\n",
      "loss: 0.951635  [  540/  740]\n",
      "loss: 0.849798  [  630/  740]\n",
      "loss: 0.543490  [  720/  740]\n",
      "loss: 1.326626  [  180/  740]\n",
      "Training Loss (Epoch): 0.977353\n",
      "Validating...\n",
      "Validation Loss: 0.808888, Validation Accuracy: 75.14%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/15\n",
      "loss: 0.693774  [   90/  740]\n",
      "loss: 0.848031  [  180/  740]\n",
      "loss: 0.855666  [  270/  740]\n",
      "loss: 0.626014  [  360/  740]\n",
      "loss: 0.717292  [  450/  740]\n",
      "loss: 0.655703  [  540/  740]\n",
      "loss: 0.433856  [  630/  740]\n",
      "loss: 0.333410  [  720/  740]\n",
      "loss: 0.619423  [  180/  740]\n",
      "Training Loss (Epoch): 0.642574\n",
      "Validating...\n",
      "Validation Loss: 0.850720, Validation Accuracy: 76.22%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/15\n",
      "loss: 0.429307  [   90/  740]\n",
      "loss: 0.267123  [  180/  740]\n",
      "loss: 0.428862  [  270/  740]\n",
      "loss: 0.671538  [  360/  740]\n",
      "loss: 0.562766  [  450/  740]\n",
      "loss: 0.354334  [  540/  740]\n",
      "loss: 0.548816  [  630/  740]\n",
      "loss: 0.462563  [  720/  740]\n",
      "loss: 0.436589  [  180/  740]\n",
      "Training Loss (Epoch): 0.462433\n",
      "Validating...\n",
      "Validation Loss: 0.620856, Validation Accuracy: 79.46%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 6/15\n",
      "loss: 0.384720  [   90/  740]\n",
      "loss: 0.371031  [  180/  740]\n",
      "loss: 0.443213  [  270/  740]\n",
      "loss: 0.191397  [  360/  740]\n",
      "loss: 0.230323  [  450/  740]\n",
      "loss: 0.318615  [  540/  740]\n",
      "loss: 0.208318  [  630/  740]\n",
      "loss: 0.305032  [  720/  740]\n",
      "loss: 0.330748  [  180/  740]\n",
      "Training Loss (Epoch): 0.309266\n",
      "Validating...\n",
      "Validation Loss: 0.495226, Validation Accuracy: 80.00%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 7/15\n",
      "loss: 0.294687  [   90/  740]\n",
      "loss: 0.156714  [  180/  740]\n",
      "loss: 0.134888  [  270/  740]\n",
      "loss: 0.252730  [  360/  740]\n",
      "loss: 0.371843  [  450/  740]\n",
      "loss: 0.175660  [  540/  740]\n",
      "loss: 0.145927  [  630/  740]\n",
      "loss: 0.229538  [  720/  740]\n",
      "loss: 0.163250  [  180/  740]\n",
      "Training Loss (Epoch): 0.213915\n",
      "Validating...\n",
      "Validation Loss: 0.399783, Validation Accuracy: 83.78%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 8/15\n",
      "loss: 0.202178  [   90/  740]\n",
      "loss: 0.179748  [  180/  740]\n",
      "loss: 0.169115  [  270/  740]\n",
      "loss: 0.129897  [  360/  740]\n",
      "loss: 0.139315  [  450/  740]\n",
      "loss: 0.220432  [  540/  740]\n",
      "loss: 0.163761  [  630/  740]\n",
      "loss: 0.208081  [  720/  740]\n",
      "loss: 0.058371  [  180/  740]\n",
      "Training Loss (Epoch): 0.163433\n",
      "Validating...\n",
      "Validation Loss: 0.388473, Validation Accuracy: 85.95%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 9/15\n",
      "loss: 0.185467  [   90/  740]\n",
      "loss: 0.148828  [  180/  740]\n",
      "loss: 0.115825  [  270/  740]\n",
      "loss: 0.110874  [  360/  740]\n",
      "loss: 0.146558  [  450/  740]\n",
      "loss: 0.214633  [  540/  740]\n",
      "loss: 0.138493  [  630/  740]\n",
      "loss: 0.247318  [  720/  740]\n",
      "loss: 0.322504  [  180/  740]\n",
      "Training Loss (Epoch): 0.181167\n",
      "Validating...\n",
      "Validation Loss: 0.395728, Validation Accuracy: 85.95%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 10/15\n",
      "loss: 0.116147  [   90/  740]\n",
      "loss: 0.069154  [  180/  740]\n",
      "loss: 0.204885  [  270/  740]\n",
      "loss: 0.130056  [  360/  740]\n",
      "loss: 0.191165  [  450/  740]\n",
      "loss: 0.197353  [  540/  740]\n",
      "loss: 0.136476  [  630/  740]\n",
      "loss: 0.112408  [  720/  740]\n",
      "loss: 0.100219  [  180/  740]\n",
      "Training Loss (Epoch): 0.139762\n",
      "Validating...\n",
      "Validation Loss: 0.419046, Validation Accuracy: 85.41%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 11/15\n",
      "loss: 0.136292  [   90/  740]\n",
      "loss: 0.111087  [  180/  740]\n",
      "loss: 0.130787  [  270/  740]\n",
      "loss: 0.127989  [  360/  740]\n",
      "loss: 0.090446  [  450/  740]\n",
      "loss: 0.107217  [  540/  740]\n",
      "loss: 0.159696  [  630/  740]\n",
      "loss: 0.292413  [  720/  740]\n",
      "loss: 0.069625  [  180/  740]\n",
      "Training Loss (Epoch): 0.136173\n",
      "Validating...\n",
      "Validation Loss: 0.415333, Validation Accuracy: 85.41%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 12/15\n",
      "loss: 0.088849  [   90/  740]\n",
      "loss: 0.194619  [  180/  740]\n",
      "loss: 0.086416  [  270/  740]\n",
      "loss: 0.161168  [  360/  740]\n",
      "loss: 0.262522  [  450/  740]\n",
      "loss: 0.156834  [  540/  740]\n",
      "loss: 0.082479  [  630/  740]\n",
      "loss: 0.174133  [  720/  740]\n",
      "loss: 0.014500  [  180/  740]\n",
      "Training Loss (Epoch): 0.135725\n",
      "Validating...\n",
      "Validation Loss: 0.413256, Validation Accuracy: 85.41%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 13/15\n",
      "loss: 0.137384  [   90/  740]\n",
      "loss: 0.261256  [  180/  740]\n",
      "loss: 0.067928  [  270/  740]\n",
      "loss: 0.124891  [  360/  740]\n",
      "loss: 0.064689  [  450/  740]\n",
      "loss: 0.173185  [  540/  740]\n",
      "loss: 0.063921  [  630/  740]\n",
      "loss: 0.187212  [  720/  740]\n",
      "loss: 0.064702  [  180/  740]\n",
      "Training Loss (Epoch): 0.127241\n",
      "Validating...\n",
      "Validation Loss: 0.410576, Validation Accuracy: 85.41%\n",
      "Learning Rate: [1e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 4\n",
      "Epoch 1/15\n",
      "loss: 2.422955  [   90/  792]\n",
      "loss: 2.267026  [  180/  792]\n",
      "loss: 2.099367  [  270/  792]\n",
      "loss: 2.150189  [  360/  792]\n",
      "loss: 2.109122  [  450/  792]\n",
      "loss: 2.045885  [  540/  792]\n",
      "loss: 1.868356  [  630/  792]\n",
      "loss: 1.852031  [  720/  792]\n",
      "loss: 1.854309  [  648/  792]\n",
      "Training Loss (Epoch): 2.074360\n",
      "Validating...\n",
      "Validation Loss: 1.891090, Validation Accuracy: 50.00%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/15\n",
      "loss: 1.922262  [   90/  792]\n",
      "loss: 1.648977  [  180/  792]\n",
      "loss: 1.448007  [  270/  792]\n",
      "loss: 1.408338  [  360/  792]\n",
      "loss: 1.466872  [  450/  792]\n",
      "loss: 1.281514  [  540/  792]\n",
      "loss: 1.110541  [  630/  792]\n",
      "loss: 1.166318  [  720/  792]\n",
      "loss: 1.103568  [  648/  792]\n",
      "Training Loss (Epoch): 1.395155\n",
      "Validating...\n",
      "Validation Loss: 0.876814, Validation Accuracy: 70.20%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/15\n",
      "loss: 0.621131  [   90/  792]\n",
      "loss: 0.990786  [  180/  792]\n",
      "loss: 0.846473  [  270/  792]\n",
      "loss: 0.841927  [  360/  792]\n",
      "loss: 0.608892  [  450/  792]\n",
      "loss: 0.834938  [  540/  792]\n",
      "loss: 0.832273  [  630/  792]\n",
      "loss: 0.674359  [  720/  792]\n",
      "loss: 0.721860  [  648/  792]\n",
      "Training Loss (Epoch): 0.774738\n",
      "Validating...\n",
      "Validation Loss: 0.931476, Validation Accuracy: 75.76%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/15\n",
      "loss: 0.653932  [   90/  792]\n",
      "loss: 0.673560  [  180/  792]\n",
      "loss: 0.360598  [  270/  792]\n",
      "loss: 0.470708  [  360/  792]\n",
      "loss: 0.575085  [  450/  792]\n",
      "loss: 0.520011  [  540/  792]\n",
      "loss: 0.458700  [  630/  792]\n",
      "loss: 0.474027  [  720/  792]\n",
      "loss: 0.494567  [  648/  792]\n",
      "Training Loss (Epoch): 0.520132\n",
      "Validating...\n",
      "Validation Loss: 0.951248, Validation Accuracy: 74.75%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 5/15\n",
      "loss: 0.426664  [   90/  792]\n",
      "loss: 0.391514  [  180/  792]\n",
      "loss: 0.291774  [  270/  792]\n",
      "loss: 0.363752  [  360/  792]\n",
      "loss: 0.201917  [  450/  792]\n",
      "loss: 0.337443  [  540/  792]\n",
      "loss: 0.347572  [  630/  792]\n",
      "loss: 0.188887  [  720/  792]\n",
      "loss: 0.195290  [  648/  792]\n",
      "Training Loss (Epoch): 0.304979\n",
      "Validating...\n",
      "Validation Loss: 0.692420, Validation Accuracy: 85.86%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 6/15\n",
      "loss: 0.265406  [   90/  792]\n",
      "loss: 0.239041  [  180/  792]\n",
      "loss: 0.228102  [  270/  792]\n",
      "loss: 0.161707  [  360/  792]\n",
      "loss: 0.144964  [  450/  792]\n",
      "loss: 0.128315  [  540/  792]\n",
      "loss: 0.130077  [  630/  792]\n",
      "loss: 0.257589  [  720/  792]\n",
      "loss: 0.222269  [  648/  792]\n",
      "Training Loss (Epoch): 0.197497\n",
      "Validating...\n",
      "Validation Loss: 0.568375, Validation Accuracy: 86.87%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 7/15\n",
      "loss: 0.134617  [   90/  792]\n",
      "loss: 0.166522  [  180/  792]\n",
      "loss: 0.102799  [  270/  792]\n",
      "loss: 0.143381  [  360/  792]\n",
      "loss: 0.105240  [  450/  792]\n",
      "loss: 0.111479  [  540/  792]\n",
      "loss: 0.185757  [  630/  792]\n",
      "loss: 0.153071  [  720/  792]\n",
      "loss: 0.072919  [  648/  792]\n",
      "Training Loss (Epoch): 0.130643\n",
      "Validating...\n",
      "Validation Loss: 0.771438, Validation Accuracy: 85.86%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 8/15\n",
      "loss: 0.109228  [   90/  792]\n",
      "loss: 0.070746  [  180/  792]\n",
      "loss: 0.064944  [  270/  792]\n",
      "loss: 0.129775  [  360/  792]\n",
      "loss: 0.052441  [  450/  792]\n",
      "loss: 0.076244  [  540/  792]\n",
      "loss: 0.053823  [  630/  792]\n",
      "loss: 0.132674  [  720/  792]\n",
      "loss: 0.081018  [  648/  792]\n",
      "Training Loss (Epoch): 0.085655\n",
      "Validating...\n",
      "Validation Loss: 0.746848, Validation Accuracy: 87.88%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 9/15\n",
      "loss: 0.071080  [   90/  792]\n",
      "loss: 0.043711  [  180/  792]\n",
      "loss: 0.047395  [  270/  792]\n",
      "loss: 0.058071  [  360/  792]\n",
      "loss: 0.069112  [  450/  792]\n",
      "loss: 0.088221  [  540/  792]\n",
      "loss: 0.136611  [  630/  792]\n",
      "loss: 0.041264  [  720/  792]\n",
      "loss: 0.064139  [  648/  792]\n",
      "Training Loss (Epoch): 0.068845\n",
      "Validating...\n",
      "Validation Loss: 0.693211, Validation Accuracy: 87.37%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 10/15\n",
      "loss: 0.137789  [   90/  792]\n",
      "loss: 0.054638  [  180/  792]\n",
      "loss: 0.058690  [  270/  792]\n",
      "loss: 0.034195  [  360/  792]\n",
      "loss: 0.086569  [  450/  792]\n",
      "loss: 0.047461  [  540/  792]\n",
      "loss: 0.048937  [  630/  792]\n",
      "loss: 0.035840  [  720/  792]\n",
      "loss: 0.026860  [  648/  792]\n",
      "Training Loss (Epoch): 0.058998\n",
      "Validating...\n",
      "Validation Loss: 0.691820, Validation Accuracy: 87.37%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 11/15\n",
      "loss: 0.051860  [   90/  792]\n",
      "loss: 0.038414  [  180/  792]\n",
      "loss: 0.062403  [  270/  792]\n",
      "loss: 0.041045  [  360/  792]\n",
      "loss: 0.070560  [  450/  792]\n",
      "loss: 0.027194  [  540/  792]\n",
      "loss: 0.065807  [  630/  792]\n",
      "loss: 0.083649  [  720/  792]\n",
      "loss: 0.084468  [  648/  792]\n",
      "Training Loss (Epoch): 0.058378\n",
      "Validating...\n",
      "Validation Loss: 0.690199, Validation Accuracy: 88.38%\n",
      "Learning Rate: [1e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 5\n",
      "Epoch 1/15\n",
      "loss: 2.430526  [   90/  748]\n",
      "loss: 2.315189  [  180/  748]\n",
      "loss: 2.294724  [  270/  748]\n",
      "loss: 2.173197  [  360/  748]\n",
      "loss: 2.041590  [  450/  748]\n",
      "loss: 2.022644  [  540/  748]\n",
      "loss: 1.974267  [  630/  748]\n",
      "loss: 1.804586  [  720/  748]\n",
      "loss: 1.751970  [  252/  748]\n",
      "Training Loss (Epoch): 2.089855\n",
      "Validating...\n",
      "Validation Loss: 2.017685, Validation Accuracy: 38.83%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/15\n",
      "loss: 1.898741  [   90/  748]\n",
      "loss: 1.643528  [  180/  748]\n",
      "loss: 1.561715  [  270/  748]\n",
      "loss: 1.395692  [  360/  748]\n",
      "loss: 1.105849  [  450/  748]\n",
      "loss: 1.146963  [  540/  748]\n",
      "loss: 1.392766  [  630/  748]\n",
      "loss: 1.125190  [  720/  748]\n",
      "loss: 0.964984  [  252/  748]\n",
      "Training Loss (Epoch): 1.359492\n",
      "Validating...\n",
      "Validation Loss: 1.334015, Validation Accuracy: 62.23%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/15\n",
      "loss: 1.168784  [   90/  748]\n",
      "loss: 1.028620  [  180/  748]\n",
      "loss: 0.812078  [  270/  748]\n",
      "loss: 0.762518  [  360/  748]\n",
      "loss: 0.713347  [  450/  748]\n",
      "loss: 0.692006  [  540/  748]\n",
      "loss: 0.550896  [  630/  748]\n",
      "loss: 0.591969  [  720/  748]\n",
      "loss: 0.787285  [  252/  748]\n",
      "Training Loss (Epoch): 0.789723\n",
      "Validating...\n",
      "Validation Loss: 1.555087, Validation Accuracy: 55.32%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/15\n",
      "loss: 0.976136  [   90/  748]\n",
      "loss: 0.721755  [  180/  748]\n",
      "loss: 1.036797  [  270/  748]\n",
      "loss: 0.774013  [  360/  748]\n",
      "loss: 0.652796  [  450/  748]\n",
      "loss: 0.683069  [  540/  748]\n",
      "loss: 0.947406  [  630/  748]\n",
      "loss: 0.680973  [  720/  748]\n",
      "loss: 0.682659  [  252/  748]\n",
      "Training Loss (Epoch): 0.795067\n",
      "Validating...\n",
      "Validation Loss: 1.133778, Validation Accuracy: 71.81%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 5/15\n",
      "loss: 0.541033  [   90/  748]\n",
      "loss: 0.409935  [  180/  748]\n",
      "loss: 0.426585  [  270/  748]\n",
      "loss: 0.506287  [  360/  748]\n",
      "loss: 0.361903  [  450/  748]\n",
      "loss: 0.502085  [  540/  748]\n",
      "loss: 0.454509  [  630/  748]\n",
      "loss: 0.404267  [  720/  748]\n",
      "loss: 0.279538  [  252/  748]\n",
      "Training Loss (Epoch): 0.431794\n",
      "Validating...\n",
      "Validation Loss: 0.868884, Validation Accuracy: 75.53%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 6/15\n",
      "loss: 0.533910  [   90/  748]\n",
      "loss: 0.421528  [  180/  748]\n",
      "loss: 0.305584  [  270/  748]\n",
      "loss: 0.250916  [  360/  748]\n",
      "loss: 0.341131  [  450/  748]\n",
      "loss: 0.376422  [  540/  748]\n",
      "loss: 0.292034  [  630/  748]\n",
      "loss: 0.190600  [  720/  748]\n",
      "loss: 0.302228  [  252/  748]\n",
      "Training Loss (Epoch): 0.334928\n",
      "Validating...\n",
      "Validation Loss: 0.720455, Validation Accuracy: 80.32%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 7/15\n",
      "loss: 0.286776  [   90/  748]\n",
      "loss: 0.214597  [  180/  748]\n",
      "loss: 0.271975  [  270/  748]\n",
      "loss: 0.215728  [  360/  748]\n",
      "loss: 0.243086  [  450/  748]\n",
      "loss: 0.282655  [  540/  748]\n",
      "loss: 0.160262  [  630/  748]\n",
      "loss: 0.284822  [  720/  748]\n",
      "loss: 0.450206  [  252/  748]\n",
      "Training Loss (Epoch): 0.267790\n",
      "Validating...\n",
      "Validation Loss: 0.607694, Validation Accuracy: 82.45%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 8/15\n",
      "loss: 0.208094  [   90/  748]\n",
      "loss: 0.168718  [  180/  748]\n",
      "loss: 0.193145  [  270/  748]\n",
      "loss: 0.285594  [  360/  748]\n",
      "loss: 0.277384  [  450/  748]\n",
      "loss: 0.134699  [  540/  748]\n",
      "loss: 0.213171  [  630/  748]\n",
      "loss: 0.158861  [  720/  748]\n",
      "loss: 0.283710  [  252/  748]\n",
      "Training Loss (Epoch): 0.213708\n",
      "Validating...\n",
      "Validation Loss: 0.618235, Validation Accuracy: 81.38%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 9/15\n",
      "loss: 0.091475  [   90/  748]\n",
      "loss: 0.207737  [  180/  748]\n",
      "loss: 0.258400  [  270/  748]\n",
      "loss: 0.232267  [  360/  748]\n",
      "loss: 0.185904  [  450/  748]\n",
      "loss: 0.231152  [  540/  748]\n",
      "loss: 0.201772  [  630/  748]\n",
      "loss: 0.166684  [  720/  748]\n",
      "loss: 0.030747  [  252/  748]\n",
      "Training Loss (Epoch): 0.178460\n",
      "Validating...\n",
      "Validation Loss: 0.585484, Validation Accuracy: 82.98%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 10/15\n",
      "loss: 0.168129  [   90/  748]\n",
      "loss: 0.099211  [  180/  748]\n",
      "loss: 0.176775  [  270/  748]\n",
      "loss: 0.150664  [  360/  748]\n",
      "loss: 0.196385  [  450/  748]\n",
      "loss: 0.145969  [  540/  748]\n",
      "loss: 0.266031  [  630/  748]\n",
      "loss: 0.240650  [  720/  748]\n",
      "loss: 0.257048  [  252/  748]\n",
      "Training Loss (Epoch): 0.188985\n",
      "Validating...\n",
      "Validation Loss: 0.576854, Validation Accuracy: 82.98%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 11/15\n",
      "loss: 0.300700  [   90/  748]\n",
      "loss: 0.196254  [  180/  748]\n",
      "loss: 0.118834  [  270/  748]\n",
      "loss: 0.164291  [  360/  748]\n",
      "loss: 0.119907  [  450/  748]\n",
      "loss: 0.169175  [  540/  748]\n",
      "loss: 0.164990  [  630/  748]\n",
      "loss: 0.175248  [  720/  748]\n",
      "loss: 0.362966  [  252/  748]\n",
      "Training Loss (Epoch): 0.196929\n",
      "Validating...\n",
      "Validation Loss: 0.559994, Validation Accuracy: 83.51%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 12/15\n",
      "loss: 0.177515  [   90/  748]\n",
      "loss: 0.109535  [  180/  748]\n",
      "loss: 0.192034  [  270/  748]\n",
      "loss: 0.218904  [  360/  748]\n",
      "loss: 0.081233  [  450/  748]\n",
      "loss: 0.232988  [  540/  748]\n",
      "loss: 0.194018  [  630/  748]\n",
      "loss: 0.202244  [  720/  748]\n",
      "loss: 0.196445  [  252/  748]\n",
      "Training Loss (Epoch): 0.178324\n",
      "Validating...\n",
      "Validation Loss: 0.558983, Validation Accuracy: 83.51%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 13/15\n",
      "loss: 0.228951  [   90/  748]\n",
      "loss: 0.172363  [  180/  748]\n",
      "loss: 0.085330  [  270/  748]\n",
      "loss: 0.186937  [  360/  748]\n",
      "loss: 0.208558  [  450/  748]\n",
      "loss: 0.172962  [  540/  748]\n",
      "loss: 0.177000  [  630/  748]\n",
      "loss: 0.166605  [  720/  748]\n",
      "loss: 0.382433  [  252/  748]\n",
      "Training Loss (Epoch): 0.197904\n",
      "Validating...\n",
      "Validation Loss: 0.559203, Validation Accuracy: 83.51%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 14/15\n",
      "loss: 0.170423  [   90/  748]\n",
      "loss: 0.155692  [  180/  748]\n",
      "loss: 0.127763  [  270/  748]\n",
      "loss: 0.196496  [  360/  748]\n",
      "loss: 0.147164  [  450/  748]\n",
      "loss: 0.219845  [  540/  748]\n",
      "loss: 0.165453  [  630/  748]\n",
      "loss: 0.200757  [  720/  748]\n",
      "loss: 0.196360  [  252/  748]\n",
      "Training Loss (Epoch): 0.175550\n",
      "Validating...\n",
      "Validation Loss: 0.560992, Validation Accuracy: 84.57%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 15/15\n",
      "loss: 0.145136  [   90/  748]\n",
      "loss: 0.152114  [  180/  748]\n",
      "loss: 0.177289  [  270/  748]\n",
      "loss: 0.183988  [  360/  748]\n",
      "loss: 0.237704  [  450/  748]\n",
      "loss: 0.160903  [  540/  748]\n",
      "loss: 0.102581  [  630/  748]\n",
      "loss: 0.243444  [  720/  748]\n",
      "loss: 0.103030  [  252/  748]\n",
      "Training Loss (Epoch): 0.167354\n",
      "Validating...\n",
      "Validation Loss: 0.562459, Validation Accuracy: 84.57%\n",
      "Learning Rate: [1e-06]\n",
      "Processing Fold 6\n",
      "Epoch 1/15\n",
      "loss: 2.304015  [   90/  658]\n",
      "loss: 2.326263  [  180/  658]\n",
      "loss: 2.189825  [  270/  658]\n",
      "loss: 2.174605  [  360/  658]\n",
      "loss: 2.105549  [  450/  658]\n",
      "loss: 1.805357  [  540/  658]\n",
      "loss: 1.886695  [  630/  658]\n",
      "loss: 1.749699  [  224/  658]\n",
      "Training Loss (Epoch): 2.067751\n",
      "Validating...\n",
      "Validation Loss: 2.086288, Validation Accuracy: 30.91%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/15\n",
      "loss: 2.038601  [   90/  658]\n",
      "loss: 1.855995  [  180/  658]\n",
      "loss: 1.602199  [  270/  658]\n",
      "loss: 1.031023  [  360/  658]\n",
      "loss: 1.332232  [  450/  658]\n",
      "loss: 1.453644  [  540/  658]\n",
      "loss: 1.784248  [  630/  658]\n",
      "loss: 1.571750  [  224/  658]\n",
      "Training Loss (Epoch): 1.583712\n",
      "Validating...\n",
      "Validation Loss: 1.321710, Validation Accuracy: 54.55%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/15\n",
      "loss: 1.222480  [   90/  658]\n",
      "loss: 1.149760  [  180/  658]\n",
      "loss: 1.056221  [  270/  658]\n",
      "loss: 0.955626  [  360/  658]\n",
      "loss: 0.997683  [  450/  658]\n",
      "loss: 1.134986  [  540/  658]\n",
      "loss: 0.805139  [  630/  658]\n",
      "loss: 0.853774  [  224/  658]\n",
      "Training Loss (Epoch): 1.021958\n",
      "Validating...\n",
      "Validation Loss: 0.931152, Validation Accuracy: 68.48%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/15\n",
      "loss: 0.690199  [   90/  658]\n",
      "loss: 0.544791  [  180/  658]\n",
      "loss: 0.594750  [  270/  658]\n",
      "loss: 0.812586  [  360/  658]\n",
      "loss: 0.942200  [  450/  658]\n",
      "loss: 0.577713  [  540/  658]\n",
      "loss: 0.440071  [  630/  658]\n",
      "loss: 0.628337  [  224/  658]\n",
      "Training Loss (Epoch): 0.653831\n",
      "Validating...\n",
      "Validation Loss: 0.657255, Validation Accuracy: 75.15%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/15\n",
      "loss: 0.600977  [   90/  658]\n",
      "loss: 0.537837  [  180/  658]\n",
      "loss: 0.448225  [  270/  658]\n",
      "loss: 0.373455  [  360/  658]\n",
      "loss: 0.326491  [  450/  658]\n",
      "loss: 0.435947  [  540/  658]\n",
      "loss: 0.271340  [  630/  658]\n",
      "loss: 0.313125  [  224/  658]\n",
      "Training Loss (Epoch): 0.413425\n",
      "Validating...\n",
      "Validation Loss: 0.503369, Validation Accuracy: 82.42%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/15\n",
      "loss: 0.337090  [   90/  658]\n",
      "loss: 0.311866  [  180/  658]\n",
      "loss: 0.669518  [  270/  658]\n",
      "loss: 0.336530  [  360/  658]\n",
      "loss: 0.425903  [  450/  658]\n",
      "loss: 0.431976  [  540/  658]\n",
      "loss: 0.331540  [  630/  658]\n",
      "loss: 0.410634  [  224/  658]\n",
      "Training Loss (Epoch): 0.406882\n",
      "Validating...\n",
      "Validation Loss: 0.622353, Validation Accuracy: 76.36%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 7/15\n",
      "loss: 0.395209  [   90/  658]\n",
      "loss: 0.367258  [  180/  658]\n",
      "loss: 0.436134  [  270/  658]\n",
      "loss: 0.456668  [  360/  658]\n",
      "loss: 0.202490  [  450/  658]\n",
      "loss: 0.234965  [  540/  658]\n",
      "loss: 0.143720  [  630/  658]\n",
      "loss: 0.174158  [  224/  658]\n",
      "Training Loss (Epoch): 0.301325\n",
      "Validating...\n",
      "Validation Loss: 0.531598, Validation Accuracy: 81.21%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 8/15\n",
      "loss: 0.191135  [   90/  658]\n",
      "loss: 0.293451  [  180/  658]\n",
      "loss: 0.230772  [  270/  658]\n",
      "loss: 0.193315  [  360/  658]\n",
      "loss: 0.198921  [  450/  658]\n",
      "loss: 0.155192  [  540/  658]\n",
      "loss: 0.145105  [  630/  658]\n",
      "loss: 0.267196  [  224/  658]\n",
      "Training Loss (Epoch): 0.209386\n",
      "Validating...\n",
      "Validation Loss: 0.409650, Validation Accuracy: 86.06%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 9/15\n",
      "loss: 0.098457  [   90/  658]\n",
      "loss: 0.148444  [  180/  658]\n",
      "loss: 0.209273  [  270/  658]\n",
      "loss: 0.170962  [  360/  658]\n",
      "loss: 0.155624  [  450/  658]\n",
      "loss: 0.111667  [  540/  658]\n",
      "loss: 0.085440  [  630/  658]\n",
      "loss: 0.346164  [  224/  658]\n",
      "Training Loss (Epoch): 0.165754\n",
      "Validating...\n",
      "Validation Loss: 0.453140, Validation Accuracy: 86.67%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 10/15\n",
      "loss: 0.128598  [   90/  658]\n",
      "loss: 0.087787  [  180/  658]\n",
      "loss: 0.163309  [  270/  658]\n",
      "loss: 0.112299  [  360/  658]\n",
      "loss: 0.105092  [  450/  658]\n",
      "loss: 0.116713  [  540/  658]\n",
      "loss: 0.224643  [  630/  658]\n",
      "loss: 0.055824  [  224/  658]\n",
      "Training Loss (Epoch): 0.124283\n",
      "Validating...\n",
      "Validation Loss: 0.417889, Validation Accuracy: 86.67%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 11/15\n",
      "loss: 0.121037  [   90/  658]\n",
      "loss: 0.150483  [  180/  658]\n",
      "loss: 0.188074  [  270/  658]\n",
      "loss: 0.107637  [  360/  658]\n",
      "loss: 0.138905  [  450/  658]\n",
      "loss: 0.066525  [  540/  658]\n",
      "loss: 0.114363  [  630/  658]\n",
      "loss: 0.240663  [  224/  658]\n",
      "Training Loss (Epoch): 0.140961\n",
      "Validating...\n",
      "Validation Loss: 0.395217, Validation Accuracy: 87.27%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 12/15\n",
      "loss: 0.092523  [   90/  658]\n",
      "loss: 0.128473  [  180/  658]\n",
      "loss: 0.080720  [  270/  658]\n",
      "loss: 0.096621  [  360/  658]\n",
      "loss: 0.117708  [  450/  658]\n",
      "loss: 0.160230  [  540/  658]\n",
      "loss: 0.096892  [  630/  658]\n",
      "loss: 0.143200  [  224/  658]\n",
      "Training Loss (Epoch): 0.114546\n",
      "Validating...\n",
      "Validation Loss: 0.396224, Validation Accuracy: 87.27%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 13/15\n",
      "loss: 0.067061  [   90/  658]\n",
      "loss: 0.134534  [  180/  658]\n",
      "loss: 0.167626  [  270/  658]\n",
      "loss: 0.097444  [  360/  658]\n",
      "loss: 0.044265  [  450/  658]\n",
      "loss: 0.107830  [  540/  658]\n",
      "loss: 0.140594  [  630/  658]\n",
      "loss: 0.192932  [  224/  658]\n",
      "Training Loss (Epoch): 0.119036\n",
      "Validating...\n",
      "Validation Loss: 0.397193, Validation Accuracy: 87.27%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 14/15\n",
      "loss: 0.132601  [   90/  658]\n",
      "loss: 0.090972  [  180/  658]\n",
      "loss: 0.123379  [  270/  658]\n",
      "loss: 0.139120  [  360/  658]\n",
      "loss: 0.078585  [  450/  658]\n",
      "loss: 0.126616  [  540/  658]\n",
      "loss: 0.081479  [  630/  658]\n",
      "loss: 0.095806  [  224/  658]\n",
      "Training Loss (Epoch): 0.108570\n",
      "Validating...\n",
      "Validation Loss: 0.398043, Validation Accuracy: 87.27%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 15/15\n",
      "loss: 0.173750  [   90/  658]\n",
      "loss: 0.101877  [  180/  658]\n",
      "loss: 0.097485  [  270/  658]\n",
      "loss: 0.113212  [  360/  658]\n",
      "loss: 0.081035  [  450/  658]\n",
      "loss: 0.080466  [  540/  658]\n",
      "loss: 0.127188  [  630/  658]\n",
      "loss: 0.187841  [  224/  658]\n",
      "Training Loss (Epoch): 0.120357\n",
      "Validating...\n",
      "Validation Loss: 0.399759, Validation Accuracy: 87.27%\n",
      "Learning Rate: [1e-06]\n",
      "Processing Fold 7\n",
      "Epoch 1/15\n",
      "loss: 2.400551  [   90/  670]\n",
      "loss: 2.294306  [  180/  670]\n",
      "loss: 2.133155  [  270/  670]\n",
      "loss: 2.045871  [  360/  670]\n",
      "loss: 2.078649  [  450/  670]\n",
      "loss: 1.830351  [  540/  670]\n",
      "loss: 1.809605  [  630/  670]\n",
      "loss: 1.790268  [  320/  670]\n",
      "Training Loss (Epoch): 2.047844\n",
      "Validating...\n",
      "Validation Loss: 1.970267, Validation Accuracy: 37.50%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/15\n",
      "loss: 1.885213  [   90/  670]\n",
      "loss: 1.666339  [  180/  670]\n",
      "loss: 1.478706  [  270/  670]\n",
      "loss: 1.215436  [  360/  670]\n",
      "loss: 1.484469  [  450/  670]\n",
      "loss: 1.428879  [  540/  670]\n",
      "loss: 1.062438  [  630/  670]\n",
      "loss: 1.432533  [  320/  670]\n",
      "Training Loss (Epoch): 1.456752\n",
      "Validating...\n",
      "Validation Loss: 1.402969, Validation Accuracy: 47.62%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/15\n",
      "loss: 1.332556  [   90/  670]\n",
      "loss: 0.995885  [  180/  670]\n",
      "loss: 1.022473  [  270/  670]\n",
      "loss: 1.220715  [  360/  670]\n",
      "loss: 0.938847  [  450/  670]\n",
      "loss: 0.776690  [  540/  670]\n",
      "loss: 0.962384  [  630/  670]\n",
      "loss: 1.199974  [  320/  670]\n",
      "Training Loss (Epoch): 1.056191\n",
      "Validating...\n",
      "Validation Loss: 0.967393, Validation Accuracy: 65.48%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/15\n",
      "loss: 0.768274  [   90/  670]\n",
      "loss: 0.610458  [  180/  670]\n",
      "loss: 0.693920  [  270/  670]\n",
      "loss: 0.817373  [  360/  670]\n",
      "loss: 0.550445  [  450/  670]\n",
      "loss: 0.599039  [  540/  670]\n",
      "loss: 0.695226  [  630/  670]\n",
      "loss: 0.508780  [  320/  670]\n",
      "Training Loss (Epoch): 0.655439\n",
      "Validating...\n",
      "Validation Loss: 0.685695, Validation Accuracy: 76.19%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/15\n",
      "loss: 0.461150  [   90/  670]\n",
      "loss: 0.483307  [  180/  670]\n",
      "loss: 0.369334  [  270/  670]\n",
      "loss: 0.306708  [  360/  670]\n",
      "loss: 0.444888  [  450/  670]\n",
      "loss: 0.342370  [  540/  670]\n",
      "loss: 0.484962  [  630/  670]\n",
      "loss: 0.921417  [  320/  670]\n",
      "Training Loss (Epoch): 0.476767\n",
      "Validating...\n",
      "Validation Loss: 0.824374, Validation Accuracy: 76.19%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/15\n",
      "loss: 0.469405  [   90/  670]\n",
      "loss: 0.355344  [  180/  670]\n",
      "loss: 0.512587  [  270/  670]\n",
      "loss: 0.549855  [  360/  670]\n",
      "loss: 0.327240  [  450/  670]\n",
      "loss: 0.498254  [  540/  670]\n",
      "loss: 0.565297  [  630/  670]\n",
      "loss: 0.292543  [  320/  670]\n",
      "Training Loss (Epoch): 0.446316\n",
      "Validating...\n",
      "Validation Loss: 0.690156, Validation Accuracy: 79.17%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 7/15\n",
      "loss: 0.184928  [   90/  670]\n",
      "loss: 0.260924  [  180/  670]\n",
      "loss: 0.326284  [  270/  670]\n",
      "loss: 0.339734  [  360/  670]\n",
      "loss: 0.256932  [  450/  670]\n",
      "loss: 0.318027  [  540/  670]\n",
      "loss: 0.316114  [  630/  670]\n",
      "loss: 0.259625  [  320/  670]\n",
      "Training Loss (Epoch): 0.282821\n",
      "Validating...\n",
      "Validation Loss: 0.531575, Validation Accuracy: 82.14%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 8/15\n",
      "loss: 0.259062  [   90/  670]\n",
      "loss: 0.123254  [  180/  670]\n",
      "loss: 0.228560  [  270/  670]\n",
      "loss: 0.113417  [  360/  670]\n",
      "loss: 0.214080  [  450/  670]\n",
      "loss: 0.211576  [  540/  670]\n",
      "loss: 0.189042  [  630/  670]\n",
      "loss: 0.192131  [  320/  670]\n",
      "Training Loss (Epoch): 0.191390\n",
      "Validating...\n",
      "Validation Loss: 0.493872, Validation Accuracy: 86.31%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 9/15\n",
      "loss: 0.164990  [   90/  670]\n",
      "loss: 0.151848  [  180/  670]\n",
      "loss: 0.135849  [  270/  670]\n",
      "loss: 0.142643  [  360/  670]\n",
      "loss: 0.163837  [  450/  670]\n",
      "loss: 0.195625  [  540/  670]\n",
      "loss: 0.081958  [  630/  670]\n",
      "loss: 0.049202  [  320/  670]\n",
      "Training Loss (Epoch): 0.135744\n",
      "Validating...\n",
      "Validation Loss: 0.610958, Validation Accuracy: 82.14%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 10/15\n",
      "loss: 0.169938  [   90/  670]\n",
      "loss: 0.066818  [  180/  670]\n",
      "loss: 0.154270  [  270/  670]\n",
      "loss: 0.066167  [  360/  670]\n",
      "loss: 0.213708  [  450/  670]\n",
      "loss: 0.184200  [  540/  670]\n",
      "loss: 0.190053  [  630/  670]\n",
      "loss: 0.103426  [  320/  670]\n",
      "Training Loss (Epoch): 0.143572\n",
      "Validating...\n",
      "Validation Loss: 0.577165, Validation Accuracy: 85.71%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 11/15\n",
      "loss: 0.112103  [   90/  670]\n",
      "loss: 0.081353  [  180/  670]\n",
      "loss: 0.057264  [  270/  670]\n",
      "loss: 0.137065  [  360/  670]\n",
      "loss: 0.100886  [  450/  670]\n",
      "loss: 0.111762  [  540/  670]\n",
      "loss: 0.057510  [  630/  670]\n",
      "loss: 0.121702  [  320/  670]\n",
      "Training Loss (Epoch): 0.097456\n",
      "Validating...\n",
      "Validation Loss: 0.560444, Validation Accuracy: 88.69%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 12/15\n",
      "loss: 0.057539  [   90/  670]\n",
      "loss: 0.079814  [  180/  670]\n",
      "loss: 0.096518  [  270/  670]\n",
      "loss: 0.057633  [  360/  670]\n",
      "loss: 0.097571  [  450/  670]\n",
      "loss: 0.080529  [  540/  670]\n",
      "loss: 0.141804  [  630/  670]\n",
      "loss: 0.030280  [  320/  670]\n",
      "Training Loss (Epoch): 0.080211\n",
      "Validating...\n",
      "Validation Loss: 0.553837, Validation Accuracy: 87.50%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 13/15\n",
      "loss: 0.056354  [   90/  670]\n",
      "loss: 0.078101  [  180/  670]\n",
      "loss: 0.024656  [  270/  670]\n",
      "loss: 0.070602  [  360/  670]\n",
      "loss: 0.114992  [  450/  670]\n",
      "loss: 0.066122  [  540/  670]\n",
      "loss: 0.131725  [  630/  670]\n",
      "loss: 0.107197  [  320/  670]\n",
      "Training Loss (Epoch): 0.081219\n",
      "Validating...\n",
      "Validation Loss: 0.554130, Validation Accuracy: 87.50%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 8\n",
      "Epoch 1/15\n",
      "loss: 2.376167  [   90/  644]\n",
      "loss: 2.266500  [  180/  644]\n",
      "loss: 2.262588  [  270/  644]\n",
      "loss: 2.144350  [  360/  644]\n",
      "loss: 2.106075  [  450/  644]\n",
      "loss: 2.021709  [  540/  644]\n",
      "loss: 1.931955  [  630/  644]\n",
      "loss: 2.243666  [  112/  644]\n",
      "Training Loss (Epoch): 2.169126\n",
      "Validating...\n",
      "Validation Loss: 2.171594, Validation Accuracy: 25.93%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/15\n",
      "loss: 2.164878  [   90/  644]\n",
      "loss: 1.997056  [  180/  644]\n",
      "loss: 1.697975  [  270/  644]\n",
      "loss: 1.515909  [  360/  644]\n",
      "loss: 1.206294  [  450/  644]\n",
      "loss: 1.848421  [  540/  644]\n",
      "loss: 1.052121  [  630/  644]\n",
      "loss: 1.719478  [  112/  644]\n",
      "Training Loss (Epoch): 1.650267\n",
      "Validating...\n",
      "Validation Loss: 1.342434, Validation Accuracy: 56.79%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/15\n",
      "loss: 1.273440  [   90/  644]\n",
      "loss: 1.205825  [  180/  644]\n",
      "loss: 0.987758  [  270/  644]\n",
      "loss: 0.984801  [  360/  644]\n",
      "loss: 1.013446  [  450/  644]\n",
      "loss: 1.007514  [  540/  644]\n",
      "loss: 0.814803  [  630/  644]\n",
      "loss: 0.357673  [  112/  644]\n",
      "Training Loss (Epoch): 0.955657\n",
      "Validating...\n",
      "Validation Loss: 1.856314, Validation Accuracy: 54.94%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/15\n",
      "loss: 1.544226  [   90/  644]\n",
      "loss: 1.142098  [  180/  644]\n",
      "loss: 1.165944  [  270/  644]\n",
      "loss: 0.939584  [  360/  644]\n",
      "loss: 1.002368  [  450/  644]\n",
      "loss: 0.972607  [  540/  644]\n",
      "loss: 0.861481  [  630/  644]\n",
      "loss: 0.322072  [  112/  644]\n",
      "Training Loss (Epoch): 0.993797\n",
      "Validating...\n",
      "Validation Loss: 1.196020, Validation Accuracy: 64.81%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 5/15\n",
      "loss: 0.834015  [   90/  644]\n",
      "loss: 0.788656  [  180/  644]\n",
      "loss: 0.789091  [  270/  644]\n",
      "loss: 0.444152  [  360/  644]\n",
      "loss: 0.671178  [  450/  644]\n",
      "loss: 0.461287  [  540/  644]\n",
      "loss: 0.568215  [  630/  644]\n",
      "loss: 1.037326  [  112/  644]\n",
      "Training Loss (Epoch): 0.699240\n",
      "Validating...\n",
      "Validation Loss: 0.880584, Validation Accuracy: 70.37%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 6/15\n",
      "loss: 0.402127  [   90/  644]\n",
      "loss: 0.415654  [  180/  644]\n",
      "loss: 0.568785  [  270/  644]\n",
      "loss: 0.477700  [  360/  644]\n",
      "loss: 0.512155  [  450/  644]\n",
      "loss: 0.372850  [  540/  644]\n",
      "loss: 0.538462  [  630/  644]\n",
      "loss: 1.437031  [  112/  644]\n",
      "Training Loss (Epoch): 0.590596\n",
      "Validating...\n",
      "Validation Loss: 0.614152, Validation Accuracy: 75.93%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 7/15\n",
      "loss: 0.464338  [   90/  644]\n",
      "loss: 0.498539  [  180/  644]\n",
      "loss: 0.509313  [  270/  644]\n",
      "loss: 0.416560  [  360/  644]\n",
      "loss: 0.374048  [  450/  644]\n",
      "loss: 0.355178  [  540/  644]\n",
      "loss: 0.334760  [  630/  644]\n",
      "loss: 0.125445  [  112/  644]\n",
      "Training Loss (Epoch): 0.384772\n",
      "Validating...\n",
      "Validation Loss: 0.547204, Validation Accuracy: 78.40%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 8/15\n",
      "loss: 0.383134  [   90/  644]\n",
      "loss: 0.425711  [  180/  644]\n",
      "loss: 0.321778  [  270/  644]\n",
      "loss: 0.349956  [  360/  644]\n",
      "loss: 0.232049  [  450/  644]\n",
      "loss: 0.236469  [  540/  644]\n",
      "loss: 0.260094  [  630/  644]\n",
      "loss: 0.385521  [  112/  644]\n",
      "Training Loss (Epoch): 0.324339\n",
      "Validating...\n",
      "Validation Loss: 0.530037, Validation Accuracy: 79.01%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 9/15\n",
      "loss: 0.243131  [   90/  644]\n",
      "loss: 0.268681  [  180/  644]\n",
      "loss: 0.398133  [  270/  644]\n",
      "loss: 0.290317  [  360/  644]\n",
      "loss: 0.326948  [  450/  644]\n",
      "loss: 0.235272  [  540/  644]\n",
      "loss: 0.265282  [  630/  644]\n",
      "loss: 0.193673  [  112/  644]\n",
      "Training Loss (Epoch): 0.277680\n",
      "Validating...\n",
      "Validation Loss: 0.535492, Validation Accuracy: 79.63%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 10/15\n",
      "loss: 0.241162  [   90/  644]\n",
      "loss: 0.206145  [  180/  644]\n",
      "loss: 0.221122  [  270/  644]\n",
      "loss: 0.387207  [  360/  644]\n",
      "loss: 0.315592  [  450/  644]\n",
      "loss: 0.235664  [  540/  644]\n",
      "loss: 0.283455  [  630/  644]\n",
      "loss: 0.492911  [  112/  644]\n",
      "Training Loss (Epoch): 0.297907\n",
      "Validating...\n",
      "Validation Loss: 0.533614, Validation Accuracy: 80.25%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 11/15\n",
      "loss: 0.376518  [   90/  644]\n",
      "loss: 0.239242  [  180/  644]\n",
      "loss: 0.266406  [  270/  644]\n",
      "loss: 0.240736  [  360/  644]\n",
      "loss: 0.271298  [  450/  644]\n",
      "loss: 0.319156  [  540/  644]\n",
      "loss: 0.230489  [  630/  644]\n",
      "loss: 0.203944  [  112/  644]\n",
      "Training Loss (Epoch): 0.268474\n",
      "Validating...\n",
      "Validation Loss: 0.531322, Validation Accuracy: 78.40%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 12/15\n",
      "loss: 0.312396  [   90/  644]\n",
      "loss: 0.225161  [  180/  644]\n",
      "loss: 0.234696  [  270/  644]\n",
      "loss: 0.184084  [  360/  644]\n",
      "loss: 0.261469  [  450/  644]\n",
      "loss: 0.331946  [  540/  644]\n",
      "loss: 0.283472  [  630/  644]\n",
      "loss: 0.852966  [  112/  644]\n",
      "Training Loss (Epoch): 0.335774\n",
      "Validating...\n",
      "Validation Loss: 0.529679, Validation Accuracy: 78.40%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 13/15\n",
      "loss: 0.155541  [   90/  644]\n",
      "loss: 0.373692  [  180/  644]\n",
      "loss: 0.381519  [  270/  644]\n",
      "loss: 0.168671  [  360/  644]\n",
      "loss: 0.404148  [  450/  644]\n",
      "loss: 0.131236  [  540/  644]\n",
      "loss: 0.202464  [  630/  644]\n",
      "loss: 0.241164  [  112/  644]\n",
      "Training Loss (Epoch): 0.257304\n",
      "Validating...\n",
      "Validation Loss: 0.528247, Validation Accuracy: 79.01%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 14/15\n",
      "loss: 0.273326  [   90/  644]\n",
      "loss: 0.270265  [  180/  644]\n",
      "loss: 0.308621  [  270/  644]\n",
      "loss: 0.292121  [  360/  644]\n",
      "loss: 0.150892  [  450/  644]\n",
      "loss: 0.294891  [  540/  644]\n",
      "loss: 0.201716  [  630/  644]\n",
      "loss: 0.270286  [  112/  644]\n",
      "Training Loss (Epoch): 0.257765\n",
      "Validating...\n",
      "Validation Loss: 0.525537, Validation Accuracy: 80.86%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 15/15\n",
      "loss: 0.200990  [   90/  644]\n",
      "loss: 0.410353  [  180/  644]\n",
      "loss: 0.211027  [  270/  644]\n",
      "loss: 0.278909  [  360/  644]\n",
      "loss: 0.253756  [  450/  644]\n",
      "loss: 0.222243  [  540/  644]\n",
      "loss: 0.188746  [  630/  644]\n",
      "loss: 0.350397  [  112/  644]\n",
      "Training Loss (Epoch): 0.264553\n",
      "Validating...\n",
      "Validation Loss: 0.523378, Validation Accuracy: 80.86%\n",
      "Learning Rate: [1e-06]\n",
      "Processing Fold 9\n",
      "Epoch 1/15\n",
      "loss: 2.399413  [   90/  652]\n",
      "loss: 2.204191  [  180/  652]\n",
      "loss: 2.014567  [  270/  652]\n",
      "loss: 1.959538  [  360/  652]\n",
      "loss: 1.826456  [  450/  652]\n",
      "loss: 1.828630  [  540/  652]\n",
      "loss: 1.842350  [  630/  652]\n",
      "loss: 1.812122  [  176/  652]\n",
      "Training Loss (Epoch): 1.985908\n",
      "Validating...\n",
      "Validation Loss: 1.955778, Validation Accuracy: 39.02%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/15\n",
      "loss: 1.957131  [   90/  652]\n",
      "loss: 1.513897  [  180/  652]\n",
      "loss: 1.386107  [  270/  652]\n",
      "loss: 1.499573  [  360/  652]\n",
      "loss: 1.203990  [  450/  652]\n",
      "loss: 1.062080  [  540/  652]\n",
      "loss: 0.869284  [  630/  652]\n",
      "loss: 0.847880  [  176/  652]\n",
      "Training Loss (Epoch): 1.292493\n",
      "Validating...\n",
      "Validation Loss: 1.343915, Validation Accuracy: 51.22%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/15\n",
      "loss: 1.138705  [   90/  652]\n",
      "loss: 1.149778  [  180/  652]\n",
      "loss: 1.137609  [  270/  652]\n",
      "loss: 0.861100  [  360/  652]\n",
      "loss: 0.708038  [  450/  652]\n",
      "loss: 0.909824  [  540/  652]\n",
      "loss: 0.783702  [  630/  652]\n",
      "loss: 0.533933  [  176/  652]\n",
      "Training Loss (Epoch): 0.902836\n",
      "Validating...\n",
      "Validation Loss: 0.909925, Validation Accuracy: 76.83%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/15\n",
      "loss: 0.666234  [   90/  652]\n",
      "loss: 0.527693  [  180/  652]\n",
      "loss: 0.539717  [  270/  652]\n",
      "loss: 0.621540  [  360/  652]\n",
      "loss: 0.393453  [  450/  652]\n",
      "loss: 0.446597  [  540/  652]\n",
      "loss: 0.577562  [  630/  652]\n",
      "loss: 0.397979  [  176/  652]\n",
      "Training Loss (Epoch): 0.521347\n",
      "Validating...\n",
      "Validation Loss: 0.751072, Validation Accuracy: 78.05%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/15\n",
      "loss: 0.555398  [   90/  652]\n",
      "loss: 0.252659  [  180/  652]\n",
      "loss: 0.408901  [  270/  652]\n",
      "loss: 0.421508  [  360/  652]\n",
      "loss: 0.158274  [  450/  652]\n",
      "loss: 0.258061  [  540/  652]\n",
      "loss: 0.294507  [  630/  652]\n",
      "loss: 0.353207  [  176/  652]\n",
      "Training Loss (Epoch): 0.337814\n",
      "Validating...\n",
      "Validation Loss: 0.684139, Validation Accuracy: 82.32%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 6/15\n",
      "loss: 0.157968  [   90/  652]\n",
      "loss: 0.327848  [  180/  652]\n",
      "loss: 0.217481  [  270/  652]\n",
      "loss: 0.330832  [  360/  652]\n",
      "loss: 0.179170  [  450/  652]\n",
      "loss: 0.137727  [  540/  652]\n",
      "loss: 0.212886  [  630/  652]\n",
      "loss: 0.055910  [  176/  652]\n",
      "Training Loss (Epoch): 0.202478\n",
      "Validating...\n",
      "Validation Loss: 0.534162, Validation Accuracy: 88.41%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 7/15\n",
      "loss: 0.132619  [   90/  652]\n",
      "loss: 0.109187  [  180/  652]\n",
      "loss: 0.112622  [  270/  652]\n",
      "loss: 0.106277  [  360/  652]\n",
      "loss: 0.193889  [  450/  652]\n",
      "loss: 0.069238  [  540/  652]\n",
      "loss: 0.147282  [  630/  652]\n",
      "loss: 1.043783  [  176/  652]\n",
      "Training Loss (Epoch): 0.239362\n",
      "Validating...\n",
      "Validation Loss: 0.504136, Validation Accuracy: 88.41%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 8/15\n",
      "loss: 0.093637  [   90/  652]\n",
      "loss: 0.099541  [  180/  652]\n",
      "loss: 0.166739  [  270/  652]\n",
      "loss: 0.154377  [  360/  652]\n",
      "loss: 0.131860  [  450/  652]\n",
      "loss: 0.123702  [  540/  652]\n",
      "loss: 0.128663  [  630/  652]\n",
      "loss: 1.145942  [  176/  652]\n",
      "Training Loss (Epoch): 0.255558\n",
      "Validating...\n",
      "Validation Loss: 0.480963, Validation Accuracy: 88.41%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 9/15\n",
      "loss: 0.064335  [   90/  652]\n",
      "loss: 0.075699  [  180/  652]\n",
      "loss: 0.174389  [  270/  652]\n",
      "loss: 0.101220  [  360/  652]\n",
      "loss: 0.211562  [  450/  652]\n",
      "loss: 0.140251  [  540/  652]\n",
      "loss: 0.121135  [  630/  652]\n",
      "loss: 0.197979  [  176/  652]\n",
      "Training Loss (Epoch): 0.135821\n",
      "Validating...\n",
      "Validation Loss: 0.499662, Validation Accuracy: 88.41%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 10/15\n",
      "loss: 0.152336  [   90/  652]\n",
      "loss: 0.062687  [  180/  652]\n",
      "loss: 0.139213  [  270/  652]\n",
      "loss: 0.118275  [  360/  652]\n",
      "loss: 0.080463  [  450/  652]\n",
      "loss: 0.127049  [  540/  652]\n",
      "loss: 0.162275  [  630/  652]\n",
      "loss: 0.052895  [  176/  652]\n",
      "Training Loss (Epoch): 0.111899\n",
      "Validating...\n",
      "Validation Loss: 0.486749, Validation Accuracy: 88.41%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 11/15\n",
      "loss: 0.063991  [   90/  652]\n",
      "loss: 0.066152  [  180/  652]\n",
      "loss: 0.085783  [  270/  652]\n",
      "loss: 0.100918  [  360/  652]\n",
      "loss: 0.112130  [  450/  652]\n",
      "loss: 0.116077  [  540/  652]\n",
      "loss: 0.143710  [  630/  652]\n",
      "loss: 0.074428  [  176/  652]\n",
      "Training Loss (Epoch): 0.095399\n",
      "Validating...\n",
      "Validation Loss: 0.484245, Validation Accuracy: 87.80%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 12/15\n",
      "loss: 0.077245  [   90/  652]\n",
      "loss: 0.112993  [  180/  652]\n",
      "loss: 0.101084  [  270/  652]\n",
      "loss: 0.073261  [  360/  652]\n",
      "loss: 0.109988  [  450/  652]\n",
      "loss: 0.092575  [  540/  652]\n",
      "loss: 0.041057  [  630/  652]\n",
      "loss: 0.324621  [  176/  652]\n",
      "Training Loss (Epoch): 0.116603\n",
      "Validating...\n",
      "Validation Loss: 0.479533, Validation Accuracy: 88.41%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 13/15\n",
      "loss: 0.105343  [   90/  652]\n",
      "loss: 0.083472  [  180/  652]\n",
      "loss: 0.086997  [  270/  652]\n",
      "loss: 0.081503  [  360/  652]\n",
      "loss: 0.083699  [  450/  652]\n",
      "loss: 0.091409  [  540/  652]\n",
      "loss: 0.119949  [  630/  652]\n",
      "loss: 0.059666  [  176/  652]\n",
      "Training Loss (Epoch): 0.089005\n",
      "Validating...\n",
      "Validation Loss: 0.476944, Validation Accuracy: 89.02%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 14/15\n",
      "loss: 0.081213  [   90/  652]\n",
      "loss: 0.113486  [  180/  652]\n",
      "loss: 0.071372  [  270/  652]\n",
      "loss: 0.081365  [  360/  652]\n",
      "loss: 0.105755  [  450/  652]\n",
      "loss: 0.124895  [  540/  652]\n",
      "loss: 0.069377  [  630/  652]\n",
      "loss: 0.028400  [  176/  652]\n",
      "Training Loss (Epoch): 0.084483\n",
      "Validating...\n",
      "Validation Loss: 0.474821, Validation Accuracy: 89.02%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 15/15\n",
      "loss: 0.065041  [   90/  652]\n",
      "loss: 0.068703  [  180/  652]\n",
      "loss: 0.137016  [  270/  652]\n",
      "loss: 0.083568  [  360/  652]\n",
      "loss: 0.120014  [  450/  652]\n",
      "loss: 0.073735  [  540/  652]\n",
      "loss: 0.071892  [  630/  652]\n",
      "loss: 0.166639  [  176/  652]\n",
      "Training Loss (Epoch): 0.098326\n",
      "Validating...\n",
      "Validation Loss: 0.473306, Validation Accuracy: 89.63%\n",
      "Learning Rate: [1e-06]\n",
      "Processing Fold 10\n",
      "Epoch 1/15\n",
      "loss: 2.397023  [   90/  669]\n",
      "loss: 2.360446  [  180/  669]\n",
      "loss: 2.249385  [  270/  669]\n",
      "loss: 2.104881  [  360/  669]\n",
      "loss: 2.092574  [  450/  669]\n",
      "loss: 1.881957  [  540/  669]\n",
      "loss: 1.967309  [  630/  669]\n",
      "loss: 1.638153  [  312/  669]\n",
      "Training Loss (Epoch): 2.086466\n",
      "Validating...\n",
      "Validation Loss: 1.986770, Validation Accuracy: 47.02%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/15\n",
      "loss: 2.082318  [   90/  669]\n",
      "loss: 1.619568  [  180/  669]\n",
      "loss: 1.698944  [  270/  669]\n",
      "loss: 1.513425  [  360/  669]\n",
      "loss: 1.341146  [  450/  669]\n",
      "loss: 1.211143  [  540/  669]\n",
      "loss: 1.226241  [  630/  669]\n",
      "loss: 1.160875  [  312/  669]\n",
      "Training Loss (Epoch): 1.481707\n",
      "Validating...\n",
      "Validation Loss: 1.029171, Validation Accuracy: 66.07%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/15\n",
      "loss: 0.934743  [   90/  669]\n",
      "loss: 1.209708  [  180/  669]\n",
      "loss: 1.029064  [  270/  669]\n",
      "loss: 1.056535  [  360/  669]\n",
      "loss: 0.823470  [  450/  669]\n",
      "loss: 1.127891  [  540/  669]\n",
      "loss: 0.923316  [  630/  669]\n",
      "loss: 0.614754  [  312/  669]\n",
      "Training Loss (Epoch): 0.964935\n",
      "Validating...\n",
      "Validation Loss: 0.832980, Validation Accuracy: 74.40%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/15\n",
      "loss: 0.927861  [   90/  669]\n",
      "loss: 0.867564  [  180/  669]\n",
      "loss: 0.784725  [  270/  669]\n",
      "loss: 0.758564  [  360/  669]\n",
      "loss: 0.587364  [  450/  669]\n",
      "loss: 0.538902  [  540/  669]\n",
      "loss: 0.621711  [  630/  669]\n",
      "loss: 0.496945  [  312/  669]\n",
      "Training Loss (Epoch): 0.697955\n",
      "Validating...\n",
      "Validation Loss: 0.816181, Validation Accuracy: 74.40%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 5/15\n",
      "loss: 0.535360  [   90/  669]\n",
      "loss: 0.538156  [  180/  669]\n",
      "loss: 0.538842  [  270/  669]\n",
      "loss: 0.649138  [  360/  669]\n",
      "loss: 0.718714  [  450/  669]\n",
      "loss: 0.438055  [  540/  669]\n",
      "loss: 0.590978  [  630/  669]\n",
      "loss: 0.767108  [  312/  669]\n",
      "Training Loss (Epoch): 0.597044\n",
      "Validating...\n",
      "Validation Loss: 0.543602, Validation Accuracy: 80.36%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 6/15\n",
      "loss: 0.541301  [   90/  669]\n",
      "loss: 0.481106  [  180/  669]\n",
      "loss: 0.527441  [  270/  669]\n",
      "loss: 0.480557  [  360/  669]\n",
      "loss: 0.404069  [  450/  669]\n",
      "loss: 0.391711  [  540/  669]\n",
      "loss: 0.307694  [  630/  669]\n",
      "loss: 0.389738  [  312/  669]\n",
      "Training Loss (Epoch): 0.440452\n",
      "Validating...\n",
      "Validation Loss: 0.537114, Validation Accuracy: 82.74%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 7/15\n",
      "loss: 0.299556  [   90/  669]\n",
      "loss: 0.344190  [  180/  669]\n",
      "loss: 0.389050  [  270/  669]\n",
      "loss: 0.459471  [  360/  669]\n",
      "loss: 0.460917  [  450/  669]\n",
      "loss: 0.469796  [  540/  669]\n",
      "loss: 0.305903  [  630/  669]\n",
      "loss: 0.260040  [  312/  669]\n",
      "Training Loss (Epoch): 0.373615\n",
      "Validating...\n",
      "Validation Loss: 0.382414, Validation Accuracy: 85.71%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 8/15\n",
      "loss: 0.281301  [   90/  669]\n",
      "loss: 0.272569  [  180/  669]\n",
      "loss: 0.388669  [  270/  669]\n",
      "loss: 0.252026  [  360/  669]\n",
      "loss: 0.271230  [  450/  669]\n",
      "loss: 0.254041  [  540/  669]\n",
      "loss: 0.409125  [  630/  669]\n",
      "loss: 0.585347  [  312/  669]\n",
      "Training Loss (Epoch): 0.339288\n",
      "Validating...\n",
      "Validation Loss: 0.383169, Validation Accuracy: 85.12%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 9/15\n",
      "loss: 0.343957  [   90/  669]\n",
      "loss: 0.231427  [  180/  669]\n",
      "loss: 0.313437  [  270/  669]\n",
      "loss: 0.371685  [  360/  669]\n",
      "loss: 0.315793  [  450/  669]\n",
      "loss: 0.216143  [  540/  669]\n",
      "loss: 0.305141  [  630/  669]\n",
      "loss: 0.403035  [  312/  669]\n",
      "Training Loss (Epoch): 0.312577\n",
      "Validating...\n",
      "Validation Loss: 0.399526, Validation Accuracy: 86.31%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 10/15\n",
      "loss: 0.339975  [   90/  669]\n",
      "loss: 0.184754  [  180/  669]\n",
      "loss: 0.305790  [  270/  669]\n",
      "loss: 0.304659  [  360/  669]\n",
      "loss: 0.305740  [  450/  669]\n",
      "loss: 0.223956  [  540/  669]\n",
      "loss: 0.286767  [  630/  669]\n",
      "loss: 0.550927  [  312/  669]\n",
      "Training Loss (Epoch): 0.312821\n",
      "Validating...\n",
      "Validation Loss: 0.401954, Validation Accuracy: 84.52%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 11/15\n",
      "loss: 0.289508  [   90/  669]\n",
      "loss: 0.235577  [  180/  669]\n",
      "loss: 0.258949  [  270/  669]\n",
      "loss: 0.313092  [  360/  669]\n",
      "loss: 0.320747  [  450/  669]\n",
      "loss: 0.330722  [  540/  669]\n",
      "loss: 0.287684  [  630/  669]\n",
      "loss: 0.313759  [  312/  669]\n",
      "Training Loss (Epoch): 0.293755\n",
      "Validating...\n",
      "Validation Loss: 0.402334, Validation Accuracy: 84.52%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 12/15\n",
      "loss: 0.297707  [   90/  669]\n",
      "loss: 0.291096  [  180/  669]\n",
      "loss: 0.212581  [  270/  669]\n",
      "loss: 0.281503  [  360/  669]\n",
      "loss: 0.430261  [  450/  669]\n",
      "loss: 0.233900  [  540/  669]\n",
      "loss: 0.331724  [  630/  669]\n",
      "loss: 0.177207  [  312/  669]\n",
      "Training Loss (Epoch): 0.281997\n",
      "Validating...\n",
      "Validation Loss: 0.403035, Validation Accuracy: 84.52%\n",
      "Learning Rate: [1e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "\n",
      "Cross-Validation Results:\n",
      "Avg Training Loss: 0.516615\n",
      "Avg Validation Loss: 0.738690\n",
      "Avg Validation Accuracy: 86.83%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.516615150707421, 0.73868970776945, 0.8683415780969866)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_tune(layer = 1, lr = 2e-4, weight_decay = 0.05, weights = \"DEFAULT\", drop = 0.7, batch_size = 90, total_epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1\n",
      "Epoch 1/15\n",
      "loss: 2.333562  [   90/  698]\n",
      "loss: 2.227712  [  180/  698]\n",
      "loss: 2.088053  [  270/  698]\n",
      "loss: 1.916219  [  360/  698]\n",
      "loss: 1.932869  [  450/  698]\n",
      "loss: 1.687907  [  540/  698]\n",
      "loss: 1.657543  [  630/  698]\n",
      "loss: 1.702854  [  544/  698]\n",
      "Training Loss (Epoch): 1.943340\n",
      "Validating...\n",
      "Validation Loss: 1.847259, Validation Accuracy: 50.86%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/15\n",
      "loss: 1.777190  [   90/  698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.554227  [  180/  698]\n",
      "loss: 1.268424  [  270/  698]\n",
      "loss: 1.561285  [  360/  698]\n",
      "loss: 1.247310  [  450/  698]\n",
      "loss: 1.190941  [  540/  698]\n",
      "loss: 1.232551  [  630/  698]\n",
      "loss: 1.022284  [  544/  698]\n",
      "Training Loss (Epoch): 1.356777\n",
      "Validating...\n",
      "Validation Loss: 1.044347, Validation Accuracy: 60.57%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/15\n",
      "loss: 1.019952  [   90/  698]\n",
      "loss: 0.870729  [  180/  698]\n",
      "loss: 0.642317  [  270/  698]\n",
      "loss: 0.576603  [  360/  698]\n",
      "loss: 0.643603  [  450/  698]\n",
      "loss: 0.591780  [  540/  698]\n",
      "loss: 0.696579  [  630/  698]\n",
      "loss: 0.610322  [  544/  698]\n",
      "Training Loss (Epoch): 0.706485\n",
      "Validating...\n",
      "Validation Loss: 0.784909, Validation Accuracy: 73.14%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/15\n",
      "loss: 0.478541  [   90/  698]\n",
      "loss: 0.440171  [  180/  698]\n",
      "loss: 0.378428  [  270/  698]\n",
      "loss: 0.542100  [  360/  698]\n",
      "loss: 0.293884  [  450/  698]\n",
      "loss: 0.436036  [  540/  698]\n",
      "loss: 0.388504  [  630/  698]\n",
      "loss: 0.278663  [  544/  698]\n",
      "Training Loss (Epoch): 0.404541\n",
      "Validating...\n",
      "Validation Loss: 0.579970, Validation Accuracy: 76.57%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/15\n",
      "loss: 0.297025  [   90/  698]\n",
      "loss: 0.404633  [  180/  698]\n",
      "loss: 0.177612  [  270/  698]\n",
      "loss: 0.355885  [  360/  698]\n",
      "loss: 0.287485  [  450/  698]\n",
      "loss: 0.277645  [  540/  698]\n",
      "loss: 0.371666  [  630/  698]\n",
      "loss: 0.195032  [  544/  698]\n",
      "Training Loss (Epoch): 0.295873\n",
      "Validating...\n",
      "Validation Loss: 0.517448, Validation Accuracy: 78.29%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 6/15\n",
      "loss: 0.285883  [   90/  698]\n",
      "loss: 0.262954  [  180/  698]\n",
      "loss: 0.282017  [  270/  698]\n",
      "loss: 0.171063  [  360/  698]\n",
      "loss: 0.133732  [  450/  698]\n",
      "loss: 0.175816  [  540/  698]\n",
      "loss: 0.160988  [  630/  698]\n",
      "loss: 0.175582  [  544/  698]\n",
      "Training Loss (Epoch): 0.206004\n",
      "Validating...\n",
      "Validation Loss: 0.308630, Validation Accuracy: 87.43%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 7/15\n",
      "loss: 0.152677  [   90/  698]\n",
      "loss: 0.028080  [  180/  698]\n",
      "loss: 0.092562  [  270/  698]\n",
      "loss: 0.168749  [  360/  698]\n",
      "loss: 0.106978  [  450/  698]\n",
      "loss: 0.145832  [  540/  698]\n",
      "loss: 0.074739  [  630/  698]\n",
      "loss: 0.118253  [  544/  698]\n",
      "Training Loss (Epoch): 0.110984\n",
      "Validating...\n",
      "Validation Loss: 0.300215, Validation Accuracy: 89.71%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 8/15\n",
      "loss: 0.080242  [   90/  698]\n",
      "loss: 0.081601  [  180/  698]\n",
      "loss: 0.033665  [  270/  698]\n",
      "loss: 0.076526  [  360/  698]\n",
      "loss: 0.154420  [  450/  698]\n",
      "loss: 0.148145  [  540/  698]\n",
      "loss: 0.019870  [  630/  698]\n",
      "loss: 0.059330  [  544/  698]\n",
      "Training Loss (Epoch): 0.081725\n",
      "Validating...\n",
      "Validation Loss: 0.314980, Validation Accuracy: 90.86%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 9/15\n",
      "loss: 0.018995  [   90/  698]\n",
      "loss: 0.041778  [  180/  698]\n",
      "loss: 0.115483  [  270/  698]\n",
      "loss: 0.078439  [  360/  698]\n",
      "loss: 0.042714  [  450/  698]\n",
      "loss: 0.075356  [  540/  698]\n",
      "loss: 0.056365  [  630/  698]\n",
      "loss: 0.064380  [  544/  698]\n",
      "Training Loss (Epoch): 0.061689\n",
      "Validating...\n",
      "Validation Loss: 0.305373, Validation Accuracy: 90.86%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 10/15\n",
      "loss: 0.084893  [   90/  698]\n",
      "loss: 0.032792  [  180/  698]\n",
      "loss: 0.076591  [  270/  698]\n",
      "loss: 0.016716  [  360/  698]\n",
      "loss: 0.130903  [  450/  698]\n",
      "loss: 0.046708  [  540/  698]\n",
      "loss: 0.030931  [  630/  698]\n",
      "loss: 0.021307  [  544/  698]\n",
      "Training Loss (Epoch): 0.055105\n",
      "Validating...\n",
      "Validation Loss: 0.294104, Validation Accuracy: 90.86%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 11/15\n",
      "loss: 0.059241  [   90/  698]\n",
      "loss: 0.093063  [  180/  698]\n",
      "loss: 0.036421  [  270/  698]\n",
      "loss: 0.013675  [  360/  698]\n",
      "loss: 0.075574  [  450/  698]\n",
      "loss: 0.072358  [  540/  698]\n",
      "loss: 0.041389  [  630/  698]\n",
      "loss: 0.022156  [  544/  698]\n",
      "Training Loss (Epoch): 0.051735\n",
      "Validating...\n",
      "Validation Loss: 0.292780, Validation Accuracy: 90.86%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 12/15\n",
      "loss: 0.023796  [   90/  698]\n",
      "loss: 0.029361  [  180/  698]\n",
      "loss: 0.058780  [  270/  698]\n",
      "loss: 0.025880  [  360/  698]\n",
      "loss: 0.077482  [  450/  698]\n",
      "loss: 0.060064  [  540/  698]\n",
      "loss: 0.076235  [  630/  698]\n",
      "loss: 0.069273  [  544/  698]\n",
      "Training Loss (Epoch): 0.052609\n",
      "Validating...\n",
      "Validation Loss: 0.291542, Validation Accuracy: 90.86%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 13/15\n",
      "loss: 0.030431  [   90/  698]\n",
      "loss: 0.084753  [  180/  698]\n",
      "loss: 0.020172  [  270/  698]\n",
      "loss: 0.028909  [  360/  698]\n",
      "loss: 0.097113  [  450/  698]\n",
      "loss: 0.039624  [  540/  698]\n",
      "loss: 0.042388  [  630/  698]\n",
      "loss: 0.074874  [  544/  698]\n",
      "Training Loss (Epoch): 0.052283\n",
      "Validating...\n",
      "Validation Loss: 0.291201, Validation Accuracy: 90.86%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 14/15\n",
      "loss: 0.100869  [   90/  698]\n",
      "loss: 0.097592  [  180/  698]\n",
      "loss: 0.058112  [  270/  698]\n",
      "loss: 0.051105  [  360/  698]\n",
      "loss: 0.028302  [  450/  698]\n",
      "loss: 0.018895  [  540/  698]\n",
      "loss: 0.031425  [  630/  698]\n",
      "loss: 0.014902  [  544/  698]\n",
      "Training Loss (Epoch): 0.050150\n",
      "Validating...\n",
      "Validation Loss: 0.290974, Validation Accuracy: 90.86%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 15/15\n",
      "loss: 0.027711  [   90/  698]\n",
      "loss: 0.057791  [  180/  698]\n",
      "loss: 0.043849  [  270/  698]\n",
      "loss: 0.091565  [  360/  698]\n",
      "loss: 0.056166  [  450/  698]\n",
      "loss: 0.063629  [  540/  698]\n",
      "loss: 0.036328  [  630/  698]\n",
      "loss: 0.022746  [  544/  698]\n",
      "Training Loss (Epoch): 0.049973\n",
      "Validating...\n",
      "Validation Loss: 0.290780, Validation Accuracy: 90.86%\n",
      "Learning Rate: [1e-06]\n",
      "Processing Fold 2\n",
      "Epoch 1/15\n",
      "loss: 2.424794  [   90/  710]\n",
      "loss: 2.188701  [  180/  710]\n",
      "loss: 2.063479  [  270/  710]\n",
      "loss: 1.931067  [  360/  710]\n",
      "loss: 1.761792  [  450/  710]\n",
      "loss: 1.756382  [  540/  710]\n",
      "loss: 1.462393  [  630/  710]\n",
      "loss: 1.418354  [  640/  710]\n",
      "Training Loss (Epoch): 1.875870\n",
      "Validating...\n",
      "Validation Loss: 1.874390, Validation Accuracy: 43.26%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/15\n",
      "loss: 1.769126  [   90/  710]\n",
      "loss: 1.437184  [  180/  710]\n",
      "loss: 1.080962  [  270/  710]\n",
      "loss: 1.091891  [  360/  710]\n",
      "loss: 0.861000  [  450/  710]\n",
      "loss: 1.093305  [  540/  710]\n",
      "loss: 0.740298  [  630/  710]\n",
      "loss: 0.767319  [  640/  710]\n",
      "Training Loss (Epoch): 1.105136\n",
      "Validating...\n",
      "Validation Loss: 0.867963, Validation Accuracy: 69.10%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/15\n",
      "loss: 0.571237  [   90/  710]\n",
      "loss: 0.480249  [  180/  710]\n",
      "loss: 0.579526  [  270/  710]\n",
      "loss: 0.589159  [  360/  710]\n",
      "loss: 0.403369  [  450/  710]\n",
      "loss: 0.639922  [  540/  710]\n",
      "loss: 0.330517  [  630/  710]\n",
      "loss: 0.343423  [  640/  710]\n",
      "Training Loss (Epoch): 0.492175\n",
      "Validating...\n",
      "Validation Loss: 0.782763, Validation Accuracy: 72.47%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/15\n",
      "loss: 0.419314  [   90/  710]\n",
      "loss: 0.352612  [  180/  710]\n",
      "loss: 0.299779  [  270/  710]\n",
      "loss: 0.488752  [  360/  710]\n",
      "loss: 0.282251  [  450/  710]\n",
      "loss: 0.199327  [  540/  710]\n",
      "loss: 0.386161  [  630/  710]\n",
      "loss: 0.278375  [  640/  710]\n",
      "Training Loss (Epoch): 0.338321\n",
      "Validating...\n",
      "Validation Loss: 0.765004, Validation Accuracy: 79.78%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/15\n",
      "loss: 0.447809  [   90/  710]\n",
      "loss: 0.142296  [  180/  710]\n",
      "loss: 0.233925  [  270/  710]\n",
      "loss: 0.260768  [  360/  710]\n",
      "loss: 0.237664  [  450/  710]\n",
      "loss: 0.185327  [  540/  710]\n",
      "loss: 0.198115  [  630/  710]\n",
      "loss: 0.182166  [  640/  710]\n",
      "Training Loss (Epoch): 0.236009\n",
      "Validating...\n",
      "Validation Loss: 0.607390, Validation Accuracy: 81.46%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/15\n",
      "loss: 0.213010  [   90/  710]\n",
      "loss: 0.257305  [  180/  710]\n",
      "loss: 0.320335  [  270/  710]\n",
      "loss: 0.346862  [  360/  710]\n",
      "loss: 0.539727  [  450/  710]\n",
      "loss: 0.105871  [  540/  710]\n",
      "loss: 0.194701  [  630/  710]\n",
      "loss: 0.490553  [  640/  710]\n",
      "Training Loss (Epoch): 0.308545\n",
      "Validating...\n",
      "Validation Loss: 0.627847, Validation Accuracy: 80.90%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 7/15\n",
      "loss: 0.138471  [   90/  710]\n",
      "loss: 0.319727  [  180/  710]\n",
      "loss: 0.275250  [  270/  710]\n",
      "loss: 0.208493  [  360/  710]\n",
      "loss: 0.154545  [  450/  710]\n",
      "loss: 0.236645  [  540/  710]\n",
      "loss: 0.207850  [  630/  710]\n",
      "loss: 0.144952  [  640/  710]\n",
      "Training Loss (Epoch): 0.210742\n",
      "Validating...\n",
      "Validation Loss: 0.462324, Validation Accuracy: 84.27%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 8/15\n",
      "loss: 0.090655  [   90/  710]\n",
      "loss: 0.057068  [  180/  710]\n",
      "loss: 0.090947  [  270/  710]\n",
      "loss: 0.115580  [  360/  710]\n",
      "loss: 0.110146  [  450/  710]\n",
      "loss: 0.035508  [  540/  710]\n",
      "loss: 0.098773  [  630/  710]\n",
      "loss: 0.072641  [  640/  710]\n",
      "Training Loss (Epoch): 0.083915\n",
      "Validating...\n",
      "Validation Loss: 0.423757, Validation Accuracy: 88.20%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 9/15\n",
      "loss: 0.063724  [   90/  710]\n",
      "loss: 0.033043  [  180/  710]\n",
      "loss: 0.068818  [  270/  710]\n",
      "loss: 0.097703  [  360/  710]\n",
      "loss: 0.045323  [  450/  710]\n",
      "loss: 0.074863  [  540/  710]\n",
      "loss: 0.081801  [  630/  710]\n",
      "loss: 0.038777  [  640/  710]\n",
      "Training Loss (Epoch): 0.063007\n",
      "Validating...\n",
      "Validation Loss: 0.421224, Validation Accuracy: 89.33%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 10/15\n",
      "loss: 0.035229  [   90/  710]\n",
      "loss: 0.043513  [  180/  710]\n",
      "loss: 0.059719  [  270/  710]\n",
      "loss: 0.021167  [  360/  710]\n",
      "loss: 0.057606  [  450/  710]\n",
      "loss: 0.066999  [  540/  710]\n",
      "loss: 0.110100  [  630/  710]\n",
      "loss: 0.050247  [  640/  710]\n",
      "Training Loss (Epoch): 0.055572\n",
      "Validating...\n",
      "Validation Loss: 0.424629, Validation Accuracy: 89.33%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 11/15\n",
      "loss: 0.020112  [   90/  710]\n",
      "loss: 0.119819  [  180/  710]\n",
      "loss: 0.040024  [  270/  710]\n",
      "loss: 0.073312  [  360/  710]\n",
      "loss: 0.026114  [  450/  710]\n",
      "loss: 0.079925  [  540/  710]\n",
      "loss: 0.015854  [  630/  710]\n",
      "loss: 0.063152  [  640/  710]\n",
      "Training Loss (Epoch): 0.054789\n",
      "Validating...\n",
      "Validation Loss: 0.424787, Validation Accuracy: 89.33%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 12/15\n",
      "loss: 0.054446  [   90/  710]\n",
      "loss: 0.037145  [  180/  710]\n",
      "loss: 0.030461  [  270/  710]\n",
      "loss: 0.071844  [  360/  710]\n",
      "loss: 0.070476  [  450/  710]\n",
      "loss: 0.049589  [  540/  710]\n",
      "loss: 0.076669  [  630/  710]\n",
      "loss: 0.110540  [  640/  710]\n",
      "Training Loss (Epoch): 0.062646\n",
      "Validating...\n",
      "Validation Loss: 0.424168, Validation Accuracy: 88.76%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 13/15\n",
      "loss: 0.032724  [   90/  710]\n",
      "loss: 0.063208  [  180/  710]\n",
      "loss: 0.025090  [  270/  710]\n",
      "loss: 0.033466  [  360/  710]\n",
      "loss: 0.044962  [  450/  710]\n",
      "loss: 0.099096  [  540/  710]\n",
      "loss: 0.128054  [  630/  710]\n",
      "loss: 0.015838  [  640/  710]\n",
      "Training Loss (Epoch): 0.055305\n",
      "Validating...\n",
      "Validation Loss: 0.422836, Validation Accuracy: 88.76%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 14/15\n",
      "loss: 0.041401  [   90/  710]\n",
      "loss: 0.102646  [  180/  710]\n",
      "loss: 0.020709  [  270/  710]\n",
      "loss: 0.020471  [  360/  710]\n",
      "loss: 0.036775  [  450/  710]\n",
      "loss: 0.065026  [  540/  710]\n",
      "loss: 0.080784  [  630/  710]\n",
      "loss: 0.023268  [  640/  710]\n",
      "Training Loss (Epoch): 0.048885\n",
      "Validating...\n",
      "Validation Loss: 0.421987, Validation Accuracy: 88.76%\n",
      "Learning Rate: [1e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 3\n",
      "Epoch 1/15\n",
      "loss: 2.367490  [   90/  740]\n",
      "loss: 2.272828  [  180/  740]\n",
      "loss: 2.167470  [  270/  740]\n",
      "loss: 2.129735  [  360/  740]\n",
      "loss: 1.775987  [  450/  740]\n",
      "loss: 1.900023  [  540/  740]\n",
      "loss: 1.741914  [  630/  740]\n",
      "loss: 1.605279  [  720/  740]\n",
      "loss: 1.545655  [  180/  740]\n",
      "Training Loss (Epoch): 1.945153\n",
      "Validating...\n",
      "Validation Loss: 1.940930, Validation Accuracy: 41.08%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/15\n",
      "loss: 1.756877  [   90/  740]\n",
      "loss: 1.422790  [  180/  740]\n",
      "loss: 1.238523  [  270/  740]\n",
      "loss: 1.106685  [  360/  740]\n",
      "loss: 1.038120  [  450/  740]\n",
      "loss: 0.987967  [  540/  740]\n",
      "loss: 0.911176  [  630/  740]\n",
      "loss: 1.367415  [  720/  740]\n",
      "loss: 0.945443  [  180/  740]\n",
      "Training Loss (Epoch): 1.197222\n",
      "Validating...\n",
      "Validation Loss: 1.766462, Validation Accuracy: 42.70%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/15\n",
      "loss: 1.611048  [   90/  740]\n",
      "loss: 0.939492  [  180/  740]\n",
      "loss: 0.952252  [  270/  740]\n",
      "loss: 1.025765  [  360/  740]\n",
      "loss: 0.835432  [  450/  740]\n",
      "loss: 0.630397  [  540/  740]\n",
      "loss: 0.832035  [  630/  740]\n",
      "loss: 0.831437  [  720/  740]\n",
      "loss: 0.788181  [  180/  740]\n",
      "Training Loss (Epoch): 0.938449\n",
      "Validating...\n",
      "Validation Loss: 0.965999, Validation Accuracy: 67.03%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/15\n",
      "loss: 0.705971  [   90/  740]\n",
      "loss: 0.592781  [  180/  740]\n",
      "loss: 0.796213  [  270/  740]\n",
      "loss: 0.429078  [  360/  740]\n",
      "loss: 0.594878  [  450/  740]\n",
      "loss: 0.546983  [  540/  740]\n",
      "loss: 0.485380  [  630/  740]\n",
      "loss: 0.418323  [  720/  740]\n",
      "loss: 0.256285  [  180/  740]\n",
      "Training Loss (Epoch): 0.536210\n",
      "Validating...\n",
      "Validation Loss: 0.647022, Validation Accuracy: 77.30%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/15\n",
      "loss: 0.452040  [   90/  740]\n",
      "loss: 0.311342  [  180/  740]\n",
      "loss: 0.616017  [  270/  740]\n",
      "loss: 0.378276  [  360/  740]\n",
      "loss: 0.454325  [  450/  740]\n",
      "loss: 0.321134  [  540/  740]\n",
      "loss: 0.341762  [  630/  740]\n",
      "loss: 0.407007  [  720/  740]\n",
      "loss: 0.092217  [  180/  740]\n",
      "Training Loss (Epoch): 0.374902\n",
      "Validating...\n",
      "Validation Loss: 0.666854, Validation Accuracy: 80.54%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/15\n",
      "loss: 0.287762  [   90/  740]\n",
      "loss: 0.451424  [  180/  740]\n",
      "loss: 0.288958  [  270/  740]\n",
      "loss: 0.203044  [  360/  740]\n",
      "loss: 0.463929  [  450/  740]\n",
      "loss: 0.322945  [  540/  740]\n",
      "loss: 0.272963  [  630/  740]\n",
      "loss: 0.386972  [  720/  740]\n",
      "loss: 0.336112  [  180/  740]\n",
      "Training Loss (Epoch): 0.334901\n",
      "Validating...\n",
      "Validation Loss: 0.399103, Validation Accuracy: 84.32%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 7/15\n",
      "loss: 0.199886  [   90/  740]\n",
      "loss: 0.211708  [  180/  740]\n",
      "loss: 0.116300  [  270/  740]\n",
      "loss: 0.113673  [  360/  740]\n",
      "loss: 0.160371  [  450/  740]\n",
      "loss: 0.197372  [  540/  740]\n",
      "loss: 0.164525  [  630/  740]\n",
      "loss: 0.219967  [  720/  740]\n",
      "loss: 0.245292  [  180/  740]\n",
      "Training Loss (Epoch): 0.181010\n",
      "Validating...\n",
      "Validation Loss: 0.431178, Validation Accuracy: 83.24%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 8/15\n",
      "loss: 0.164434  [   90/  740]\n",
      "loss: 0.083306  [  180/  740]\n",
      "loss: 0.196343  [  270/  740]\n",
      "loss: 0.089865  [  360/  740]\n",
      "loss: 0.143181  [  450/  740]\n",
      "loss: 0.203294  [  540/  740]\n",
      "loss: 0.172765  [  630/  740]\n",
      "loss: 0.073899  [  720/  740]\n",
      "loss: 0.045012  [  180/  740]\n",
      "Training Loss (Epoch): 0.130233\n",
      "Validating...\n",
      "Validation Loss: 0.347109, Validation Accuracy: 85.41%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 9/15\n",
      "loss: 0.121523  [   90/  740]\n",
      "loss: 0.087138  [  180/  740]\n",
      "loss: 0.085048  [  270/  740]\n",
      "loss: 0.083070  [  360/  740]\n",
      "loss: 0.056035  [  450/  740]\n",
      "loss: 0.088465  [  540/  740]\n",
      "loss: 0.097383  [  630/  740]\n",
      "loss: 0.190963  [  720/  740]\n",
      "loss: 0.097690  [  180/  740]\n",
      "Training Loss (Epoch): 0.100813\n",
      "Validating...\n",
      "Validation Loss: 0.332184, Validation Accuracy: 85.41%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 10/15\n",
      "loss: 0.039339  [   90/  740]\n",
      "loss: 0.116581  [  180/  740]\n",
      "loss: 0.032027  [  270/  740]\n",
      "loss: 0.137683  [  360/  740]\n",
      "loss: 0.177683  [  450/  740]\n",
      "loss: 0.114866  [  540/  740]\n",
      "loss: 0.066664  [  630/  740]\n",
      "loss: 0.070997  [  720/  740]\n",
      "loss: 0.003105  [  180/  740]\n",
      "Training Loss (Epoch): 0.084327\n",
      "Validating...\n",
      "Validation Loss: 0.352346, Validation Accuracy: 86.49%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 11/15\n",
      "loss: 0.078902  [   90/  740]\n",
      "loss: 0.204015  [  180/  740]\n",
      "loss: 0.029716  [  270/  740]\n",
      "loss: 0.085744  [  360/  740]\n",
      "loss: 0.035109  [  450/  740]\n",
      "loss: 0.101080  [  540/  740]\n",
      "loss: 0.023065  [  630/  740]\n",
      "loss: 0.126978  [  720/  740]\n",
      "loss: 0.036932  [  180/  740]\n",
      "Training Loss (Epoch): 0.080171\n",
      "Validating...\n",
      "Validation Loss: 0.352450, Validation Accuracy: 86.49%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 12/15\n",
      "loss: 0.108029  [   90/  740]\n",
      "loss: 0.085969  [  180/  740]\n",
      "loss: 0.103763  [  270/  740]\n",
      "loss: 0.049838  [  360/  740]\n",
      "loss: 0.016594  [  450/  740]\n",
      "loss: 0.093155  [  540/  740]\n",
      "loss: 0.074330  [  630/  740]\n",
      "loss: 0.090396  [  720/  740]\n",
      "loss: 0.101817  [  180/  740]\n",
      "Training Loss (Epoch): 0.080432\n",
      "Validating...\n",
      "Validation Loss: 0.350642, Validation Accuracy: 86.49%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 13/15\n",
      "loss: 0.071056  [   90/  740]\n",
      "loss: 0.073651  [  180/  740]\n",
      "loss: 0.095368  [  270/  740]\n",
      "loss: 0.055970  [  360/  740]\n",
      "loss: 0.036355  [  450/  740]\n",
      "loss: 0.079061  [  540/  740]\n",
      "loss: 0.078364  [  630/  740]\n",
      "loss: 0.133764  [  720/  740]\n",
      "loss: 0.197505  [  180/  740]\n",
      "Training Loss (Epoch): 0.091233\n",
      "Validating...\n",
      "Validation Loss: 0.346994, Validation Accuracy: 86.49%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 14/15\n",
      "loss: 0.069833  [   90/  740]\n",
      "loss: 0.092121  [  180/  740]\n",
      "loss: 0.045913  [  270/  740]\n",
      "loss: 0.054526  [  360/  740]\n",
      "loss: 0.124347  [  450/  740]\n",
      "loss: 0.065980  [  540/  740]\n",
      "loss: 0.111067  [  630/  740]\n",
      "loss: 0.078033  [  720/  740]\n",
      "loss: 0.001748  [  180/  740]\n",
      "Training Loss (Epoch): 0.071508\n",
      "Validating...\n",
      "Validation Loss: 0.343171, Validation Accuracy: 87.03%\n",
      "Learning Rate: [1e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 4\n",
      "Epoch 1/15\n",
      "loss: 2.392965  [   90/  792]\n",
      "loss: 2.286539  [  180/  792]\n",
      "loss: 2.107198  [  270/  792]\n",
      "loss: 2.036753  [  360/  792]\n",
      "loss: 2.025433  [  450/  792]\n",
      "loss: 1.842444  [  540/  792]\n",
      "loss: 1.738078  [  630/  792]\n",
      "loss: 1.645397  [  720/  792]\n",
      "loss: 1.739476  [  648/  792]\n",
      "Training Loss (Epoch): 1.979365\n",
      "Validating...\n",
      "Validation Loss: 1.720332, Validation Accuracy: 53.54%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/15\n",
      "loss: 1.831933  [   90/  792]\n",
      "loss: 1.460886  [  180/  792]\n",
      "loss: 1.103705  [  270/  792]\n",
      "loss: 1.316591  [  360/  792]\n",
      "loss: 1.215883  [  450/  792]\n",
      "loss: 1.150741  [  540/  792]\n",
      "loss: 1.001304  [  630/  792]\n",
      "loss: 0.854968  [  720/  792]\n",
      "loss: 0.845734  [  648/  792]\n",
      "Training Loss (Epoch): 1.197972\n",
      "Validating...\n",
      "Validation Loss: 0.903157, Validation Accuracy: 71.72%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/15\n",
      "loss: 0.759172  [   90/  792]\n",
      "loss: 0.803383  [  180/  792]\n",
      "loss: 0.777973  [  270/  792]\n",
      "loss: 0.555988  [  360/  792]\n",
      "loss: 0.571317  [  450/  792]\n",
      "loss: 0.375063  [  540/  792]\n",
      "loss: 0.686496  [  630/  792]\n",
      "loss: 0.630369  [  720/  792]\n",
      "loss: 0.635413  [  648/  792]\n",
      "Training Loss (Epoch): 0.643908\n",
      "Validating...\n",
      "Validation Loss: 0.913142, Validation Accuracy: 71.21%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/15\n",
      "loss: 0.581135  [   90/  792]\n",
      "loss: 0.511526  [  180/  792]\n",
      "loss: 0.574137  [  270/  792]\n",
      "loss: 0.362376  [  360/  792]\n",
      "loss: 0.674773  [  450/  792]\n",
      "loss: 0.384793  [  540/  792]\n",
      "loss: 0.700722  [  630/  792]\n",
      "loss: 0.638956  [  720/  792]\n",
      "loss: 0.671881  [  648/  792]\n",
      "Training Loss (Epoch): 0.566700\n",
      "Validating...\n",
      "Validation Loss: 0.910054, Validation Accuracy: 79.29%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 5/15\n",
      "loss: 0.382030  [   90/  792]\n",
      "loss: 0.362369  [  180/  792]\n",
      "loss: 0.262391  [  270/  792]\n",
      "loss: 0.336646  [  360/  792]\n",
      "loss: 0.329387  [  450/  792]\n",
      "loss: 0.421422  [  540/  792]\n",
      "loss: 0.248761  [  630/  792]\n",
      "loss: 0.327713  [  720/  792]\n",
      "loss: 0.303019  [  648/  792]\n",
      "Training Loss (Epoch): 0.330415\n",
      "Validating...\n",
      "Validation Loss: 0.801201, Validation Accuracy: 83.33%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 6/15\n",
      "loss: 0.188669  [   90/  792]\n",
      "loss: 0.188768  [  180/  792]\n",
      "loss: 0.202295  [  270/  792]\n",
      "loss: 0.268207  [  360/  792]\n",
      "loss: 0.185382  [  450/  792]\n",
      "loss: 0.209883  [  540/  792]\n",
      "loss: 0.349809  [  630/  792]\n",
      "loss: 0.185169  [  720/  792]\n",
      "loss: 0.154283  [  648/  792]\n",
      "Training Loss (Epoch): 0.214718\n",
      "Validating...\n",
      "Validation Loss: 0.898749, Validation Accuracy: 87.37%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 7/15\n",
      "loss: 0.288816  [   90/  792]\n",
      "loss: 0.199779  [  180/  792]\n",
      "loss: 0.146068  [  270/  792]\n",
      "loss: 0.129183  [  360/  792]\n",
      "loss: 0.209758  [  450/  792]\n",
      "loss: 0.154120  [  540/  792]\n",
      "loss: 0.123029  [  630/  792]\n",
      "loss: 0.098187  [  720/  792]\n",
      "loss: 0.078252  [  648/  792]\n",
      "Training Loss (Epoch): 0.158577\n",
      "Validating...\n",
      "Validation Loss: 0.961945, Validation Accuracy: 85.86%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 8/15\n",
      "loss: 0.104422  [   90/  792]\n",
      "loss: 0.074596  [  180/  792]\n",
      "loss: 0.129291  [  270/  792]\n",
      "loss: 0.074543  [  360/  792]\n",
      "loss: 0.140464  [  450/  792]\n",
      "loss: 0.093422  [  540/  792]\n",
      "loss: 0.130039  [  630/  792]\n",
      "loss: 0.188183  [  720/  792]\n",
      "loss: 0.136549  [  648/  792]\n",
      "Training Loss (Epoch): 0.119057\n",
      "Validating...\n",
      "Validation Loss: 0.933642, Validation Accuracy: 88.38%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 9/15\n",
      "loss: 0.127735  [   90/  792]\n",
      "loss: 0.045371  [  180/  792]\n",
      "loss: 0.139289  [  270/  792]\n",
      "loss: 0.060347  [  360/  792]\n",
      "loss: 0.173621  [  450/  792]\n",
      "loss: 0.132395  [  540/  792]\n",
      "loss: 0.093901  [  630/  792]\n",
      "loss: 0.078568  [  720/  792]\n",
      "loss: 0.106053  [  648/  792]\n",
      "Training Loss (Epoch): 0.106364\n",
      "Validating...\n",
      "Validation Loss: 0.945204, Validation Accuracy: 88.89%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 10/15\n",
      "loss: 0.154368  [   90/  792]\n",
      "loss: 0.086747  [  180/  792]\n",
      "loss: 0.098954  [  270/  792]\n",
      "loss: 0.142703  [  360/  792]\n",
      "loss: 0.050124  [  450/  792]\n",
      "loss: 0.143503  [  540/  792]\n",
      "loss: 0.045455  [  630/  792]\n",
      "loss: 0.072259  [  720/  792]\n",
      "loss: 0.085073  [  648/  792]\n",
      "Training Loss (Epoch): 0.097687\n",
      "Validating...\n",
      "Validation Loss: 0.948773, Validation Accuracy: 88.38%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 5\n",
      "Epoch 1/15\n",
      "loss: 2.379334  [   90/  748]\n",
      "loss: 2.202548  [  180/  748]\n",
      "loss: 2.109129  [  270/  748]\n",
      "loss: 2.051822  [  360/  748]\n",
      "loss: 1.946176  [  450/  748]\n",
      "loss: 1.844364  [  540/  748]\n",
      "loss: 1.771696  [  630/  748]\n",
      "loss: 1.642890  [  720/  748]\n",
      "loss: 1.591756  [  252/  748]\n",
      "Training Loss (Epoch): 1.948857\n",
      "Validating...\n",
      "Validation Loss: 1.915713, Validation Accuracy: 42.02%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/15\n",
      "loss: 1.770141  [   90/  748]\n",
      "loss: 1.359226  [  180/  748]\n",
      "loss: 1.208554  [  270/  748]\n",
      "loss: 1.106802  [  360/  748]\n",
      "loss: 1.379885  [  450/  748]\n",
      "loss: 1.345894  [  540/  748]\n",
      "loss: 1.275324  [  630/  748]\n",
      "loss: 1.366538  [  720/  748]\n",
      "loss: 1.115952  [  252/  748]\n",
      "Training Loss (Epoch): 1.325368\n",
      "Validating...\n",
      "Validation Loss: 1.301339, Validation Accuracy: 56.38%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/15\n",
      "loss: 0.816777  [   90/  748]\n",
      "loss: 0.927331  [  180/  748]\n",
      "loss: 0.702055  [  270/  748]\n",
      "loss: 0.851765  [  360/  748]\n",
      "loss: 0.814548  [  450/  748]\n",
      "loss: 0.912339  [  540/  748]\n",
      "loss: 0.679340  [  630/  748]\n",
      "loss: 1.380998  [  720/  748]\n",
      "loss: 0.673403  [  252/  748]\n",
      "Training Loss (Epoch): 0.862062\n",
      "Validating...\n",
      "Validation Loss: 1.083691, Validation Accuracy: 70.21%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/15\n",
      "loss: 0.815155  [   90/  748]\n",
      "loss: 0.587982  [  180/  748]\n",
      "loss: 0.516830  [  270/  748]\n",
      "loss: 0.601922  [  360/  748]\n",
      "loss: 0.589319  [  450/  748]\n",
      "loss: 0.632823  [  540/  748]\n",
      "loss: 0.419877  [  630/  748]\n",
      "loss: 0.318400  [  720/  748]\n",
      "loss: 0.500051  [  252/  748]\n",
      "Training Loss (Epoch): 0.553595\n",
      "Validating...\n",
      "Validation Loss: 1.415078, Validation Accuracy: 71.81%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/15\n",
      "loss: 0.569696  [   90/  748]\n",
      "loss: 0.339463  [  180/  748]\n",
      "loss: 0.435538  [  270/  748]\n",
      "loss: 0.297934  [  360/  748]\n",
      "loss: 0.291057  [  450/  748]\n",
      "loss: 0.354039  [  540/  748]\n",
      "loss: 0.226250  [  630/  748]\n",
      "loss: 0.359340  [  720/  748]\n",
      "loss: 0.800118  [  252/  748]\n",
      "Training Loss (Epoch): 0.408160\n",
      "Validating...\n",
      "Validation Loss: 0.792817, Validation Accuracy: 77.66%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 6/15\n",
      "loss: 0.336682  [   90/  748]\n",
      "loss: 0.265031  [  180/  748]\n",
      "loss: 0.312079  [  270/  748]\n",
      "loss: 0.387017  [  360/  748]\n",
      "loss: 0.290870  [  450/  748]\n",
      "loss: 0.257110  [  540/  748]\n",
      "loss: 0.237665  [  630/  748]\n",
      "loss: 0.271416  [  720/  748]\n",
      "loss: 0.422821  [  252/  748]\n",
      "Training Loss (Epoch): 0.308966\n",
      "Validating...\n",
      "Validation Loss: 0.720665, Validation Accuracy: 81.91%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 7/15\n",
      "loss: 0.163764  [   90/  748]\n",
      "loss: 0.221382  [  180/  748]\n",
      "loss: 0.267726  [  270/  748]\n",
      "loss: 0.249034  [  360/  748]\n",
      "loss: 0.197850  [  450/  748]\n",
      "loss: 0.251785  [  540/  748]\n",
      "loss: 0.199523  [  630/  748]\n",
      "loss: 0.173990  [  720/  748]\n",
      "loss: 0.034660  [  252/  748]\n",
      "Training Loss (Epoch): 0.195524\n",
      "Validating...\n",
      "Validation Loss: 0.619447, Validation Accuracy: 81.38%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 8/15\n",
      "loss: 0.183120  [   90/  748]\n",
      "loss: 0.092521  [  180/  748]\n",
      "loss: 0.250614  [  270/  748]\n",
      "loss: 0.115249  [  360/  748]\n",
      "loss: 0.214733  [  450/  748]\n",
      "loss: 0.152856  [  540/  748]\n",
      "loss: 0.292681  [  630/  748]\n",
      "loss: 0.206529  [  720/  748]\n",
      "loss: 0.334053  [  252/  748]\n",
      "Training Loss (Epoch): 0.204706\n",
      "Validating...\n",
      "Validation Loss: 0.712676, Validation Accuracy: 84.04%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 9/15\n",
      "loss: 0.263822  [   90/  748]\n",
      "loss: 0.178314  [  180/  748]\n",
      "loss: 0.127626  [  270/  748]\n",
      "loss: 0.153964  [  360/  748]\n",
      "loss: 0.076326  [  450/  748]\n",
      "loss: 0.135650  [  540/  748]\n",
      "loss: 0.140367  [  630/  748]\n",
      "loss: 0.163113  [  720/  748]\n",
      "loss: 0.310076  [  252/  748]\n",
      "Training Loss (Epoch): 0.172140\n",
      "Validating...\n",
      "Validation Loss: 0.606034, Validation Accuracy: 85.11%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 10/15\n",
      "loss: 0.110425  [   90/  748]\n",
      "loss: 0.079286  [  180/  748]\n",
      "loss: 0.145177  [  270/  748]\n",
      "loss: 0.176330  [  360/  748]\n",
      "loss: 0.067390  [  450/  748]\n",
      "loss: 0.213665  [  540/  748]\n",
      "loss: 0.185510  [  630/  748]\n",
      "loss: 0.184614  [  720/  748]\n",
      "loss: 0.145971  [  252/  748]\n",
      "Training Loss (Epoch): 0.145374\n",
      "Validating...\n",
      "Validation Loss: 0.526787, Validation Accuracy: 85.64%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 11/15\n",
      "loss: 0.198786  [   90/  748]\n",
      "loss: 0.168411  [  180/  748]\n",
      "loss: 0.061350  [  270/  748]\n",
      "loss: 0.170803  [  360/  748]\n",
      "loss: 0.130825  [  450/  748]\n",
      "loss: 0.127152  [  540/  748]\n",
      "loss: 0.141459  [  630/  748]\n",
      "loss: 0.106048  [  720/  748]\n",
      "loss: 0.157829  [  252/  748]\n",
      "Training Loss (Epoch): 0.140296\n",
      "Validating...\n",
      "Validation Loss: 0.522895, Validation Accuracy: 85.64%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 12/15\n",
      "loss: 0.155060  [   90/  748]\n",
      "loss: 0.119243  [  180/  748]\n",
      "loss: 0.069119  [  270/  748]\n",
      "loss: 0.130446  [  360/  748]\n",
      "loss: 0.116531  [  450/  748]\n",
      "loss: 0.211188  [  540/  748]\n",
      "loss: 0.106850  [  630/  748]\n",
      "loss: 0.155884  [  720/  748]\n",
      "loss: 0.192253  [  252/  748]\n",
      "Training Loss (Epoch): 0.139619\n",
      "Validating...\n",
      "Validation Loss: 0.520811, Validation Accuracy: 86.17%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 13/15\n",
      "loss: 0.116347  [   90/  748]\n",
      "loss: 0.135726  [  180/  748]\n",
      "loss: 0.129195  [  270/  748]\n",
      "loss: 0.106358  [  360/  748]\n",
      "loss: 0.195158  [  450/  748]\n",
      "loss: 0.141247  [  540/  748]\n",
      "loss: 0.071807  [  630/  748]\n",
      "loss: 0.190270  [  720/  748]\n",
      "loss: 0.081381  [  252/  748]\n",
      "Training Loss (Epoch): 0.129721\n",
      "Validating...\n",
      "Validation Loss: 0.520330, Validation Accuracy: 86.17%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 14/15\n",
      "loss: 0.155771  [   90/  748]\n",
      "loss: 0.146592  [  180/  748]\n",
      "loss: 0.119173  [  270/  748]\n",
      "loss: 0.120264  [  360/  748]\n",
      "loss: 0.184630  [  450/  748]\n",
      "loss: 0.125545  [  540/  748]\n",
      "loss: 0.060976  [  630/  748]\n",
      "loss: 0.125852  [  720/  748]\n",
      "loss: 0.232795  [  252/  748]\n",
      "Training Loss (Epoch): 0.141289\n",
      "Validating...\n",
      "Validation Loss: 0.518348, Validation Accuracy: 85.64%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 15/15\n",
      "loss: 0.100450  [   90/  748]\n",
      "loss: 0.185595  [  180/  748]\n",
      "loss: 0.112715  [  270/  748]\n",
      "loss: 0.116412  [  360/  748]\n",
      "loss: 0.090543  [  450/  748]\n",
      "loss: 0.162962  [  540/  748]\n",
      "loss: 0.137791  [  630/  748]\n",
      "loss: 0.124326  [  720/  748]\n",
      "loss: 0.234113  [  252/  748]\n",
      "Training Loss (Epoch): 0.140545\n",
      "Validating...\n",
      "Validation Loss: 0.518285, Validation Accuracy: 85.64%\n",
      "Learning Rate: [1e-06]\n",
      "Processing Fold 6\n",
      "Epoch 1/15\n",
      "loss: 2.401916  [   90/  658]\n",
      "loss: 2.224839  [  180/  658]\n",
      "loss: 2.100872  [  270/  658]\n",
      "loss: 2.049124  [  360/  658]\n",
      "loss: 1.889719  [  450/  658]\n",
      "loss: 1.922029  [  540/  658]\n",
      "loss: 1.751897  [  630/  658]\n",
      "loss: 1.487310  [  224/  658]\n",
      "Training Loss (Epoch): 1.978463\n",
      "Validating...\n",
      "Validation Loss: 2.012048, Validation Accuracy: 38.79%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/15\n",
      "loss: 1.927767  [   90/  658]\n",
      "loss: 1.587181  [  180/  658]\n",
      "loss: 1.414435  [  270/  658]\n",
      "loss: 1.354936  [  360/  658]\n",
      "loss: 1.696023  [  450/  658]\n",
      "loss: 1.156069  [  540/  658]\n",
      "loss: 1.013269  [  630/  658]\n",
      "loss: 1.341901  [  224/  658]\n",
      "Training Loss (Epoch): 1.436448\n",
      "Validating...\n",
      "Validation Loss: 1.300069, Validation Accuracy: 52.12%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/15\n",
      "loss: 1.095275  [   90/  658]\n",
      "loss: 0.896524  [  180/  658]\n",
      "loss: 1.211162  [  270/  658]\n",
      "loss: 0.824263  [  360/  658]\n",
      "loss: 0.839916  [  450/  658]\n",
      "loss: 0.863943  [  540/  658]\n",
      "loss: 0.733233  [  630/  658]\n",
      "loss: 0.873416  [  224/  658]\n",
      "Training Loss (Epoch): 0.917217\n",
      "Validating...\n",
      "Validation Loss: 0.774646, Validation Accuracy: 73.94%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/15\n",
      "loss: 0.711179  [   90/  658]\n",
      "loss: 0.614469  [  180/  658]\n",
      "loss: 0.668586  [  270/  658]\n",
      "loss: 0.604494  [  360/  658]\n",
      "loss: 0.543995  [  450/  658]\n",
      "loss: 0.519405  [  540/  658]\n",
      "loss: 0.544046  [  630/  658]\n",
      "loss: 0.391686  [  224/  658]\n",
      "Training Loss (Epoch): 0.574733\n",
      "Validating...\n",
      "Validation Loss: 0.561327, Validation Accuracy: 80.00%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/15\n",
      "loss: 0.461627  [   90/  658]\n",
      "loss: 0.433477  [  180/  658]\n",
      "loss: 0.444023  [  270/  658]\n",
      "loss: 0.443366  [  360/  658]\n",
      "loss: 0.336240  [  450/  658]\n",
      "loss: 0.362589  [  540/  658]\n",
      "loss: 0.303174  [  630/  658]\n",
      "loss: 0.251966  [  224/  658]\n",
      "Training Loss (Epoch): 0.379558\n",
      "Validating...\n",
      "Validation Loss: 0.727543, Validation Accuracy: 76.36%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 6/15\n",
      "loss: 0.506254  [   90/  658]\n",
      "loss: 0.417998  [  180/  658]\n",
      "loss: 0.291609  [  270/  658]\n",
      "loss: 0.275654  [  360/  658]\n",
      "loss: 0.291088  [  450/  658]\n",
      "loss: 0.311145  [  540/  658]\n",
      "loss: 0.195863  [  630/  658]\n",
      "loss: 0.396080  [  224/  658]\n",
      "Training Loss (Epoch): 0.335711\n",
      "Validating...\n",
      "Validation Loss: 0.444500, Validation Accuracy: 83.64%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 7/15\n",
      "loss: 0.147463  [   90/  658]\n",
      "loss: 0.381084  [  180/  658]\n",
      "loss: 0.356065  [  270/  658]\n",
      "loss: 0.225019  [  360/  658]\n",
      "loss: 0.197722  [  450/  658]\n",
      "loss: 0.201392  [  540/  658]\n",
      "loss: 0.147788  [  630/  658]\n",
      "loss: 0.413639  [  224/  658]\n",
      "Training Loss (Epoch): 0.258771\n",
      "Validating...\n",
      "Validation Loss: 0.386636, Validation Accuracy: 87.88%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 8/15\n",
      "loss: 0.185394  [   90/  658]\n",
      "loss: 0.192363  [  180/  658]\n",
      "loss: 0.195176  [  270/  658]\n",
      "loss: 0.191520  [  360/  658]\n",
      "loss: 0.106151  [  450/  658]\n",
      "loss: 0.202479  [  540/  658]\n",
      "loss: 0.256596  [  630/  658]\n",
      "loss: 0.093121  [  224/  658]\n",
      "Training Loss (Epoch): 0.177850\n",
      "Validating...\n",
      "Validation Loss: 0.368793, Validation Accuracy: 88.48%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 9/15\n",
      "loss: 0.185391  [   90/  658]\n",
      "loss: 0.227725  [  180/  658]\n",
      "loss: 0.205254  [  270/  658]\n",
      "loss: 0.143859  [  360/  658]\n",
      "loss: 0.196987  [  450/  658]\n",
      "loss: 0.076557  [  540/  658]\n",
      "loss: 0.142528  [  630/  658]\n",
      "loss: 0.043625  [  224/  658]\n",
      "Training Loss (Epoch): 0.152741\n",
      "Validating...\n",
      "Validation Loss: 0.380996, Validation Accuracy: 89.09%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 10/15\n",
      "loss: 0.102520  [   90/  658]\n",
      "loss: 0.196071  [  180/  658]\n",
      "loss: 0.093917  [  270/  658]\n",
      "loss: 0.104630  [  360/  658]\n",
      "loss: 0.137345  [  450/  658]\n",
      "loss: 0.175755  [  540/  658]\n",
      "loss: 0.116885  [  630/  658]\n",
      "loss: 0.127810  [  224/  658]\n",
      "Training Loss (Epoch): 0.131867\n",
      "Validating...\n",
      "Validation Loss: 0.385772, Validation Accuracy: 89.70%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 11/15\n",
      "loss: 0.061043  [   90/  658]\n",
      "loss: 0.164475  [  180/  658]\n",
      "loss: 0.183068  [  270/  658]\n",
      "loss: 0.127850  [  360/  658]\n",
      "loss: 0.043862  [  450/  658]\n",
      "loss: 0.107700  [  540/  658]\n",
      "loss: 0.161320  [  630/  658]\n",
      "loss: 0.189369  [  224/  658]\n",
      "Training Loss (Epoch): 0.129836\n",
      "Validating...\n",
      "Validation Loss: 0.385210, Validation Accuracy: 89.09%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 12/15\n",
      "loss: 0.130543  [   90/  658]\n",
      "loss: 0.102777  [  180/  658]\n",
      "loss: 0.114267  [  270/  658]\n",
      "loss: 0.128441  [  360/  658]\n",
      "loss: 0.102711  [  450/  658]\n",
      "loss: 0.130070  [  540/  658]\n",
      "loss: 0.119739  [  630/  658]\n",
      "loss: 0.119790  [  224/  658]\n",
      "Training Loss (Epoch): 0.118542\n",
      "Validating...\n",
      "Validation Loss: 0.385392, Validation Accuracy: 89.09%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 13/15\n",
      "loss: 0.151707  [   90/  658]\n",
      "loss: 0.112748  [  180/  658]\n",
      "loss: 0.105485  [  270/  658]\n",
      "loss: 0.163455  [  360/  658]\n",
      "loss: 0.088596  [  450/  658]\n",
      "loss: 0.091603  [  540/  658]\n",
      "loss: 0.071174  [  630/  658]\n",
      "loss: 0.172660  [  224/  658]\n",
      "Training Loss (Epoch): 0.119679\n",
      "Validating...\n",
      "Validation Loss: 0.385363, Validation Accuracy: 89.09%\n",
      "Learning Rate: [1e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 7\n",
      "Epoch 1/15\n",
      "loss: 2.332091  [   90/  670]\n",
      "loss: 2.202779  [  180/  670]\n",
      "loss: 2.093564  [  270/  670]\n",
      "loss: 1.957397  [  360/  670]\n",
      "loss: 1.983188  [  450/  670]\n",
      "loss: 1.693164  [  540/  670]\n",
      "loss: 1.703564  [  630/  670]\n",
      "loss: 1.519227  [  320/  670]\n",
      "Training Loss (Epoch): 1.935622\n",
      "Validating...\n",
      "Validation Loss: 1.899296, Validation Accuracy: 41.67%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/15\n",
      "loss: 1.802211  [   90/  670]\n",
      "loss: 1.433796  [  180/  670]\n",
      "loss: 1.171042  [  270/  670]\n",
      "loss: 1.348116  [  360/  670]\n",
      "loss: 1.497699  [  450/  670]\n",
      "loss: 1.515285  [  540/  670]\n",
      "loss: 1.100326  [  630/  670]\n",
      "loss: 1.304150  [  320/  670]\n",
      "Training Loss (Epoch): 1.396578\n",
      "Validating...\n",
      "Validation Loss: 1.144211, Validation Accuracy: 61.90%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/15\n",
      "loss: 1.160972  [   90/  670]\n",
      "loss: 0.961501  [  180/  670]\n",
      "loss: 0.920851  [  270/  670]\n",
      "loss: 0.921606  [  360/  670]\n",
      "loss: 0.760690  [  450/  670]\n",
      "loss: 0.852489  [  540/  670]\n",
      "loss: 0.715530  [  630/  670]\n",
      "loss: 0.774839  [  320/  670]\n",
      "Training Loss (Epoch): 0.883560\n",
      "Validating...\n",
      "Validation Loss: 1.015514, Validation Accuracy: 63.69%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/15\n",
      "loss: 0.745381  [   90/  670]\n",
      "loss: 0.573752  [  180/  670]\n",
      "loss: 0.646704  [  270/  670]\n",
      "loss: 0.669718  [  360/  670]\n",
      "loss: 0.505029  [  450/  670]\n",
      "loss: 0.475128  [  540/  670]\n",
      "loss: 0.615516  [  630/  670]\n",
      "loss: 0.489097  [  320/  670]\n",
      "Training Loss (Epoch): 0.590041\n",
      "Validating...\n",
      "Validation Loss: 0.669470, Validation Accuracy: 75.00%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/15\n",
      "loss: 0.247137  [   90/  670]\n",
      "loss: 0.369229  [  180/  670]\n",
      "loss: 0.359342  [  270/  670]\n",
      "loss: 0.465128  [  360/  670]\n",
      "loss: 0.387807  [  450/  670]\n",
      "loss: 0.389018  [  540/  670]\n",
      "loss: 0.376640  [  630/  670]\n",
      "loss: 0.819083  [  320/  670]\n",
      "Training Loss (Epoch): 0.426673\n",
      "Validating...\n",
      "Validation Loss: 0.832514, Validation Accuracy: 76.79%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/15\n",
      "loss: 0.423836  [   90/  670]\n",
      "loss: 0.316333  [  180/  670]\n",
      "loss: 0.400509  [  270/  670]\n",
      "loss: 0.326178  [  360/  670]\n",
      "loss: 0.272290  [  450/  670]\n",
      "loss: 0.405762  [  540/  670]\n",
      "loss: 0.457540  [  630/  670]\n",
      "loss: 0.267833  [  320/  670]\n",
      "Training Loss (Epoch): 0.358785\n",
      "Validating...\n",
      "Validation Loss: 0.701350, Validation Accuracy: 77.38%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 7/15\n",
      "loss: 0.212236  [   90/  670]\n",
      "loss: 0.229995  [  180/  670]\n",
      "loss: 0.193950  [  270/  670]\n",
      "loss: 0.204539  [  360/  670]\n",
      "loss: 0.223131  [  450/  670]\n",
      "loss: 0.262689  [  540/  670]\n",
      "loss: 0.261462  [  630/  670]\n",
      "loss: 0.234147  [  320/  670]\n",
      "Training Loss (Epoch): 0.227769\n",
      "Validating...\n",
      "Validation Loss: 0.502991, Validation Accuracy: 83.93%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 8/15\n",
      "loss: 0.248974  [   90/  670]\n",
      "loss: 0.076859  [  180/  670]\n",
      "loss: 0.195506  [  270/  670]\n",
      "loss: 0.115458  [  360/  670]\n",
      "loss: 0.194535  [  450/  670]\n",
      "loss: 0.205840  [  540/  670]\n",
      "loss: 0.097608  [  630/  670]\n",
      "loss: 0.134891  [  320/  670]\n",
      "Training Loss (Epoch): 0.158709\n",
      "Validating...\n",
      "Validation Loss: 0.551375, Validation Accuracy: 85.12%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 9/15\n",
      "loss: 0.129386  [   90/  670]\n",
      "loss: 0.149895  [  180/  670]\n",
      "loss: 0.104385  [  270/  670]\n",
      "loss: 0.133957  [  360/  670]\n",
      "loss: 0.161810  [  450/  670]\n",
      "loss: 0.205049  [  540/  670]\n",
      "loss: 0.075259  [  630/  670]\n",
      "loss: 0.065992  [  320/  670]\n",
      "Training Loss (Epoch): 0.128217\n",
      "Validating...\n",
      "Validation Loss: 0.620618, Validation Accuracy: 85.12%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 10/15\n",
      "loss: 0.132601  [   90/  670]\n",
      "loss: 0.058152  [  180/  670]\n",
      "loss: 0.118973  [  270/  670]\n",
      "loss: 0.054791  [  360/  670]\n",
      "loss: 0.189919  [  450/  670]\n",
      "loss: 0.132840  [  540/  670]\n",
      "loss: 0.188854  [  630/  670]\n",
      "loss: 0.048718  [  320/  670]\n",
      "Training Loss (Epoch): 0.115606\n",
      "Validating...\n",
      "Validation Loss: 0.676305, Validation Accuracy: 86.31%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 11/15\n",
      "loss: 0.121345  [   90/  670]\n",
      "loss: 0.079217  [  180/  670]\n",
      "loss: 0.042045  [  270/  670]\n",
      "loss: 0.132247  [  360/  670]\n",
      "loss: 0.109028  [  450/  670]\n",
      "loss: 0.098658  [  540/  670]\n",
      "loss: 0.054347  [  630/  670]\n",
      "loss: 0.176082  [  320/  670]\n",
      "Training Loss (Epoch): 0.101621\n",
      "Validating...\n",
      "Validation Loss: 0.642112, Validation Accuracy: 86.31%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 12/15\n",
      "loss: 0.059133  [   90/  670]\n",
      "loss: 0.076760  [  180/  670]\n",
      "loss: 0.086051  [  270/  670]\n",
      "loss: 0.059834  [  360/  670]\n",
      "loss: 0.113499  [  450/  670]\n",
      "loss: 0.073837  [  540/  670]\n",
      "loss: 0.162009  [  630/  670]\n",
      "loss: 0.030688  [  320/  670]\n",
      "Training Loss (Epoch): 0.082726\n",
      "Validating...\n",
      "Validation Loss: 0.608301, Validation Accuracy: 86.90%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 8\n",
      "Epoch 1/15\n",
      "loss: 2.391659  [   90/  644]\n",
      "loss: 2.247153  [  180/  644]\n",
      "loss: 2.177598  [  270/  644]\n",
      "loss: 2.071949  [  360/  644]\n",
      "loss: 1.955849  [  450/  644]\n",
      "loss: 1.774497  [  540/  644]\n",
      "loss: 1.788393  [  630/  644]\n",
      "loss: 1.767901  [  112/  644]\n",
      "Training Loss (Epoch): 2.021875\n",
      "Validating...\n",
      "Validation Loss: 2.030951, Validation Accuracy: 38.27%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/15\n",
      "loss: 2.024017  [   90/  644]\n",
      "loss: 1.789424  [  180/  644]\n",
      "loss: 1.409347  [  270/  644]\n",
      "loss: 1.376041  [  360/  644]\n",
      "loss: 1.793108  [  450/  644]\n",
      "loss: 1.405314  [  540/  644]\n",
      "loss: 1.548482  [  630/  644]\n",
      "loss: 2.071232  [  112/  644]\n",
      "Training Loss (Epoch): 1.677120\n",
      "Validating...\n",
      "Validation Loss: 1.630038, Validation Accuracy: 39.51%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/15\n",
      "loss: 1.565380  [   90/  644]\n",
      "loss: 1.377404  [  180/  644]\n",
      "loss: 1.036610  [  270/  644]\n",
      "loss: 1.298094  [  360/  644]\n",
      "loss: 1.015142  [  450/  644]\n",
      "loss: 0.960668  [  540/  644]\n",
      "loss: 1.012979  [  630/  644]\n",
      "loss: 1.322169  [  112/  644]\n",
      "Training Loss (Epoch): 1.198555\n",
      "Validating...\n",
      "Validation Loss: 1.051174, Validation Accuracy: 66.05%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/15\n",
      "loss: 0.957808  [   90/  644]\n",
      "loss: 0.755593  [  180/  644]\n",
      "loss: 0.806865  [  270/  644]\n",
      "loss: 0.809921  [  360/  644]\n",
      "loss: 0.714193  [  450/  644]\n",
      "loss: 0.830166  [  540/  644]\n",
      "loss: 0.603161  [  630/  644]\n",
      "loss: 0.255603  [  112/  644]\n",
      "Training Loss (Epoch): 0.716664\n",
      "Validating...\n",
      "Validation Loss: 1.100431, Validation Accuracy: 66.67%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/15\n",
      "loss: 0.961141  [   90/  644]\n",
      "loss: 0.742682  [  180/  644]\n",
      "loss: 0.689852  [  270/  644]\n",
      "loss: 0.611854  [  360/  644]\n",
      "loss: 0.580890  [  450/  644]\n",
      "loss: 0.519477  [  540/  644]\n",
      "loss: 0.438150  [  630/  644]\n",
      "loss: 0.069614  [  112/  644]\n",
      "Training Loss (Epoch): 0.576708\n",
      "Validating...\n",
      "Validation Loss: 0.916755, Validation Accuracy: 74.07%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 6/15\n",
      "loss: 0.543593  [   90/  644]\n",
      "loss: 0.468734  [  180/  644]\n",
      "loss: 0.405487  [  270/  644]\n",
      "loss: 0.264509  [  360/  644]\n",
      "loss: 0.329063  [  450/  644]\n",
      "loss: 0.247520  [  540/  644]\n",
      "loss: 0.338188  [  630/  644]\n",
      "loss: 0.680854  [  112/  644]\n",
      "Training Loss (Epoch): 0.409743\n",
      "Validating...\n",
      "Validation Loss: 0.559005, Validation Accuracy: 79.63%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 7/15\n",
      "loss: 0.225942  [   90/  644]\n",
      "loss: 0.269311  [  180/  644]\n",
      "loss: 0.237723  [  270/  644]\n",
      "loss: 0.306937  [  360/  644]\n",
      "loss: 0.329691  [  450/  644]\n",
      "loss: 0.233556  [  540/  644]\n",
      "loss: 0.287486  [  630/  644]\n",
      "loss: 0.843409  [  112/  644]\n",
      "Training Loss (Epoch): 0.341757\n",
      "Validating...\n",
      "Validation Loss: 0.480662, Validation Accuracy: 83.33%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 8/15\n",
      "loss: 0.221778  [   90/  644]\n",
      "loss: 0.279506  [  180/  644]\n",
      "loss: 0.270498  [  270/  644]\n",
      "loss: 0.163054  [  360/  644]\n",
      "loss: 0.173951  [  450/  644]\n",
      "loss: 0.189999  [  540/  644]\n",
      "loss: 0.197486  [  630/  644]\n",
      "loss: 0.038966  [  112/  644]\n",
      "Training Loss (Epoch): 0.191905\n",
      "Validating...\n",
      "Validation Loss: 0.468237, Validation Accuracy: 82.10%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 9/15\n",
      "loss: 0.235134  [   90/  644]\n",
      "loss: 0.221026  [  180/  644]\n",
      "loss: 0.171215  [  270/  644]\n",
      "loss: 0.185162  [  360/  644]\n",
      "loss: 0.109729  [  450/  644]\n",
      "loss: 0.117709  [  540/  644]\n",
      "loss: 0.144984  [  630/  644]\n",
      "loss: 0.686852  [  112/  644]\n",
      "Training Loss (Epoch): 0.233976\n",
      "Validating...\n",
      "Validation Loss: 0.466646, Validation Accuracy: 83.33%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 10/15\n",
      "loss: 0.090989  [   90/  644]\n",
      "loss: 0.163047  [  180/  644]\n",
      "loss: 0.199229  [  270/  644]\n",
      "loss: 0.182324  [  360/  644]\n",
      "loss: 0.174927  [  450/  644]\n",
      "loss: 0.136644  [  540/  644]\n",
      "loss: 0.113175  [  630/  644]\n",
      "loss: 0.147411  [  112/  644]\n",
      "Training Loss (Epoch): 0.150968\n",
      "Validating...\n",
      "Validation Loss: 0.557600, Validation Accuracy: 82.72%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 11/15\n",
      "loss: 0.155153  [   90/  644]\n",
      "loss: 0.128519  [  180/  644]\n",
      "loss: 0.107970  [  270/  644]\n",
      "loss: 0.185996  [  360/  644]\n",
      "loss: 0.186373  [  450/  644]\n",
      "loss: 0.184248  [  540/  644]\n",
      "loss: 0.124602  [  630/  644]\n",
      "loss: 0.454858  [  112/  644]\n",
      "Training Loss (Epoch): 0.190965\n",
      "Validating...\n",
      "Validation Loss: 0.560336, Validation Accuracy: 82.72%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 12/15\n",
      "loss: 0.190434  [   90/  644]\n",
      "loss: 0.122625  [  180/  644]\n",
      "loss: 0.143901  [  270/  644]\n",
      "loss: 0.146814  [  360/  644]\n",
      "loss: 0.150673  [  450/  644]\n",
      "loss: 0.176307  [  540/  644]\n",
      "loss: 0.149135  [  630/  644]\n",
      "loss: 0.184064  [  112/  644]\n",
      "Training Loss (Epoch): 0.157994\n",
      "Validating...\n",
      "Validation Loss: 0.553992, Validation Accuracy: 83.33%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 13/15\n",
      "loss: 0.157309  [   90/  644]\n",
      "loss: 0.109172  [  180/  644]\n",
      "loss: 0.118047  [  270/  644]\n",
      "loss: 0.113907  [  360/  644]\n",
      "loss: 0.148607  [  450/  644]\n",
      "loss: 0.167273  [  540/  644]\n",
      "loss: 0.175220  [  630/  644]\n",
      "loss: 0.480216  [  112/  644]\n",
      "Training Loss (Epoch): 0.183719\n",
      "Validating...\n",
      "Validation Loss: 0.549700, Validation Accuracy: 83.95%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 14/15\n",
      "loss: 0.064888  [   90/  644]\n",
      "loss: 0.178266  [  180/  644]\n",
      "loss: 0.190019  [  270/  644]\n",
      "loss: 0.085208  [  360/  644]\n",
      "loss: 0.297039  [  450/  644]\n",
      "loss: 0.062648  [  540/  644]\n",
      "loss: 0.092679  [  630/  644]\n",
      "loss: 0.028290  [  112/  644]\n",
      "Training Loss (Epoch): 0.124880\n",
      "Validating...\n",
      "Validation Loss: 0.545923, Validation Accuracy: 83.33%\n",
      "Learning Rate: [1e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 9\n",
      "Epoch 1/15\n",
      "loss: 2.321435  [   90/  652]\n",
      "loss: 2.200672  [  180/  652]\n",
      "loss: 2.040061  [  270/  652]\n",
      "loss: 1.892597  [  360/  652]\n",
      "loss: 1.689914  [  450/  652]\n",
      "loss: 1.622815  [  540/  652]\n",
      "loss: 1.596968  [  630/  652]\n",
      "loss: 1.517268  [  176/  652]\n",
      "Training Loss (Epoch): 1.860216\n",
      "Validating...\n",
      "Validation Loss: 1.850626, Validation Accuracy: 53.66%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/15\n",
      "loss: 1.928389  [   90/  652]\n",
      "loss: 1.510862  [  180/  652]\n",
      "loss: 0.914436  [  270/  652]\n",
      "loss: 1.543082  [  360/  652]\n",
      "loss: 1.054923  [  450/  652]\n",
      "loss: 1.161736  [  540/  652]\n",
      "loss: 0.998997  [  630/  652]\n",
      "loss: 0.641663  [  176/  652]\n",
      "Training Loss (Epoch): 1.219261\n",
      "Validating...\n",
      "Validation Loss: 0.742719, Validation Accuracy: 71.34%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/15\n",
      "loss: 0.762673  [   90/  652]\n",
      "loss: 0.888374  [  180/  652]\n",
      "loss: 0.703319  [  270/  652]\n",
      "loss: 0.628167  [  360/  652]\n",
      "loss: 0.512611  [  450/  652]\n",
      "loss: 0.752794  [  540/  652]\n",
      "loss: 0.590844  [  630/  652]\n",
      "loss: 0.882942  [  176/  652]\n",
      "Training Loss (Epoch): 0.715216\n",
      "Validating...\n",
      "Validation Loss: 0.545342, Validation Accuracy: 84.76%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/15\n",
      "loss: 0.312044  [   90/  652]\n",
      "loss: 0.504630  [  180/  652]\n",
      "loss: 0.732996  [  270/  652]\n",
      "loss: 0.775224  [  360/  652]\n",
      "loss: 0.392628  [  450/  652]\n",
      "loss: 0.367199  [  540/  652]\n",
      "loss: 0.404069  [  630/  652]\n",
      "loss: 0.350195  [  176/  652]\n",
      "Training Loss (Epoch): 0.479873\n",
      "Validating...\n",
      "Validation Loss: 0.629464, Validation Accuracy: 84.15%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/15\n",
      "loss: 0.471360  [   90/  652]\n",
      "loss: 0.444326  [  180/  652]\n",
      "loss: 0.133658  [  270/  652]\n",
      "loss: 0.316509  [  360/  652]\n",
      "loss: 0.287676  [  450/  652]\n",
      "loss: 0.201629  [  540/  652]\n",
      "loss: 0.271722  [  630/  652]\n",
      "loss: 0.463193  [  176/  652]\n",
      "Training Loss (Epoch): 0.323759\n",
      "Validating...\n",
      "Validation Loss: 0.414376, Validation Accuracy: 87.80%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 6/15\n",
      "loss: 0.161747  [   90/  652]\n",
      "loss: 0.234842  [  180/  652]\n",
      "loss: 0.217323  [  270/  652]\n",
      "loss: 0.165231  [  360/  652]\n",
      "loss: 0.112127  [  450/  652]\n",
      "loss: 0.138546  [  540/  652]\n",
      "loss: 0.253794  [  630/  652]\n",
      "loss: 0.380316  [  176/  652]\n",
      "Training Loss (Epoch): 0.207991\n",
      "Validating...\n",
      "Validation Loss: 0.339223, Validation Accuracy: 90.85%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 7/15\n",
      "loss: 0.157043  [   90/  652]\n",
      "loss: 0.090322  [  180/  652]\n",
      "loss: 0.188731  [  270/  652]\n",
      "loss: 0.198308  [  360/  652]\n",
      "loss: 0.096556  [  450/  652]\n",
      "loss: 0.104815  [  540/  652]\n",
      "loss: 0.195535  [  630/  652]\n",
      "loss: 0.147860  [  176/  652]\n",
      "Training Loss (Epoch): 0.147396\n",
      "Validating...\n",
      "Validation Loss: 0.347462, Validation Accuracy: 89.02%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 8/15\n",
      "loss: 0.086906  [   90/  652]\n",
      "loss: 0.140821  [  180/  652]\n",
      "loss: 0.102356  [  270/  652]\n",
      "loss: 0.169191  [  360/  652]\n",
      "loss: 0.108182  [  450/  652]\n",
      "loss: 0.120763  [  540/  652]\n",
      "loss: 0.122934  [  630/  652]\n",
      "loss: 0.036559  [  176/  652]\n",
      "Training Loss (Epoch): 0.110964\n",
      "Validating...\n",
      "Validation Loss: 0.352590, Validation Accuracy: 89.63%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 9/15\n",
      "loss: 0.110405  [   90/  652]\n",
      "loss: 0.088861  [  180/  652]\n",
      "loss: 0.112513  [  270/  652]\n",
      "loss: 0.085272  [  360/  652]\n",
      "loss: 0.157681  [  450/  652]\n",
      "loss: 0.062260  [  540/  652]\n",
      "loss: 0.105056  [  630/  652]\n",
      "loss: 0.261503  [  176/  652]\n",
      "Training Loss (Epoch): 0.122944\n",
      "Validating...\n",
      "Validation Loss: 0.338896, Validation Accuracy: 89.63%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 10/15\n",
      "loss: 0.069821  [   90/  652]\n",
      "loss: 0.103668  [  180/  652]\n",
      "loss: 0.149813  [  270/  652]\n",
      "loss: 0.108003  [  360/  652]\n",
      "loss: 0.087470  [  450/  652]\n",
      "loss: 0.089663  [  540/  652]\n",
      "loss: 0.102495  [  630/  652]\n",
      "loss: 0.757076  [  176/  652]\n",
      "Training Loss (Epoch): 0.183501\n",
      "Validating...\n",
      "Validation Loss: 0.331926, Validation Accuracy: 89.63%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 11/15\n",
      "loss: 0.069777  [   90/  652]\n",
      "loss: 0.068734  [  180/  652]\n",
      "loss: 0.138218  [  270/  652]\n",
      "loss: 0.126756  [  360/  652]\n",
      "loss: 0.127873  [  450/  652]\n",
      "loss: 0.102174  [  540/  652]\n",
      "loss: 0.068968  [  630/  652]\n",
      "loss: 0.117858  [  176/  652]\n",
      "Training Loss (Epoch): 0.102545\n",
      "Validating...\n",
      "Validation Loss: 0.324468, Validation Accuracy: 90.24%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 12/15\n",
      "loss: 0.140715  [   90/  652]\n",
      "loss: 0.028703  [  180/  652]\n",
      "loss: 0.107613  [  270/  652]\n",
      "loss: 0.089596  [  360/  652]\n",
      "loss: 0.055896  [  450/  652]\n",
      "loss: 0.104560  [  540/  652]\n",
      "loss: 0.155775  [  630/  652]\n",
      "loss: 0.137728  [  176/  652]\n",
      "Training Loss (Epoch): 0.102573\n",
      "Validating...\n",
      "Validation Loss: 0.320550, Validation Accuracy: 90.24%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 13/15\n",
      "loss: 0.058749  [   90/  652]\n",
      "loss: 0.075816  [  180/  652]\n",
      "loss: 0.085972  [  270/  652]\n",
      "loss: 0.125046  [  360/  652]\n",
      "loss: 0.079304  [  450/  652]\n",
      "loss: 0.086705  [  540/  652]\n",
      "loss: 0.183911  [  630/  652]\n",
      "loss: 0.065583  [  176/  652]\n",
      "Training Loss (Epoch): 0.095136\n",
      "Validating...\n",
      "Validation Loss: 0.318853, Validation Accuracy: 90.24%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 14/15\n",
      "loss: 0.064847  [   90/  652]\n",
      "loss: 0.123469  [  180/  652]\n",
      "loss: 0.112715  [  270/  652]\n",
      "loss: 0.067955  [  360/  652]\n",
      "loss: 0.126185  [  450/  652]\n",
      "loss: 0.110378  [  540/  652]\n",
      "loss: 0.034371  [  630/  652]\n",
      "loss: 0.269257  [  176/  652]\n",
      "Training Loss (Epoch): 0.113647\n",
      "Validating...\n",
      "Validation Loss: 0.317443, Validation Accuracy: 90.24%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 15/15\n",
      "loss: 0.128293  [   90/  652]\n",
      "loss: 0.070445  [  180/  652]\n",
      "loss: 0.074889  [  270/  652]\n",
      "loss: 0.104562  [  360/  652]\n",
      "loss: 0.080858  [  450/  652]\n",
      "loss: 0.091435  [  540/  652]\n",
      "loss: 0.134553  [  630/  652]\n",
      "loss: 0.055688  [  176/  652]\n",
      "Training Loss (Epoch): 0.092590\n",
      "Validating...\n",
      "Validation Loss: 0.317058, Validation Accuracy: 90.24%\n",
      "Learning Rate: [1e-06]\n",
      "Processing Fold 10\n",
      "Epoch 1/15\n",
      "loss: 2.442341  [   90/  669]\n",
      "loss: 2.301098  [  180/  669]\n",
      "loss: 2.125458  [  270/  669]\n",
      "loss: 2.111881  [  360/  669]\n",
      "loss: 1.901079  [  450/  669]\n",
      "loss: 1.793765  [  540/  669]\n",
      "loss: 1.735959  [  630/  669]\n",
      "loss: 1.712852  [  312/  669]\n",
      "Training Loss (Epoch): 2.015554\n",
      "Validating...\n",
      "Validation Loss: 1.970754, Validation Accuracy: 35.71%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/15\n",
      "loss: 1.986224  [   90/  669]\n",
      "loss: 1.570626  [  180/  669]\n",
      "loss: 1.622922  [  270/  669]\n",
      "loss: 1.210222  [  360/  669]\n",
      "loss: 1.118704  [  450/  669]\n",
      "loss: 1.594229  [  540/  669]\n",
      "loss: 1.324043  [  630/  669]\n",
      "loss: 0.989912  [  312/  669]\n",
      "Training Loss (Epoch): 1.427110\n",
      "Validating...\n",
      "Validation Loss: 1.070755, Validation Accuracy: 61.90%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/15\n",
      "loss: 1.061928  [   90/  669]\n",
      "loss: 1.002176  [  180/  669]\n",
      "loss: 1.160065  [  270/  669]\n",
      "loss: 0.845350  [  360/  669]\n",
      "loss: 1.114379  [  450/  669]\n",
      "loss: 0.771410  [  540/  669]\n",
      "loss: 0.896541  [  630/  669]\n",
      "loss: 0.530868  [  312/  669]\n",
      "Training Loss (Epoch): 0.922840\n",
      "Validating...\n",
      "Validation Loss: 0.723599, Validation Accuracy: 70.83%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/15\n",
      "loss: 0.810051  [   90/  669]\n",
      "loss: 0.628317  [  180/  669]\n",
      "loss: 0.849371  [  270/  669]\n",
      "loss: 0.728472  [  360/  669]\n",
      "loss: 0.597691  [  450/  669]\n",
      "loss: 0.550461  [  540/  669]\n",
      "loss: 0.772079  [  630/  669]\n",
      "loss: 0.452053  [  312/  669]\n",
      "Training Loss (Epoch): 0.673562\n",
      "Validating...\n",
      "Validation Loss: 0.677652, Validation Accuracy: 73.81%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/15\n",
      "loss: 0.634999  [   90/  669]\n",
      "loss: 0.409061  [  180/  669]\n",
      "loss: 0.551721  [  270/  669]\n",
      "loss: 0.724076  [  360/  669]\n",
      "loss: 0.728855  [  450/  669]\n",
      "loss: 0.702607  [  540/  669]\n",
      "loss: 0.765007  [  630/  669]\n",
      "loss: 0.638466  [  312/  669]\n",
      "Training Loss (Epoch): 0.644349\n",
      "Validating...\n",
      "Validation Loss: 0.687093, Validation Accuracy: 75.60%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/15\n",
      "loss: 0.545904  [   90/  669]\n",
      "loss: 0.615836  [  180/  669]\n",
      "loss: 0.528360  [  270/  669]\n",
      "loss: 0.548071  [  360/  669]\n",
      "loss: 0.491681  [  450/  669]\n",
      "loss: 0.379750  [  540/  669]\n",
      "loss: 0.499415  [  630/  669]\n",
      "loss: 0.299842  [  312/  669]\n",
      "Training Loss (Epoch): 0.488608\n",
      "Validating...\n",
      "Validation Loss: 0.546404, Validation Accuracy: 77.98%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 7/15\n",
      "loss: 0.483811  [   90/  669]\n",
      "loss: 0.370982  [  180/  669]\n",
      "loss: 0.387463  [  270/  669]\n",
      "loss: 0.340767  [  360/  669]\n",
      "loss: 0.555769  [  450/  669]\n",
      "loss: 0.355688  [  540/  669]\n",
      "loss: 0.420499  [  630/  669]\n",
      "loss: 0.573290  [  312/  669]\n",
      "Training Loss (Epoch): 0.436034\n",
      "Validating...\n",
      "Validation Loss: 0.497503, Validation Accuracy: 84.52%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 8/15\n",
      "loss: 0.480081  [   90/  669]\n",
      "loss: 0.328908  [  180/  669]\n",
      "loss: 0.427362  [  270/  669]\n",
      "loss: 0.317149  [  360/  669]\n",
      "loss: 0.328822  [  450/  669]\n",
      "loss: 0.308732  [  540/  669]\n",
      "loss: 0.296255  [  630/  669]\n",
      "loss: 0.234299  [  312/  669]\n",
      "Training Loss (Epoch): 0.340201\n",
      "Validating...\n",
      "Validation Loss: 0.486492, Validation Accuracy: 82.14%\n",
      "Learning Rate: [4e-05]\n",
      "Epoch 9/15\n",
      "loss: 0.204106  [   90/  669]\n",
      "loss: 0.242571  [  180/  669]\n",
      "loss: 0.309627  [  270/  669]\n",
      "loss: 0.429213  [  360/  669]\n",
      "loss: 0.309660  [  450/  669]\n",
      "loss: 0.343087  [  540/  669]\n",
      "loss: 0.247573  [  630/  669]\n",
      "loss: 0.204852  [  312/  669]\n",
      "Training Loss (Epoch): 0.286336\n",
      "Validating...\n",
      "Validation Loss: 0.417804, Validation Accuracy: 85.71%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 10/15\n",
      "loss: 0.237216  [   90/  669]\n",
      "loss: 0.204087  [  180/  669]\n",
      "loss: 0.333274  [  270/  669]\n",
      "loss: 0.215573  [  360/  669]\n",
      "loss: 0.199127  [  450/  669]\n",
      "loss: 0.184973  [  540/  669]\n",
      "loss: 0.384322  [  630/  669]\n",
      "loss: 0.487015  [  312/  669]\n",
      "Training Loss (Epoch): 0.280698\n",
      "Validating...\n",
      "Validation Loss: 0.405212, Validation Accuracy: 86.90%\n",
      "Learning Rate: [8.000000000000001e-06]\n",
      "Epoch 11/15\n",
      "loss: 0.252295  [   90/  669]\n",
      "loss: 0.171686  [  180/  669]\n",
      "loss: 0.274280  [  270/  669]\n",
      "loss: 0.282729  [  360/  669]\n",
      "loss: 0.285485  [  450/  669]\n",
      "loss: 0.215155  [  540/  669]\n",
      "loss: 0.224742  [  630/  669]\n",
      "loss: 0.342801  [  312/  669]\n",
      "Training Loss (Epoch): 0.256147\n",
      "Validating...\n",
      "Validation Loss: 0.409308, Validation Accuracy: 88.10%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 12/15\n",
      "loss: 0.261443  [   90/  669]\n",
      "loss: 0.134506  [  180/  669]\n",
      "loss: 0.268644  [  270/  669]\n",
      "loss: 0.254381  [  360/  669]\n",
      "loss: 0.239267  [  450/  669]\n",
      "loss: 0.155344  [  540/  669]\n",
      "loss: 0.280822  [  630/  669]\n",
      "loss: 0.439650  [  312/  669]\n",
      "Training Loss (Epoch): 0.254257\n",
      "Validating...\n",
      "Validation Loss: 0.410689, Validation Accuracy: 88.10%\n",
      "Learning Rate: [1.6000000000000004e-06]\n",
      "Epoch 13/15\n",
      "loss: 0.238021  [   90/  669]\n",
      "loss: 0.202470  [  180/  669]\n",
      "loss: 0.195329  [  270/  669]\n",
      "loss: 0.225850  [  360/  669]\n",
      "loss: 0.247856  [  450/  669]\n",
      "loss: 0.314453  [  540/  669]\n",
      "loss: 0.249974  [  630/  669]\n",
      "loss: 0.222968  [  312/  669]\n",
      "Training Loss (Epoch): 0.237115\n",
      "Validating...\n",
      "Validation Loss: 0.410157, Validation Accuracy: 88.10%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 14/15\n",
      "loss: 0.270031  [   90/  669]\n",
      "loss: 0.203580  [  180/  669]\n",
      "loss: 0.155415  [  270/  669]\n",
      "loss: 0.229573  [  360/  669]\n",
      "loss: 0.317210  [  450/  669]\n",
      "loss: 0.205909  [  540/  669]\n",
      "loss: 0.307060  [  630/  669]\n",
      "loss: 0.151808  [  312/  669]\n",
      "Training Loss (Epoch): 0.230073\n",
      "Validating...\n",
      "Validation Loss: 0.410001, Validation Accuracy: 88.10%\n",
      "Learning Rate: [1e-06]\n",
      "Epoch 15/15\n",
      "loss: 0.240190  [   90/  669]\n",
      "loss: 0.238063  [  180/  669]\n",
      "loss: 0.281230  [  270/  669]\n",
      "loss: 0.168173  [  360/  669]\n",
      "loss: 0.216077  [  450/  669]\n",
      "loss: 0.224353  [  540/  669]\n",
      "loss: 0.193054  [  630/  669]\n",
      "loss: 0.422383  [  312/  669]\n",
      "Training Loss (Epoch): 0.247941\n",
      "Validating...\n",
      "Validation Loss: 0.408999, Validation Accuracy: 88.10%\n",
      "Learning Rate: [1e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "\n",
      "Cross-Validation Results:\n",
      "Avg Training Loss: 0.476542\n",
      "Avg Validation Loss: 0.705979\n",
      "Avg Validation Accuracy: 87.83%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4765420298020603, 0.7059788434215627, 0.8783384959474356)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_tune(layer = 1, lr = 2e-4, weight_decay = 0.05, weights = \"DEFAULT\", drop = 0.5, batch_size = 90, total_epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchaudio\n",
    "\n",
    "# audio_path = \"./UrbanSound8k/audio/fold1/137156-9-0-30.wav\"\n",
    "# waveform, sample_rate = torchaudio.load(audio_path)\n",
    "# print(f\"Shape: {waveform.shape}, Sample Rate: {sample_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_stereogram(spectrogram):\n",
    "    # Convert to numpy\n",
    "    spectrogram_np = spectrogram.numpy()  # Shape: (2, Freq, Time)\n",
    "\n",
    "    # Plot left and right channels\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(6, 6), constrained_layout=True)\n",
    "\n",
    "    axs[0].imshow(spectrogram_np[0], aspect='auto', origin='lower', cmap='magma')\n",
    "    axs[0].set_title(f\"Spectrogram {i+1} - Left Channel\")\n",
    "    axs[0].set_ylabel(\"Frequency Bins\")\n",
    "    axs[0].set_xlabel(\"Time Frames\")\n",
    "\n",
    "    axs[1].imshow(spectrogram_np[1], aspect='auto', origin='lower', cmap='magma')\n",
    "    axs[1].set_title(f\"Spectrogram {i+1} - Right Channel\")\n",
    "    axs[1].set_ylabel(\"Frequency Bins\")\n",
    "    axs[1].set_xlabel(\"Time Frames\")\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "urbad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
