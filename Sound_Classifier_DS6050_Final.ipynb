{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "mBSFTJ5M_z-H"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n",
    "from torch.cuda import manual_seed_all\n",
    "from torch import manual_seed as torch_manual_seed\n",
    "from torch.backends import cudnn\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "3uDKfjRHMuxk"
   },
   "outputs": [],
   "source": [
    "# pre spectrogram augmentations\n",
    "# these are examples and can be changed based on domain knowledge\n",
    "\n",
    "def stretch_waveform(waveform, rate=1.2):\n",
    "    time_stretch = T.TimeStretch()\n",
    "    # `rate > 1.0` speeds up, `rate < 1.0` slows down\n",
    "    return time_stretch(waveform, rate)\n",
    "\n",
    "def shift_pitch(waveform, sample_rate=44100, n_steps = 2):\n",
    "    pitch_shift = T.PitchShift(sample_rate, n_steps)  # Shift up by 2 semitones\n",
    "    return pitch_shift(waveform)\n",
    "\n",
    "def scale_volume(waveform, factor = None):\n",
    "    if factor is None:\n",
    "        waveform *= torch.FloatTensor(1).uniform_(0.8, 1.5).item()  # Amplifies waveform by random factor\n",
    "    else:\n",
    "        waveform *= factor\n",
    "    return waveform\n",
    "\n",
    "def crop_waveform(waveform, crop_size):\n",
    "    start = torch.randint(0, max(1, waveform.size(-1) - crop_size), (1,)).item()\n",
    "    return waveform[:, start:start + crop_size]\n",
    "\n",
    "def apply_reverb(waveform):\n",
    "    reverb = T.Reverberate()\n",
    "    return reverb(waveform)\n",
    "\n",
    "def time_shift(waveform, shift):\n",
    "    return torch.roll(waveform, shifts=shift, dims=-1)\n",
    "\n",
    "def add_noise(waveform, noise_level=0.005):\n",
    "    noise = torch.randn_like(waveform) * noise_level\n",
    "    return waveform + noise\n",
    "\n",
    "# Augment on-the-fly stochastically\n",
    "# again these are just examples and do not necessarily utilize the methods above\n",
    "def augment_waveform(data):\n",
    "    waveform, sample_rate = data\n",
    "    if torch.rand(1).item() > 0.9:\n",
    "        waveform = add_noise(waveform)\n",
    "    if torch.rand(1).item() > 0.9:\n",
    "        waveform = time_shift(waveform, shifts=torch.randint(-waveform.size(-1) // 2, waveform.size(-1) // 2, (1,)).item())\n",
    "    if torch.rand(1).item() > 0.9:\n",
    "        waveform = scale_volume(waveform)\n",
    "    if torch.rand(1).item() > 0.9:\n",
    "        waveform = apply_reverb(waveform)\n",
    "    if torch.rand(1).item() > 0.9:\n",
    "        waveform = shift_pitch(waveform, sample_rate, n_steps= torch.randint(-12, 12, (1,)).item())\n",
    "    if torch.rand(1).item() > 0.9:\n",
    "        waveform = stretch_waveform(waveform, rate= torch.FloatTensor(1).uniform_(0.5, 1.5).item())\n",
    "    return waveform, sample_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "Ww8OMV8nNZcf"
   },
   "outputs": [],
   "source": [
    "# Create a MelSpectrogram transformation\n",
    "mel_spectrogram_transform = T.MelSpectrogram(\n",
    "    sample_rate=44100,         # Default sample rate, change if needed\n",
    "    n_fft=1024,                # Number of FFT bins\n",
    "    hop_length=512,            # Hop length between windows\n",
    "    n_mels=64                  # Number of Mel bands\n",
    ")\n",
    "\n",
    "def waveform_to_spectrogram(data):\n",
    "    waveform, sample_rate = data\n",
    "    spectrogram = mel_spectrogram_transform(waveform)  # Apply the spectrogram transformation\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "khV1u_wUIR-o"
   },
   "outputs": [],
   "source": [
    "# post spectrogram augmentations\n",
    "\n",
    "# Example augmentations, could add more\n",
    "time_mask = T.TimeMasking(time_mask_param=10)\n",
    "\n",
    "freq_mask = T.FrequencyMasking(freq_mask_param=8)\n",
    "\n",
    "# hybridizes two sounds\n",
    "def mixup(spectrogram1, spectrogram2, alpha=0.2):\n",
    "    lam = torch.FloatTensor(1).uniform_(0, alpha).item()\n",
    "    return lam * spectrogram1 + (1 - lam) * spectrogram2\n",
    "\n",
    "# should probably implement a randomization process like above\n",
    "def augment_spectrogram(spectrogram):\n",
    "    augmented = time_mask(spectrogram)  # Apply time masking\n",
    "    augmented = freq_mask(augmented)   # Apply frequency masking\n",
    "    return augmented\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "2U9n6Z-fPiwY"
   },
   "outputs": [],
   "source": [
    "# Decode audio files\n",
    "def decode_audio(file_tuple):\n",
    "    file_path, file = file_tuple\n",
    "    waveform, sample_rate = torchaudio.load(file_path)\n",
    "    return waveform, sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "class UrbanSoundDataset(Dataset):\n",
    "    def __init__(self, audio_path, fold, csv_path, transform=None):\n",
    "        self.audio_path = os.path.join(audio_path, f\"fold{fold}\")\n",
    "        self.file_list = [os.path.join(self.audio_path, f) for f in os.listdir(self.audio_path) if f.endswith(\".wav\")]\n",
    "        self.transform = transform\n",
    "\n",
    "        # Load the metadata CSV file\n",
    "        self.metadata = pd.read_csv(csv_path)\n",
    "\n",
    "    def get_label(self, file_name):\n",
    "        \"\"\"Fetch the class label for a given file name from the metadata.\"\"\"\n",
    "        label_row = self.metadata.loc[self.metadata['slice_file_name'] == file_name, 'class']\n",
    "        if not label_row.empty:\n",
    "            return label_row.values[0]\n",
    "        else:\n",
    "            raise ValueError(f\"File name {file_name} not found in metadata CSV.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load the audio file\n",
    "        file_path = self.file_list[idx]\n",
    "        waveform, sample_rate = torchaudio.load(file_path)\n",
    "\n",
    "        # Convert mono to stereo if necessary\n",
    "        if waveform.size(0) == 1:  # If mono\n",
    "            waveform = waveform.repeat(3, 1)\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            waveform = self.transform(waveform)\n",
    "\n",
    "        # Extract the file name from the path\n",
    "        file_name = os.path.basename(file_path)\n",
    "\n",
    "        # Get the corresponding label for the file\n",
    "        label = self.get_label(file_name)\n",
    "\n",
    "        return waveform, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asm2fe/.local/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torchaudio.transforms as T\n",
    "\n",
    "# Example transformations\n",
    "def augment_waveform(waveform):\n",
    "    # Add your augmentation logic here (e.g., noise addition, time stretch, etc.)\n",
    "    return waveform\n",
    "\n",
    "waveform_to_spectrogram = T.MelSpectrogram(sample_rate=16000, n_mels=128)\n",
    "augment_spectrogram = T.AmplitudeToDB()\n",
    "\n",
    "# Combine transformations into a callable function\n",
    "def transform_pipeline(waveform):\n",
    "    waveform = augment_waveform(waveform)\n",
    "    spectrogram = waveform_to_spectrogram(waveform)\n",
    "    # spectrogram = augment_spectrogram(spectrogram)\n",
    "    return spectrogram\n",
    "\n",
    "def pad_with_noise(spectrogram, max_time, noise_std=0.01):\n",
    "    \"\"\"\n",
    "    Pads a spectrogram with Gaussian noise instead of zeros.\n",
    "\n",
    "    Args:\n",
    "        spectrogram (Tensor): Shape (channels, freq_bins, time_steps)\n",
    "        max_time (int): Target time dimension\n",
    "        noise_std (float): Standard deviation of the Gaussian noise\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Padded spectrogram with noise\n",
    "    \"\"\"\n",
    "    # Compute how much padding is needed\n",
    "    pad_amount = max_time - spectrogram.size(2)\n",
    "    \n",
    "    if pad_amount > 0:\n",
    "        # Generate random noise matching the shape of missing time steps\n",
    "        noise = torch.randn((spectrogram.size(0), spectrogram.size(1), pad_amount)) * noise_std\n",
    "        \n",
    "        # Concatenate noise along the time axis\n",
    "        spectrogram = torch.cat([spectrogram, noise], dim=2)\n",
    "    \n",
    "    return spectrogram\n",
    "\n",
    "# def convert_to_three_channels(spectrogram):\n",
    "#     # Convert [2, 224, 224] to [3, 224, 224]\n",
    "#     if spectrogram.size(0) == 2:\n",
    "#         # Duplicate the first channel to create a third channel\n",
    "#         return torch.cat((spectrogram, spectrogram[0:1, :, :]), dim=0)\n",
    "#     return spectrogram\n",
    "\n",
    "def convert_to_three_channels(spectrogram):\n",
    "    # Convert [2, 224, 224] to [3, 224, 224]\n",
    "    if spectrogram.size(0) == 2:\n",
    "        # Calculate the mean of the two channels\n",
    "        mean_channel = torch.mean(spectrogram, dim=0, keepdim=True)\n",
    "        # Concatenate the mean channel as the third channel\n",
    "        return torch.cat((spectrogram, mean_channel), dim=0)\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "\n",
    "class densenet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    DenseNet Class, derived from Pytorch. Intended for model manipulation (i.e. unfreezing layers, etc.)\n",
    "    To use model, try (densenet).model(data)\n",
    "    May change to reflect manual implementation of densenet161.\n",
    "    \"\"\"\n",
    "    def __init__(self, weights = \"DEFAULT\", drop = 0.5):\n",
    "        super().__init__()  # Initialize the nn.Module base class\n",
    "        self.model = torchvision.models.densenet161(weights = weights)\n",
    "        \n",
    "        num_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Dropout(drop),  # Add dropout with 50% probability\n",
    "            nn.Linear(num_features, 10)  # Adjust for 10 output classes (UrbanSound8k)\n",
    "        )\n",
    "        \n",
    "        # Ensure classifier is trainable\n",
    "        for param in self.model.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)  # Delegate forward pass to the original DenseNet\n",
    "\n",
    "    def layer_change(self, layer=0):\n",
    "        if layer > 0:    \n",
    "            # Freeze earlier layers (optional)\n",
    "            for name, param in self.model.features.named_parameters():\n",
    "                if \"conv0\" in name or \"denseblock1\" in name:  # Freeze initial layers and denseblock1\n",
    "                    param.requires_grad = False\n",
    "        if layer > 1:    \n",
    "            # Freeze earlier layers (optional)\n",
    "            for name, param in self.model.features.named_parameters():\n",
    "                if \"denseblock2\" in name:  # Freeze initial layers and denseblock2\n",
    "                    param.requires_grad = False\n",
    "        if layer > 2:    \n",
    "            # Freeze earlier layers (optional)\n",
    "            for name, param in self.model.features.named_parameters():\n",
    "                if \"denseblock3\" in name:  # Freeze initial layers and denseblock3\n",
    "                    param.requires_grad = False\n",
    "        if layer > 3:    \n",
    "            # Freeze earlier layers (optional)\n",
    "            for name, param in self.model.features.named_parameters():\n",
    "                if \"denseblock4\" in name:  # Freeze initial layers and denseblock4\n",
    "                    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = densenet()\n",
    "# for param in model.model.features.named_parameters():\n",
    "#     print(param[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and testing loops\n",
    "\n",
    "def train_loop(train_dataloader, val_dataloader, model, loss_fn, optimizer, scheduler=None, epochs=1):\n",
    "    model.train()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Store metrics\n",
    "    epoch_train_losses = []  # Track training loss across epochs\n",
    "    epoch_val_losses = []  # Track validation loss across epochs\n",
    "    epoch_val_accuracies = []  # Track validation accuracy across epochs\n",
    "\n",
    "    # Training loop with early stopping\n",
    "    early_stopping = EarlyStopping(patience=3, min_delta=0.01)\n",
    "    \n",
    "    early_stop_epoch = None\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        size = len(train_dataloader.dataset)\n",
    "        total_loss = 0  # Initialize variable to accumulate training loss\n",
    "        \n",
    "\n",
    "        for batch, (X, y) in enumerate(train_dataloader):\n",
    "            # Compute prediction and loss\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Print progress periodically\n",
    "            total_batches = len(train_dataloader)\n",
    "            if batch % (total_batches // 5) == 0:  # Prints 5 times per epoch\n",
    "                current = (batch + 1) * len(X)\n",
    "                print(f\"loss: {loss.item():>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "        # Average training loss for the epoch\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "        print(f\"Training Loss (Epoch): {avg_train_loss:>7f}\")\n",
    "        epoch_train_losses.append(avg_train_loss)\n",
    "\n",
    "        # **Validation Step**\n",
    "        print(\"Validating...\")\n",
    "        avg_val_loss, val_accuracy = test_loop(val_dataloader, model, loss_fn, verbose=False)\n",
    "        print(f\"Validation Loss: {avg_val_loss:.6f}, Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "\n",
    "        # Track validation metrics\n",
    "        epoch_val_losses.append(avg_val_loss)\n",
    "        epoch_val_accuracies.append(val_accuracy)\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(val_accuracy)\n",
    "            print(f\"Learning Rate: {scheduler.get_last_lr()}\")\n",
    "        \n",
    "        # Check for early stopping\n",
    "        early_stopping(avg_val_loss)\n",
    "        if early_stopping.stop_training:\n",
    "            print(\"Early stopping triggered. Training stopped.\")\n",
    "            early_stop_epoch = epoch\n",
    "            break\n",
    "\n",
    "    # Return metrics for tracking/aggregation across folds\n",
    "    return epoch_train_losses, epoch_val_losses, epoch_val_accuracies, early_stop_epoch\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn, verbose=True):\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    # Average loss and accuracy for this fold\n",
    "    avg_test_loss = test_loss / num_batches\n",
    "    accuracy = correct / size\n",
    "    if verbose:\n",
    "        print(f\"Test Error: \\n Accuracy: {(100*accuracy):>0.1f}%, Avg loss: {avg_test_loss:>8f} \\n\")\n",
    "    return avg_test_loss, accuracy  # Return both average loss and accuracy for this fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "BLCzmvxcHvKs"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    # Resize and normalize for DenseNet\n",
    "    resize_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize for DenseNet\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Standard ImageNet normalization\n",
    "    ])\n",
    "    \n",
    "    inputs, labels = zip(*batch)  # Separate inputs and labels\n",
    "    max_time = max(spectrogram.size(2) for spectrogram in inputs)\n",
    "\n",
    "    # Pad inputs to the same length along the time dimension\n",
    "    padded_inputs = [\n",
    "        torch.nn.functional.pad(input, (0, max_time - input.size(2)))\n",
    "        for input in inputs\n",
    "    ]\n",
    "\n",
    "    # Convert to 3 channels and resize\n",
    "    resized_inputs = [resize_transform(convert_to_three_channels(input)) for input in padded_inputs]\n",
    "    \n",
    "    # Map labels to numeric class IDs\n",
    "    class_mapping = {\n",
    "        \"air_conditioner\": 0,\n",
    "        \"car_horn\": 1,\n",
    "        \"children_playing\": 2,\n",
    "        \"dog_bark\": 3,\n",
    "        \"drilling\": 4,\n",
    "        \"engine_idling\": 5,\n",
    "        \"gun_shot\": 6,\n",
    "        \"jackhammer\": 7,\n",
    "        \"siren\": 8,\n",
    "        \"street_music\": 9\n",
    "    }\n",
    "\n",
    "    numeric_labels = [class_mapping[label] for label in labels]\n",
    "\n",
    "    # Stack inputs and labels\n",
    "    return torch.stack(resized_inputs), torch.tensor(numeric_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3, min_delta=0.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How many epochs to wait for improvement.\n",
    "            min_delta (float): Minimum change in monitored value to qualify as improvement.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.stop_training = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None or val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.stop_training = True   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sfs/gpfs/tardis/home/asm2fe/UrbanAdversary\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# Specify paths and batch size\n",
    "AUDIO_PATH = \"./UrbanSound8K/audio\"\n",
    "CSV_PATH = \"./UrbanSound8K/metadata/UrbanSound8K.csv\"\n",
    "batch_size = 70\n",
    "epochs = 20\n",
    "\n",
    "def setup_seed(seed):\n",
    "    torch_manual_seed(seed)\n",
    "    manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    cudnn.deterministic = True\n",
    "\n",
    "def dense_tune(layer = 0, lr = 2e-4, weight_decay = 0.2, weights = \"DEFAULT\", drop = 0.5, SEED = 666):\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    setup_seed(SEED)\n",
    "\n",
    "    # Variables to accumulate metrics across folds\n",
    "    fold_train_losses = []\n",
    "    fold_val_losses = []\n",
    "    fold_val_accuracies = []\n",
    "\n",
    "    # Loop through folds\n",
    "    for fold in range(1, 11):\n",
    "        model = densenet(weights = weights, drop = drop)\n",
    "        model.layer_change(layer = layer) # freeze first conv and dense block(s) if desired\n",
    "\n",
    "        print(f\"Processing Fold {fold}\")\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay = weight_decay)\n",
    "        # optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001, weight_decay = 0.01, momentum = 0.9)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='max', factor=0.5, patience=0, threshold_mode = 'abs', threshold= 0.01, min_lr=1e-9)\n",
    "\n",
    "        # Initialize dataset and DataLoader\n",
    "        dataset = UrbanSoundDataset(audio_path=AUDIO_PATH, fold=fold, transform=transform_pipeline, csv_path=CSV_PATH)\n",
    "        train_indices, val_indices = train_test_split(list(range(len(dataset))), test_size=0.2, random_state=42)\n",
    "\n",
    "        train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "        val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
    "\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "        val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "        # Train and validate (over multiple epochs per fold)\n",
    "        epoch_train_losses, epoch_val_losses, epoch_val_accuracies, early_stop_epoch = train_loop(\n",
    "            train_dataloader, val_dataloader, model, loss_fn, optimizer, scheduler, epochs=epochs\n",
    "        )\n",
    "\n",
    "        # Aggregate metrics up to the stopping epoch\n",
    "        if early_stop_epoch is not None:\n",
    "            fold_train_losses.append(sum(epoch_train_losses[:early_stop_epoch+1]) / (early_stop_epoch+1))  # Mean up to early stop\n",
    "            fold_val_losses.append(sum(epoch_val_losses[:early_stop_epoch+1]) / (early_stop_epoch+1))      # Mean up to early stop\n",
    "            fold_val_accuracies.append(sum(epoch_val_accuracies[:early_stop_epoch+1]) / (early_stop_epoch+1))  # Mean up to early stop\n",
    "        else:\n",
    "            # If no early stopping occurred, aggregate metrics across all epochs\n",
    "            fold_train_losses.append(sum(epoch_train_losses) / len(epoch_train_losses))\n",
    "            fold_val_losses.append(sum(epoch_val_losses) / len(epoch_val_losses))\n",
    "            fold_val_accuracies.append(sum(epoch_val_accuracies) / len(epoch_val_accuracies))\n",
    "\n",
    "        # # Aggregate fold-level metrics (e.g., mean across all epochs)\n",
    "        # fold_train_losses.append(sum(epoch_train_losses) / len(epoch_train_losses))  # Mean of training losses\n",
    "        # fold_val_losses.append(sum(epoch_val_losses) / len(epoch_val_losses))        # Mean of validation losses\n",
    "        # fold_val_accuracies.append(sum(epoch_val_accuracies) / len(epoch_val_accuracies))  # Mean of validation accuracies\n",
    "\n",
    "    # Compute average metrics across folds\n",
    "    mean_train_loss = sum(fold_train_losses) / len(fold_train_losses)\n",
    "    mean_val_loss = sum(fold_val_losses) / len(fold_val_losses)\n",
    "    mean_val_accuracy = sum(fold_val_accuracies) / len(fold_val_accuracies)\n",
    "\n",
    "    print(f\"\\nCross-Validation Results:\")\n",
    "    print(f\"Avg Training Loss: {mean_train_loss:.6f}\")\n",
    "    print(f\"Avg Validation Loss: {mean_val_loss:.6f}\")\n",
    "    print(f\"Avg Validation Accuracy: {mean_val_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense_tune(layer = 0, lr = 2e-4, weight_decay = 0.2, weights = \"DEFAULT\", drop = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1\n",
      "Epoch 1/20\n",
      "loss: 2.345630  [   70/  698]\n",
      "loss: 2.094388  [  210/  698]\n",
      "loss: 1.921020  [  350/  698]\n",
      "loss: 1.729051  [  490/  698]\n",
      "loss: 1.623411  [  630/  698]\n",
      "Training Loss (Epoch): 1.943488\n",
      "Validating...\n",
      "Validation Loss: 1.881623, Validation Accuracy: 43.43%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 1.798832  [   70/  698]\n",
      "loss: 1.305873  [  210/  698]\n",
      "loss: 1.220195  [  350/  698]\n",
      "loss: 1.172055  [  490/  698]\n",
      "loss: 0.929250  [  630/  698]\n",
      "Training Loss (Epoch): 1.224383\n",
      "Validating...\n",
      "Validation Loss: 0.936450, Validation Accuracy: 66.29%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 0.772587  [   70/  698]\n",
      "loss: 0.592083  [  210/  698]\n",
      "loss: 0.523305  [  350/  698]\n",
      "loss: 0.455551  [  490/  698]\n",
      "loss: 0.729686  [  630/  698]\n",
      "Training Loss (Epoch): 0.664011\n",
      "Validating...\n",
      "Validation Loss: 0.852308, Validation Accuracy: 73.71%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/20\n",
      "loss: 0.684272  [   70/  698]\n",
      "loss: 0.661563  [  210/  698]\n",
      "loss: 0.340157  [  350/  698]\n",
      "loss: 0.427867  [  490/  698]\n",
      "loss: 0.307899  [  630/  698]\n",
      "Training Loss (Epoch): 0.438845\n",
      "Validating...\n",
      "Validation Loss: 0.509111, Validation Accuracy: 82.86%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/20\n",
      "loss: 0.334577  [   70/  698]\n",
      "loss: 0.193336  [  210/  698]\n",
      "loss: 0.243955  [  350/  698]\n",
      "loss: 0.282710  [  490/  698]\n",
      "loss: 0.394585  [  630/  698]\n",
      "Training Loss (Epoch): 0.287147\n",
      "Validating...\n",
      "Validation Loss: 0.666926, Validation Accuracy: 74.29%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 6/20\n",
      "loss: 0.468016  [   70/  698]\n",
      "loss: 0.299912  [  210/  698]\n",
      "loss: 0.193657  [  350/  698]\n",
      "loss: 0.194508  [  490/  698]\n",
      "loss: 0.109245  [  630/  698]\n",
      "Training Loss (Epoch): 0.244302\n",
      "Validating...\n",
      "Validation Loss: 0.324117, Validation Accuracy: 89.14%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 7/20\n",
      "loss: 0.221378  [   70/  698]\n",
      "loss: 0.035680  [  210/  698]\n",
      "loss: 0.083883  [  350/  698]\n",
      "loss: 0.137557  [  490/  698]\n",
      "loss: 0.033940  [  630/  698]\n",
      "Training Loss (Epoch): 0.118233\n",
      "Validating...\n",
      "Validation Loss: 0.305445, Validation Accuracy: 90.29%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 8/20\n",
      "loss: 0.110039  [   70/  698]\n",
      "loss: 0.118879  [  210/  698]\n",
      "loss: 0.095775  [  350/  698]\n",
      "loss: 0.224603  [  490/  698]\n",
      "loss: 0.096737  [  630/  698]\n",
      "Training Loss (Epoch): 0.115682\n",
      "Validating...\n",
      "Validation Loss: 0.370628, Validation Accuracy: 89.14%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 9/20\n",
      "loss: 0.013788  [   70/  698]\n",
      "loss: 0.040031  [  210/  698]\n",
      "loss: 0.097422  [  350/  698]\n",
      "loss: 0.138698  [  490/  698]\n",
      "loss: 0.059648  [  630/  698]\n",
      "Training Loss (Epoch): 0.085687\n",
      "Validating...\n",
      "Validation Loss: 0.356502, Validation Accuracy: 88.00%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 10/20\n",
      "loss: 0.095906  [   70/  698]\n",
      "loss: 0.086332  [  210/  698]\n",
      "loss: 0.010833  [  350/  698]\n",
      "loss: 0.041377  [  490/  698]\n",
      "loss: 0.006728  [  630/  698]\n",
      "Training Loss (Epoch): 0.062349\n",
      "Validating...\n",
      "Validation Loss: 0.294304, Validation Accuracy: 92.00%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 11/20\n",
      "loss: 0.067704  [   70/  698]\n",
      "loss: 0.052682  [  210/  698]\n",
      "loss: 0.012596  [  350/  698]\n",
      "loss: 0.086018  [  490/  698]\n",
      "loss: 0.077446  [  630/  698]\n",
      "Training Loss (Epoch): 0.050081\n",
      "Validating...\n",
      "Validation Loss: 0.293275, Validation Accuracy: 91.43%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 12/20\n",
      "loss: 0.006254  [   70/  698]\n",
      "loss: 0.049953  [  210/  698]\n",
      "loss: 0.019569  [  350/  698]\n",
      "loss: 0.044378  [  490/  698]\n",
      "loss: 0.062070  [  630/  698]\n",
      "Training Loss (Epoch): 0.045652\n",
      "Validating...\n",
      "Validation Loss: 0.287469, Validation Accuracy: 91.43%\n",
      "Learning Rate: [6.25e-06]\n",
      "Epoch 13/20\n",
      "loss: 0.028499  [   70/  698]\n",
      "loss: 0.055367  [  210/  698]\n",
      "loss: 0.043456  [  350/  698]\n",
      "loss: 0.030348  [  490/  698]\n",
      "loss: 0.045174  [  630/  698]\n",
      "Training Loss (Epoch): 0.043065\n",
      "Validating...\n",
      "Validation Loss: 0.284512, Validation Accuracy: 91.43%\n",
      "Learning Rate: [3.125e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 2\n",
      "Epoch 1/20\n",
      "loss: 2.347645  [   70/  710]\n",
      "loss: 2.066521  [  210/  710]\n",
      "loss: 1.816252  [  350/  710]\n",
      "loss: 1.660507  [  490/  710]\n",
      "loss: 1.601420  [  630/  710]\n",
      "loss: 1.726038  [  110/  710]\n",
      "Training Loss (Epoch): 1.846876\n",
      "Validating...\n",
      "Validation Loss: 1.765508, Validation Accuracy: 54.49%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 1.672610  [   70/  710]\n",
      "loss: 1.161663  [  210/  710]\n",
      "loss: 0.913781  [  350/  710]\n",
      "loss: 0.761553  [  490/  710]\n",
      "loss: 1.118441  [  630/  710]\n",
      "loss: 0.776096  [  110/  710]\n",
      "Training Loss (Epoch): 1.050306\n",
      "Validating...\n",
      "Validation Loss: 1.283431, Validation Accuracy: 53.93%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 3/20\n",
      "loss: 1.337210  [   70/  710]\n",
      "loss: 0.686692  [  210/  710]\n",
      "loss: 0.566775  [  350/  710]\n",
      "loss: 0.542972  [  490/  710]\n",
      "loss: 0.431676  [  630/  710]\n",
      "loss: 0.702031  [  110/  710]\n",
      "Training Loss (Epoch): 0.688282\n",
      "Validating...\n",
      "Validation Loss: 0.696421, Validation Accuracy: 78.65%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 4/20\n",
      "loss: 0.302453  [   70/  710]\n",
      "loss: 0.350349  [  210/  710]\n",
      "loss: 0.203148  [  350/  710]\n",
      "loss: 0.558941  [  490/  710]\n",
      "loss: 0.281663  [  630/  710]\n",
      "loss: 1.467883  [  110/  710]\n",
      "Training Loss (Epoch): 0.471835\n",
      "Validating...\n",
      "Validation Loss: 1.002702, Validation Accuracy: 75.28%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 5/20\n",
      "loss: 0.475080  [   70/  710]\n",
      "loss: 0.338715  [  210/  710]\n",
      "loss: 0.575003  [  350/  710]\n",
      "loss: 0.377367  [  490/  710]\n",
      "loss: 0.482269  [  630/  710]\n",
      "loss: 0.280175  [  110/  710]\n",
      "Training Loss (Epoch): 0.420811\n",
      "Validating...\n",
      "Validation Loss: 0.517739, Validation Accuracy: 85.39%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 6/20\n",
      "loss: 0.108081  [   70/  710]\n",
      "loss: 0.286513  [  210/  710]\n",
      "loss: 0.338873  [  350/  710]\n",
      "loss: 0.171660  [  490/  710]\n",
      "loss: 0.115407  [  630/  710]\n",
      "loss: 0.232969  [  110/  710]\n",
      "Training Loss (Epoch): 0.232874\n",
      "Validating...\n",
      "Validation Loss: 0.451044, Validation Accuracy: 85.96%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 7/20\n",
      "loss: 0.214029  [   70/  710]\n",
      "loss: 0.165588  [  210/  710]\n",
      "loss: 0.085871  [  350/  710]\n",
      "loss: 0.171027  [  490/  710]\n",
      "loss: 0.075227  [  630/  710]\n",
      "loss: 0.336847  [  110/  710]\n",
      "Training Loss (Epoch): 0.156873\n",
      "Validating...\n",
      "Validation Loss: 0.462113, Validation Accuracy: 88.76%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 8/20\n",
      "loss: 0.129949  [   70/  710]\n",
      "loss: 0.120968  [  210/  710]\n",
      "loss: 0.189360  [  350/  710]\n",
      "loss: 0.207714  [  490/  710]\n",
      "loss: 0.059163  [  630/  710]\n",
      "loss: 0.024222  [  110/  710]\n",
      "Training Loss (Epoch): 0.118980\n",
      "Validating...\n",
      "Validation Loss: 0.442367, Validation Accuracy: 88.76%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 9/20\n",
      "loss: 0.021983  [   70/  710]\n",
      "loss: 0.183094  [  210/  710]\n",
      "loss: 0.073323  [  350/  710]\n",
      "loss: 0.132143  [  490/  710]\n",
      "loss: 0.078720  [  630/  710]\n",
      "loss: 0.048458  [  110/  710]\n",
      "Training Loss (Epoch): 0.090453\n",
      "Validating...\n",
      "Validation Loss: 0.438942, Validation Accuracy: 90.45%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 10/20\n",
      "loss: 0.099623  [   70/  710]\n",
      "loss: 0.046061  [  210/  710]\n",
      "loss: 0.098809  [  350/  710]\n",
      "loss: 0.105264  [  490/  710]\n",
      "loss: 0.070932  [  630/  710]\n",
      "loss: 0.001794  [  110/  710]\n",
      "Training Loss (Epoch): 0.065241\n",
      "Validating...\n",
      "Validation Loss: 0.430209, Validation Accuracy: 91.01%\n",
      "Learning Rate: [6.25e-06]\n",
      "Epoch 11/20\n",
      "loss: 0.047281  [   70/  710]\n",
      "loss: 0.045922  [  210/  710]\n",
      "loss: 0.081194  [  350/  710]\n",
      "loss: 0.030010  [  490/  710]\n",
      "loss: 0.068973  [  630/  710]\n",
      "loss: 0.037082  [  110/  710]\n",
      "Training Loss (Epoch): 0.057643\n",
      "Validating...\n",
      "Validation Loss: 0.440608, Validation Accuracy: 90.45%\n",
      "Learning Rate: [3.125e-06]\n",
      "Epoch 12/20\n",
      "loss: 0.056271  [   70/  710]\n",
      "loss: 0.063268  [  210/  710]\n",
      "loss: 0.032298  [  350/  710]\n",
      "loss: 0.043732  [  490/  710]\n",
      "loss: 0.099900  [  630/  710]\n",
      "loss: 0.054296  [  110/  710]\n",
      "Training Loss (Epoch): 0.055164\n",
      "Validating...\n",
      "Validation Loss: 0.441445, Validation Accuracy: 90.45%\n",
      "Learning Rate: [1.5625e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 3\n",
      "Epoch 1/20\n",
      "loss: 2.332122  [   70/  740]\n",
      "loss: 2.104071  [  210/  740]\n",
      "loss: 1.905744  [  350/  740]\n",
      "loss: 1.651350  [  490/  740]\n",
      "loss: 1.669714  [  630/  740]\n",
      "loss: 1.384632  [  440/  740]\n",
      "Training Loss (Epoch): 1.848321\n",
      "Validating...\n",
      "Validation Loss: 1.811304, Validation Accuracy: 50.81%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 1.768559  [   70/  740]\n",
      "loss: 1.085759  [  210/  740]\n",
      "loss: 1.420382  [  350/  740]\n",
      "loss: 1.122762  [  490/  740]\n",
      "loss: 1.031430  [  630/  740]\n",
      "loss: 0.796553  [  440/  740]\n",
      "Training Loss (Epoch): 1.167100\n",
      "Validating...\n",
      "Validation Loss: 0.909658, Validation Accuracy: 69.73%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 0.731982  [   70/  740]\n",
      "loss: 0.751791  [  210/  740]\n",
      "loss: 1.029658  [  350/  740]\n",
      "loss: 0.751799  [  490/  740]\n",
      "loss: 0.757067  [  630/  740]\n",
      "loss: 0.818198  [  440/  740]\n",
      "Training Loss (Epoch): 0.771277\n",
      "Validating...\n",
      "Validation Loss: 0.998416, Validation Accuracy: 67.03%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 4/20\n",
      "loss: 0.636157  [   70/  740]\n",
      "loss: 0.528180  [  210/  740]\n",
      "loss: 0.429764  [  350/  740]\n",
      "loss: 0.371983  [  490/  740]\n",
      "loss: 0.442647  [  630/  740]\n",
      "loss: 0.458567  [  440/  740]\n",
      "Training Loss (Epoch): 0.476366\n",
      "Validating...\n",
      "Validation Loss: 0.659122, Validation Accuracy: 82.16%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 5/20\n",
      "loss: 0.320594  [   70/  740]\n",
      "loss: 0.146992  [  210/  740]\n",
      "loss: 0.281944  [  350/  740]\n",
      "loss: 0.397925  [  490/  740]\n",
      "loss: 0.369777  [  630/  740]\n",
      "loss: 0.162154  [  440/  740]\n",
      "Training Loss (Epoch): 0.298379\n",
      "Validating...\n",
      "Validation Loss: 0.662998, Validation Accuracy: 76.76%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 6/20\n",
      "loss: 0.442040  [   70/  740]\n",
      "loss: 0.119178  [  210/  740]\n",
      "loss: 0.216719  [  350/  740]\n",
      "loss: 0.266223  [  490/  740]\n",
      "loss: 0.150957  [  630/  740]\n",
      "loss: 0.087768  [  440/  740]\n",
      "Training Loss (Epoch): 0.209432\n",
      "Validating...\n",
      "Validation Loss: 0.449017, Validation Accuracy: 85.41%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 7/20\n",
      "loss: 0.177831  [   70/  740]\n",
      "loss: 0.091854  [  210/  740]\n",
      "loss: 0.207898  [  350/  740]\n",
      "loss: 0.079518  [  490/  740]\n",
      "loss: 0.235295  [  630/  740]\n",
      "loss: 0.178176  [  440/  740]\n",
      "Training Loss (Epoch): 0.162166\n",
      "Validating...\n",
      "Validation Loss: 0.409874, Validation Accuracy: 85.41%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 8/20\n",
      "loss: 0.083265  [   70/  740]\n",
      "loss: 0.190527  [  210/  740]\n",
      "loss: 0.036953  [  350/  740]\n",
      "loss: 0.167709  [  490/  740]\n",
      "loss: 0.054285  [  630/  740]\n",
      "loss: 0.193537  [  440/  740]\n",
      "Training Loss (Epoch): 0.113746\n",
      "Validating...\n",
      "Validation Loss: 0.396057, Validation Accuracy: 86.49%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 9/20\n",
      "loss: 0.157542  [   70/  740]\n",
      "loss: 0.079277  [  210/  740]\n",
      "loss: 0.055132  [  350/  740]\n",
      "loss: 0.075584  [  490/  740]\n",
      "loss: 0.074842  [  630/  740]\n",
      "loss: 0.018414  [  440/  740]\n",
      "Training Loss (Epoch): 0.090384\n",
      "Validating...\n",
      "Validation Loss: 0.378163, Validation Accuracy: 86.49%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 10/20\n",
      "loss: 0.089191  [   70/  740]\n",
      "loss: 0.090985  [  210/  740]\n",
      "loss: 0.045029  [  350/  740]\n",
      "loss: 0.126736  [  490/  740]\n",
      "loss: 0.085625  [  630/  740]\n",
      "loss: 0.175888  [  440/  740]\n",
      "Training Loss (Epoch): 0.076547\n",
      "Validating...\n",
      "Validation Loss: 0.372408, Validation Accuracy: 87.57%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 11/20\n",
      "loss: 0.069639  [   70/  740]\n",
      "loss: 0.043339  [  210/  740]\n",
      "loss: 0.061617  [  350/  740]\n",
      "loss: 0.067677  [  490/  740]\n",
      "loss: 0.056240  [  630/  740]\n",
      "loss: 0.220227  [  440/  740]\n",
      "Training Loss (Epoch): 0.077192\n",
      "Validating...\n",
      "Validation Loss: 0.411774, Validation Accuracy: 85.95%\n",
      "Learning Rate: [6.25e-06]\n",
      "Epoch 12/20\n",
      "loss: 0.039851  [   70/  740]\n",
      "loss: 0.024581  [  210/  740]\n",
      "loss: 0.072387  [  350/  740]\n",
      "loss: 0.063192  [  490/  740]\n",
      "loss: 0.094368  [  630/  740]\n",
      "loss: 0.024881  [  440/  740]\n",
      "Training Loss (Epoch): 0.056793\n",
      "Validating...\n",
      "Validation Loss: 0.397034, Validation Accuracy: 87.57%\n",
      "Learning Rate: [3.125e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 4\n",
      "Epoch 1/20\n",
      "loss: 2.404945  [   70/  792]\n",
      "loss: 2.200254  [  210/  792]\n",
      "loss: 2.099240  [  350/  792]\n",
      "loss: 1.934175  [  490/  792]\n",
      "loss: 1.870685  [  630/  792]\n",
      "loss: 1.773783  [  770/  792]\n",
      "Training Loss (Epoch): 2.005432\n",
      "Validating...\n",
      "Validation Loss: 1.734605, Validation Accuracy: 54.55%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 1.695125  [   70/  792]\n",
      "loss: 1.386011  [  210/  792]\n",
      "loss: 1.319839  [  350/  792]\n",
      "loss: 1.545349  [  490/  792]\n",
      "loss: 1.147810  [  630/  792]\n",
      "loss: 1.016742  [  770/  792]\n",
      "Training Loss (Epoch): 1.262915\n",
      "Validating...\n",
      "Validation Loss: 1.083612, Validation Accuracy: 64.14%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 0.941782  [   70/  792]\n",
      "loss: 0.894147  [  210/  792]\n",
      "loss: 0.869164  [  350/  792]\n",
      "loss: 0.594230  [  490/  792]\n",
      "loss: 0.659947  [  630/  792]\n",
      "loss: 0.598131  [  770/  792]\n",
      "Training Loss (Epoch): 0.812184\n",
      "Validating...\n",
      "Validation Loss: 0.850488, Validation Accuracy: 71.72%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/20\n",
      "loss: 0.697105  [   70/  792]\n",
      "loss: 0.714924  [  210/  792]\n",
      "loss: 0.523366  [  350/  792]\n",
      "loss: 0.334824  [  490/  792]\n",
      "loss: 0.383778  [  630/  792]\n",
      "loss: 0.558028  [  770/  792]\n",
      "Training Loss (Epoch): 0.543153\n",
      "Validating...\n",
      "Validation Loss: 0.569999, Validation Accuracy: 77.78%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/20\n",
      "loss: 0.502084  [   70/  792]\n",
      "loss: 0.250027  [  210/  792]\n",
      "loss: 0.423176  [  350/  792]\n",
      "loss: 0.326336  [  490/  792]\n",
      "loss: 0.321522  [  630/  792]\n",
      "loss: 0.457132  [  770/  792]\n",
      "Training Loss (Epoch): 0.360476\n",
      "Validating...\n",
      "Validation Loss: 0.689637, Validation Accuracy: 82.83%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/20\n",
      "loss: 0.380703  [   70/  792]\n",
      "loss: 0.154410  [  210/  792]\n",
      "loss: 0.434338  [  350/  792]\n",
      "loss: 0.376167  [  490/  792]\n",
      "loss: 0.375677  [  630/  792]\n",
      "loss: 0.283711  [  770/  792]\n",
      "Training Loss (Epoch): 0.328068\n",
      "Validating...\n",
      "Validation Loss: 0.692418, Validation Accuracy: 77.27%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 7/20\n",
      "loss: 0.306748  [   70/  792]\n",
      "loss: 0.235865  [  210/  792]\n",
      "loss: 0.226989  [  350/  792]\n",
      "loss: 0.189849  [  490/  792]\n",
      "loss: 0.204559  [  630/  792]\n",
      "loss: 0.179196  [  770/  792]\n",
      "Training Loss (Epoch): 0.234233\n",
      "Validating...\n",
      "Validation Loss: 0.502203, Validation Accuracy: 84.34%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 8/20\n",
      "loss: 0.087364  [   70/  792]\n",
      "loss: 0.127853  [  210/  792]\n",
      "loss: 0.181195  [  350/  792]\n",
      "loss: 0.120382  [  490/  792]\n",
      "loss: 0.133390  [  630/  792]\n",
      "loss: 0.109345  [  770/  792]\n",
      "Training Loss (Epoch): 0.118120\n",
      "Validating...\n",
      "Validation Loss: 0.438580, Validation Accuracy: 87.88%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 9/20\n",
      "loss: 0.132207  [   70/  792]\n",
      "loss: 0.108561  [  210/  792]\n",
      "loss: 0.073877  [  350/  792]\n",
      "loss: 0.026248  [  490/  792]\n",
      "loss: 0.041274  [  630/  792]\n",
      "loss: 0.061394  [  770/  792]\n",
      "Training Loss (Epoch): 0.108806\n",
      "Validating...\n",
      "Validation Loss: 0.646038, Validation Accuracy: 87.88%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 10/20\n",
      "loss: 0.009880  [   70/  792]\n",
      "loss: 0.252415  [  210/  792]\n",
      "loss: 0.093249  [  350/  792]\n",
      "loss: 0.042936  [  490/  792]\n",
      "loss: 0.124224  [  630/  792]\n",
      "loss: 0.172289  [  770/  792]\n",
      "Training Loss (Epoch): 0.125427\n",
      "Validating...\n",
      "Validation Loss: 0.427397, Validation Accuracy: 90.40%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 11/20\n",
      "loss: 0.080985  [   70/  792]\n",
      "loss: 0.056442  [  210/  792]\n",
      "loss: 0.095031  [  350/  792]\n",
      "loss: 0.052657  [  490/  792]\n",
      "loss: 0.046989  [  630/  792]\n",
      "loss: 0.062412  [  770/  792]\n",
      "Training Loss (Epoch): 0.052323\n",
      "Validating...\n",
      "Validation Loss: 0.445166, Validation Accuracy: 87.37%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 12/20\n",
      "loss: 0.024101  [   70/  792]\n",
      "loss: 0.004539  [  210/  792]\n",
      "loss: 0.041127  [  350/  792]\n",
      "loss: 0.037854  [  490/  792]\n",
      "loss: 0.082573  [  630/  792]\n",
      "loss: 0.060397  [  770/  792]\n",
      "Training Loss (Epoch): 0.033436\n",
      "Validating...\n",
      "Validation Loss: 0.358283, Validation Accuracy: 89.90%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 13/20\n",
      "loss: 0.093441  [   70/  792]\n",
      "loss: 0.010343  [  210/  792]\n",
      "loss: 0.007075  [  350/  792]\n",
      "loss: 0.058197  [  490/  792]\n",
      "loss: 0.010827  [  630/  792]\n",
      "loss: 0.015988  [  770/  792]\n",
      "Training Loss (Epoch): 0.025674\n",
      "Validating...\n",
      "Validation Loss: 0.352705, Validation Accuracy: 90.40%\n",
      "Learning Rate: [6.25e-06]\n",
      "Epoch 14/20\n",
      "loss: 0.014205  [   70/  792]\n",
      "loss: 0.030845  [  210/  792]\n",
      "loss: 0.013946  [  350/  792]\n",
      "loss: 0.004081  [  490/  792]\n",
      "loss: 0.035324  [  630/  792]\n",
      "loss: 0.040397  [  770/  792]\n",
      "Training Loss (Epoch): 0.023091\n",
      "Validating...\n",
      "Validation Loss: 0.353014, Validation Accuracy: 90.91%\n",
      "Learning Rate: [3.125e-06]\n",
      "Epoch 15/20\n",
      "loss: 0.012371  [   70/  792]\n",
      "loss: 0.044145  [  210/  792]\n",
      "loss: 0.005994  [  350/  792]\n",
      "loss: 0.062792  [  490/  792]\n",
      "loss: 0.008782  [  630/  792]\n",
      "loss: 0.008401  [  770/  792]\n",
      "Training Loss (Epoch): 0.025465\n",
      "Validating...\n",
      "Validation Loss: 0.354603, Validation Accuracy: 90.91%\n",
      "Learning Rate: [1.5625e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 5\n",
      "Epoch 1/20\n",
      "loss: 2.386152  [   70/  748]\n",
      "loss: 2.130273  [  210/  748]\n",
      "loss: 2.147933  [  350/  748]\n",
      "loss: 1.953254  [  490/  748]\n",
      "loss: 1.888918  [  630/  748]\n",
      "loss: 1.624546  [  528/  748]\n",
      "Training Loss (Epoch): 1.989035\n",
      "Validating...\n",
      "Validation Loss: 1.867825, Validation Accuracy: 42.02%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 1.731008  [   70/  748]\n",
      "loss: 1.428202  [  210/  748]\n",
      "loss: 1.377499  [  350/  748]\n",
      "loss: 1.270206  [  490/  748]\n",
      "loss: 0.963215  [  630/  748]\n",
      "loss: 0.726336  [  528/  748]\n",
      "Training Loss (Epoch): 1.258843\n",
      "Validating...\n",
      "Validation Loss: 1.023898, Validation Accuracy: 68.62%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 0.658581  [   70/  748]\n",
      "loss: 0.539162  [  210/  748]\n",
      "loss: 0.837945  [  350/  748]\n",
      "loss: 0.672715  [  490/  748]\n",
      "loss: 0.815884  [  630/  748]\n",
      "loss: 0.580138  [  528/  748]\n",
      "Training Loss (Epoch): 0.784091\n",
      "Validating...\n",
      "Validation Loss: 0.852533, Validation Accuracy: 75.00%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/20\n",
      "loss: 0.551734  [   70/  748]\n",
      "loss: 0.466629  [  210/  748]\n",
      "loss: 0.616180  [  350/  748]\n",
      "loss: 0.528996  [  490/  748]\n",
      "loss: 0.714887  [  630/  748]\n",
      "loss: 0.421675  [  528/  748]\n",
      "Training Loss (Epoch): 0.488665\n",
      "Validating...\n",
      "Validation Loss: 0.735652, Validation Accuracy: 73.94%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 5/20\n",
      "loss: 0.534222  [   70/  748]\n",
      "loss: 0.354240  [  210/  748]\n",
      "loss: 0.220854  [  350/  748]\n",
      "loss: 0.187851  [  490/  748]\n",
      "loss: 0.458100  [  630/  748]\n",
      "loss: 0.182441  [  528/  748]\n",
      "Training Loss (Epoch): 0.326523\n",
      "Validating...\n",
      "Validation Loss: 0.726094, Validation Accuracy: 76.60%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 6/20\n",
      "loss: 0.240008  [   70/  748]\n",
      "loss: 0.138928  [  210/  748]\n",
      "loss: 0.121597  [  350/  748]\n",
      "loss: 0.231333  [  490/  748]\n",
      "loss: 0.099033  [  630/  748]\n",
      "loss: 0.089978  [  528/  748]\n",
      "Training Loss (Epoch): 0.177003\n",
      "Validating...\n",
      "Validation Loss: 0.508807, Validation Accuracy: 86.17%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 7/20\n",
      "loss: 0.183228  [   70/  748]\n",
      "loss: 0.163648  [  210/  748]\n",
      "loss: 0.215872  [  350/  748]\n",
      "loss: 0.233998  [  490/  748]\n",
      "loss: 0.117497  [  630/  748]\n",
      "loss: 0.325896  [  528/  748]\n",
      "Training Loss (Epoch): 0.181312\n",
      "Validating...\n",
      "Validation Loss: 0.502857, Validation Accuracy: 82.98%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 8/20\n",
      "loss: 0.107929  [   70/  748]\n",
      "loss: 0.194705  [  210/  748]\n",
      "loss: 0.177705  [  350/  748]\n",
      "loss: 0.052871  [  490/  748]\n",
      "loss: 0.096171  [  630/  748]\n",
      "loss: 0.051691  [  528/  748]\n",
      "Training Loss (Epoch): 0.112346\n",
      "Validating...\n",
      "Validation Loss: 0.381184, Validation Accuracy: 87.77%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 9/20\n",
      "loss: 0.166833  [   70/  748]\n",
      "loss: 0.046393  [  210/  748]\n",
      "loss: 0.064171  [  350/  748]\n",
      "loss: 0.053166  [  490/  748]\n",
      "loss: 0.142977  [  630/  748]\n",
      "loss: 0.064121  [  528/  748]\n",
      "Training Loss (Epoch): 0.069997\n",
      "Validating...\n",
      "Validation Loss: 0.393971, Validation Accuracy: 89.89%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 10/20\n",
      "loss: 0.054014  [   70/  748]\n",
      "loss: 0.060997  [  210/  748]\n",
      "loss: 0.115278  [  350/  748]\n",
      "loss: 0.039980  [  490/  748]\n",
      "loss: 0.060010  [  630/  748]\n",
      "loss: 0.031955  [  528/  748]\n",
      "Training Loss (Epoch): 0.055949\n",
      "Validating...\n",
      "Validation Loss: 0.384821, Validation Accuracy: 89.89%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 11/20\n",
      "loss: 0.024336  [   70/  748]\n",
      "loss: 0.074907  [  210/  748]\n",
      "loss: 0.053996  [  350/  748]\n",
      "loss: 0.030409  [  490/  748]\n",
      "loss: 0.037577  [  630/  748]\n",
      "loss: 0.015560  [  528/  748]\n",
      "Training Loss (Epoch): 0.035392\n",
      "Validating...\n",
      "Validation Loss: 0.388821, Validation Accuracy: 89.89%\n",
      "Learning Rate: [1.25e-05]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 6\n",
      "Epoch 1/20\n",
      "loss: 2.444789  [   70/  658]\n",
      "loss: 2.255749  [  210/  658]\n",
      "loss: 2.070381  [  350/  658]\n",
      "loss: 1.903611  [  490/  658]\n",
      "loss: 1.892492  [  630/  658]\n",
      "Training Loss (Epoch): 2.052884\n",
      "Validating...\n",
      "Validation Loss: 1.956324, Validation Accuracy: 30.30%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 1.801422  [   70/  658]\n",
      "loss: 1.542038  [  210/  658]\n",
      "loss: 1.452339  [  350/  658]\n",
      "loss: 1.045609  [  490/  658]\n",
      "loss: 1.221380  [  630/  658]\n",
      "Training Loss (Epoch): 1.357222\n",
      "Validating...\n",
      "Validation Loss: 1.093017, Validation Accuracy: 64.24%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 1.045672  [   70/  658]\n",
      "loss: 0.952667  [  210/  658]\n",
      "loss: 0.925574  [  350/  658]\n",
      "loss: 1.083062  [  490/  658]\n",
      "loss: 0.823655  [  630/  658]\n",
      "Training Loss (Epoch): 1.004006\n",
      "Validating...\n",
      "Validation Loss: 0.922213, Validation Accuracy: 66.67%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/20\n",
      "loss: 0.544896  [   70/  658]\n",
      "loss: 0.684985  [  210/  658]\n",
      "loss: 0.506502  [  350/  658]\n",
      "loss: 0.476206  [  490/  658]\n",
      "loss: 0.559111  [  630/  658]\n",
      "Training Loss (Epoch): 0.572753\n",
      "Validating...\n",
      "Validation Loss: 0.688392, Validation Accuracy: 77.58%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/20\n",
      "loss: 0.358467  [   70/  658]\n",
      "loss: 0.395705  [  210/  658]\n",
      "loss: 0.621634  [  350/  658]\n",
      "loss: 0.702554  [  490/  658]\n",
      "loss: 0.334862  [  630/  658]\n",
      "Training Loss (Epoch): 0.461607\n",
      "Validating...\n",
      "Validation Loss: 0.573994, Validation Accuracy: 82.42%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/20\n",
      "loss: 0.471166  [   70/  658]\n",
      "loss: 0.386111  [  210/  658]\n",
      "loss: 0.485583  [  350/  658]\n",
      "loss: 0.584084  [  490/  658]\n",
      "loss: 0.299569  [  630/  658]\n",
      "Training Loss (Epoch): 0.453249\n",
      "Validating...\n",
      "Validation Loss: 0.812451, Validation Accuracy: 75.15%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 7/20\n",
      "loss: 0.579191  [   70/  658]\n",
      "loss: 0.407302  [  210/  658]\n",
      "loss: 0.366051  [  350/  658]\n",
      "loss: 0.283926  [  490/  658]\n",
      "loss: 0.331879  [  630/  658]\n",
      "Training Loss (Epoch): 0.390967\n",
      "Validating...\n",
      "Validation Loss: 0.456249, Validation Accuracy: 84.24%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 8/20\n",
      "loss: 0.174498  [   70/  658]\n",
      "loss: 0.175151  [  210/  658]\n",
      "loss: 0.176427  [  350/  658]\n",
      "loss: 0.212595  [  490/  658]\n",
      "loss: 0.181728  [  630/  658]\n",
      "Training Loss (Epoch): 0.190179\n",
      "Validating...\n",
      "Validation Loss: 0.468076, Validation Accuracy: 84.85%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 9/20\n",
      "loss: 0.224621  [   70/  658]\n",
      "loss: 0.129115  [  210/  658]\n",
      "loss: 0.160935  [  350/  658]\n",
      "loss: 0.118281  [  490/  658]\n",
      "loss: 0.046041  [  630/  658]\n",
      "Training Loss (Epoch): 0.120719\n",
      "Validating...\n",
      "Validation Loss: 0.425691, Validation Accuracy: 87.27%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 10/20\n",
      "loss: 0.169832  [   70/  658]\n",
      "loss: 0.086240  [  210/  658]\n",
      "loss: 0.148365  [  350/  658]\n",
      "loss: 0.077015  [  490/  658]\n",
      "loss: 0.063644  [  630/  658]\n",
      "Training Loss (Epoch): 0.082401\n",
      "Validating...\n",
      "Validation Loss: 0.401412, Validation Accuracy: 89.09%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 11/20\n",
      "loss: 0.047020  [   70/  658]\n",
      "loss: 0.151886  [  210/  658]\n",
      "loss: 0.200094  [  350/  658]\n",
      "loss: 0.089774  [  490/  658]\n",
      "loss: 0.093872  [  630/  658]\n",
      "Training Loss (Epoch): 0.096521\n",
      "Validating...\n",
      "Validation Loss: 0.395138, Validation Accuracy: 89.09%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 12/20\n",
      "loss: 0.025329  [   70/  658]\n",
      "loss: 0.115878  [  210/  658]\n",
      "loss: 0.067705  [  350/  658]\n",
      "loss: 0.045184  [  490/  658]\n",
      "loss: 0.056856  [  630/  658]\n",
      "Training Loss (Epoch): 0.073176\n",
      "Validating...\n",
      "Validation Loss: 0.383251, Validation Accuracy: 90.91%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 13/20\n",
      "loss: 0.042969  [   70/  658]\n",
      "loss: 0.059099  [  210/  658]\n",
      "loss: 0.058606  [  350/  658]\n",
      "loss: 0.052313  [  490/  658]\n",
      "loss: 0.123387  [  630/  658]\n",
      "Training Loss (Epoch): 0.064344\n",
      "Validating...\n",
      "Validation Loss: 0.386407, Validation Accuracy: 89.09%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 14/20\n",
      "loss: 0.044988  [   70/  658]\n",
      "loss: 0.063802  [  210/  658]\n",
      "loss: 0.065148  [  350/  658]\n",
      "loss: 0.055143  [  490/  658]\n",
      "loss: 0.052479  [  630/  658]\n",
      "Training Loss (Epoch): 0.051154\n",
      "Validating...\n",
      "Validation Loss: 0.361327, Validation Accuracy: 90.91%\n",
      "Learning Rate: [6.25e-06]\n",
      "Epoch 15/20\n",
      "loss: 0.074620  [   70/  658]\n",
      "loss: 0.051831  [  210/  658]\n",
      "loss: 0.036771  [  350/  658]\n",
      "loss: 0.068125  [  490/  658]\n",
      "loss: 0.041057  [  630/  658]\n",
      "Training Loss (Epoch): 0.056303\n",
      "Validating...\n",
      "Validation Loss: 0.364264, Validation Accuracy: 90.30%\n",
      "Learning Rate: [3.125e-06]\n",
      "Epoch 16/20\n",
      "loss: 0.022824  [   70/  658]\n",
      "loss: 0.045077  [  210/  658]\n",
      "loss: 0.080002  [  350/  658]\n",
      "loss: 0.077614  [  490/  658]\n",
      "loss: 0.060490  [  630/  658]\n",
      "Training Loss (Epoch): 0.055428\n",
      "Validating...\n",
      "Validation Loss: 0.367460, Validation Accuracy: 90.30%\n",
      "Learning Rate: [1.5625e-06]\n",
      "Epoch 17/20\n",
      "loss: 0.127661  [   70/  658]\n",
      "loss: 0.056151  [  210/  658]\n",
      "loss: 0.051454  [  350/  658]\n",
      "loss: 0.021066  [  490/  658]\n",
      "loss: 0.032733  [  630/  658]\n",
      "Training Loss (Epoch): 0.051245\n",
      "Validating...\n",
      "Validation Loss: 0.367466, Validation Accuracy: 90.30%\n",
      "Learning Rate: [7.8125e-07]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 7\n",
      "Epoch 1/20\n",
      "loss: 2.380963  [   70/  670]\n",
      "loss: 2.183462  [  210/  670]\n",
      "loss: 1.970765  [  350/  670]\n",
      "loss: 1.668749  [  490/  670]\n",
      "loss: 1.810056  [  630/  670]\n",
      "Training Loss (Epoch): 1.966460\n",
      "Validating...\n",
      "Validation Loss: 1.756687, Validation Accuracy: 44.64%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 1.702660  [   70/  670]\n",
      "loss: 1.383480  [  210/  670]\n",
      "loss: 1.292950  [  350/  670]\n",
      "loss: 1.054265  [  490/  670]\n",
      "loss: 1.326634  [  630/  670]\n",
      "Training Loss (Epoch): 1.290786\n",
      "Validating...\n",
      "Validation Loss: 0.942358, Validation Accuracy: 69.05%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 0.781465  [   70/  670]\n",
      "loss: 0.988867  [  210/  670]\n",
      "loss: 0.708178  [  350/  670]\n",
      "loss: 1.069400  [  490/  670]\n",
      "loss: 0.882232  [  630/  670]\n",
      "Training Loss (Epoch): 0.887432\n",
      "Validating...\n",
      "Validation Loss: 0.995429, Validation Accuracy: 66.07%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 4/20\n",
      "loss: 0.772319  [   70/  670]\n",
      "loss: 0.698142  [  210/  670]\n",
      "loss: 0.619767  [  350/  670]\n",
      "loss: 0.417171  [  490/  670]\n",
      "loss: 0.492080  [  630/  670]\n",
      "Training Loss (Epoch): 0.639731\n",
      "Validating...\n",
      "Validation Loss: 0.746726, Validation Accuracy: 74.40%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 5/20\n",
      "loss: 0.393605  [   70/  670]\n",
      "loss: 0.366227  [  210/  670]\n",
      "loss: 0.452480  [  350/  670]\n",
      "loss: 0.381914  [  490/  670]\n",
      "loss: 0.383232  [  630/  670]\n",
      "Training Loss (Epoch): 0.382614\n",
      "Validating...\n",
      "Validation Loss: 0.624637, Validation Accuracy: 79.17%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 6/20\n",
      "loss: 0.222218  [   70/  670]\n",
      "loss: 0.268994  [  210/  670]\n",
      "loss: 0.248460  [  350/  670]\n",
      "loss: 0.164122  [  490/  670]\n",
      "loss: 0.424291  [  630/  670]\n",
      "Training Loss (Epoch): 0.310780\n",
      "Validating...\n",
      "Validation Loss: 1.118395, Validation Accuracy: 80.95%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 7/20\n",
      "loss: 0.311972  [   70/  670]\n",
      "loss: 0.160059  [  210/  670]\n",
      "loss: 0.279764  [  350/  670]\n",
      "loss: 0.268527  [  490/  670]\n",
      "loss: 0.255481  [  630/  670]\n",
      "Training Loss (Epoch): 0.279464\n",
      "Validating...\n",
      "Validation Loss: 0.972078, Validation Accuracy: 74.40%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 8/20\n",
      "loss: 0.219513  [   70/  670]\n",
      "loss: 0.186684  [  210/  670]\n",
      "loss: 0.263703  [  350/  670]\n",
      "loss: 0.177924  [  490/  670]\n",
      "loss: 0.233495  [  630/  670]\n",
      "Training Loss (Epoch): 0.219411\n",
      "Validating...\n",
      "Validation Loss: 0.548162, Validation Accuracy: 84.52%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 9/20\n",
      "loss: 0.170488  [   70/  670]\n",
      "loss: 0.140986  [  210/  670]\n",
      "loss: 0.069420  [  350/  670]\n",
      "loss: 0.209156  [  490/  670]\n",
      "loss: 0.072443  [  630/  670]\n",
      "Training Loss (Epoch): 0.125781\n",
      "Validating...\n",
      "Validation Loss: 0.622005, Validation Accuracy: 84.52%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 10/20\n",
      "loss: 0.128992  [   70/  670]\n",
      "loss: 0.072553  [  210/  670]\n",
      "loss: 0.117655  [  350/  670]\n",
      "loss: 0.106342  [  490/  670]\n",
      "loss: 0.062169  [  630/  670]\n",
      "Training Loss (Epoch): 0.088736\n",
      "Validating...\n",
      "Validation Loss: 0.631919, Validation Accuracy: 85.71%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 11/20\n",
      "loss: 0.102715  [   70/  670]\n",
      "loss: 0.058716  [  210/  670]\n",
      "loss: 0.047644  [  350/  670]\n",
      "loss: 0.102366  [  490/  670]\n",
      "loss: 0.147143  [  630/  670]\n",
      "Training Loss (Epoch): 0.072986\n",
      "Validating...\n",
      "Validation Loss: 0.639679, Validation Accuracy: 86.90%\n",
      "Learning Rate: [2.5e-05]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 8\n",
      "Epoch 1/20\n",
      "loss: 2.332144  [   70/  644]\n",
      "loss: 2.153876  [  210/  644]\n",
      "loss: 2.065624  [  350/  644]\n",
      "loss: 1.915803  [  490/  644]\n",
      "loss: 1.705543  [  630/  644]\n",
      "Training Loss (Epoch): 2.017772\n",
      "Validating...\n",
      "Validation Loss: 1.896274, Validation Accuracy: 45.06%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 1.852467  [   70/  644]\n",
      "loss: 1.652394  [  210/  644]\n",
      "loss: 1.301665  [  350/  644]\n",
      "loss: 1.844235  [  490/  644]\n",
      "loss: 1.377023  [  630/  644]\n",
      "Training Loss (Epoch): 1.449455\n",
      "Validating...\n",
      "Validation Loss: 1.106329, Validation Accuracy: 61.11%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 0.787924  [   70/  644]\n",
      "loss: 0.985824  [  210/  644]\n",
      "loss: 1.088375  [  350/  644]\n",
      "loss: 0.694817  [  490/  644]\n",
      "loss: 0.761926  [  630/  644]\n",
      "Training Loss (Epoch): 0.861263\n",
      "Validating...\n",
      "Validation Loss: 1.010417, Validation Accuracy: 64.81%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/20\n",
      "loss: 0.723861  [   70/  644]\n",
      "loss: 0.654892  [  210/  644]\n",
      "loss: 0.420687  [  350/  644]\n",
      "loss: 0.706632  [  490/  644]\n",
      "loss: 0.495203  [  630/  644]\n",
      "Training Loss (Epoch): 0.747862\n",
      "Validating...\n",
      "Validation Loss: 1.047134, Validation Accuracy: 75.31%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/20\n",
      "loss: 0.646220  [   70/  644]\n",
      "loss: 0.679291  [  210/  644]\n",
      "loss: 0.692495  [  350/  644]\n",
      "loss: 0.514990  [  490/  644]\n",
      "loss: 0.620504  [  630/  644]\n",
      "Training Loss (Epoch): 0.641759\n",
      "Validating...\n",
      "Validation Loss: 0.570915, Validation Accuracy: 79.63%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/20\n",
      "loss: 0.499471  [   70/  644]\n",
      "loss: 0.414371  [  210/  644]\n",
      "loss: 0.481082  [  350/  644]\n",
      "loss: 0.255299  [  490/  644]\n",
      "loss: 0.417425  [  630/  644]\n",
      "Training Loss (Epoch): 0.433111\n",
      "Validating...\n",
      "Validation Loss: 0.730040, Validation Accuracy: 76.54%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 7/20\n",
      "loss: 0.383003  [   70/  644]\n",
      "loss: 0.548652  [  210/  644]\n",
      "loss: 0.376186  [  350/  644]\n",
      "loss: 0.508467  [  490/  644]\n",
      "loss: 0.435365  [  630/  644]\n",
      "Training Loss (Epoch): 0.436787\n",
      "Validating...\n",
      "Validation Loss: 0.499196, Validation Accuracy: 81.48%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 8/20\n",
      "loss: 0.289104  [   70/  644]\n",
      "loss: 0.332933  [  210/  644]\n",
      "loss: 0.274123  [  350/  644]\n",
      "loss: 0.130286  [  490/  644]\n",
      "loss: 0.258427  [  630/  644]\n",
      "Training Loss (Epoch): 0.288232\n",
      "Validating...\n",
      "Validation Loss: 0.625129, Validation Accuracy: 82.10%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 9/20\n",
      "loss: 0.219382  [   70/  644]\n",
      "loss: 0.203189  [  210/  644]\n",
      "loss: 0.204154  [  350/  644]\n",
      "loss: 0.177383  [  490/  644]\n",
      "loss: 0.173168  [  630/  644]\n",
      "Training Loss (Epoch): 0.201676\n",
      "Validating...\n",
      "Validation Loss: 0.418046, Validation Accuracy: 88.27%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 10/20\n",
      "loss: 0.118667  [   70/  644]\n",
      "loss: 0.300463  [  210/  644]\n",
      "loss: 0.130464  [  350/  644]\n",
      "loss: 0.060920  [  490/  644]\n",
      "loss: 0.175913  [  630/  644]\n",
      "Training Loss (Epoch): 0.131570\n",
      "Validating...\n",
      "Validation Loss: 0.595502, Validation Accuracy: 82.72%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 11/20\n",
      "loss: 0.137391  [   70/  644]\n",
      "loss: 0.212695  [  210/  644]\n",
      "loss: 0.102241  [  350/  644]\n",
      "loss: 0.042693  [  490/  644]\n",
      "loss: 0.096370  [  630/  644]\n",
      "Training Loss (Epoch): 0.203444\n",
      "Validating...\n",
      "Validation Loss: 0.398442, Validation Accuracy: 90.74%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 12/20\n",
      "loss: 0.053882  [   70/  644]\n",
      "loss: 0.094839  [  210/  644]\n",
      "loss: 0.194614  [  350/  644]\n",
      "loss: 0.116437  [  490/  644]\n",
      "loss: 0.096717  [  630/  644]\n",
      "Training Loss (Epoch): 0.117052\n",
      "Validating...\n",
      "Validation Loss: 0.490479, Validation Accuracy: 85.19%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 13/20\n",
      "loss: 0.129941  [   70/  644]\n",
      "loss: 0.098813  [  210/  644]\n",
      "loss: 0.105064  [  350/  644]\n",
      "loss: 0.061901  [  490/  644]\n",
      "loss: 0.063858  [  630/  644]\n",
      "Training Loss (Epoch): 0.085030\n",
      "Validating...\n",
      "Validation Loss: 0.373131, Validation Accuracy: 91.36%\n",
      "Learning Rate: [6.25e-06]\n",
      "Epoch 14/20\n",
      "loss: 0.118991  [   70/  644]\n",
      "loss: 0.062722  [  210/  644]\n",
      "loss: 0.047251  [  350/  644]\n",
      "loss: 0.084991  [  490/  644]\n",
      "loss: 0.105851  [  630/  644]\n",
      "Training Loss (Epoch): 0.076987\n",
      "Validating...\n",
      "Validation Loss: 0.362828, Validation Accuracy: 90.12%\n",
      "Learning Rate: [3.125e-06]\n",
      "Epoch 15/20\n",
      "loss: 0.132725  [   70/  644]\n",
      "loss: 0.027740  [  210/  644]\n",
      "loss: 0.050312  [  350/  644]\n",
      "loss: 0.045023  [  490/  644]\n",
      "loss: 0.052740  [  630/  644]\n",
      "Training Loss (Epoch): 0.069699\n",
      "Validating...\n",
      "Validation Loss: 0.360650, Validation Accuracy: 90.12%\n",
      "Learning Rate: [1.5625e-06]\n",
      "Epoch 16/20\n",
      "loss: 0.015105  [   70/  644]\n",
      "loss: 0.077687  [  210/  644]\n",
      "loss: 0.042912  [  350/  644]\n",
      "loss: 0.027906  [  490/  644]\n",
      "loss: 0.046455  [  630/  644]\n",
      "Training Loss (Epoch): 0.059375\n",
      "Validating...\n",
      "Validation Loss: 0.358964, Validation Accuracy: 90.12%\n",
      "Learning Rate: [7.8125e-07]\n",
      "Epoch 17/20\n",
      "loss: 0.081919  [   70/  644]\n",
      "loss: 0.074557  [  210/  644]\n",
      "loss: 0.120408  [  350/  644]\n",
      "loss: 0.029742  [  490/  644]\n",
      "loss: 0.055203  [  630/  644]\n",
      "Training Loss (Epoch): 0.060940\n",
      "Validating...\n",
      "Validation Loss: 0.358899, Validation Accuracy: 90.12%\n",
      "Learning Rate: [3.90625e-07]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 9\n",
      "Epoch 1/20\n",
      "loss: 2.479698  [   70/  652]\n",
      "loss: 2.140578  [  210/  652]\n",
      "loss: 1.900890  [  350/  652]\n",
      "loss: 1.710528  [  490/  652]\n",
      "loss: 1.471344  [  630/  652]\n",
      "Training Loss (Epoch): 1.847167\n",
      "Validating...\n",
      "Validation Loss: 1.790906, Validation Accuracy: 59.15%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 1.744420  [   70/  652]\n",
      "loss: 1.190415  [  210/  652]\n",
      "loss: 0.985446  [  350/  652]\n",
      "loss: 1.443796  [  490/  652]\n",
      "loss: 1.026692  [  630/  652]\n",
      "Training Loss (Epoch): 1.193103\n",
      "Validating...\n",
      "Validation Loss: 0.830565, Validation Accuracy: 73.17%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 0.662888  [   70/  652]\n",
      "loss: 0.787303  [  210/  652]\n",
      "loss: 0.746545  [  350/  652]\n",
      "loss: 0.833938  [  490/  652]\n",
      "loss: 0.656693  [  630/  652]\n",
      "Training Loss (Epoch): 0.641887\n",
      "Validating...\n",
      "Validation Loss: 0.793420, Validation Accuracy: 68.90%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 4/20\n",
      "loss: 0.467471  [   70/  652]\n",
      "loss: 0.598707  [  210/  652]\n",
      "loss: 0.391406  [  350/  652]\n",
      "loss: 0.288089  [  490/  652]\n",
      "loss: 0.439434  [  630/  652]\n",
      "Training Loss (Epoch): 0.414365\n",
      "Validating...\n",
      "Validation Loss: 0.621240, Validation Accuracy: 78.66%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 5/20\n",
      "loss: 0.552681  [   70/  652]\n",
      "loss: 0.277677  [  210/  652]\n",
      "loss: 0.304225  [  350/  652]\n",
      "loss: 0.201686  [  490/  652]\n",
      "loss: 0.353972  [  630/  652]\n",
      "Training Loss (Epoch): 0.338561\n",
      "Validating...\n",
      "Validation Loss: 0.405108, Validation Accuracy: 87.20%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 6/20\n",
      "loss: 0.253109  [   70/  652]\n",
      "loss: 0.256549  [  210/  652]\n",
      "loss: 0.189257  [  350/  652]\n",
      "loss: 0.287886  [  490/  652]\n",
      "loss: 0.285571  [  630/  652]\n",
      "Training Loss (Epoch): 0.252605\n",
      "Validating...\n",
      "Validation Loss: 0.401597, Validation Accuracy: 86.59%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 7/20\n",
      "loss: 0.137870  [   70/  652]\n",
      "loss: 0.194572  [  210/  652]\n",
      "loss: 0.168384  [  350/  652]\n",
      "loss: 0.087280  [  490/  652]\n",
      "loss: 0.177032  [  630/  652]\n",
      "Training Loss (Epoch): 0.160267\n",
      "Validating...\n",
      "Validation Loss: 0.321177, Validation Accuracy: 89.02%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 8/20\n",
      "loss: 0.153160  [   70/  652]\n",
      "loss: 0.088744  [  210/  652]\n",
      "loss: 0.079482  [  350/  652]\n",
      "loss: 0.121530  [  490/  652]\n",
      "loss: 0.135543  [  630/  652]\n",
      "Training Loss (Epoch): 0.135399\n",
      "Validating...\n",
      "Validation Loss: 0.348857, Validation Accuracy: 87.20%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 9/20\n",
      "loss: 0.073315  [   70/  652]\n",
      "loss: 0.089758  [  210/  652]\n",
      "loss: 0.056878  [  350/  652]\n",
      "loss: 0.078837  [  490/  652]\n",
      "loss: 0.116937  [  630/  652]\n",
      "Training Loss (Epoch): 0.138575\n",
      "Validating...\n",
      "Validation Loss: 0.374209, Validation Accuracy: 89.02%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 10/20\n",
      "loss: 0.059832  [   70/  652]\n",
      "loss: 0.066456  [  210/  652]\n",
      "loss: 0.102954  [  350/  652]\n",
      "loss: 0.161746  [  490/  652]\n",
      "loss: 0.033342  [  630/  652]\n",
      "Training Loss (Epoch): 0.100364\n",
      "Validating...\n",
      "Validation Loss: 0.385581, Validation Accuracy: 89.63%\n",
      "Learning Rate: [6.25e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 10\n",
      "Epoch 1/20\n",
      "loss: 2.440294  [   70/  669]\n",
      "loss: 2.148230  [  210/  669]\n",
      "loss: 1.882422  [  350/  669]\n",
      "loss: 1.805141  [  490/  669]\n",
      "loss: 1.732060  [  630/  669]\n",
      "Training Loss (Epoch): 1.991394\n",
      "Validating...\n",
      "Validation Loss: 1.823460, Validation Accuracy: 33.33%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 1.898342  [   70/  669]\n",
      "loss: 1.460206  [  210/  669]\n",
      "loss: 1.508691  [  350/  669]\n",
      "loss: 1.037912  [  490/  669]\n",
      "loss: 1.134754  [  630/  669]\n",
      "Training Loss (Epoch): 1.359245\n",
      "Validating...\n",
      "Validation Loss: 0.869103, Validation Accuracy: 67.86%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 0.806569  [   70/  669]\n",
      "loss: 0.966560  [  210/  669]\n",
      "loss: 0.747784  [  350/  669]\n",
      "loss: 0.603121  [  490/  669]\n",
      "loss: 0.719623  [  630/  669]\n",
      "Training Loss (Epoch): 0.837916\n",
      "Validating...\n",
      "Validation Loss: 0.663517, Validation Accuracy: 75.60%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/20\n",
      "loss: 0.586985  [   70/  669]\n",
      "loss: 0.446640  [  210/  669]\n",
      "loss: 0.768357  [  350/  669]\n",
      "loss: 0.801961  [  490/  669]\n",
      "loss: 0.640662  [  630/  669]\n",
      "Training Loss (Epoch): 0.737068\n",
      "Validating...\n",
      "Validation Loss: 0.658276, Validation Accuracy: 75.00%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 5/20\n",
      "loss: 0.412177  [   70/  669]\n",
      "loss: 0.527726  [  210/  669]\n",
      "loss: 0.405107  [  350/  669]\n",
      "loss: 0.468138  [  490/  669]\n",
      "loss: 0.514711  [  630/  669]\n",
      "Training Loss (Epoch): 0.509021\n",
      "Validating...\n",
      "Validation Loss: 0.423030, Validation Accuracy: 85.12%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 6/20\n",
      "loss: 0.235552  [   70/  669]\n",
      "loss: 0.485109  [  210/  669]\n",
      "loss: 0.347827  [  350/  669]\n",
      "loss: 0.540553  [  490/  669]\n",
      "loss: 0.470807  [  630/  669]\n",
      "Training Loss (Epoch): 0.399021\n",
      "Validating...\n",
      "Validation Loss: 0.384538, Validation Accuracy: 84.52%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 7/20\n",
      "loss: 0.282222  [   70/  669]\n",
      "loss: 0.264934  [  210/  669]\n",
      "loss: 0.491205  [  350/  669]\n",
      "loss: 0.301752  [  490/  669]\n",
      "loss: 0.252407  [  630/  669]\n",
      "Training Loss (Epoch): 0.311864\n",
      "Validating...\n",
      "Validation Loss: 0.369611, Validation Accuracy: 88.10%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 8/20\n",
      "loss: 0.354874  [   70/  669]\n",
      "loss: 0.317537  [  210/  669]\n",
      "loss: 0.257571  [  350/  669]\n",
      "loss: 0.253791  [  490/  669]\n",
      "loss: 0.426099  [  630/  669]\n",
      "Training Loss (Epoch): 0.262359\n",
      "Validating...\n",
      "Validation Loss: 0.326910, Validation Accuracy: 88.69%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 9/20\n",
      "loss: 0.195923  [   70/  669]\n",
      "loss: 0.257076  [  210/  669]\n",
      "loss: 0.224965  [  350/  669]\n",
      "loss: 0.295092  [  490/  669]\n",
      "loss: 0.287805  [  630/  669]\n",
      "Training Loss (Epoch): 0.224760\n",
      "Validating...\n",
      "Validation Loss: 0.297787, Validation Accuracy: 89.29%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 10/20\n",
      "loss: 0.221424  [   70/  669]\n",
      "loss: 0.238688  [  210/  669]\n",
      "loss: 0.163687  [  350/  669]\n",
      "loss: 0.131623  [  490/  669]\n",
      "loss: 0.297004  [  630/  669]\n",
      "Training Loss (Epoch): 0.199839\n",
      "Validating...\n",
      "Validation Loss: 0.308721, Validation Accuracy: 91.07%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 11/20\n",
      "loss: 0.241922  [   70/  669]\n",
      "loss: 0.244473  [  210/  669]\n",
      "loss: 0.109332  [  350/  669]\n",
      "loss: 0.169325  [  490/  669]\n",
      "loss: 0.158623  [  630/  669]\n",
      "Training Loss (Epoch): 0.194971\n",
      "Validating...\n",
      "Validation Loss: 0.311330, Validation Accuracy: 91.67%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 12/20\n",
      "loss: 0.185058  [   70/  669]\n",
      "loss: 0.258302  [  210/  669]\n",
      "loss: 0.101724  [  350/  669]\n",
      "loss: 0.182745  [  490/  669]\n",
      "loss: 0.094868  [  630/  669]\n",
      "Training Loss (Epoch): 0.166177\n",
      "Validating...\n",
      "Validation Loss: 0.322125, Validation Accuracy: 91.67%\n",
      "Learning Rate: [6.25e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "\n",
      "Cross-Validation Results:\n",
      "Avg Training Loss: 0.476954\n",
      "Avg Validation Loss: 0.659312\n",
      "Avg Validation Accuracy: 80.01%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dense_tune(layer = 1, lr = 2e-4, weight_decay = 0.2, weights = \"DEFAULT\", drop = 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1\n",
      "Epoch 1/20\n",
      "loss: 2.345630  [   70/  698]\n",
      "loss: 2.072950  [  210/  698]\n",
      "loss: 1.931110  [  350/  698]\n",
      "loss: 1.737942  [  490/  698]\n",
      "loss: 1.688270  [  630/  698]\n",
      "Training Loss (Epoch): 1.961481\n",
      "Validating...\n",
      "Validation Loss: 1.915651, Validation Accuracy: 45.71%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 1.853691  [   70/  698]\n",
      "loss: 1.421431  [  210/  698]\n",
      "loss: 1.291020  [  350/  698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.214056  [  490/  698]\n",
      "loss: 0.979030  [  630/  698]\n",
      "Training Loss (Epoch): 1.236584\n",
      "Validating...\n",
      "Validation Loss: 0.795196, Validation Accuracy: 71.43%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 0.723062  [   70/  698]\n",
      "loss: 0.591281  [  210/  698]\n",
      "loss: 0.678622  [  350/  698]\n",
      "loss: 0.348995  [  490/  698]\n",
      "loss: 0.502151  [  630/  698]\n",
      "Training Loss (Epoch): 0.601294\n",
      "Validating...\n",
      "Validation Loss: 0.526140, Validation Accuracy: 80.00%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/20\n",
      "loss: 0.420100  [   70/  698]\n",
      "loss: 0.451533  [  210/  698]\n",
      "loss: 0.253627  [  350/  698]\n",
      "loss: 0.374431  [  490/  698]\n",
      "loss: 0.278992  [  630/  698]\n",
      "Training Loss (Epoch): 0.320396\n",
      "Validating...\n",
      "Validation Loss: 0.447303, Validation Accuracy: 84.00%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/20\n",
      "loss: 0.195092  [   70/  698]\n",
      "loss: 0.275549  [  210/  698]\n",
      "loss: 0.486779  [  350/  698]\n",
      "loss: 0.291594  [  490/  698]\n",
      "loss: 0.569473  [  630/  698]\n",
      "Training Loss (Epoch): 0.286737\n",
      "Validating...\n",
      "Validation Loss: 0.508612, Validation Accuracy: 85.71%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/20\n",
      "loss: 0.256609  [   70/  698]\n",
      "loss: 0.164923  [  210/  698]\n",
      "loss: 0.114419  [  350/  698]\n",
      "loss: 0.294936  [  490/  698]\n",
      "loss: 0.240753  [  630/  698]\n",
      "Training Loss (Epoch): 0.217071\n",
      "Validating...\n",
      "Validation Loss: 0.312452, Validation Accuracy: 89.71%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 7/20\n",
      "loss: 0.109531  [   70/  698]\n",
      "loss: 0.106252  [  210/  698]\n",
      "loss: 0.074986  [  350/  698]\n",
      "loss: 0.133151  [  490/  698]\n",
      "loss: 0.145907  [  630/  698]\n",
      "Training Loss (Epoch): 0.119242\n",
      "Validating...\n",
      "Validation Loss: 0.405386, Validation Accuracy: 87.43%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 8/20\n",
      "loss: 0.181012  [   70/  698]\n",
      "loss: 0.088184  [  210/  698]\n",
      "loss: 0.060552  [  350/  698]\n",
      "loss: 0.166065  [  490/  698]\n",
      "loss: 0.011978  [  630/  698]\n",
      "Training Loss (Epoch): 0.092468\n",
      "Validating...\n",
      "Validation Loss: 0.309561, Validation Accuracy: 90.86%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 9/20\n",
      "loss: 0.008821  [   70/  698]\n",
      "loss: 0.032824  [  210/  698]\n",
      "loss: 0.066907  [  350/  698]\n",
      "loss: 0.089139  [  490/  698]\n",
      "loss: 0.064144  [  630/  698]\n",
      "Training Loss (Epoch): 0.060785\n",
      "Validating...\n",
      "Validation Loss: 0.357368, Validation Accuracy: 90.29%\n",
      "Learning Rate: [5e-05]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 2\n",
      "Epoch 1/20\n",
      "loss: 2.274845  [   70/  710]\n",
      "loss: 2.157304  [  210/  710]\n",
      "loss: 1.940256  [  350/  710]\n",
      "loss: 1.834673  [  490/  710]\n",
      "loss: 1.482588  [  630/  710]\n",
      "loss: 1.931968  [  110/  710]\n",
      "Training Loss (Epoch): 1.869303\n",
      "Validating...\n",
      "Validation Loss: 1.828345, Validation Accuracy: 42.13%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 1.775449  [   70/  710]\n",
      "loss: 1.450797  [  210/  710]\n",
      "loss: 1.284838  [  350/  710]\n",
      "loss: 1.141788  [  490/  710]\n",
      "loss: 1.170380  [  630/  710]\n",
      "loss: 0.802664  [  110/  710]\n",
      "Training Loss (Epoch): 1.216372\n",
      "Validating...\n",
      "Validation Loss: 0.969784, Validation Accuracy: 65.17%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 0.806528  [   70/  710]\n",
      "loss: 0.607459  [  210/  710]\n",
      "loss: 0.858519  [  350/  710]\n",
      "loss: 0.654489  [  490/  710]\n",
      "loss: 0.563488  [  630/  710]\n",
      "loss: 0.945814  [  110/  710]\n",
      "Training Loss (Epoch): 0.728510\n",
      "Validating...\n",
      "Validation Loss: 0.824399, Validation Accuracy: 73.03%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/20\n",
      "loss: 0.622662  [   70/  710]\n",
      "loss: 0.844499  [  210/  710]\n",
      "loss: 0.550927  [  350/  710]\n",
      "loss: 0.741503  [  490/  710]\n",
      "loss: 0.480350  [  630/  710]\n",
      "loss: 0.350337  [  110/  710]\n",
      "Training Loss (Epoch): 0.611327\n",
      "Validating...\n",
      "Validation Loss: 0.564739, Validation Accuracy: 84.83%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/20\n",
      "loss: 0.269148  [   70/  710]\n",
      "loss: 0.389089  [  210/  710]\n",
      "loss: 0.199783  [  350/  710]\n",
      "loss: 0.186271  [  490/  710]\n",
      "loss: 0.303269  [  630/  710]\n",
      "loss: 0.467772  [  110/  710]\n",
      "Training Loss (Epoch): 0.300236\n",
      "Validating...\n",
      "Validation Loss: 1.168494, Validation Accuracy: 73.03%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 6/20\n",
      "loss: 0.833490  [   70/  710]\n",
      "loss: 0.420265  [  210/  710]\n",
      "loss: 0.173857  [  350/  710]\n",
      "loss: 0.293903  [  490/  710]\n",
      "loss: 0.264144  [  630/  710]\n",
      "loss: 0.073867  [  110/  710]\n",
      "Training Loss (Epoch): 0.345124\n",
      "Validating...\n",
      "Validation Loss: 0.542928, Validation Accuracy: 83.71%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 7/20\n",
      "loss: 0.190592  [   70/  710]\n",
      "loss: 0.195694  [  210/  710]\n",
      "loss: 0.183333  [  350/  710]\n",
      "loss: 0.167840  [  490/  710]\n",
      "loss: 0.108874  [  630/  710]\n",
      "loss: 0.041881  [  110/  710]\n",
      "Training Loss (Epoch): 0.158275\n",
      "Validating...\n",
      "Validation Loss: 0.479446, Validation Accuracy: 87.64%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 8/20\n",
      "loss: 0.146544  [   70/  710]\n",
      "loss: 0.100056  [  210/  710]\n",
      "loss: 0.033559  [  350/  710]\n",
      "loss: 0.142275  [  490/  710]\n",
      "loss: 0.062831  [  630/  710]\n",
      "loss: 0.235095  [  110/  710]\n",
      "Training Loss (Epoch): 0.120070\n",
      "Validating...\n",
      "Validation Loss: 0.463740, Validation Accuracy: 88.76%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 9/20\n",
      "loss: 0.045034  [   70/  710]\n",
      "loss: 0.098484  [  210/  710]\n",
      "loss: 0.189290  [  350/  710]\n",
      "loss: 0.149525  [  490/  710]\n",
      "loss: 0.085339  [  630/  710]\n",
      "loss: 0.021029  [  110/  710]\n",
      "Training Loss (Epoch): 0.092036\n",
      "Validating...\n",
      "Validation Loss: 0.597802, Validation Accuracy: 88.20%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 10/20\n",
      "loss: 0.036303  [   70/  710]\n",
      "loss: 0.122654  [  210/  710]\n",
      "loss: 0.135814  [  350/  710]\n",
      "loss: 0.059634  [  490/  710]\n",
      "loss: 0.021068  [  630/  710]\n",
      "loss: 0.000955  [  110/  710]\n",
      "Training Loss (Epoch): 0.071386\n",
      "Validating...\n",
      "Validation Loss: 0.540587, Validation Accuracy: 88.20%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 11/20\n",
      "loss: 0.090608  [   70/  710]\n",
      "loss: 0.084096  [  210/  710]\n",
      "loss: 0.031413  [  350/  710]\n",
      "loss: 0.116739  [  490/  710]\n",
      "loss: 0.034614  [  630/  710]\n",
      "loss: 0.000995  [  110/  710]\n",
      "Training Loss (Epoch): 0.057459\n",
      "Validating...\n",
      "Validation Loss: 0.534133, Validation Accuracy: 87.64%\n",
      "Learning Rate: [6.25e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 3\n",
      "Epoch 1/20\n",
      "loss: 2.423446  [   70/  740]\n",
      "loss: 2.182137  [  210/  740]\n",
      "loss: 1.938198  [  350/  740]\n",
      "loss: 1.703753  [  490/  740]\n",
      "loss: 1.697320  [  630/  740]\n",
      "loss: 1.456633  [  440/  740]\n",
      "Training Loss (Epoch): 1.932799\n",
      "Validating...\n",
      "Validation Loss: 1.833733, Validation Accuracy: 44.32%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 1.654343  [   70/  740]\n",
      "loss: 1.216550  [  210/  740]\n",
      "loss: 1.143372  [  350/  740]\n",
      "loss: 1.264220  [  490/  740]\n",
      "loss: 1.079624  [  630/  740]\n",
      "loss: 0.944290  [  440/  740]\n",
      "Training Loss (Epoch): 1.221526\n",
      "Validating...\n",
      "Validation Loss: 1.008902, Validation Accuracy: 63.78%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 0.864308  [   70/  740]\n",
      "loss: 0.741384  [  210/  740]\n",
      "loss: 0.860658  [  350/  740]\n",
      "loss: 0.516580  [  490/  740]\n",
      "loss: 0.745712  [  630/  740]\n",
      "loss: 0.670101  [  440/  740]\n",
      "Training Loss (Epoch): 0.698054\n",
      "Validating...\n",
      "Validation Loss: 0.810241, Validation Accuracy: 72.43%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/20\n",
      "loss: 0.535996  [   70/  740]\n",
      "loss: 0.449271  [  210/  740]\n",
      "loss: 0.444833  [  350/  740]\n",
      "loss: 0.434205  [  490/  740]\n",
      "loss: 0.363752  [  630/  740]\n",
      "loss: 0.500925  [  440/  740]\n",
      "Training Loss (Epoch): 0.428160\n",
      "Validating...\n",
      "Validation Loss: 0.482745, Validation Accuracy: 82.70%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/20\n",
      "loss: 0.229331  [   70/  740]\n",
      "loss: 0.176856  [  210/  740]\n",
      "loss: 0.184129  [  350/  740]\n",
      "loss: 0.315564  [  490/  740]\n",
      "loss: 0.483223  [  630/  740]\n",
      "loss: 0.122551  [  440/  740]\n",
      "Training Loss (Epoch): 0.287441\n",
      "Validating...\n",
      "Validation Loss: 0.875353, Validation Accuracy: 73.51%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 6/20\n",
      "loss: 0.356680  [   70/  740]\n",
      "loss: 0.409202  [  210/  740]\n",
      "loss: 0.217738  [  350/  740]\n",
      "loss: 0.183146  [  490/  740]\n",
      "loss: 0.270238  [  630/  740]\n",
      "loss: 0.341675  [  440/  740]\n",
      "Training Loss (Epoch): 0.278980\n",
      "Validating...\n",
      "Validation Loss: 0.514940, Validation Accuracy: 82.16%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 7/20\n",
      "loss: 0.186608  [   70/  740]\n",
      "loss: 0.200878  [  210/  740]\n",
      "loss: 0.206989  [  350/  740]\n",
      "loss: 0.247018  [  490/  740]\n",
      "loss: 0.159344  [  630/  740]\n",
      "loss: 0.070856  [  440/  740]\n",
      "Training Loss (Epoch): 0.189401\n",
      "Validating...\n",
      "Validation Loss: 0.329217, Validation Accuracy: 88.65%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 8/20\n",
      "loss: 0.155417  [   70/  740]\n",
      "loss: 0.311122  [  210/  740]\n",
      "loss: 0.133608  [  350/  740]\n",
      "loss: 0.141300  [  490/  740]\n",
      "loss: 0.098778  [  630/  740]\n",
      "loss: 0.120468  [  440/  740]\n",
      "Training Loss (Epoch): 0.130842\n",
      "Validating...\n",
      "Validation Loss: 0.268533, Validation Accuracy: 90.27%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 9/20\n",
      "loss: 0.056883  [   70/  740]\n",
      "loss: 0.092484  [  210/  740]\n",
      "loss: 0.126676  [  350/  740]\n",
      "loss: 0.066497  [  490/  740]\n",
      "loss: 0.065743  [  630/  740]\n",
      "loss: 0.052563  [  440/  740]\n",
      "Training Loss (Epoch): 0.082556\n",
      "Validating...\n",
      "Validation Loss: 0.306806, Validation Accuracy: 89.73%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 10/20\n",
      "loss: 0.078326  [   70/  740]\n",
      "loss: 0.030177  [  210/  740]\n",
      "loss: 0.073285  [  350/  740]\n",
      "loss: 0.016731  [  490/  740]\n",
      "loss: 0.041120  [  630/  740]\n",
      "loss: 0.002238  [  440/  740]\n",
      "Training Loss (Epoch): 0.065445\n",
      "Validating...\n",
      "Validation Loss: 0.280262, Validation Accuracy: 88.11%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 11/20\n",
      "loss: 0.076281  [   70/  740]\n",
      "loss: 0.017949  [  210/  740]\n",
      "loss: 0.036417  [  350/  740]\n",
      "loss: 0.062012  [  490/  740]\n",
      "loss: 0.009832  [  630/  740]\n",
      "loss: 0.039483  [  440/  740]\n",
      "Training Loss (Epoch): 0.054013\n",
      "Validating...\n",
      "Validation Loss: 0.245112, Validation Accuracy: 91.89%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 12/20\n",
      "loss: 0.032978  [   70/  740]\n",
      "loss: 0.018670  [  210/  740]\n",
      "loss: 0.054551  [  350/  740]\n",
      "loss: 0.005421  [  490/  740]\n",
      "loss: 0.063824  [  630/  740]\n",
      "loss: 0.069969  [  440/  740]\n",
      "Training Loss (Epoch): 0.053807\n",
      "Validating...\n",
      "Validation Loss: 0.247118, Validation Accuracy: 92.43%\n",
      "Learning Rate: [6.25e-06]\n",
      "Epoch 13/20\n",
      "loss: 0.035260  [   70/  740]\n",
      "loss: 0.101530  [  210/  740]\n",
      "loss: 0.032541  [  350/  740]\n",
      "loss: 0.028919  [  490/  740]\n",
      "loss: 0.011688  [  630/  740]\n",
      "loss: 0.102975  [  440/  740]\n",
      "Training Loss (Epoch): 0.044067\n",
      "Validating...\n",
      "Validation Loss: 0.245711, Validation Accuracy: 92.43%\n",
      "Learning Rate: [3.125e-06]\n",
      "Epoch 14/20\n",
      "loss: 0.076435  [   70/  740]\n",
      "loss: 0.050377  [  210/  740]\n",
      "loss: 0.040904  [  350/  740]\n",
      "loss: 0.026253  [  490/  740]\n",
      "loss: 0.042104  [  630/  740]\n",
      "loss: 0.005246  [  440/  740]\n",
      "Training Loss (Epoch): 0.042251\n",
      "Validating...\n",
      "Validation Loss: 0.241909, Validation Accuracy: 91.89%\n",
      "Learning Rate: [1.5625e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 4\n",
      "Epoch 1/20\n",
      "loss: 2.310130  [   70/  792]\n",
      "loss: 2.100086  [  210/  792]\n",
      "loss: 2.086617  [  350/  792]\n",
      "loss: 1.861007  [  490/  792]\n",
      "loss: 1.859653  [  630/  792]\n",
      "loss: 1.834986  [  770/  792]\n",
      "Training Loss (Epoch): 2.002502\n",
      "Validating...\n",
      "Validation Loss: 1.690137, Validation Accuracy: 49.49%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 1.688105  [   70/  792]\n",
      "loss: 1.465344  [  210/  792]\n",
      "loss: 1.217973  [  350/  792]\n",
      "loss: 0.979571  [  490/  792]\n",
      "loss: 1.064186  [  630/  792]\n",
      "loss: 0.958214  [  770/  792]\n",
      "Training Loss (Epoch): 1.224202\n",
      "Validating...\n",
      "Validation Loss: 0.838281, Validation Accuracy: 75.25%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 0.817116  [   70/  792]\n",
      "loss: 0.693026  [  210/  792]\n",
      "loss: 0.655577  [  350/  792]\n",
      "loss: 0.699712  [  490/  792]\n",
      "loss: 0.744760  [  630/  792]\n",
      "loss: 0.744071  [  770/  792]\n",
      "Training Loss (Epoch): 0.715447\n",
      "Validating...\n",
      "Validation Loss: 0.637219, Validation Accuracy: 81.31%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/20\n",
      "loss: 0.446018  [   70/  792]\n",
      "loss: 0.464783  [  210/  792]\n",
      "loss: 0.466707  [  350/  792]\n",
      "loss: 0.328482  [  490/  792]\n",
      "loss: 0.643487  [  630/  792]\n",
      "loss: 0.517631  [  770/  792]\n",
      "Training Loss (Epoch): 0.485671\n",
      "Validating...\n",
      "Validation Loss: 0.494757, Validation Accuracy: 84.34%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/20\n",
      "loss: 0.376919  [   70/  792]\n",
      "loss: 0.323447  [  210/  792]\n",
      "loss: 0.363038  [  350/  792]\n",
      "loss: 0.508012  [  490/  792]\n",
      "loss: 0.374534  [  630/  792]\n",
      "loss: 0.250508  [  770/  792]\n",
      "Training Loss (Epoch): 0.316004\n",
      "Validating...\n",
      "Validation Loss: 0.557248, Validation Accuracy: 80.81%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 6/20\n",
      "loss: 0.220455  [   70/  792]\n",
      "loss: 0.181000  [  210/  792]\n",
      "loss: 0.272352  [  350/  792]\n",
      "loss: 0.160520  [  490/  792]\n",
      "loss: 0.204938  [  630/  792]\n",
      "loss: 0.095366  [  770/  792]\n",
      "Training Loss (Epoch): 0.177041\n",
      "Validating...\n",
      "Validation Loss: 0.459425, Validation Accuracy: 87.88%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 7/20\n",
      "loss: 0.118359  [   70/  792]\n",
      "loss: 0.148418  [  210/  792]\n",
      "loss: 0.058855  [  350/  792]\n",
      "loss: 0.012438  [  490/  792]\n",
      "loss: 0.123366  [  630/  792]\n",
      "loss: 0.114018  [  770/  792]\n",
      "Training Loss (Epoch): 0.113774\n",
      "Validating...\n",
      "Validation Loss: 0.568207, Validation Accuracy: 88.89%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 8/20\n",
      "loss: 0.070734  [   70/  792]\n",
      "loss: 0.078298  [  210/  792]\n",
      "loss: 0.049046  [  350/  792]\n",
      "loss: 0.038779  [  490/  792]\n",
      "loss: 0.070438  [  630/  792]\n",
      "loss: 0.118602  [  770/  792]\n",
      "Training Loss (Epoch): 0.073279\n",
      "Validating...\n",
      "Validation Loss: 0.410972, Validation Accuracy: 90.40%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 9/20\n",
      "loss: 0.049814  [   70/  792]\n",
      "loss: 0.074240  [  210/  792]\n",
      "loss: 0.027415  [  350/  792]\n",
      "loss: 0.044714  [  490/  792]\n",
      "loss: 0.053215  [  630/  792]\n",
      "loss: 0.099931  [  770/  792]\n",
      "Training Loss (Epoch): 0.054949\n",
      "Validating...\n",
      "Validation Loss: 0.452255, Validation Accuracy: 89.39%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 10/20\n",
      "loss: 0.063707  [   70/  792]\n",
      "loss: 0.012698  [  210/  792]\n",
      "loss: 0.056132  [  350/  792]\n",
      "loss: 0.007622  [  490/  792]\n",
      "loss: 0.007435  [  630/  792]\n",
      "loss: 0.040294  [  770/  792]\n",
      "Training Loss (Epoch): 0.046527\n",
      "Validating...\n",
      "Validation Loss: 0.502462, Validation Accuracy: 88.89%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 11/20\n",
      "loss: 0.005414  [   70/  792]\n",
      "loss: 0.005442  [  210/  792]\n",
      "loss: 0.020194  [  350/  792]\n",
      "loss: 0.023758  [  490/  792]\n",
      "loss: 0.029896  [  630/  792]\n",
      "loss: 0.023317  [  770/  792]\n",
      "Training Loss (Epoch): 0.029196\n",
      "Validating...\n",
      "Validation Loss: 0.461636, Validation Accuracy: 91.92%\n",
      "Learning Rate: [2.5e-05]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 5\n",
      "Epoch 1/20\n",
      "loss: 2.264281  [   70/  748]\n",
      "loss: 2.127042  [  210/  748]\n",
      "loss: 2.067611  [  350/  748]\n",
      "loss: 1.769653  [  490/  748]\n",
      "loss: 1.735438  [  630/  748]\n",
      "loss: 1.410758  [  528/  748]\n",
      "Training Loss (Epoch): 1.930608\n",
      "Validating...\n",
      "Validation Loss: 1.898049, Validation Accuracy: 44.68%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 1.786197  [   70/  748]\n",
      "loss: 1.309385  [  210/  748]\n",
      "loss: 1.421043  [  350/  748]\n",
      "loss: 0.899878  [  490/  748]\n",
      "loss: 1.035450  [  630/  748]\n",
      "loss: 0.542739  [  528/  748]\n",
      "Training Loss (Epoch): 1.126218\n",
      "Validating...\n",
      "Validation Loss: 1.142996, Validation Accuracy: 61.17%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 0.691461  [   70/  748]\n",
      "loss: 0.605079  [  210/  748]\n",
      "loss: 0.638987  [  350/  748]\n",
      "loss: 0.778234  [  490/  748]\n",
      "loss: 0.810799  [  630/  748]\n",
      "loss: 0.676483  [  528/  748]\n",
      "Training Loss (Epoch): 0.701062\n",
      "Validating...\n",
      "Validation Loss: 0.916600, Validation Accuracy: 66.49%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/20\n",
      "loss: 0.514024  [   70/  748]\n",
      "loss: 0.376320  [  210/  748]\n",
      "loss: 0.386228  [  350/  748]\n",
      "loss: 0.343928  [  490/  748]\n",
      "loss: 0.715170  [  630/  748]\n",
      "loss: 0.615975  [  528/  748]\n",
      "Training Loss (Epoch): 0.592077\n",
      "Validating...\n",
      "Validation Loss: 0.831813, Validation Accuracy: 70.74%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/20\n",
      "loss: 0.544546  [   70/  748]\n",
      "loss: 0.311833  [  210/  748]\n",
      "loss: 0.280743  [  350/  748]\n",
      "loss: 0.401545  [  490/  748]\n",
      "loss: 0.350033  [  630/  748]\n",
      "loss: 0.450683  [  528/  748]\n",
      "Training Loss (Epoch): 0.395623\n",
      "Validating...\n",
      "Validation Loss: 1.204579, Validation Accuracy: 67.55%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 6/20\n",
      "loss: 0.393151  [   70/  748]\n",
      "loss: 0.241054  [  210/  748]\n",
      "loss: 0.282008  [  350/  748]\n",
      "loss: 0.310550  [  490/  748]\n",
      "loss: 0.158620  [  630/  748]\n",
      "loss: 0.349383  [  528/  748]\n",
      "Training Loss (Epoch): 0.278948\n",
      "Validating...\n",
      "Validation Loss: 0.694283, Validation Accuracy: 81.38%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 7/20\n",
      "loss: 0.289757  [   70/  748]\n",
      "loss: 0.119749  [  210/  748]\n",
      "loss: 0.142830  [  350/  748]\n",
      "loss: 0.112564  [  490/  748]\n",
      "loss: 0.081845  [  630/  748]\n",
      "loss: 0.153454  [  528/  748]\n",
      "Training Loss (Epoch): 0.166112\n",
      "Validating...\n",
      "Validation Loss: 0.626940, Validation Accuracy: 81.91%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 8/20\n",
      "loss: 0.147263  [   70/  748]\n",
      "loss: 0.045779  [  210/  748]\n",
      "loss: 0.107139  [  350/  748]\n",
      "loss: 0.143039  [  490/  748]\n",
      "loss: 0.116242  [  630/  748]\n",
      "loss: 0.046741  [  528/  748]\n",
      "Training Loss (Epoch): 0.101686\n",
      "Validating...\n",
      "Validation Loss: 0.519074, Validation Accuracy: 85.64%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 9/20\n",
      "loss: 0.044338  [   70/  748]\n",
      "loss: 0.226209  [  210/  748]\n",
      "loss: 0.086537  [  350/  748]\n",
      "loss: 0.270668  [  490/  748]\n",
      "loss: 0.051063  [  630/  748]\n",
      "loss: 0.039061  [  528/  748]\n",
      "Training Loss (Epoch): 0.100285\n",
      "Validating...\n",
      "Validation Loss: 0.558264, Validation Accuracy: 83.51%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 10/20\n",
      "loss: 0.042948  [   70/  748]\n",
      "loss: 0.004897  [  210/  748]\n",
      "loss: 0.051731  [  350/  748]\n",
      "loss: 0.031712  [  490/  748]\n",
      "loss: 0.077376  [  630/  748]\n",
      "loss: 0.033006  [  528/  748]\n",
      "Training Loss (Epoch): 0.077090\n",
      "Validating...\n",
      "Validation Loss: 0.489184, Validation Accuracy: 85.64%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 11/20\n",
      "loss: 0.056200  [   70/  748]\n",
      "loss: 0.040301  [  210/  748]\n",
      "loss: 0.078562  [  350/  748]\n",
      "loss: 0.058243  [  490/  748]\n",
      "loss: 0.126647  [  630/  748]\n",
      "loss: 0.065283  [  528/  748]\n",
      "Training Loss (Epoch): 0.064169\n",
      "Validating...\n",
      "Validation Loss: 0.481539, Validation Accuracy: 86.17%\n",
      "Learning Rate: [6.25e-06]\n",
      "Epoch 12/20\n",
      "loss: 0.090578  [   70/  748]\n",
      "loss: 0.097677  [  210/  748]\n",
      "loss: 0.034754  [  350/  748]\n",
      "loss: 0.053839  [  490/  748]\n",
      "loss: 0.046173  [  630/  748]\n",
      "loss: 0.048544  [  528/  748]\n",
      "Training Loss (Epoch): 0.051091\n",
      "Validating...\n",
      "Validation Loss: 0.487515, Validation Accuracy: 86.17%\n",
      "Learning Rate: [3.125e-06]\n",
      "Epoch 13/20\n",
      "loss: 0.049488  [   70/  748]\n",
      "loss: 0.056308  [  210/  748]\n",
      "loss: 0.061111  [  350/  748]\n",
      "loss: 0.050999  [  490/  748]\n",
      "loss: 0.035523  [  630/  748]\n",
      "loss: 0.016981  [  528/  748]\n",
      "Training Loss (Epoch): 0.049563\n",
      "Validating...\n",
      "Validation Loss: 0.493452, Validation Accuracy: 85.11%\n",
      "Learning Rate: [1.5625e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 6\n",
      "Epoch 1/20\n",
      "loss: 2.333571  [   70/  658]\n",
      "loss: 2.205270  [  210/  658]\n",
      "loss: 2.123694  [  350/  658]\n",
      "loss: 1.808523  [  490/  658]\n",
      "loss: 1.724280  [  630/  658]\n",
      "Training Loss (Epoch): 2.018098\n",
      "Validating...\n",
      "Validation Loss: 1.981885, Validation Accuracy: 38.18%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 1.945151  [   70/  658]\n",
      "loss: 1.368438  [  210/  658]\n",
      "loss: 1.330151  [  350/  658]\n",
      "loss: 1.270590  [  490/  658]\n",
      "loss: 1.037430  [  630/  658]\n",
      "Training Loss (Epoch): 1.281500\n",
      "Validating...\n",
      "Validation Loss: 1.073775, Validation Accuracy: 56.97%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 0.741967  [   70/  658]\n",
      "loss: 0.763775  [  210/  658]\n",
      "loss: 0.826481  [  350/  658]\n",
      "loss: 0.764960  [  490/  658]\n",
      "loss: 0.767882  [  630/  658]\n",
      "Training Loss (Epoch): 0.844992\n",
      "Validating...\n",
      "Validation Loss: 0.724489, Validation Accuracy: 72.73%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/20\n",
      "loss: 0.488683  [   70/  658]\n",
      "loss: 0.785901  [  210/  658]\n",
      "loss: 0.528442  [  350/  658]\n",
      "loss: 0.481457  [  490/  658]\n",
      "loss: 0.374305  [  630/  658]\n",
      "Training Loss (Epoch): 0.582550\n",
      "Validating...\n",
      "Validation Loss: 0.544556, Validation Accuracy: 83.03%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/20\n",
      "loss: 0.279261  [   70/  658]\n",
      "loss: 0.499366  [  210/  658]\n",
      "loss: 0.247389  [  350/  658]\n",
      "loss: 0.360378  [  490/  658]\n",
      "loss: 0.419042  [  630/  658]\n",
      "Training Loss (Epoch): 0.357841\n",
      "Validating...\n",
      "Validation Loss: 0.769936, Validation Accuracy: 77.58%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 6/20\n",
      "loss: 0.283289  [   70/  658]\n",
      "loss: 0.147160  [  210/  658]\n",
      "loss: 0.218490  [  350/  658]\n",
      "loss: 0.213806  [  490/  658]\n",
      "loss: 0.267160  [  630/  658]\n",
      "Training Loss (Epoch): 0.242647\n",
      "Validating...\n",
      "Validation Loss: 0.520830, Validation Accuracy: 84.24%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 7/20\n",
      "loss: 0.088729  [   70/  658]\n",
      "loss: 0.252723  [  210/  658]\n",
      "loss: 0.119588  [  350/  658]\n",
      "loss: 0.054083  [  490/  658]\n",
      "loss: 0.213411  [  630/  658]\n",
      "Training Loss (Epoch): 0.189936\n",
      "Validating...\n",
      "Validation Loss: 0.465520, Validation Accuracy: 88.48%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 8/20\n",
      "loss: 0.198622  [   70/  658]\n",
      "loss: 0.184043  [  210/  658]\n",
      "loss: 0.153077  [  350/  658]\n",
      "loss: 0.174973  [  490/  658]\n",
      "loss: 0.270052  [  630/  658]\n",
      "Training Loss (Epoch): 0.161411\n",
      "Validating...\n",
      "Validation Loss: 0.378946, Validation Accuracy: 87.27%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 9/20\n",
      "loss: 0.058915  [   70/  658]\n",
      "loss: 0.124989  [  210/  658]\n",
      "loss: 0.126510  [  350/  658]\n",
      "loss: 0.035651  [  490/  658]\n",
      "loss: 0.198908  [  630/  658]\n",
      "Training Loss (Epoch): 0.114160\n",
      "Validating...\n",
      "Validation Loss: 0.393360, Validation Accuracy: 90.30%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 10/20\n",
      "loss: 0.035675  [   70/  658]\n",
      "loss: 0.089909  [  210/  658]\n",
      "loss: 0.137782  [  350/  658]\n",
      "loss: 0.133444  [  490/  658]\n",
      "loss: 0.111632  [  630/  658]\n",
      "Training Loss (Epoch): 0.091467\n",
      "Validating...\n",
      "Validation Loss: 0.415939, Validation Accuracy: 89.09%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 11/20\n",
      "loss: 0.111784  [   70/  658]\n",
      "loss: 0.027010  [  210/  658]\n",
      "loss: 0.045673  [  350/  658]\n",
      "loss: 0.099068  [  490/  658]\n",
      "loss: 0.030780  [  630/  658]\n",
      "Training Loss (Epoch): 0.075594\n",
      "Validating...\n",
      "Validation Loss: 0.381752, Validation Accuracy: 90.91%\n",
      "Learning Rate: [1.25e-05]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 7\n",
      "Epoch 1/20\n",
      "loss: 2.293022  [   70/  670]\n",
      "loss: 2.167268  [  210/  670]\n",
      "loss: 1.950766  [  350/  670]\n",
      "loss: 1.631973  [  490/  670]\n",
      "loss: 1.537465  [  630/  670]\n",
      "Training Loss (Epoch): 1.885999\n",
      "Validating...\n",
      "Validation Loss: 1.908317, Validation Accuracy: 44.64%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 1.925927  [   70/  670]\n",
      "loss: 1.339075  [  210/  670]\n",
      "loss: 0.922548  [  350/  670]\n",
      "loss: 1.195967  [  490/  670]\n",
      "loss: 1.478605  [  630/  670]\n",
      "Training Loss (Epoch): 1.356863\n",
      "Validating...\n",
      "Validation Loss: 1.417858, Validation Accuracy: 55.36%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 1.133997  [   70/  670]\n",
      "loss: 0.887578  [  210/  670]\n",
      "loss: 0.778141  [  350/  670]\n",
      "loss: 0.729529  [  490/  670]\n",
      "loss: 0.809882  [  630/  670]\n",
      "Training Loss (Epoch): 0.839011\n",
      "Validating...\n",
      "Validation Loss: 1.146758, Validation Accuracy: 66.07%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/20\n",
      "loss: 0.603728  [   70/  670]\n",
      "loss: 0.835981  [  210/  670]\n",
      "loss: 0.918774  [  350/  670]\n",
      "loss: 0.998323  [  490/  670]\n",
      "loss: 0.711728  [  630/  670]\n",
      "Training Loss (Epoch): 0.822806\n",
      "Validating...\n",
      "Validation Loss: 1.005793, Validation Accuracy: 72.62%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/20\n",
      "loss: 0.549913  [   70/  670]\n",
      "loss: 0.756637  [  210/  670]\n",
      "loss: 0.396992  [  350/  670]\n",
      "loss: 0.533568  [  490/  670]\n",
      "loss: 0.471980  [  630/  670]\n",
      "Training Loss (Epoch): 0.496364\n",
      "Validating...\n",
      "Validation Loss: 0.749915, Validation Accuracy: 80.36%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/20\n",
      "loss: 0.436174  [   70/  670]\n",
      "loss: 0.195748  [  210/  670]\n",
      "loss: 0.374917  [  350/  670]\n",
      "loss: 0.388021  [  490/  670]\n",
      "loss: 0.682239  [  630/  670]\n",
      "Training Loss (Epoch): 0.378035\n",
      "Validating...\n",
      "Validation Loss: 0.989125, Validation Accuracy: 68.45%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 7/20\n",
      "loss: 0.858106  [   70/  670]\n",
      "loss: 0.310293  [  210/  670]\n",
      "loss: 0.155344  [  350/  670]\n",
      "loss: 0.339825  [  490/  670]\n",
      "loss: 0.381977  [  630/  670]\n",
      "Training Loss (Epoch): 0.392005\n",
      "Validating...\n",
      "Validation Loss: 0.663091, Validation Accuracy: 77.98%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 8/20\n",
      "loss: 0.322815  [   70/  670]\n",
      "loss: 0.301504  [  210/  670]\n",
      "loss: 0.245347  [  350/  670]\n",
      "loss: 0.163316  [  490/  670]\n",
      "loss: 0.229479  [  630/  670]\n",
      "Training Loss (Epoch): 0.229962\n",
      "Validating...\n",
      "Validation Loss: 0.523538, Validation Accuracy: 84.52%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 9/20\n",
      "loss: 0.067889  [   70/  670]\n",
      "loss: 0.148679  [  210/  670]\n",
      "loss: 0.179676  [  350/  670]\n",
      "loss: 0.181364  [  490/  670]\n",
      "loss: 0.196996  [  630/  670]\n",
      "Training Loss (Epoch): 0.160671\n",
      "Validating...\n",
      "Validation Loss: 0.523658, Validation Accuracy: 85.12%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 10/20\n",
      "loss: 0.189977  [   70/  670]\n",
      "loss: 0.108282  [  210/  670]\n",
      "loss: 0.240290  [  350/  670]\n",
      "loss: 0.142707  [  490/  670]\n",
      "loss: 0.088286  [  630/  670]\n",
      "Training Loss (Epoch): 0.125189\n",
      "Validating...\n",
      "Validation Loss: 0.519071, Validation Accuracy: 86.31%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 11/20\n",
      "loss: 0.111393  [   70/  670]\n",
      "loss: 0.074298  [  210/  670]\n",
      "loss: 0.076455  [  350/  670]\n",
      "loss: 0.067479  [  490/  670]\n",
      "loss: 0.029148  [  630/  670]\n",
      "Training Loss (Epoch): 0.111613\n",
      "Validating...\n",
      "Validation Loss: 0.539026, Validation Accuracy: 83.93%\n",
      "Learning Rate: [1.25e-05]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 8\n",
      "Epoch 1/20\n",
      "loss: 2.361713  [   70/  644]\n",
      "loss: 2.140389  [  210/  644]\n",
      "loss: 2.097808  [  350/  644]\n",
      "loss: 1.936790  [  490/  644]\n",
      "loss: 1.676415  [  630/  644]\n",
      "Training Loss (Epoch): 1.983051\n",
      "Validating...\n",
      "Validation Loss: 1.996245, Validation Accuracy: 37.65%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 2.020869  [   70/  644]\n",
      "loss: 1.674450  [  210/  644]\n",
      "loss: 1.433833  [  350/  644]\n",
      "loss: 1.955811  [  490/  644]\n",
      "loss: 1.325050  [  630/  644]\n",
      "Training Loss (Epoch): 1.554595\n",
      "Validating...\n",
      "Validation Loss: 1.410106, Validation Accuracy: 53.70%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 1.074024  [   70/  644]\n",
      "loss: 0.965055  [  210/  644]\n",
      "loss: 1.157916  [  350/  644]\n",
      "loss: 0.916836  [  490/  644]\n",
      "loss: 0.841147  [  630/  644]\n",
      "Training Loss (Epoch): 0.989172\n",
      "Validating...\n",
      "Validation Loss: 1.178476, Validation Accuracy: 59.88%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/20\n",
      "loss: 0.810615  [   70/  644]\n",
      "loss: 0.915101  [  210/  644]\n",
      "loss: 0.559913  [  350/  644]\n",
      "loss: 0.929421  [  490/  644]\n",
      "loss: 0.660679  [  630/  644]\n",
      "Training Loss (Epoch): 0.737408\n",
      "Validating...\n",
      "Validation Loss: 0.832489, Validation Accuracy: 69.14%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/20\n",
      "loss: 0.639955  [   70/  644]\n",
      "loss: 0.615775  [  210/  644]\n",
      "loss: 0.679235  [  350/  644]\n",
      "loss: 0.265460  [  490/  644]\n",
      "loss: 0.305121  [  630/  644]\n",
      "Training Loss (Epoch): 0.495595\n",
      "Validating...\n",
      "Validation Loss: 0.748305, Validation Accuracy: 74.07%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/20\n",
      "loss: 0.447438  [   70/  644]\n",
      "loss: 0.555676  [  210/  644]\n",
      "loss: 0.265676  [  350/  644]\n",
      "loss: 0.327303  [  490/  644]\n",
      "loss: 0.327432  [  630/  644]\n",
      "Training Loss (Epoch): 0.343636\n",
      "Validating...\n",
      "Validation Loss: 0.525339, Validation Accuracy: 79.01%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 7/20\n",
      "loss: 0.336957  [   70/  644]\n",
      "loss: 0.371953  [  210/  644]\n",
      "loss: 0.238971  [  350/  644]\n",
      "loss: 0.124798  [  490/  644]\n",
      "loss: 0.242019  [  630/  644]\n",
      "Training Loss (Epoch): 0.335627\n",
      "Validating...\n",
      "Validation Loss: 0.828601, Validation Accuracy: 80.25%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 8/20\n",
      "loss: 0.210834  [   70/  644]\n",
      "loss: 0.258088  [  210/  644]\n",
      "loss: 0.309638  [  350/  644]\n",
      "loss: 0.359548  [  490/  644]\n",
      "loss: 0.259458  [  630/  644]\n",
      "Training Loss (Epoch): 0.311125\n",
      "Validating...\n",
      "Validation Loss: 0.603784, Validation Accuracy: 77.78%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 9/20\n",
      "loss: 0.283826  [   70/  644]\n",
      "loss: 0.193901  [  210/  644]\n",
      "loss: 0.217399  [  350/  644]\n",
      "loss: 0.138437  [  490/  644]\n",
      "loss: 0.094749  [  630/  644]\n",
      "Training Loss (Epoch): 0.189974\n",
      "Validating...\n",
      "Validation Loss: 0.344884, Validation Accuracy: 87.04%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 10/20\n",
      "loss: 0.139146  [   70/  644]\n",
      "loss: 0.130925  [  210/  644]\n",
      "loss: 0.045364  [  350/  644]\n",
      "loss: 0.090708  [  490/  644]\n",
      "loss: 0.194815  [  630/  644]\n",
      "Training Loss (Epoch): 0.118914\n",
      "Validating...\n",
      "Validation Loss: 0.418554, Validation Accuracy: 85.80%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 11/20\n",
      "loss: 0.095764  [   70/  644]\n",
      "loss: 0.078984  [  210/  644]\n",
      "loss: 0.129529  [  350/  644]\n",
      "loss: 0.153071  [  490/  644]\n",
      "loss: 0.061774  [  630/  644]\n",
      "Training Loss (Epoch): 0.091284\n",
      "Validating...\n",
      "Validation Loss: 0.410122, Validation Accuracy: 88.89%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 12/20\n",
      "loss: 0.072105  [   70/  644]\n",
      "loss: 0.066396  [  210/  644]\n",
      "loss: 0.015166  [  350/  644]\n",
      "loss: 0.076466  [  490/  644]\n",
      "loss: 0.053993  [  630/  644]\n",
      "Training Loss (Epoch): 0.062940\n",
      "Validating...\n",
      "Validation Loss: 0.382962, Validation Accuracy: 90.12%\n",
      "Learning Rate: [5e-05]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 9\n",
      "Epoch 1/20\n",
      "loss: 2.456615  [   70/  652]\n",
      "loss: 2.155012  [  210/  652]\n",
      "loss: 2.031408  [  350/  652]\n",
      "loss: 1.740575  [  490/  652]\n",
      "loss: 1.501241  [  630/  652]\n",
      "Training Loss (Epoch): 1.950340\n",
      "Validating...\n",
      "Validation Loss: 1.859550, Validation Accuracy: 49.39%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 1.847980  [   70/  652]\n",
      "loss: 1.072582  [  210/  652]\n",
      "loss: 1.601732  [  350/  652]\n",
      "loss: 1.118414  [  490/  652]\n",
      "loss: 0.987789  [  630/  652]\n",
      "Training Loss (Epoch): 1.191473\n",
      "Validating...\n",
      "Validation Loss: 0.749973, Validation Accuracy: 78.05%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 0.871397  [   70/  652]\n",
      "loss: 0.532912  [  210/  652]\n",
      "loss: 0.877338  [  350/  652]\n",
      "loss: 0.371803  [  490/  652]\n",
      "loss: 0.648299  [  630/  652]\n",
      "Training Loss (Epoch): 0.647649\n",
      "Validating...\n",
      "Validation Loss: 0.486228, Validation Accuracy: 83.54%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/20\n",
      "loss: 0.428441  [   70/  652]\n",
      "loss: 0.272939  [  210/  652]\n",
      "loss: 0.477254  [  350/  652]\n",
      "loss: 0.332822  [  490/  652]\n",
      "loss: 0.228962  [  630/  652]\n",
      "Training Loss (Epoch): 0.379231\n",
      "Validating...\n",
      "Validation Loss: 0.593852, Validation Accuracy: 81.71%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 5/20\n",
      "loss: 0.434481  [   70/  652]\n",
      "loss: 0.300895  [  210/  652]\n",
      "loss: 0.336424  [  350/  652]\n",
      "loss: 0.133269  [  490/  652]\n",
      "loss: 0.536315  [  630/  652]\n",
      "Training Loss (Epoch): 0.302966\n",
      "Validating...\n",
      "Validation Loss: 0.416514, Validation Accuracy: 84.76%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 6/20\n",
      "loss: 0.131934  [   70/  652]\n",
      "loss: 0.174889  [  210/  652]\n",
      "loss: 0.278448  [  350/  652]\n",
      "loss: 0.141972  [  490/  652]\n",
      "loss: 0.289243  [  630/  652]\n",
      "Training Loss (Epoch): 0.202015\n",
      "Validating...\n",
      "Validation Loss: 0.432945, Validation Accuracy: 85.37%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 7/20\n",
      "loss: 0.175514  [   70/  652]\n",
      "loss: 0.101890  [  210/  652]\n",
      "loss: 0.160503  [  350/  652]\n",
      "loss: 0.125683  [  490/  652]\n",
      "loss: 0.141834  [  630/  652]\n",
      "Training Loss (Epoch): 0.149002\n",
      "Validating...\n",
      "Validation Loss: 0.448995, Validation Accuracy: 85.98%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 8/20\n",
      "loss: 0.100715  [   70/  652]\n",
      "loss: 0.171955  [  210/  652]\n",
      "loss: 0.082526  [  350/  652]\n",
      "loss: 0.120271  [  490/  652]\n",
      "loss: 0.042612  [  630/  652]\n",
      "Training Loss (Epoch): 0.170021\n",
      "Validating...\n",
      "Validation Loss: 0.346692, Validation Accuracy: 89.02%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 9/20\n",
      "loss: 0.057144  [   70/  652]\n",
      "loss: 0.128118  [  210/  652]\n",
      "loss: 0.251773  [  350/  652]\n",
      "loss: 0.046627  [  490/  652]\n",
      "loss: 0.475388  [  630/  652]\n",
      "Training Loss (Epoch): 0.183709\n",
      "Validating...\n",
      "Validation Loss: 0.417125, Validation Accuracy: 85.37%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 10/20\n",
      "loss: 0.337637  [   70/  652]\n",
      "loss: 0.099402  [  210/  652]\n",
      "loss: 0.150926  [  350/  652]\n",
      "loss: 0.172662  [  490/  652]\n",
      "loss: 0.164467  [  630/  652]\n",
      "Training Loss (Epoch): 0.244098\n",
      "Validating...\n",
      "Validation Loss: 0.312735, Validation Accuracy: 91.46%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 11/20\n",
      "loss: 0.089082  [   70/  652]\n",
      "loss: 0.116058  [  210/  652]\n",
      "loss: 0.063380  [  350/  652]\n",
      "loss: 0.181809  [  490/  652]\n",
      "loss: 0.054592  [  630/  652]\n",
      "Training Loss (Epoch): 0.093702\n",
      "Validating...\n",
      "Validation Loss: 0.333598, Validation Accuracy: 91.46%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 12/20\n",
      "loss: 0.080084  [   70/  652]\n",
      "loss: 0.082481  [  210/  652]\n",
      "loss: 0.179149  [  350/  652]\n",
      "loss: 0.048506  [  490/  652]\n",
      "loss: 0.100777  [  630/  652]\n",
      "Training Loss (Epoch): 0.087075\n",
      "Validating...\n",
      "Validation Loss: 0.328090, Validation Accuracy: 90.85%\n",
      "Learning Rate: [6.25e-06]\n",
      "Epoch 13/20\n",
      "loss: 0.109987  [   70/  652]\n",
      "loss: 0.079188  [  210/  652]\n",
      "loss: 0.148195  [  350/  652]\n",
      "loss: 0.041204  [  490/  652]\n",
      "loss: 0.063075  [  630/  652]\n",
      "Training Loss (Epoch): 0.095359\n",
      "Validating...\n",
      "Validation Loss: 0.323551, Validation Accuracy: 90.85%\n",
      "Learning Rate: [3.125e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 10\n",
      "Epoch 1/20\n",
      "loss: 2.367463  [   70/  669]\n",
      "loss: 2.170587  [  210/  669]\n",
      "loss: 2.033870  [  350/  669]\n",
      "loss: 1.814390  [  490/  669]\n",
      "loss: 1.849517  [  630/  669]\n",
      "Training Loss (Epoch): 2.030398\n",
      "Validating...\n",
      "Validation Loss: 1.920302, Validation Accuracy: 42.26%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 1.887795  [   70/  669]\n",
      "loss: 1.750087  [  210/  669]\n",
      "loss: 1.325186  [  350/  669]\n",
      "loss: 1.431720  [  490/  669]\n",
      "loss: 1.136266  [  630/  669]\n",
      "Training Loss (Epoch): 1.427838\n",
      "Validating...\n",
      "Validation Loss: 1.129282, Validation Accuracy: 66.67%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 1.294322  [   70/  669]\n",
      "loss: 0.980355  [  210/  669]\n",
      "loss: 0.870405  [  350/  669]\n",
      "loss: 0.933624  [  490/  669]\n",
      "loss: 0.972103  [  630/  669]\n",
      "Training Loss (Epoch): 0.882419\n",
      "Validating...\n",
      "Validation Loss: 0.732961, Validation Accuracy: 70.83%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/20\n",
      "loss: 0.844938  [   70/  669]\n",
      "loss: 0.626990  [  210/  669]\n",
      "loss: 0.609139  [  350/  669]\n",
      "loss: 0.605561  [  490/  669]\n",
      "loss: 0.384576  [  630/  669]\n",
      "Training Loss (Epoch): 0.619564\n",
      "Validating...\n",
      "Validation Loss: 0.645847, Validation Accuracy: 77.98%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/20\n",
      "loss: 0.420335  [   70/  669]\n",
      "loss: 0.519142  [  210/  669]\n",
      "loss: 0.401701  [  350/  669]\n",
      "loss: 0.335709  [  490/  669]\n",
      "loss: 0.559784  [  630/  669]\n",
      "Training Loss (Epoch): 0.554061\n",
      "Validating...\n",
      "Validation Loss: 0.614225, Validation Accuracy: 79.76%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/20\n",
      "loss: 0.326200  [   70/  669]\n",
      "loss: 0.690908  [  210/  669]\n",
      "loss: 0.636124  [  350/  669]\n",
      "loss: 0.581220  [  490/  669]\n",
      "loss: 0.431376  [  630/  669]\n",
      "Training Loss (Epoch): 0.493317\n",
      "Validating...\n",
      "Validation Loss: 0.498970, Validation Accuracy: 83.93%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 7/20\n",
      "loss: 0.276400  [   70/  669]\n",
      "loss: 0.359361  [  210/  669]\n",
      "loss: 0.208109  [  350/  669]\n",
      "loss: 0.441944  [  490/  669]\n",
      "loss: 0.356332  [  630/  669]\n",
      "Training Loss (Epoch): 0.384298\n",
      "Validating...\n",
      "Validation Loss: 0.643972, Validation Accuracy: 79.76%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 8/20\n",
      "loss: 0.597902  [   70/  669]\n",
      "loss: 0.207914  [  210/  669]\n",
      "loss: 0.401442  [  350/  669]\n",
      "loss: 0.326967  [  490/  669]\n",
      "loss: 0.317249  [  630/  669]\n",
      "Training Loss (Epoch): 0.345608\n",
      "Validating...\n",
      "Validation Loss: 0.358146, Validation Accuracy: 86.31%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 9/20\n",
      "loss: 0.339719  [   70/  669]\n",
      "loss: 0.139058  [  210/  669]\n",
      "loss: 0.120924  [  350/  669]\n",
      "loss: 0.149096  [  490/  669]\n",
      "loss: 0.210392  [  630/  669]\n",
      "Training Loss (Epoch): 0.272555\n",
      "Validating...\n",
      "Validation Loss: 0.342899, Validation Accuracy: 89.88%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 10/20\n",
      "loss: 0.224928  [   70/  669]\n",
      "loss: 0.263776  [  210/  669]\n",
      "loss: 0.210980  [  350/  669]\n",
      "loss: 0.198226  [  490/  669]\n",
      "loss: 0.190913  [  630/  669]\n",
      "Training Loss (Epoch): 0.219165\n",
      "Validating...\n",
      "Validation Loss: 0.329398, Validation Accuracy: 87.50%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 11/20\n",
      "loss: 0.203140  [   70/  669]\n",
      "loss: 0.123536  [  210/  669]\n",
      "loss: 0.121497  [  350/  669]\n",
      "loss: 0.253922  [  490/  669]\n",
      "loss: 0.249638  [  630/  669]\n",
      "Training Loss (Epoch): 0.181164\n",
      "Validating...\n",
      "Validation Loss: 0.391239, Validation Accuracy: 87.50%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 12/20\n",
      "loss: 0.152599  [   70/  669]\n",
      "loss: 0.183220  [  210/  669]\n",
      "loss: 0.130226  [  350/  669]\n",
      "loss: 0.134443  [  490/  669]\n",
      "loss: 0.201556  [  630/  669]\n",
      "Training Loss (Epoch): 0.153751\n",
      "Validating...\n",
      "Validation Loss: 0.379378, Validation Accuracy: 89.88%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 13/20\n",
      "loss: 0.052787  [   70/  669]\n",
      "loss: 0.086580  [  210/  669]\n",
      "loss: 0.091326  [  350/  669]\n",
      "loss: 0.243184  [  490/  669]\n",
      "loss: 0.182201  [  630/  669]\n",
      "Training Loss (Epoch): 0.142316\n",
      "Validating...\n",
      "Validation Loss: 0.389541, Validation Accuracy: 88.69%\n",
      "Learning Rate: [6.25e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "\n",
      "Cross-Validation Results:\n",
      "Avg Training Loss: 0.514556\n",
      "Avg Validation Loss: 0.697843\n",
      "Avg Validation Accuracy: 78.70%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dense_tune(layer = 2, lr = 2e-4, weight_decay = 0.2, weights = \"DEFAULT\", drop = 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1\n",
      "Epoch 1/20\n",
      "loss: 2.345630  [   70/  698]\n",
      "loss: 2.072877  [  210/  698]\n",
      "loss: 1.962428  [  350/  698]\n",
      "loss: 1.739533  [  490/  698]\n",
      "loss: 1.749560  [  630/  698]\n",
      "Training Loss (Epoch): 1.983971\n",
      "Validating...\n",
      "Validation Loss: 1.925203, Validation Accuracy: 46.29%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 1.898814  [   70/  698]\n",
      "loss: 1.599640  [  210/  698]\n",
      "loss: 1.364550  [  350/  698]\n",
      "loss: 1.153509  [  490/  698]\n",
      "loss: 1.062906  [  630/  698]\n",
      "Training Loss (Epoch): 1.334219\n",
      "Validating...\n",
      "Validation Loss: 0.926143, Validation Accuracy: 68.57%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 0.839380  [   70/  698]\n",
      "loss: 0.883843  [  210/  698]\n",
      "loss: 0.554768  [  350/  698]\n",
      "loss: 0.439027  [  490/  698]\n",
      "loss: 0.636104  [  630/  698]\n",
      "Training Loss (Epoch): 0.677705\n",
      "Validating...\n",
      "Validation Loss: 0.638317, Validation Accuracy: 74.29%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/20\n",
      "loss: 0.438796  [   70/  698]\n",
      "loss: 0.381360  [  210/  698]\n",
      "loss: 0.357722  [  350/  698]\n",
      "loss: 0.269120  [  490/  698]\n",
      "loss: 0.348908  [  630/  698]\n",
      "Training Loss (Epoch): 0.366451\n",
      "Validating...\n",
      "Validation Loss: 0.503358, Validation Accuracy: 81.14%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/20\n",
      "loss: 0.260326  [   70/  698]\n",
      "loss: 0.214042  [  210/  698]\n",
      "loss: 0.340778  [  350/  698]\n",
      "loss: 0.281721  [  490/  698]\n",
      "loss: 0.357695  [  630/  698]\n",
      "Training Loss (Epoch): 0.264333\n",
      "Validating...\n",
      "Validation Loss: 0.390292, Validation Accuracy: 86.86%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/20\n",
      "loss: 0.245737  [   70/  698]\n",
      "loss: 0.156507  [  210/  698]\n",
      "loss: 0.110919  [  350/  698]\n",
      "loss: 0.208212  [  490/  698]\n",
      "loss: 0.128944  [  630/  698]\n",
      "Training Loss (Epoch): 0.156021\n",
      "Validating...\n",
      "Validation Loss: 0.354791, Validation Accuracy: 84.00%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 7/20\n",
      "loss: 0.176732  [   70/  698]\n",
      "loss: 0.059712  [  210/  698]\n",
      "loss: 0.087280  [  350/  698]\n",
      "loss: 0.151080  [  490/  698]\n",
      "loss: 0.054330  [  630/  698]\n",
      "Training Loss (Epoch): 0.111450\n",
      "Validating...\n",
      "Validation Loss: 0.268671, Validation Accuracy: 90.29%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 8/20\n",
      "loss: 0.042380  [   70/  698]\n",
      "loss: 0.083217  [  210/  698]\n",
      "loss: 0.077106  [  350/  698]\n",
      "loss: 0.123347  [  490/  698]\n",
      "loss: 0.019705  [  630/  698]\n",
      "Training Loss (Epoch): 0.076350\n",
      "Validating...\n",
      "Validation Loss: 0.314930, Validation Accuracy: 86.29%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 9/20\n",
      "loss: 0.013420  [   70/  698]\n",
      "loss: 0.026522  [  210/  698]\n",
      "loss: 0.059293  [  350/  698]\n",
      "loss: 0.106527  [  490/  698]\n",
      "loss: 0.056370  [  630/  698]\n",
      "Training Loss (Epoch): 0.062621\n",
      "Validating...\n",
      "Validation Loss: 0.267097, Validation Accuracy: 92.57%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 10/20\n",
      "loss: 0.075948  [   70/  698]\n",
      "loss: 0.062265  [  210/  698]\n",
      "loss: 0.010764  [  350/  698]\n",
      "loss: 0.044789  [  490/  698]\n",
      "loss: 0.005504  [  630/  698]\n",
      "Training Loss (Epoch): 0.053018\n",
      "Validating...\n",
      "Validation Loss: 0.269682, Validation Accuracy: 90.29%\n",
      "Learning Rate: [2.5e-05]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 2\n",
      "Epoch 1/20\n",
      "loss: 2.397573  [   70/  710]\n",
      "loss: 2.199772  [  210/  710]\n",
      "loss: 1.920111  [  350/  710]\n",
      "loss: 1.821658  [  490/  710]\n",
      "loss: 1.676510  [  630/  710]\n",
      "loss: 1.925599  [  110/  710]\n",
      "Training Loss (Epoch): 1.937730\n",
      "Validating...\n",
      "Validation Loss: 1.881971, Validation Accuracy: 43.26%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 1.702159  [   70/  710]\n",
      "loss: 1.382026  [  210/  710]\n",
      "loss: 1.395889  [  350/  710]\n",
      "loss: 1.369638  [  490/  710]\n",
      "loss: 0.956729  [  630/  710]\n",
      "loss: 0.952085  [  110/  710]\n",
      "Training Loss (Epoch): 1.299186\n",
      "Validating...\n",
      "Validation Loss: 1.038372, Validation Accuracy: 64.61%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 0.929290  [   70/  710]\n",
      "loss: 1.111317  [  210/  710]\n",
      "loss: 0.573540  [  350/  710]\n",
      "loss: 1.131757  [  490/  710]\n",
      "loss: 0.533739  [  630/  710]\n",
      "loss: 0.632030  [  110/  710]\n",
      "Training Loss (Epoch): 0.758694\n",
      "Validating...\n",
      "Validation Loss: 0.702552, Validation Accuracy: 77.53%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/20\n",
      "loss: 0.442246  [   70/  710]\n",
      "loss: 0.451177  [  210/  710]\n",
      "loss: 0.308098  [  350/  710]\n",
      "loss: 0.210635  [  490/  710]\n",
      "loss: 0.468509  [  630/  710]\n",
      "loss: 0.564542  [  110/  710]\n",
      "Training Loss (Epoch): 0.447371\n",
      "Validating...\n",
      "Validation Loss: 0.772503, Validation Accuracy: 75.28%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 5/20\n",
      "loss: 0.559121  [   70/  710]\n",
      "loss: 0.557591  [  210/  710]\n",
      "loss: 0.192043  [  350/  710]\n",
      "loss: 0.205170  [  490/  710]\n",
      "loss: 0.331762  [  630/  710]\n",
      "loss: 0.344583  [  110/  710]\n",
      "Training Loss (Epoch): 0.351418\n",
      "Validating...\n",
      "Validation Loss: 0.666742, Validation Accuracy: 80.34%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 6/20\n",
      "loss: 0.288764  [   70/  710]\n",
      "loss: 0.216483  [  210/  710]\n",
      "loss: 0.170719  [  350/  710]\n",
      "loss: 0.112326  [  490/  710]\n",
      "loss: 0.167114  [  630/  710]\n",
      "loss: 0.098981  [  110/  710]\n",
      "Training Loss (Epoch): 0.192302\n",
      "Validating...\n",
      "Validation Loss: 0.499709, Validation Accuracy: 88.20%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 7/20\n",
      "loss: 0.136852  [   70/  710]\n",
      "loss: 0.127393  [  210/  710]\n",
      "loss: 0.060194  [  350/  710]\n",
      "loss: 0.323471  [  490/  710]\n",
      "loss: 0.130993  [  630/  710]\n",
      "loss: 1.095644  [  110/  710]\n",
      "Training Loss (Epoch): 0.243443\n",
      "Validating...\n",
      "Validation Loss: 0.482403, Validation Accuracy: 87.64%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 8/20\n",
      "loss: 0.058635  [   70/  710]\n",
      "loss: 0.194171  [  210/  710]\n",
      "loss: 0.332639  [  350/  710]\n",
      "loss: 0.158189  [  490/  710]\n",
      "loss: 0.105406  [  630/  710]\n",
      "loss: 0.076963  [  110/  710]\n",
      "Training Loss (Epoch): 0.138898\n",
      "Validating...\n",
      "Validation Loss: 0.540625, Validation Accuracy: 83.15%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 9/20\n",
      "loss: 0.059731  [   70/  710]\n",
      "loss: 0.154153  [  210/  710]\n",
      "loss: 0.170720  [  350/  710]\n",
      "loss: 0.086485  [  490/  710]\n",
      "loss: 0.054777  [  630/  710]\n",
      "loss: 0.014894  [  110/  710]\n",
      "Training Loss (Epoch): 0.102694\n",
      "Validating...\n",
      "Validation Loss: 0.479263, Validation Accuracy: 87.08%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 10/20\n",
      "loss: 0.131401  [   70/  710]\n",
      "loss: 0.129040  [  210/  710]\n",
      "loss: 0.067895  [  350/  710]\n",
      "loss: 0.172792  [  490/  710]\n",
      "loss: 0.036005  [  630/  710]\n",
      "loss: 0.011771  [  110/  710]\n",
      "Training Loss (Epoch): 0.091237\n",
      "Validating...\n",
      "Validation Loss: 0.458379, Validation Accuracy: 88.20%\n",
      "Learning Rate: [6.25e-06]\n",
      "Epoch 11/20\n",
      "loss: 0.115532  [   70/  710]\n",
      "loss: 0.105098  [  210/  710]\n",
      "loss: 0.145360  [  350/  710]\n",
      "loss: 0.070539  [  490/  710]\n",
      "loss: 0.058157  [  630/  710]\n",
      "loss: 0.046220  [  110/  710]\n",
      "Training Loss (Epoch): 0.079491\n",
      "Validating...\n",
      "Validation Loss: 0.457762, Validation Accuracy: 88.76%\n",
      "Learning Rate: [3.125e-06]\n",
      "Epoch 12/20\n",
      "loss: 0.029857  [   70/  710]\n",
      "loss: 0.124646  [  210/  710]\n",
      "loss: 0.048799  [  350/  710]\n",
      "loss: 0.108019  [  490/  710]\n",
      "loss: 0.153481  [  630/  710]\n",
      "loss: 0.063335  [  110/  710]\n",
      "Training Loss (Epoch): 0.086841\n",
      "Validating...\n",
      "Validation Loss: 0.460571, Validation Accuracy: 88.76%\n",
      "Learning Rate: [1.5625e-06]\n",
      "Epoch 13/20\n",
      "loss: 0.090358  [   70/  710]\n",
      "loss: 0.072925  [  210/  710]\n",
      "loss: 0.165526  [  350/  710]\n",
      "loss: 0.156283  [  490/  710]\n",
      "loss: 0.083341  [  630/  710]\n",
      "loss: 0.015006  [  110/  710]\n",
      "Training Loss (Epoch): 0.073684\n",
      "Validating...\n",
      "Validation Loss: 0.459222, Validation Accuracy: 88.76%\n",
      "Learning Rate: [7.8125e-07]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 3\n",
      "Epoch 1/20\n",
      "loss: 2.382110  [   70/  740]\n",
      "loss: 2.251153  [  210/  740]\n",
      "loss: 2.040684  [  350/  740]\n",
      "loss: 2.010685  [  490/  740]\n",
      "loss: 1.685081  [  630/  740]\n",
      "loss: 1.626801  [  440/  740]\n",
      "Training Loss (Epoch): 1.973195\n",
      "Validating...\n",
      "Validation Loss: 1.955361, Validation Accuracy: 45.95%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 1.752253  [   70/  740]\n",
      "loss: 1.503154  [  210/  740]\n",
      "loss: 1.056078  [  350/  740]\n",
      "loss: 1.202335  [  490/  740]\n",
      "loss: 1.059899  [  630/  740]\n",
      "loss: 0.666053  [  440/  740]\n",
      "Training Loss (Epoch): 1.269171\n",
      "Validating...\n",
      "Validation Loss: 0.999970, Validation Accuracy: 62.70%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 0.547215  [   70/  740]\n",
      "loss: 0.570385  [  210/  740]\n",
      "loss: 0.714652  [  350/  740]\n",
      "loss: 0.547370  [  490/  740]\n",
      "loss: 0.820342  [  630/  740]\n",
      "loss: 0.578011  [  440/  740]\n",
      "Training Loss (Epoch): 0.673549\n",
      "Validating...\n",
      "Validation Loss: 0.844090, Validation Accuracy: 73.51%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/20\n",
      "loss: 0.560027  [   70/  740]\n",
      "loss: 0.330290  [  210/  740]\n",
      "loss: 0.753874  [  350/  740]\n",
      "loss: 0.289361  [  490/  740]\n",
      "loss: 0.436106  [  630/  740]\n",
      "loss: 0.376647  [  440/  740]\n",
      "Training Loss (Epoch): 0.461125\n",
      "Validating...\n",
      "Validation Loss: 0.623767, Validation Accuracy: 78.92%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/20\n",
      "loss: 0.471234  [   70/  740]\n",
      "loss: 0.403839  [  210/  740]\n",
      "loss: 0.310259  [  350/  740]\n",
      "loss: 0.248550  [  490/  740]\n",
      "loss: 0.333911  [  630/  740]\n",
      "loss: 0.232803  [  440/  740]\n",
      "Training Loss (Epoch): 0.314390\n",
      "Validating...\n",
      "Validation Loss: 0.734351, Validation Accuracy: 76.22%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 6/20\n",
      "loss: 0.158999  [   70/  740]\n",
      "loss: 0.283677  [  210/  740]\n",
      "loss: 0.210026  [  350/  740]\n",
      "loss: 0.295211  [  490/  740]\n",
      "loss: 0.156655  [  630/  740]\n",
      "loss: 0.230814  [  440/  740]\n",
      "Training Loss (Epoch): 0.239729\n",
      "Validating...\n",
      "Validation Loss: 0.488173, Validation Accuracy: 83.24%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 7/20\n",
      "loss: 0.143592  [   70/  740]\n",
      "loss: 0.113447  [  210/  740]\n",
      "loss: 0.158557  [  350/  740]\n",
      "loss: 0.086023  [  490/  740]\n",
      "loss: 0.080733  [  630/  740]\n",
      "loss: 0.029647  [  440/  740]\n",
      "Training Loss (Epoch): 0.151953\n",
      "Validating...\n",
      "Validation Loss: 0.547156, Validation Accuracy: 79.46%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 8/20\n",
      "loss: 0.204737  [   70/  740]\n",
      "loss: 0.082378  [  210/  740]\n",
      "loss: 0.101193  [  350/  740]\n",
      "loss: 0.134293  [  490/  740]\n",
      "loss: 0.023669  [  630/  740]\n",
      "loss: 0.062218  [  440/  740]\n",
      "Training Loss (Epoch): 0.114641\n",
      "Validating...\n",
      "Validation Loss: 0.427159, Validation Accuracy: 85.41%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 9/20\n",
      "loss: 0.126592  [   70/  740]\n",
      "loss: 0.034352  [  210/  740]\n",
      "loss: 0.125105  [  350/  740]\n",
      "loss: 0.012173  [  490/  740]\n",
      "loss: 0.160497  [  630/  740]\n",
      "loss: 0.095968  [  440/  740]\n",
      "Training Loss (Epoch): 0.103969\n",
      "Validating...\n",
      "Validation Loss: 0.370563, Validation Accuracy: 87.03%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 10/20\n",
      "loss: 0.054655  [   70/  740]\n",
      "loss: 0.135462  [  210/  740]\n",
      "loss: 0.033510  [  350/  740]\n",
      "loss: 0.138493  [  490/  740]\n",
      "loss: 0.049206  [  630/  740]\n",
      "loss: 0.165378  [  440/  740]\n",
      "Training Loss (Epoch): 0.087396\n",
      "Validating...\n",
      "Validation Loss: 0.373599, Validation Accuracy: 87.57%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 11/20\n",
      "loss: 0.113175  [   70/  740]\n",
      "loss: 0.089966  [  210/  740]\n",
      "loss: 0.066039  [  350/  740]\n",
      "loss: 0.067885  [  490/  740]\n",
      "loss: 0.084270  [  630/  740]\n",
      "loss: 0.044971  [  440/  740]\n",
      "Training Loss (Epoch): 0.076365\n",
      "Validating...\n",
      "Validation Loss: 0.306777, Validation Accuracy: 88.11%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 12/20\n",
      "loss: 0.086311  [   70/  740]\n",
      "loss: 0.059561  [  210/  740]\n",
      "loss: 0.057661  [  350/  740]\n",
      "loss: 0.146015  [  490/  740]\n",
      "loss: 0.060895  [  630/  740]\n",
      "loss: 0.161368  [  440/  740]\n",
      "Training Loss (Epoch): 0.072840\n",
      "Validating...\n",
      "Validation Loss: 0.311986, Validation Accuracy: 88.11%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 13/20\n",
      "loss: 0.057423  [   70/  740]\n",
      "loss: 0.041788  [  210/  740]\n",
      "loss: 0.049651  [  350/  740]\n",
      "loss: 0.069886  [  490/  740]\n",
      "loss: 0.046680  [  630/  740]\n",
      "loss: 0.177068  [  440/  740]\n",
      "Training Loss (Epoch): 0.063699\n",
      "Validating...\n",
      "Validation Loss: 0.328584, Validation Accuracy: 87.57%\n",
      "Learning Rate: [6.25e-06]\n",
      "Epoch 14/20\n",
      "loss: 0.027281  [   70/  740]\n",
      "loss: 0.011554  [  210/  740]\n",
      "loss: 0.064025  [  350/  740]\n",
      "loss: 0.048652  [  490/  740]\n",
      "loss: 0.071174  [  630/  740]\n",
      "loss: 0.027305  [  440/  740]\n",
      "Training Loss (Epoch): 0.049524\n",
      "Validating...\n",
      "Validation Loss: 0.319538, Validation Accuracy: 87.57%\n",
      "Learning Rate: [3.125e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 4\n",
      "Epoch 1/20\n",
      "loss: 2.404945  [   70/  792]\n",
      "loss: 2.212987  [  210/  792]\n",
      "loss: 2.094273  [  350/  792]\n",
      "loss: 1.939107  [  490/  792]\n",
      "loss: 1.873388  [  630/  792]\n",
      "loss: 1.817585  [  770/  792]\n",
      "Training Loss (Epoch): 2.015700\n",
      "Validating...\n",
      "Validation Loss: 1.806643, Validation Accuracy: 53.54%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 1.751877  [   70/  792]\n",
      "loss: 1.556718  [  210/  792]\n",
      "loss: 1.393642  [  350/  792]\n",
      "loss: 1.292261  [  490/  792]\n",
      "loss: 1.121974  [  630/  792]\n",
      "loss: 0.969469  [  770/  792]\n",
      "Training Loss (Epoch): 1.262698\n",
      "Validating...\n",
      "Validation Loss: 0.958707, Validation Accuracy: 66.16%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 0.936355  [   70/  792]\n",
      "loss: 0.692800  [  210/  792]\n",
      "loss: 0.686616  [  350/  792]\n",
      "loss: 0.636413  [  490/  792]\n",
      "loss: 0.552578  [  630/  792]\n",
      "loss: 0.547104  [  770/  792]\n",
      "Training Loss (Epoch): 0.715618\n",
      "Validating...\n",
      "Validation Loss: 0.910523, Validation Accuracy: 70.20%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/20\n",
      "loss: 0.731589  [   70/  792]\n",
      "loss: 0.815827  [  210/  792]\n",
      "loss: 0.505516  [  350/  792]\n",
      "loss: 0.384851  [  490/  792]\n",
      "loss: 0.432564  [  630/  792]\n",
      "loss: 0.502061  [  770/  792]\n",
      "Training Loss (Epoch): 0.548391\n",
      "Validating...\n",
      "Validation Loss: 0.516118, Validation Accuracy: 80.30%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/20\n",
      "loss: 0.421385  [   70/  792]\n",
      "loss: 0.313478  [  210/  792]\n",
      "loss: 0.307867  [  350/  792]\n",
      "loss: 0.263088  [  490/  792]\n",
      "loss: 0.334063  [  630/  792]\n",
      "loss: 0.299497  [  770/  792]\n",
      "Training Loss (Epoch): 0.324135\n",
      "Validating...\n",
      "Validation Loss: 0.417693, Validation Accuracy: 84.85%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/20\n",
      "loss: 0.310045  [   70/  792]\n",
      "loss: 0.128149  [  210/  792]\n",
      "loss: 0.196252  [  350/  792]\n",
      "loss: 0.246284  [  490/  792]\n",
      "loss: 0.238355  [  630/  792]\n",
      "loss: 0.269927  [  770/  792]\n",
      "Training Loss (Epoch): 0.224816\n",
      "Validating...\n",
      "Validation Loss: 0.739064, Validation Accuracy: 81.82%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 7/20\n",
      "loss: 0.258184  [   70/  792]\n",
      "loss: 0.289152  [  210/  792]\n",
      "loss: 0.139982  [  350/  792]\n",
      "loss: 0.296635  [  490/  792]\n",
      "loss: 0.209544  [  630/  792]\n",
      "loss: 0.128968  [  770/  792]\n",
      "Training Loss (Epoch): 0.221405\n",
      "Validating...\n",
      "Validation Loss: 0.490969, Validation Accuracy: 83.84%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 8/20\n",
      "loss: 0.088219  [   70/  792]\n",
      "loss: 0.114633  [  210/  792]\n",
      "loss: 0.200844  [  350/  792]\n",
      "loss: 0.109090  [  490/  792]\n",
      "loss: 0.190245  [  630/  792]\n",
      "loss: 0.070965  [  770/  792]\n",
      "Training Loss (Epoch): 0.124663\n",
      "Validating...\n",
      "Validation Loss: 0.347152, Validation Accuracy: 88.89%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 9/20\n",
      "loss: 0.122439  [   70/  792]\n",
      "loss: 0.118390  [  210/  792]\n",
      "loss: 0.082282  [  350/  792]\n",
      "loss: 0.021292  [  490/  792]\n",
      "loss: 0.035440  [  630/  792]\n",
      "loss: 0.100530  [  770/  792]\n",
      "Training Loss (Epoch): 0.144493\n",
      "Validating...\n",
      "Validation Loss: 0.383170, Validation Accuracy: 87.37%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 10/20\n",
      "loss: 0.013426  [   70/  792]\n",
      "loss: 0.092646  [  210/  792]\n",
      "loss: 0.139118  [  350/  792]\n",
      "loss: 0.057834  [  490/  792]\n",
      "loss: 0.153114  [  630/  792]\n",
      "loss: 0.098302  [  770/  792]\n",
      "Training Loss (Epoch): 0.096372\n",
      "Validating...\n",
      "Validation Loss: 0.456283, Validation Accuracy: 86.36%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 11/20\n",
      "loss: 0.137223  [   70/  792]\n",
      "loss: 0.055259  [  210/  792]\n",
      "loss: 0.119774  [  350/  792]\n",
      "loss: 0.065295  [  490/  792]\n",
      "loss: 0.051010  [  630/  792]\n",
      "loss: 0.069443  [  770/  792]\n",
      "Training Loss (Epoch): 0.077260\n",
      "Validating...\n",
      "Validation Loss: 0.364150, Validation Accuracy: 87.37%\n",
      "Learning Rate: [6.25e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 5\n",
      "Epoch 1/20\n",
      "loss: 2.347473  [   70/  748]\n",
      "loss: 2.225538  [  210/  748]\n",
      "loss: 1.953655  [  350/  748]\n",
      "loss: 1.897570  [  490/  748]\n",
      "loss: 1.774105  [  630/  748]\n",
      "loss: 1.796839  [  528/  748]\n",
      "Training Loss (Epoch): 2.001775\n",
      "Validating...\n",
      "Validation Loss: 1.967563, Validation Accuracy: 43.09%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 1.844277  [   70/  748]\n",
      "loss: 1.588272  [  210/  748]\n",
      "loss: 1.173813  [  350/  748]\n",
      "loss: 1.373533  [  490/  748]\n",
      "loss: 1.018179  [  630/  748]\n",
      "loss: 1.188111  [  528/  748]\n",
      "Training Loss (Epoch): 1.318896\n",
      "Validating...\n",
      "Validation Loss: 1.157236, Validation Accuracy: 59.57%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 0.927597  [   70/  748]\n",
      "loss: 0.649034  [  210/  748]\n",
      "loss: 0.768717  [  350/  748]\n",
      "loss: 0.721427  [  490/  748]\n",
      "loss: 0.732704  [  630/  748]\n",
      "loss: 0.913825  [  528/  748]\n",
      "Training Loss (Epoch): 0.745351\n",
      "Validating...\n",
      "Validation Loss: 0.820534, Validation Accuracy: 67.55%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/20\n",
      "loss: 0.654020  [   70/  748]\n",
      "loss: 0.396943  [  210/  748]\n",
      "loss: 0.442074  [  350/  748]\n",
      "loss: 0.401279  [  490/  748]\n",
      "loss: 0.228495  [  630/  748]\n",
      "loss: 0.303395  [  528/  748]\n",
      "Training Loss (Epoch): 0.440789\n",
      "Validating...\n",
      "Validation Loss: 0.616526, Validation Accuracy: 78.19%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/20\n",
      "loss: 0.242783  [   70/  748]\n",
      "loss: 0.271857  [  210/  748]\n",
      "loss: 0.384090  [  350/  748]\n",
      "loss: 0.182926  [  490/  748]\n",
      "loss: 0.390119  [  630/  748]\n",
      "loss: 0.294081  [  528/  748]\n",
      "Training Loss (Epoch): 0.279693\n",
      "Validating...\n",
      "Validation Loss: 0.585623, Validation Accuracy: 79.79%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/20\n",
      "loss: 0.190003  [   70/  748]\n",
      "loss: 0.246643  [  210/  748]\n",
      "loss: 0.262258  [  350/  748]\n",
      "loss: 0.252407  [  490/  748]\n",
      "loss: 0.133762  [  630/  748]\n",
      "loss: 0.113827  [  528/  748]\n",
      "Training Loss (Epoch): 0.204278\n",
      "Validating...\n",
      "Validation Loss: 0.641950, Validation Accuracy: 79.26%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 7/20\n",
      "loss: 0.205758  [   70/  748]\n",
      "loss: 0.025757  [  210/  748]\n",
      "loss: 0.240787  [  350/  748]\n",
      "loss: 0.100538  [  490/  748]\n",
      "loss: 0.183501  [  630/  748]\n",
      "loss: 0.130074  [  528/  748]\n",
      "Training Loss (Epoch): 0.201748\n",
      "Validating...\n",
      "Validation Loss: 0.510998, Validation Accuracy: 84.04%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 8/20\n",
      "loss: 0.433449  [   70/  748]\n",
      "loss: 0.199466  [  210/  748]\n",
      "loss: 0.218024  [  350/  748]\n",
      "loss: 0.116852  [  490/  748]\n",
      "loss: 0.417737  [  630/  748]\n",
      "loss: 0.177394  [  528/  748]\n",
      "Training Loss (Epoch): 0.198682\n",
      "Validating...\n",
      "Validation Loss: 0.483126, Validation Accuracy: 82.98%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 9/20\n",
      "loss: 0.219098  [   70/  748]\n",
      "loss: 0.158539  [  210/  748]\n",
      "loss: 0.080781  [  350/  748]\n",
      "loss: 0.100985  [  490/  748]\n",
      "loss: 0.076308  [  630/  748]\n",
      "loss: 0.094570  [  528/  748]\n",
      "Training Loss (Epoch): 0.107884\n",
      "Validating...\n",
      "Validation Loss: 0.371207, Validation Accuracy: 87.77%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 10/20\n",
      "loss: 0.117145  [   70/  748]\n",
      "loss: 0.093220  [  210/  748]\n",
      "loss: 0.103644  [  350/  748]\n",
      "loss: 0.082402  [  490/  748]\n",
      "loss: 0.044983  [  630/  748]\n",
      "loss: 0.032419  [  528/  748]\n",
      "Training Loss (Epoch): 0.075549\n",
      "Validating...\n",
      "Validation Loss: 0.375028, Validation Accuracy: 88.30%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 11/20\n",
      "loss: 0.086133  [   70/  748]\n",
      "loss: 0.062344  [  210/  748]\n",
      "loss: 0.085212  [  350/  748]\n",
      "loss: 0.028979  [  490/  748]\n",
      "loss: 0.095080  [  630/  748]\n",
      "loss: 0.047379  [  528/  748]\n",
      "Training Loss (Epoch): 0.059443\n",
      "Validating...\n",
      "Validation Loss: 0.381476, Validation Accuracy: 86.70%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 12/20\n",
      "loss: 0.032634  [   70/  748]\n",
      "loss: 0.066118  [  210/  748]\n",
      "loss: 0.091694  [  350/  748]\n",
      "loss: 0.019560  [  490/  748]\n",
      "loss: 0.080196  [  630/  748]\n",
      "loss: 0.032191  [  528/  748]\n",
      "Training Loss (Epoch): 0.052499\n",
      "Validating...\n",
      "Validation Loss: 0.381488, Validation Accuracy: 87.23%\n",
      "Learning Rate: [6.25e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 6\n",
      "Epoch 1/20\n",
      "loss: 2.404132  [   70/  658]\n",
      "loss: 2.204485  [  210/  658]\n",
      "loss: 1.898308  [  350/  658]\n",
      "loss: 1.932635  [  490/  658]\n",
      "loss: 1.747556  [  630/  658]\n",
      "Training Loss (Epoch): 2.019649\n",
      "Validating...\n",
      "Validation Loss: 2.014883, Validation Accuracy: 33.94%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 1.953567  [   70/  658]\n",
      "loss: 1.605635  [  210/  658]\n",
      "loss: 1.265083  [  350/  658]\n",
      "loss: 1.073333  [  490/  658]\n",
      "loss: 0.879933  [  630/  658]\n",
      "Training Loss (Epoch): 1.380791\n",
      "Validating...\n",
      "Validation Loss: 1.189837, Validation Accuracy: 58.79%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 0.955745  [   70/  658]\n",
      "loss: 1.023356  [  210/  658]\n",
      "loss: 0.640860  [  350/  658]\n",
      "loss: 0.742014  [  490/  658]\n",
      "loss: 0.643225  [  630/  658]\n",
      "Training Loss (Epoch): 0.851267\n",
      "Validating...\n",
      "Validation Loss: 0.876968, Validation Accuracy: 68.48%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/20\n",
      "loss: 0.567869  [   70/  658]\n",
      "loss: 0.425997  [  210/  658]\n",
      "loss: 0.757017  [  350/  658]\n",
      "loss: 0.573302  [  490/  658]\n",
      "loss: 0.473832  [  630/  658]\n",
      "Training Loss (Epoch): 0.578543\n",
      "Validating...\n",
      "Validation Loss: 0.885067, Validation Accuracy: 70.91%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/20\n",
      "loss: 0.408777  [   70/  658]\n",
      "loss: 0.614582  [  210/  658]\n",
      "loss: 0.324871  [  350/  658]\n",
      "loss: 0.250510  [  490/  658]\n",
      "loss: 0.415162  [  630/  658]\n",
      "Training Loss (Epoch): 0.405919\n",
      "Validating...\n",
      "Validation Loss: 0.436771, Validation Accuracy: 86.06%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/20\n",
      "loss: 0.381721  [   70/  658]\n",
      "loss: 0.233271  [  210/  658]\n",
      "loss: 0.259646  [  350/  658]\n",
      "loss: 0.272181  [  490/  658]\n",
      "loss: 0.384361  [  630/  658]\n",
      "Training Loss (Epoch): 0.348352\n",
      "Validating...\n",
      "Validation Loss: 0.510804, Validation Accuracy: 82.42%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 7/20\n",
      "loss: 0.225191  [   70/  658]\n",
      "loss: 0.289685  [  210/  658]\n",
      "loss: 0.228693  [  350/  658]\n",
      "loss: 0.302350  [  490/  658]\n",
      "loss: 0.421468  [  630/  658]\n",
      "Training Loss (Epoch): 0.305493\n",
      "Validating...\n",
      "Validation Loss: 0.405376, Validation Accuracy: 85.45%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 8/20\n",
      "loss: 0.112575  [   70/  658]\n",
      "loss: 0.240210  [  210/  658]\n",
      "loss: 0.265676  [  350/  658]\n",
      "loss: 0.184371  [  490/  658]\n",
      "loss: 0.172214  [  630/  658]\n",
      "Training Loss (Epoch): 0.196843\n",
      "Validating...\n",
      "Validation Loss: 0.449138, Validation Accuracy: 86.06%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 9/20\n",
      "loss: 0.263380  [   70/  658]\n",
      "loss: 0.109886  [  210/  658]\n",
      "loss: 0.158299  [  350/  658]\n",
      "loss: 0.158172  [  490/  658]\n",
      "loss: 0.103906  [  630/  658]\n",
      "Training Loss (Epoch): 0.178679\n",
      "Validating...\n",
      "Validation Loss: 0.385774, Validation Accuracy: 88.48%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 10/20\n",
      "loss: 0.197050  [   70/  658]\n",
      "loss: 0.084883  [  210/  658]\n",
      "loss: 0.120658  [  350/  658]\n",
      "loss: 0.144193  [  490/  658]\n",
      "loss: 0.090497  [  630/  658]\n",
      "Training Loss (Epoch): 0.158259\n",
      "Validating...\n",
      "Validation Loss: 0.368284, Validation Accuracy: 89.09%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 11/20\n",
      "loss: 0.171628  [   70/  658]\n",
      "loss: 0.108130  [  210/  658]\n",
      "loss: 0.098835  [  350/  658]\n",
      "loss: 0.117842  [  490/  658]\n",
      "loss: 0.164376  [  630/  658]\n",
      "Training Loss (Epoch): 0.130960\n",
      "Validating...\n",
      "Validation Loss: 0.372287, Validation Accuracy: 89.09%\n",
      "Learning Rate: [6.25e-06]\n",
      "Epoch 12/20\n",
      "loss: 0.211154  [   70/  658]\n",
      "loss: 0.110379  [  210/  658]\n",
      "loss: 0.223220  [  350/  658]\n",
      "loss: 0.096799  [  490/  658]\n",
      "loss: 0.100613  [  630/  658]\n",
      "Training Loss (Epoch): 0.130571\n",
      "Validating...\n",
      "Validation Loss: 0.364463, Validation Accuracy: 88.48%\n",
      "Learning Rate: [3.125e-06]\n",
      "Epoch 13/20\n",
      "loss: 0.229086  [   70/  658]\n",
      "loss: 0.119692  [  210/  658]\n",
      "loss: 0.192261  [  350/  658]\n",
      "loss: 0.080176  [  490/  658]\n",
      "loss: 0.074112  [  630/  658]\n",
      "Training Loss (Epoch): 0.121551\n",
      "Validating...\n",
      "Validation Loss: 0.361039, Validation Accuracy: 88.48%\n",
      "Learning Rate: [1.5625e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 7\n",
      "Epoch 1/20\n",
      "loss: 2.327336  [   70/  670]\n",
      "loss: 2.117093  [  210/  670]\n",
      "loss: 1.948556  [  350/  670]\n",
      "loss: 1.849665  [  490/  670]\n",
      "loss: 1.770712  [  630/  670]\n",
      "Training Loss (Epoch): 1.996791\n",
      "Validating...\n",
      "Validation Loss: 1.975757, Validation Accuracy: 40.48%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 1.934868  [   70/  670]\n",
      "loss: 1.474099  [  210/  670]\n",
      "loss: 1.075939  [  350/  670]\n",
      "loss: 1.153849  [  490/  670]\n",
      "loss: 1.389902  [  630/  670]\n",
      "Training Loss (Epoch): 1.397336\n",
      "Validating...\n",
      "Validation Loss: 1.140602, Validation Accuracy: 57.14%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 1.104434  [   70/  670]\n",
      "loss: 1.158612  [  210/  670]\n",
      "loss: 0.686329  [  350/  670]\n",
      "loss: 1.029951  [  490/  670]\n",
      "loss: 0.697633  [  630/  670]\n",
      "Training Loss (Epoch): 0.927765\n",
      "Validating...\n",
      "Validation Loss: 0.855396, Validation Accuracy: 67.86%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/20\n",
      "loss: 0.791708  [   70/  670]\n",
      "loss: 0.826961  [  210/  670]\n",
      "loss: 0.787060  [  350/  670]\n",
      "loss: 0.535303  [  490/  670]\n",
      "loss: 0.525915  [  630/  670]\n",
      "Training Loss (Epoch): 0.678803\n",
      "Validating...\n",
      "Validation Loss: 0.773825, Validation Accuracy: 73.21%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/20\n",
      "loss: 0.423765  [   70/  670]\n",
      "loss: 0.352790  [  210/  670]\n",
      "loss: 0.435175  [  350/  670]\n",
      "loss: 0.404611  [  490/  670]\n",
      "loss: 0.443603  [  630/  670]\n",
      "Training Loss (Epoch): 0.432870\n",
      "Validating...\n",
      "Validation Loss: 0.548056, Validation Accuracy: 79.76%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/20\n",
      "loss: 0.434933  [   70/  670]\n",
      "loss: 0.205403  [  210/  670]\n",
      "loss: 0.493353  [  350/  670]\n",
      "loss: 0.288702  [  490/  670]\n",
      "loss: 0.241824  [  630/  670]\n",
      "Training Loss (Epoch): 0.319954\n",
      "Validating...\n",
      "Validation Loss: 0.544633, Validation Accuracy: 81.55%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 7/20\n",
      "loss: 0.252929  [   70/  670]\n",
      "loss: 0.181375  [  210/  670]\n",
      "loss: 0.260444  [  350/  670]\n",
      "loss: 0.136290  [  490/  670]\n",
      "loss: 0.247809  [  630/  670]\n",
      "Training Loss (Epoch): 0.286105\n",
      "Validating...\n",
      "Validation Loss: 0.426941, Validation Accuracy: 85.71%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 8/20\n",
      "loss: 0.229976  [   70/  670]\n",
      "loss: 0.179458  [  210/  670]\n",
      "loss: 0.126227  [  350/  670]\n",
      "loss: 0.225378  [  490/  670]\n",
      "loss: 0.215637  [  630/  670]\n",
      "Training Loss (Epoch): 0.231006\n",
      "Validating...\n",
      "Validation Loss: 0.521340, Validation Accuracy: 87.50%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 9/20\n",
      "loss: 0.143946  [   70/  670]\n",
      "loss: 0.050202  [  210/  670]\n",
      "loss: 0.290295  [  350/  670]\n",
      "loss: 0.097654  [  490/  670]\n",
      "loss: 0.166307  [  630/  670]\n",
      "Training Loss (Epoch): 0.161397\n",
      "Validating...\n",
      "Validation Loss: 0.461654, Validation Accuracy: 83.93%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 10/20\n",
      "loss: 0.146690  [   70/  670]\n",
      "loss: 0.069368  [  210/  670]\n",
      "loss: 0.064627  [  350/  670]\n",
      "loss: 0.225051  [  490/  670]\n",
      "loss: 0.179593  [  630/  670]\n",
      "Training Loss (Epoch): 0.121523\n",
      "Validating...\n",
      "Validation Loss: 0.527592, Validation Accuracy: 85.71%\n",
      "Learning Rate: [5e-05]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 8\n",
      "Epoch 1/20\n",
      "loss: 2.360890  [   70/  644]\n",
      "loss: 2.218903  [  210/  644]\n",
      "loss: 2.077142  [  350/  644]\n",
      "loss: 1.886163  [  490/  644]\n",
      "loss: 1.847758  [  630/  644]\n",
      "Training Loss (Epoch): 2.048838\n",
      "Validating...\n",
      "Validation Loss: 2.046566, Validation Accuracy: 43.21%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 2.015530  [   70/  644]\n",
      "loss: 1.842481  [  210/  644]\n",
      "loss: 1.593305  [  350/  644]\n",
      "loss: 0.938823  [  490/  644]\n",
      "loss: 0.961843  [  630/  644]\n",
      "Training Loss (Epoch): 1.434757\n",
      "Validating...\n",
      "Validation Loss: 1.180825, Validation Accuracy: 61.73%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 1.200832  [   70/  644]\n",
      "loss: 0.965213  [  210/  644]\n",
      "loss: 1.037644  [  350/  644]\n",
      "loss: 0.734804  [  490/  644]\n",
      "loss: 0.693704  [  630/  644]\n",
      "Training Loss (Epoch): 0.854401\n",
      "Validating...\n",
      "Validation Loss: 1.481695, Validation Accuracy: 54.94%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 4/20\n",
      "loss: 0.867765  [   70/  644]\n",
      "loss: 1.139539  [  210/  644]\n",
      "loss: 0.551081  [  350/  644]\n",
      "loss: 0.640421  [  490/  644]\n",
      "loss: 0.715384  [  630/  644]\n",
      "Training Loss (Epoch): 0.818172\n",
      "Validating...\n",
      "Validation Loss: 0.719221, Validation Accuracy: 72.22%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 5/20\n",
      "loss: 0.523447  [   70/  644]\n",
      "loss: 0.539693  [  210/  644]\n",
      "loss: 0.694603  [  350/  644]\n",
      "loss: 0.722384  [  490/  644]\n",
      "loss: 0.547731  [  630/  644]\n",
      "Training Loss (Epoch): 0.597221\n",
      "Validating...\n",
      "Validation Loss: 0.649053, Validation Accuracy: 75.31%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 6/20\n",
      "loss: 0.408039  [   70/  644]\n",
      "loss: 0.359750  [  210/  644]\n",
      "loss: 0.523925  [  350/  644]\n",
      "loss: 0.317504  [  490/  644]\n",
      "loss: 0.311002  [  630/  644]\n",
      "Training Loss (Epoch): 0.390530\n",
      "Validating...\n",
      "Validation Loss: 0.512374, Validation Accuracy: 79.01%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 7/20\n",
      "loss: 0.336140  [   70/  644]\n",
      "loss: 0.348682  [  210/  644]\n",
      "loss: 0.157333  [  350/  644]\n",
      "loss: 0.279576  [  490/  644]\n",
      "loss: 0.508805  [  630/  644]\n",
      "Training Loss (Epoch): 0.392270\n",
      "Validating...\n",
      "Validation Loss: 0.510237, Validation Accuracy: 78.40%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 8/20\n",
      "loss: 0.337827  [   70/  644]\n",
      "loss: 0.178556  [  210/  644]\n",
      "loss: 0.366552  [  350/  644]\n",
      "loss: 0.329015  [  490/  644]\n",
      "loss: 0.216461  [  630/  644]\n",
      "Training Loss (Epoch): 0.255340\n",
      "Validating...\n",
      "Validation Loss: 0.437242, Validation Accuracy: 81.48%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 9/20\n",
      "loss: 0.201722  [   70/  644]\n",
      "loss: 0.181322  [  210/  644]\n",
      "loss: 0.130355  [  350/  644]\n",
      "loss: 0.224361  [  490/  644]\n",
      "loss: 0.120832  [  630/  644]\n",
      "Training Loss (Epoch): 0.184991\n",
      "Validating...\n",
      "Validation Loss: 0.390594, Validation Accuracy: 85.80%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 10/20\n",
      "loss: 0.112719  [   70/  644]\n",
      "loss: 0.208607  [  210/  644]\n",
      "loss: 0.155540  [  350/  644]\n",
      "loss: 0.226291  [  490/  644]\n",
      "loss: 0.136542  [  630/  644]\n",
      "Training Loss (Epoch): 0.137813\n",
      "Validating...\n",
      "Validation Loss: 0.384201, Validation Accuracy: 83.95%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 11/20\n",
      "loss: 0.095610  [   70/  644]\n",
      "loss: 0.179213  [  210/  644]\n",
      "loss: 0.175008  [  350/  644]\n",
      "loss: 0.088698  [  490/  644]\n",
      "loss: 0.081244  [  630/  644]\n",
      "Training Loss (Epoch): 0.125670\n",
      "Validating...\n",
      "Validation Loss: 0.356423, Validation Accuracy: 87.04%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 12/20\n",
      "loss: 0.074389  [   70/  644]\n",
      "loss: 0.112253  [  210/  644]\n",
      "loss: 0.072613  [  350/  644]\n",
      "loss: 0.099039  [  490/  644]\n",
      "loss: 0.105300  [  630/  644]\n",
      "Training Loss (Epoch): 0.126955\n",
      "Validating...\n",
      "Validation Loss: 0.336648, Validation Accuracy: 87.65%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 13/20\n",
      "loss: 0.169440  [   70/  644]\n",
      "loss: 0.074179  [  210/  644]\n",
      "loss: 0.144059  [  350/  644]\n",
      "loss: 0.060592  [  490/  644]\n",
      "loss: 0.117921  [  630/  644]\n",
      "Training Loss (Epoch): 0.096578\n",
      "Validating...\n",
      "Validation Loss: 0.320813, Validation Accuracy: 90.74%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 14/20\n",
      "loss: 0.109800  [   70/  644]\n",
      "loss: 0.071821  [  210/  644]\n",
      "loss: 0.060928  [  350/  644]\n",
      "loss: 0.072817  [  490/  644]\n",
      "loss: 0.070342  [  630/  644]\n",
      "Training Loss (Epoch): 0.088271\n",
      "Validating...\n",
      "Validation Loss: 0.329469, Validation Accuracy: 88.89%\n",
      "Learning Rate: [6.25e-06]\n",
      "Epoch 15/20\n",
      "loss: 0.130734  [   70/  644]\n",
      "loss: 0.086088  [  210/  644]\n",
      "loss: 0.060022  [  350/  644]\n",
      "loss: 0.131643  [  490/  644]\n",
      "loss: 0.049054  [  630/  644]\n",
      "Training Loss (Epoch): 0.076352\n",
      "Validating...\n",
      "Validation Loss: 0.330170, Validation Accuracy: 89.51%\n",
      "Learning Rate: [3.125e-06]\n",
      "Epoch 16/20\n",
      "loss: 0.073018  [   70/  644]\n",
      "loss: 0.071281  [  210/  644]\n",
      "loss: 0.075566  [  350/  644]\n",
      "loss: 0.051961  [  490/  644]\n",
      "loss: 0.051375  [  630/  644]\n",
      "Training Loss (Epoch): 0.085799\n",
      "Validating...\n",
      "Validation Loss: 0.329832, Validation Accuracy: 87.65%\n",
      "Learning Rate: [1.5625e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 9\n",
      "Epoch 1/20\n",
      "loss: 2.315544  [   70/  652]\n",
      "loss: 2.087348  [  210/  652]\n",
      "loss: 1.801464  [  350/  652]\n",
      "loss: 1.685402  [  490/  652]\n",
      "loss: 1.678598  [  630/  652]\n",
      "Training Loss (Epoch): 1.883705\n",
      "Validating...\n",
      "Validation Loss: 1.867579, Validation Accuracy: 51.22%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 1.837099  [   70/  652]\n",
      "loss: 1.365943  [  210/  652]\n",
      "loss: 1.048330  [  350/  652]\n",
      "loss: 0.757441  [  490/  652]\n",
      "loss: 0.948045  [  630/  652]\n",
      "Training Loss (Epoch): 1.180326\n",
      "Validating...\n",
      "Validation Loss: 0.807860, Validation Accuracy: 70.73%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 0.730007  [   70/  652]\n",
      "loss: 0.647456  [  210/  652]\n",
      "loss: 0.600444  [  350/  652]\n",
      "loss: 0.698813  [  490/  652]\n",
      "loss: 0.655124  [  630/  652]\n",
      "Training Loss (Epoch): 0.680589\n",
      "Validating...\n",
      "Validation Loss: 0.886577, Validation Accuracy: 64.63%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 4/20\n",
      "loss: 0.806524  [   70/  652]\n",
      "loss: 0.286937  [  210/  652]\n",
      "loss: 0.444806  [  350/  652]\n",
      "loss: 0.603161  [  490/  652]\n",
      "loss: 0.376903  [  630/  652]\n",
      "Training Loss (Epoch): 0.474738\n",
      "Validating...\n",
      "Validation Loss: 0.427794, Validation Accuracy: 85.98%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 5/20\n",
      "loss: 0.307820  [   70/  652]\n",
      "loss: 0.293034  [  210/  652]\n",
      "loss: 0.345993  [  350/  652]\n",
      "loss: 0.260778  [  490/  652]\n",
      "loss: 0.201183  [  630/  652]\n",
      "Training Loss (Epoch): 0.264844\n",
      "Validating...\n",
      "Validation Loss: 0.475835, Validation Accuracy: 84.15%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 6/20\n",
      "loss: 0.300191  [   70/  652]\n",
      "loss: 0.246826  [  210/  652]\n",
      "loss: 0.297624  [  350/  652]\n",
      "loss: 0.153994  [  490/  652]\n",
      "loss: 0.134565  [  630/  652]\n",
      "Training Loss (Epoch): 0.203140\n",
      "Validating...\n",
      "Validation Loss: 0.424160, Validation Accuracy: 87.20%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 7/20\n",
      "loss: 0.194146  [   70/  652]\n",
      "loss: 0.132985  [  210/  652]\n",
      "loss: 0.164461  [  350/  652]\n",
      "loss: 0.123833  [  490/  652]\n",
      "loss: 0.110794  [  630/  652]\n",
      "Training Loss (Epoch): 0.142142\n",
      "Validating...\n",
      "Validation Loss: 0.376896, Validation Accuracy: 89.02%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 8/20\n",
      "loss: 0.152462  [   70/  652]\n",
      "loss: 0.155465  [  210/  652]\n",
      "loss: 0.133014  [  350/  652]\n",
      "loss: 0.112047  [  490/  652]\n",
      "loss: 0.101905  [  630/  652]\n",
      "Training Loss (Epoch): 0.118997\n",
      "Validating...\n",
      "Validation Loss: 0.448847, Validation Accuracy: 90.24%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 9/20\n",
      "loss: 0.084433  [   70/  652]\n",
      "loss: 0.089592  [  210/  652]\n",
      "loss: 0.155978  [  350/  652]\n",
      "loss: 0.108015  [  490/  652]\n",
      "loss: 0.041925  [  630/  652]\n",
      "Training Loss (Epoch): 0.097575\n",
      "Validating...\n",
      "Validation Loss: 0.427361, Validation Accuracy: 89.63%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 10/20\n",
      "loss: 0.051279  [   70/  652]\n",
      "loss: 0.083196  [  210/  652]\n",
      "loss: 0.075434  [  350/  652]\n",
      "loss: 0.081122  [  490/  652]\n",
      "loss: 0.057846  [  630/  652]\n",
      "Training Loss (Epoch): 0.076846\n",
      "Validating...\n",
      "Validation Loss: 0.422186, Validation Accuracy: 90.24%\n",
      "Learning Rate: [1.25e-05]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 10\n",
      "Epoch 1/20\n",
      "loss: 2.384461  [   70/  669]\n",
      "loss: 2.163725  [  210/  669]\n",
      "loss: 2.044364  [  350/  669]\n",
      "loss: 1.836701  [  490/  669]\n",
      "loss: 1.667063  [  630/  669]\n",
      "Training Loss (Epoch): 2.011488\n",
      "Validating...\n",
      "Validation Loss: 1.930583, Validation Accuracy: 43.45%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 1.954475  [   70/  669]\n",
      "loss: 1.595603  [  210/  669]\n",
      "loss: 1.420860  [  350/  669]\n",
      "loss: 1.162988  [  490/  669]\n",
      "loss: 1.122729  [  630/  669]\n",
      "Training Loss (Epoch): 1.441223\n",
      "Validating...\n",
      "Validation Loss: 0.839633, Validation Accuracy: 72.02%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 0.737842  [   70/  669]\n",
      "loss: 0.937677  [  210/  669]\n",
      "loss: 0.652121  [  350/  669]\n",
      "loss: 0.856837  [  490/  669]\n",
      "loss: 0.631406  [  630/  669]\n",
      "Training Loss (Epoch): 0.774540\n",
      "Validating...\n",
      "Validation Loss: 0.976824, Validation Accuracy: 72.62%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 4/20\n",
      "loss: 0.817205  [   70/  669]\n",
      "loss: 0.495619  [  210/  669]\n",
      "loss: 0.668308  [  350/  669]\n",
      "loss: 0.574201  [  490/  669]\n",
      "loss: 0.515198  [  630/  669]\n",
      "Training Loss (Epoch): 0.568464\n",
      "Validating...\n",
      "Validation Loss: 0.663400, Validation Accuracy: 77.38%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 5/20\n",
      "loss: 0.520929  [   70/  669]\n",
      "loss: 0.355622  [  210/  669]\n",
      "loss: 0.268555  [  350/  669]\n",
      "loss: 0.320071  [  490/  669]\n",
      "loss: 0.401766  [  630/  669]\n",
      "Training Loss (Epoch): 0.448276\n",
      "Validating...\n",
      "Validation Loss: 0.520189, Validation Accuracy: 81.55%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 6/20\n",
      "loss: 0.341116  [   70/  669]\n",
      "loss: 0.379863  [  210/  669]\n",
      "loss: 0.324625  [  350/  669]\n",
      "loss: 0.391485  [  490/  669]\n",
      "loss: 0.247273  [  630/  669]\n",
      "Training Loss (Epoch): 0.363532\n",
      "Validating...\n",
      "Validation Loss: 0.545928, Validation Accuracy: 83.93%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 7/20\n",
      "loss: 0.284354  [   70/  669]\n",
      "loss: 0.404754  [  210/  669]\n",
      "loss: 0.206081  [  350/  669]\n",
      "loss: 0.328877  [  490/  669]\n",
      "loss: 0.437552  [  630/  669]\n",
      "Training Loss (Epoch): 0.311637\n",
      "Validating...\n",
      "Validation Loss: 0.468233, Validation Accuracy: 85.71%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 8/20\n",
      "loss: 0.204906  [   70/  669]\n",
      "loss: 0.237689  [  210/  669]\n",
      "loss: 0.207060  [  350/  669]\n",
      "loss: 0.277340  [  490/  669]\n",
      "loss: 0.348632  [  630/  669]\n",
      "Training Loss (Epoch): 0.263803\n",
      "Validating...\n",
      "Validation Loss: 0.508461, Validation Accuracy: 82.14%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 9/20\n",
      "loss: 0.166275  [   70/  669]\n",
      "loss: 0.192727  [  210/  669]\n",
      "loss: 0.172167  [  350/  669]\n",
      "loss: 0.318952  [  490/  669]\n",
      "loss: 0.240400  [  630/  669]\n",
      "Training Loss (Epoch): 0.233242\n",
      "Validating...\n",
      "Validation Loss: 0.504640, Validation Accuracy: 84.52%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 10/20\n",
      "loss: 0.158885  [   70/  669]\n",
      "loss: 0.192225  [  210/  669]\n",
      "loss: 0.161683  [  350/  669]\n",
      "loss: 0.195024  [  490/  669]\n",
      "loss: 0.250113  [  630/  669]\n",
      "Training Loss (Epoch): 0.186811\n",
      "Validating...\n",
      "Validation Loss: 0.468077, Validation Accuracy: 85.71%\n",
      "Learning Rate: [1.25e-05]\n",
      "Early stopping triggered. Training stopped.\n",
      "\n",
      "Cross-Validation Results:\n",
      "Avg Training Loss: 0.518947\n",
      "Avg Validation Loss: 0.673442\n",
      "Avg Validation Accuracy: 78.34%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dense_tune(layer = 3, lr = 2e-4, weight_decay = 0.2, weights = \"DEFAULT\", drop = 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1\n",
      "Epoch 1/20\n",
      "loss: 2.345630  [   70/  698]\n",
      "loss: 2.251592  [  210/  698]\n",
      "loss: 2.221283  [  350/  698]\n",
      "loss: 2.066443  [  490/  698]\n",
      "loss: 2.048594  [  630/  698]\n",
      "Training Loss (Epoch): 2.198322\n",
      "Validating...\n",
      "Validation Loss: 2.172462, Validation Accuracy: 33.71%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 2.187246  [   70/  698]\n",
      "loss: 2.087860  [  210/  698]\n",
      "loss: 1.968873  [  350/  698]\n",
      "loss: 1.856637  [  490/  698]\n",
      "loss: 1.765840  [  630/  698]\n",
      "Training Loss (Epoch): 1.928014\n",
      "Validating...\n",
      "Validation Loss: 1.618063, Validation Accuracy: 50.29%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 1.639433  [   70/  698]\n",
      "loss: 1.311768  [  210/  698]\n",
      "loss: 1.326423  [  350/  698]\n",
      "loss: 1.108037  [  490/  698]\n",
      "loss: 1.128855  [  630/  698]\n",
      "Training Loss (Epoch): 1.283857\n",
      "Validating...\n",
      "Validation Loss: 1.093366, Validation Accuracy: 60.57%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/20\n",
      "loss: 1.027994  [   70/  698]\n",
      "loss: 0.938204  [  210/  698]\n",
      "loss: 0.800702  [  350/  698]\n",
      "loss: 0.747084  [  490/  698]\n",
      "loss: 0.719803  [  630/  698]\n",
      "Training Loss (Epoch): 0.832555\n",
      "Validating...\n",
      "Validation Loss: 0.762063, Validation Accuracy: 78.29%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/20\n",
      "loss: 0.659934  [   70/  698]\n",
      "loss: 0.637138  [  210/  698]\n",
      "loss: 0.499844  [  350/  698]\n",
      "loss: 0.527821  [  490/  698]\n",
      "loss: 0.578289  [  630/  698]\n",
      "Training Loss (Epoch): 0.532791\n",
      "Validating...\n",
      "Validation Loss: 0.514031, Validation Accuracy: 83.43%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/20\n",
      "loss: 0.402743  [   70/  698]\n",
      "loss: 0.267258  [  210/  698]\n",
      "loss: 0.312726  [  350/  698]\n",
      "loss: 0.319633  [  490/  698]\n",
      "loss: 0.381904  [  630/  698]\n",
      "Training Loss (Epoch): 0.323576\n",
      "Validating...\n",
      "Validation Loss: 0.438239, Validation Accuracy: 87.43%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 7/20\n",
      "loss: 0.345795  [   70/  698]\n",
      "loss: 0.135077  [  210/  698]\n",
      "loss: 0.202808  [  350/  698]\n",
      "loss: 0.184986  [  490/  698]\n",
      "loss: 0.317390  [  630/  698]\n",
      "Training Loss (Epoch): 0.260461\n",
      "Validating...\n",
      "Validation Loss: 0.408513, Validation Accuracy: 84.57%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 8/20\n",
      "loss: 0.125162  [   70/  698]\n",
      "loss: 0.239498  [  210/  698]\n",
      "loss: 0.152578  [  350/  698]\n",
      "loss: 0.215777  [  490/  698]\n",
      "loss: 0.112869  [  630/  698]\n",
      "Training Loss (Epoch): 0.175461\n",
      "Validating...\n",
      "Validation Loss: 0.317670, Validation Accuracy: 88.00%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 9/20\n",
      "loss: 0.121214  [   70/  698]\n",
      "loss: 0.092341  [  210/  698]\n",
      "loss: 0.124982  [  350/  698]\n",
      "loss: 0.130544  [  490/  698]\n",
      "loss: 0.100875  [  630/  698]\n",
      "Training Loss (Epoch): 0.128587\n",
      "Validating...\n",
      "Validation Loss: 0.298224, Validation Accuracy: 90.29%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 10/20\n",
      "loss: 0.168635  [   70/  698]\n",
      "loss: 0.113163  [  210/  698]\n",
      "loss: 0.048917  [  350/  698]\n",
      "loss: 0.082736  [  490/  698]\n",
      "loss: 0.070554  [  630/  698]\n",
      "Training Loss (Epoch): 0.109519\n",
      "Validating...\n",
      "Validation Loss: 0.283094, Validation Accuracy: 88.57%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 11/20\n",
      "loss: 0.097683  [   70/  698]\n",
      "loss: 0.094880  [  210/  698]\n",
      "loss: 0.047141  [  350/  698]\n",
      "loss: 0.162985  [  490/  698]\n",
      "loss: 0.138070  [  630/  698]\n",
      "Training Loss (Epoch): 0.096860\n",
      "Validating...\n",
      "Validation Loss: 0.274355, Validation Accuracy: 89.71%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 12/20\n",
      "loss: 0.060570  [   70/  698]\n",
      "loss: 0.081369  [  210/  698]\n",
      "loss: 0.058465  [  350/  698]\n",
      "loss: 0.087977  [  490/  698]\n",
      "loss: 0.098653  [  630/  698]\n",
      "Training Loss (Epoch): 0.091346\n",
      "Validating...\n",
      "Validation Loss: 0.273651, Validation Accuracy: 89.14%\n",
      "Learning Rate: [6.25e-06]\n",
      "Epoch 13/20\n",
      "loss: 0.071430  [   70/  698]\n",
      "loss: 0.110789  [  210/  698]\n",
      "loss: 0.093009  [  350/  698]\n",
      "loss: 0.071808  [  490/  698]\n",
      "loss: 0.082042  [  630/  698]\n",
      "Training Loss (Epoch): 0.087436\n",
      "Validating...\n",
      "Validation Loss: 0.275283, Validation Accuracy: 89.14%\n",
      "Learning Rate: [3.125e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 2\n",
      "Epoch 1/20\n",
      "loss: 2.347645  [   70/  710]\n",
      "loss: 2.233132  [  210/  710]\n",
      "loss: 2.114766  [  350/  710]\n",
      "loss: 2.103601  [  490/  710]\n",
      "loss: 2.149550  [  630/  710]\n",
      "loss: 2.233290  [  110/  710]\n",
      "Training Loss (Epoch): 2.187694\n",
      "Validating...\n",
      "Validation Loss: 2.116805, Validation Accuracy: 34.27%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 2.111121  [   70/  710]\n",
      "loss: 1.962566  [  210/  710]\n",
      "loss: 1.853025  [  350/  710]\n",
      "loss: 1.651365  [  490/  710]\n",
      "loss: 1.739227  [  630/  710]\n",
      "loss: 1.502746  [  110/  710]\n",
      "Training Loss (Epoch): 1.788715\n",
      "Validating...\n",
      "Validation Loss: 1.625478, Validation Accuracy: 48.88%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 1.286253  [   70/  710]\n",
      "loss: 1.345609  [  210/  710]\n",
      "loss: 1.085721  [  350/  710]\n",
      "loss: 1.088404  [  490/  710]\n",
      "loss: 0.896889  [  630/  710]\n",
      "loss: 0.609382  [  110/  710]\n",
      "Training Loss (Epoch): 1.122888\n",
      "Validating...\n",
      "Validation Loss: 1.062939, Validation Accuracy: 63.48%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/20\n",
      "loss: 0.839375  [   70/  710]\n",
      "loss: 0.759345  [  210/  710]\n",
      "loss: 0.592819  [  350/  710]\n",
      "loss: 0.748333  [  490/  710]\n",
      "loss: 0.612601  [  630/  710]\n",
      "loss: 1.383365  [  110/  710]\n",
      "Training Loss (Epoch): 0.777067\n",
      "Validating...\n",
      "Validation Loss: 0.798335, Validation Accuracy: 72.47%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/20\n",
      "loss: 0.543876  [   70/  710]\n",
      "loss: 0.568487  [  210/  710]\n",
      "loss: 0.863215  [  350/  710]\n",
      "loss: 0.541169  [  490/  710]\n",
      "loss: 0.651405  [  630/  710]\n",
      "loss: 0.485745  [  110/  710]\n",
      "Training Loss (Epoch): 0.623224\n",
      "Validating...\n",
      "Validation Loss: 0.751441, Validation Accuracy: 77.53%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/20\n",
      "loss: 0.360109  [   70/  710]\n",
      "loss: 0.522062  [  210/  710]\n",
      "loss: 0.438102  [  350/  710]\n",
      "loss: 0.248719  [  490/  710]\n",
      "loss: 0.305296  [  630/  710]\n",
      "loss: 0.168217  [  110/  710]\n",
      "Training Loss (Epoch): 0.377251\n",
      "Validating...\n",
      "Validation Loss: 0.622245, Validation Accuracy: 81.46%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 7/20\n",
      "loss: 0.421869  [   70/  710]\n",
      "loss: 0.389972  [  210/  710]\n",
      "loss: 0.190430  [  350/  710]\n",
      "loss: 0.281432  [  490/  710]\n",
      "loss: 0.116079  [  630/  710]\n",
      "loss: 0.174823  [  110/  710]\n",
      "Training Loss (Epoch): 0.271514\n",
      "Validating...\n",
      "Validation Loss: 0.506258, Validation Accuracy: 81.46%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 8/20\n",
      "loss: 0.220778  [   70/  710]\n",
      "loss: 0.291065  [  210/  710]\n",
      "loss: 0.336802  [  350/  710]\n",
      "loss: 0.200694  [  490/  710]\n",
      "loss: 0.239685  [  630/  710]\n",
      "loss: 0.121881  [  110/  710]\n",
      "Training Loss (Epoch): 0.246367\n",
      "Validating...\n",
      "Validation Loss: 0.624535, Validation Accuracy: 79.78%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 9/20\n",
      "loss: 0.096779  [   70/  710]\n",
      "loss: 0.310487  [  210/  710]\n",
      "loss: 0.202265  [  350/  710]\n",
      "loss: 0.192533  [  490/  710]\n",
      "loss: 0.176364  [  630/  710]\n",
      "loss: 0.242631  [  110/  710]\n",
      "Training Loss (Epoch): 0.190500\n",
      "Validating...\n",
      "Validation Loss: 0.397158, Validation Accuracy: 88.76%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 10/20\n",
      "loss: 0.148847  [   70/  710]\n",
      "loss: 0.160579  [  210/  710]\n",
      "loss: 0.283278  [  350/  710]\n",
      "loss: 0.207516  [  490/  710]\n",
      "loss: 0.166283  [  630/  710]\n",
      "loss: 0.026517  [  110/  710]\n",
      "Training Loss (Epoch): 0.154446\n",
      "Validating...\n",
      "Validation Loss: 0.397293, Validation Accuracy: 87.64%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 11/20\n",
      "loss: 0.110738  [   70/  710]\n",
      "loss: 0.081553  [  210/  710]\n",
      "loss: 0.141126  [  350/  710]\n",
      "loss: 0.099483  [  490/  710]\n",
      "loss: 0.134775  [  630/  710]\n",
      "loss: 0.073743  [  110/  710]\n",
      "Training Loss (Epoch): 0.123503\n",
      "Validating...\n",
      "Validation Loss: 0.385576, Validation Accuracy: 88.20%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 12/20\n",
      "loss: 0.154940  [   70/  710]\n",
      "loss: 0.121101  [  210/  710]\n",
      "loss: 0.092190  [  350/  710]\n",
      "loss: 0.092484  [  490/  710]\n",
      "loss: 0.155495  [  630/  710]\n",
      "loss: 0.061739  [  110/  710]\n",
      "Training Loss (Epoch): 0.113988\n",
      "Validating...\n",
      "Validation Loss: 0.371332, Validation Accuracy: 88.20%\n",
      "Learning Rate: [6.25e-06]\n",
      "Epoch 13/20\n",
      "loss: 0.107209  [   70/  710]\n",
      "loss: 0.171647  [  210/  710]\n",
      "loss: 0.098873  [  350/  710]\n",
      "loss: 0.132212  [  490/  710]\n",
      "loss: 0.071234  [  630/  710]\n",
      "loss: 0.135982  [  110/  710]\n",
      "Training Loss (Epoch): 0.119716\n",
      "Validating...\n",
      "Validation Loss: 0.371210, Validation Accuracy: 88.76%\n",
      "Learning Rate: [3.125e-06]\n",
      "Epoch 14/20\n",
      "loss: 0.119088  [   70/  710]\n",
      "loss: 0.140932  [  210/  710]\n",
      "loss: 0.150520  [  350/  710]\n",
      "loss: 0.138066  [  490/  710]\n",
      "loss: 0.117447  [  630/  710]\n",
      "loss: 0.087778  [  110/  710]\n",
      "Training Loss (Epoch): 0.114597\n",
      "Validating...\n",
      "Validation Loss: 0.379164, Validation Accuracy: 88.76%\n",
      "Learning Rate: [1.5625e-06]\n",
      "Epoch 15/20\n",
      "loss: 0.085896  [   70/  710]\n",
      "loss: 0.102912  [  210/  710]\n",
      "loss: 0.061232  [  350/  710]\n",
      "loss: 0.109296  [  490/  710]\n",
      "loss: 0.214363  [  630/  710]\n",
      "loss: 0.218682  [  110/  710]\n",
      "Training Loss (Epoch): 0.128575\n",
      "Validating...\n",
      "Validation Loss: 0.382012, Validation Accuracy: 88.76%\n",
      "Learning Rate: [7.8125e-07]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 3\n",
      "Epoch 1/20\n",
      "loss: 2.335367  [   70/  740]\n",
      "loss: 2.379182  [  210/  740]\n",
      "loss: 2.287864  [  350/  740]\n",
      "loss: 2.222192  [  490/  740]\n",
      "loss: 2.198272  [  630/  740]\n",
      "loss: 2.088326  [  440/  740]\n",
      "Training Loss (Epoch): 2.234791\n",
      "Validating...\n",
      "Validation Loss: 2.218815, Validation Accuracy: 23.78%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 2.123795  [   70/  740]\n",
      "loss: 2.086973  [  210/  740]\n",
      "loss: 1.940191  [  350/  740]\n",
      "loss: 1.920817  [  490/  740]\n",
      "loss: 1.785020  [  630/  740]\n",
      "loss: 1.533407  [  440/  740]\n",
      "Training Loss (Epoch): 1.923144\n",
      "Validating...\n",
      "Validation Loss: 1.566780, Validation Accuracy: 54.59%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 1.421363  [   70/  740]\n",
      "loss: 1.317608  [  210/  740]\n",
      "loss: 1.109697  [  350/  740]\n",
      "loss: 1.317959  [  490/  740]\n",
      "loss: 0.828217  [  630/  740]\n",
      "loss: 0.811531  [  440/  740]\n",
      "Training Loss (Epoch): 1.186357\n",
      "Validating...\n",
      "Validation Loss: 1.000788, Validation Accuracy: 70.81%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/20\n",
      "loss: 0.938486  [   70/  740]\n",
      "loss: 0.600974  [  210/  740]\n",
      "loss: 0.832129  [  350/  740]\n",
      "loss: 0.671946  [  490/  740]\n",
      "loss: 0.812694  [  630/  740]\n",
      "loss: 0.641167  [  440/  740]\n",
      "Training Loss (Epoch): 0.784838\n",
      "Validating...\n",
      "Validation Loss: 0.819821, Validation Accuracy: 75.68%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/20\n",
      "loss: 0.838314  [   70/  740]\n",
      "loss: 0.549606  [  210/  740]\n",
      "loss: 0.384137  [  350/  740]\n",
      "loss: 0.605568  [  490/  740]\n",
      "loss: 0.303342  [  630/  740]\n",
      "loss: 0.533266  [  440/  740]\n",
      "Training Loss (Epoch): 0.520276\n",
      "Validating...\n",
      "Validation Loss: 0.629730, Validation Accuracy: 79.46%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/20\n",
      "loss: 0.528921  [   70/  740]\n",
      "loss: 0.320393  [  210/  740]\n",
      "loss: 0.357453  [  350/  740]\n",
      "loss: 0.250838  [  490/  740]\n",
      "loss: 0.322258  [  630/  740]\n",
      "loss: 0.227858  [  440/  740]\n",
      "Training Loss (Epoch): 0.351050\n",
      "Validating...\n",
      "Validation Loss: 0.573120, Validation Accuracy: 78.92%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 7/20\n",
      "loss: 0.379516  [   70/  740]\n",
      "loss: 0.355477  [  210/  740]\n",
      "loss: 0.103649  [  350/  740]\n",
      "loss: 0.407603  [  490/  740]\n",
      "loss: 0.176477  [  630/  740]\n",
      "loss: 0.442463  [  440/  740]\n",
      "Training Loss (Epoch): 0.261362\n",
      "Validating...\n",
      "Validation Loss: 0.497833, Validation Accuracy: 81.08%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 8/20\n",
      "loss: 0.179683  [   70/  740]\n",
      "loss: 0.173457  [  210/  740]\n",
      "loss: 0.164718  [  350/  740]\n",
      "loss: 0.296122  [  490/  740]\n",
      "loss: 0.174245  [  630/  740]\n",
      "loss: 0.409108  [  440/  740]\n",
      "Training Loss (Epoch): 0.224015\n",
      "Validating...\n",
      "Validation Loss: 0.467112, Validation Accuracy: 80.54%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 9/20\n",
      "loss: 0.104705  [   70/  740]\n",
      "loss: 0.128428  [  210/  740]\n",
      "loss: 0.155794  [  350/  740]\n",
      "loss: 0.164773  [  490/  740]\n",
      "loss: 0.317037  [  630/  740]\n",
      "loss: 0.073513  [  440/  740]\n",
      "Training Loss (Epoch): 0.169988\n",
      "Validating...\n",
      "Validation Loss: 0.428672, Validation Accuracy: 83.24%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 10/20\n",
      "loss: 0.213060  [   70/  740]\n",
      "loss: 0.228906  [  210/  740]\n",
      "loss: 0.120854  [  350/  740]\n",
      "loss: 0.083133  [  490/  740]\n",
      "loss: 0.254032  [  630/  740]\n",
      "loss: 0.149139  [  440/  740]\n",
      "Training Loss (Epoch): 0.162972\n",
      "Validating...\n",
      "Validation Loss: 0.423788, Validation Accuracy: 84.32%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 11/20\n",
      "loss: 0.049380  [   70/  740]\n",
      "loss: 0.107328  [  210/  740]\n",
      "loss: 0.193024  [  350/  740]\n",
      "loss: 0.324813  [  490/  740]\n",
      "loss: 0.097808  [  630/  740]\n",
      "loss: 0.055226  [  440/  740]\n",
      "Training Loss (Epoch): 0.139493\n",
      "Validating...\n",
      "Validation Loss: 0.434903, Validation Accuracy: 81.08%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 12/20\n",
      "loss: 0.177084  [   70/  740]\n",
      "loss: 0.085501  [  210/  740]\n",
      "loss: 0.098331  [  350/  740]\n",
      "loss: 0.109114  [  490/  740]\n",
      "loss: 0.054983  [  630/  740]\n",
      "loss: 0.082379  [  440/  740]\n",
      "Training Loss (Epoch): 0.115347\n",
      "Validating...\n",
      "Validation Loss: 0.407128, Validation Accuracy: 85.95%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 13/20\n",
      "loss: 0.102172  [   70/  740]\n",
      "loss: 0.126111  [  210/  740]\n",
      "loss: 0.037548  [  350/  740]\n",
      "loss: 0.050554  [  490/  740]\n",
      "loss: 0.161235  [  630/  740]\n",
      "loss: 0.162430  [  440/  740]\n",
      "Training Loss (Epoch): 0.108213\n",
      "Validating...\n",
      "Validation Loss: 0.412291, Validation Accuracy: 83.24%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 14/20\n",
      "loss: 0.061441  [   70/  740]\n",
      "loss: 0.152525  [  210/  740]\n",
      "loss: 0.135961  [  350/  740]\n",
      "loss: 0.107179  [  490/  740]\n",
      "loss: 0.109787  [  630/  740]\n",
      "loss: 0.119969  [  440/  740]\n",
      "Training Loss (Epoch): 0.108686\n",
      "Validating...\n",
      "Validation Loss: 0.401506, Validation Accuracy: 84.32%\n",
      "Learning Rate: [6.25e-06]\n",
      "Epoch 15/20\n",
      "loss: 0.084906  [   70/  740]\n",
      "loss: 0.061081  [  210/  740]\n",
      "loss: 0.137563  [  350/  740]\n",
      "loss: 0.136944  [  490/  740]\n",
      "loss: 0.124443  [  630/  740]\n",
      "loss: 0.025915  [  440/  740]\n",
      "Training Loss (Epoch): 0.098025\n",
      "Validating...\n",
      "Validation Loss: 0.391582, Validation Accuracy: 84.86%\n",
      "Learning Rate: [3.125e-06]\n",
      "Epoch 16/20\n",
      "loss: 0.034340  [   70/  740]\n",
      "loss: 0.144647  [  210/  740]\n",
      "loss: 0.160759  [  350/  740]\n",
      "loss: 0.067650  [  490/  740]\n",
      "loss: 0.119580  [  630/  740]\n",
      "loss: 0.105444  [  440/  740]\n",
      "Training Loss (Epoch): 0.107831\n",
      "Validating...\n",
      "Validation Loss: 0.391916, Validation Accuracy: 84.32%\n",
      "Learning Rate: [1.5625e-06]\n",
      "Epoch 17/20\n",
      "loss: 0.164020  [   70/  740]\n",
      "loss: 0.171447  [  210/  740]\n",
      "loss: 0.046056  [  350/  740]\n",
      "loss: 0.051969  [  490/  740]\n",
      "loss: 0.052498  [  630/  740]\n",
      "loss: 0.103696  [  440/  740]\n",
      "Training Loss (Epoch): 0.099181\n",
      "Validating...\n",
      "Validation Loss: 0.393462, Validation Accuracy: 84.32%\n",
      "Learning Rate: [7.8125e-07]\n",
      "Epoch 18/20\n",
      "loss: 0.041191  [   70/  740]\n",
      "loss: 0.147626  [  210/  740]\n",
      "loss: 0.125005  [  350/  740]\n",
      "loss: 0.072370  [  490/  740]\n",
      "loss: 0.044137  [  630/  740]\n",
      "loss: 0.132198  [  440/  740]\n",
      "Training Loss (Epoch): 0.102174\n",
      "Validating...\n",
      "Validation Loss: 0.393862, Validation Accuracy: 84.32%\n",
      "Learning Rate: [3.90625e-07]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 4\n",
      "Epoch 1/20\n",
      "loss: 2.366894  [   70/  792]\n",
      "loss: 2.249876  [  210/  792]\n",
      "loss: 2.281868  [  350/  792]\n",
      "loss: 2.213992  [  490/  792]\n",
      "loss: 2.109446  [  630/  792]\n",
      "loss: 2.224183  [  770/  792]\n",
      "Training Loss (Epoch): 2.194901\n",
      "Validating...\n",
      "Validation Loss: 2.154401, Validation Accuracy: 29.80%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 2.128042  [   70/  792]\n",
      "loss: 2.066917  [  210/  792]\n",
      "loss: 1.928385  [  350/  792]\n",
      "loss: 1.938804  [  490/  792]\n",
      "loss: 1.702494  [  630/  792]\n",
      "loss: 1.738344  [  770/  792]\n",
      "Training Loss (Epoch): 1.922687\n",
      "Validating...\n",
      "Validation Loss: 1.491633, Validation Accuracy: 53.54%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 1.326330  [   70/  792]\n",
      "loss: 1.451952  [  210/  792]\n",
      "loss: 1.438740  [  350/  792]\n",
      "loss: 1.109474  [  490/  792]\n",
      "loss: 1.086824  [  630/  792]\n",
      "loss: 0.915734  [  770/  792]\n",
      "Training Loss (Epoch): 1.235643\n",
      "Validating...\n",
      "Validation Loss: 0.966525, Validation Accuracy: 70.71%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/20\n",
      "loss: 1.004030  [   70/  792]\n",
      "loss: 0.811437  [  210/  792]\n",
      "loss: 0.700386  [  350/  792]\n",
      "loss: 0.738233  [  490/  792]\n",
      "loss: 0.658132  [  630/  792]\n",
      "loss: 0.579587  [  770/  792]\n",
      "Training Loss (Epoch): 0.735780\n",
      "Validating...\n",
      "Validation Loss: 0.672378, Validation Accuracy: 78.28%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/20\n",
      "loss: 0.630912  [   70/  792]\n",
      "loss: 0.571963  [  210/  792]\n",
      "loss: 0.510682  [  350/  792]\n",
      "loss: 0.479908  [  490/  792]\n",
      "loss: 0.428446  [  630/  792]\n",
      "loss: 0.454393  [  770/  792]\n",
      "Training Loss (Epoch): 0.520020\n",
      "Validating...\n",
      "Validation Loss: 0.509536, Validation Accuracy: 82.83%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/20\n",
      "loss: 0.322015  [   70/  792]\n",
      "loss: 0.251654  [  210/  792]\n",
      "loss: 0.279855  [  350/  792]\n",
      "loss: 0.486949  [  490/  792]\n",
      "loss: 0.354207  [  630/  792]\n",
      "loss: 0.292639  [  770/  792]\n",
      "Training Loss (Epoch): 0.342837\n",
      "Validating...\n",
      "Validation Loss: 0.441776, Validation Accuracy: 83.84%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 7/20\n",
      "loss: 0.284125  [   70/  792]\n",
      "loss: 0.270174  [  210/  792]\n",
      "loss: 0.426464  [  350/  792]\n",
      "loss: 0.270605  [  490/  792]\n",
      "loss: 0.146060  [  630/  792]\n",
      "loss: 0.256930  [  770/  792]\n",
      "Training Loss (Epoch): 0.247158\n",
      "Validating...\n",
      "Validation Loss: 0.452848, Validation Accuracy: 85.86%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 8/20\n",
      "loss: 0.207930  [   70/  792]\n",
      "loss: 0.211377  [  210/  792]\n",
      "loss: 0.206068  [  350/  792]\n",
      "loss: 0.169486  [  490/  792]\n",
      "loss: 0.204863  [  630/  792]\n",
      "loss: 0.093709  [  770/  792]\n",
      "Training Loss (Epoch): 0.181648\n",
      "Validating...\n",
      "Validation Loss: 0.410652, Validation Accuracy: 82.32%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 9/20\n",
      "loss: 0.090806  [   70/  792]\n",
      "loss: 0.071947  [  210/  792]\n",
      "loss: 0.106935  [  350/  792]\n",
      "loss: 0.125190  [  490/  792]\n",
      "loss: 0.141958  [  630/  792]\n",
      "loss: 0.124476  [  770/  792]\n",
      "Training Loss (Epoch): 0.137986\n",
      "Validating...\n",
      "Validation Loss: 0.413597, Validation Accuracy: 84.85%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 10/20\n",
      "loss: 0.105103  [   70/  792]\n",
      "loss: 0.071050  [  210/  792]\n",
      "loss: 0.175021  [  350/  792]\n",
      "loss: 0.050671  [  490/  792]\n",
      "loss: 0.101081  [  630/  792]\n",
      "loss: 0.031920  [  770/  792]\n",
      "Training Loss (Epoch): 0.084962\n",
      "Validating...\n",
      "Validation Loss: 0.392706, Validation Accuracy: 86.36%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 11/20\n",
      "loss: 0.064534  [   70/  792]\n",
      "loss: 0.037919  [  210/  792]\n",
      "loss: 0.077812  [  350/  792]\n",
      "loss: 0.086846  [  490/  792]\n",
      "loss: 0.109506  [  630/  792]\n",
      "loss: 0.051599  [  770/  792]\n",
      "Training Loss (Epoch): 0.070124\n",
      "Validating...\n",
      "Validation Loss: 0.386470, Validation Accuracy: 88.38%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 12/20\n",
      "loss: 0.061343  [   70/  792]\n",
      "loss: 0.087146  [  210/  792]\n",
      "loss: 0.078829  [  350/  792]\n",
      "loss: 0.063100  [  490/  792]\n",
      "loss: 0.055127  [  630/  792]\n",
      "loss: 0.102727  [  770/  792]\n",
      "Training Loss (Epoch): 0.059869\n",
      "Validating...\n",
      "Validation Loss: 0.357792, Validation Accuracy: 88.38%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 13/20\n",
      "loss: 0.030082  [   70/  792]\n",
      "loss: 0.047888  [  210/  792]\n",
      "loss: 0.051892  [  350/  792]\n",
      "loss: 0.022219  [  490/  792]\n",
      "loss: 0.055032  [  630/  792]\n",
      "loss: 0.038727  [  770/  792]\n",
      "Training Loss (Epoch): 0.079255\n",
      "Validating...\n",
      "Validation Loss: 0.341030, Validation Accuracy: 87.88%\n",
      "Learning Rate: [6.25e-06]\n",
      "Epoch 14/20\n",
      "loss: 0.064861  [   70/  792]\n",
      "loss: 0.050601  [  210/  792]\n",
      "loss: 0.031006  [  350/  792]\n",
      "loss: 0.099325  [  490/  792]\n",
      "loss: 0.042390  [  630/  792]\n",
      "loss: 0.019009  [  770/  792]\n",
      "Training Loss (Epoch): 0.055593\n",
      "Validating...\n",
      "Validation Loss: 0.332038, Validation Accuracy: 88.38%\n",
      "Learning Rate: [3.125e-06]\n",
      "Epoch 15/20\n",
      "loss: 0.078202  [   70/  792]\n",
      "loss: 0.086663  [  210/  792]\n",
      "loss: 0.089395  [  350/  792]\n",
      "loss: 0.040238  [  490/  792]\n",
      "loss: 0.040321  [  630/  792]\n",
      "loss: 0.012616  [  770/  792]\n",
      "Training Loss (Epoch): 0.056115\n",
      "Validating...\n",
      "Validation Loss: 0.332949, Validation Accuracy: 88.38%\n",
      "Learning Rate: [1.5625e-06]\n",
      "Epoch 16/20\n",
      "loss: 0.044250  [   70/  792]\n",
      "loss: 0.036926  [  210/  792]\n",
      "loss: 0.076506  [  350/  792]\n",
      "loss: 0.074140  [  490/  792]\n",
      "loss: 0.066768  [  630/  792]\n",
      "loss: 0.077044  [  770/  792]\n",
      "Training Loss (Epoch): 0.069726\n",
      "Validating...\n",
      "Validation Loss: 0.333457, Validation Accuracy: 88.38%\n",
      "Learning Rate: [7.8125e-07]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 5\n",
      "Epoch 1/20\n",
      "loss: 2.361672  [   70/  748]\n",
      "loss: 2.360988  [  210/  748]\n",
      "loss: 2.292486  [  350/  748]\n",
      "loss: 2.249649  [  490/  748]\n",
      "loss: 2.118591  [  630/  748]\n",
      "loss: 2.121299  [  528/  748]\n",
      "Training Loss (Epoch): 2.234410\n",
      "Validating...\n",
      "Validation Loss: 2.199799, Validation Accuracy: 21.81%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 2.161963  [   70/  748]\n",
      "loss: 2.089439  [  210/  748]\n",
      "loss: 2.095451  [  350/  748]\n",
      "loss: 1.956792  [  490/  748]\n",
      "loss: 1.796000  [  630/  748]\n",
      "loss: 1.639518  [  528/  748]\n",
      "Training Loss (Epoch): 1.963609\n",
      "Validating...\n",
      "Validation Loss: 1.699722, Validation Accuracy: 44.68%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 1.562622  [   70/  748]\n",
      "loss: 1.375468  [  210/  748]\n",
      "loss: 1.280420  [  350/  748]\n",
      "loss: 1.059030  [  490/  748]\n",
      "loss: 1.070546  [  630/  748]\n",
      "loss: 0.998762  [  528/  748]\n",
      "Training Loss (Epoch): 1.200903\n",
      "Validating...\n",
      "Validation Loss: 1.175613, Validation Accuracy: 62.23%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/20\n",
      "loss: 0.785613  [   70/  748]\n",
      "loss: 1.002254  [  210/  748]\n",
      "loss: 0.700505  [  350/  748]\n",
      "loss: 0.880230  [  490/  748]\n",
      "loss: 0.582341  [  630/  748]\n",
      "loss: 0.609704  [  528/  748]\n",
      "Training Loss (Epoch): 0.735488\n",
      "Validating...\n",
      "Validation Loss: 0.940676, Validation Accuracy: 71.28%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/20\n",
      "loss: 0.671380  [   70/  748]\n",
      "loss: 0.524180  [  210/  748]\n",
      "loss: 0.406099  [  350/  748]\n",
      "loss: 0.648733  [  490/  748]\n",
      "loss: 0.410517  [  630/  748]\n",
      "loss: 0.461092  [  528/  748]\n",
      "Training Loss (Epoch): 0.528561\n",
      "Validating...\n",
      "Validation Loss: 0.774953, Validation Accuracy: 71.81%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 6/20\n",
      "loss: 0.347418  [   70/  748]\n",
      "loss: 0.441375  [  210/  748]\n",
      "loss: 0.242157  [  350/  748]\n",
      "loss: 0.456460  [  490/  748]\n",
      "loss: 0.326190  [  630/  748]\n",
      "loss: 0.273410  [  528/  748]\n",
      "Training Loss (Epoch): 0.357881\n",
      "Validating...\n",
      "Validation Loss: 0.652131, Validation Accuracy: 80.85%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 7/20\n",
      "loss: 0.389814  [   70/  748]\n",
      "loss: 0.305283  [  210/  748]\n",
      "loss: 0.253162  [  350/  748]\n",
      "loss: 0.305164  [  490/  748]\n",
      "loss: 0.189417  [  630/  748]\n",
      "loss: 0.198853  [  528/  748]\n",
      "Training Loss (Epoch): 0.273906\n",
      "Validating...\n",
      "Validation Loss: 0.640771, Validation Accuracy: 79.26%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 8/20\n",
      "loss: 0.386038  [   70/  748]\n",
      "loss: 0.256817  [  210/  748]\n",
      "loss: 0.160958  [  350/  748]\n",
      "loss: 0.210835  [  490/  748]\n",
      "loss: 0.159850  [  630/  748]\n",
      "loss: 0.191113  [  528/  748]\n",
      "Training Loss (Epoch): 0.232883\n",
      "Validating...\n",
      "Validation Loss: 0.586956, Validation Accuracy: 81.38%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 9/20\n",
      "loss: 0.422633  [   70/  748]\n",
      "loss: 0.220663  [  210/  748]\n",
      "loss: 0.208993  [  350/  748]\n",
      "loss: 0.255077  [  490/  748]\n",
      "loss: 0.222584  [  630/  748]\n",
      "loss: 0.106595  [  528/  748]\n",
      "Training Loss (Epoch): 0.205538\n",
      "Validating...\n",
      "Validation Loss: 0.592067, Validation Accuracy: 79.79%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 10/20\n",
      "loss: 0.176278  [   70/  748]\n",
      "loss: 0.153486  [  210/  748]\n",
      "loss: 0.161954  [  350/  748]\n",
      "loss: 0.123207  [  490/  748]\n",
      "loss: 0.229062  [  630/  748]\n",
      "loss: 0.225529  [  528/  748]\n",
      "Training Loss (Epoch): 0.175652\n",
      "Validating...\n",
      "Validation Loss: 0.576321, Validation Accuracy: 81.38%\n",
      "Learning Rate: [6.25e-06]\n",
      "Epoch 11/20\n",
      "loss: 0.142380  [   70/  748]\n",
      "loss: 0.223421  [  210/  748]\n",
      "loss: 0.169795  [  350/  748]\n",
      "loss: 0.209184  [  490/  748]\n",
      "loss: 0.183773  [  630/  748]\n",
      "loss: 0.150932  [  528/  748]\n",
      "Training Loss (Epoch): 0.166393\n",
      "Validating...\n",
      "Validation Loss: 0.568244, Validation Accuracy: 81.91%\n",
      "Learning Rate: [6.25e-06]\n",
      "Epoch 12/20\n",
      "loss: 0.098468  [   70/  748]\n",
      "loss: 0.202710  [  210/  748]\n",
      "loss: 0.183044  [  350/  748]\n",
      "loss: 0.113734  [  490/  748]\n",
      "loss: 0.198217  [  630/  748]\n",
      "loss: 0.118248  [  528/  748]\n",
      "Training Loss (Epoch): 0.175627\n",
      "Validating...\n",
      "Validation Loss: 0.553031, Validation Accuracy: 81.91%\n",
      "Learning Rate: [3.125e-06]\n",
      "Epoch 13/20\n",
      "loss: 0.216048  [   70/  748]\n",
      "loss: 0.122553  [  210/  748]\n",
      "loss: 0.133541  [  350/  748]\n",
      "loss: 0.161766  [  490/  748]\n",
      "loss: 0.191822  [  630/  748]\n",
      "loss: 0.388589  [  528/  748]\n",
      "Training Loss (Epoch): 0.173893\n",
      "Validating...\n",
      "Validation Loss: 0.551389, Validation Accuracy: 81.91%\n",
      "Learning Rate: [1.5625e-06]\n",
      "Epoch 14/20\n",
      "loss: 0.152426  [   70/  748]\n",
      "loss: 0.151312  [  210/  748]\n",
      "loss: 0.166790  [  350/  748]\n",
      "loss: 0.119275  [  490/  748]\n",
      "loss: 0.149694  [  630/  748]\n",
      "loss: 0.200287  [  528/  748]\n",
      "Training Loss (Epoch): 0.164491\n",
      "Validating...\n",
      "Validation Loss: 0.552547, Validation Accuracy: 81.91%\n",
      "Learning Rate: [7.8125e-07]\n",
      "Epoch 15/20\n",
      "loss: 0.156746  [   70/  748]\n",
      "loss: 0.144729  [  210/  748]\n",
      "loss: 0.194749  [  350/  748]\n",
      "loss: 0.150804  [  490/  748]\n",
      "loss: 0.257889  [  630/  748]\n",
      "loss: 0.052316  [  528/  748]\n",
      "Training Loss (Epoch): 0.155504\n",
      "Validating...\n",
      "Validation Loss: 0.552723, Validation Accuracy: 81.91%\n",
      "Learning Rate: [3.90625e-07]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 6\n",
      "Epoch 1/20\n",
      "loss: 2.338867  [   70/  658]\n",
      "loss: 2.289308  [  210/  658]\n",
      "loss: 2.416937  [  350/  658]\n",
      "loss: 2.190267  [  490/  658]\n",
      "loss: 2.143246  [  630/  658]\n",
      "Training Loss (Epoch): 2.265771\n",
      "Validating...\n",
      "Validation Loss: 2.221064, Validation Accuracy: 24.85%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 2.207503  [   70/  658]\n",
      "loss: 2.128048  [  210/  658]\n",
      "loss: 1.941249  [  350/  658]\n",
      "loss: 1.985499  [  490/  658]\n",
      "loss: 1.973263  [  630/  658]\n",
      "Training Loss (Epoch): 2.010377\n",
      "Validating...\n",
      "Validation Loss: 1.753218, Validation Accuracy: 43.03%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 1.726184  [   70/  658]\n",
      "loss: 1.465634  [  210/  658]\n",
      "loss: 1.407941  [  350/  658]\n",
      "loss: 1.396343  [  490/  658]\n",
      "loss: 1.204563  [  630/  658]\n",
      "Training Loss (Epoch): 1.368689\n",
      "Validating...\n",
      "Validation Loss: 1.195784, Validation Accuracy: 58.79%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/20\n",
      "loss: 1.019245  [   70/  658]\n",
      "loss: 0.755143  [  210/  658]\n",
      "loss: 0.915955  [  350/  658]\n",
      "loss: 0.894589  [  490/  658]\n",
      "loss: 0.788928  [  630/  658]\n",
      "Training Loss (Epoch): 0.887667\n",
      "Validating...\n",
      "Validation Loss: 0.860924, Validation Accuracy: 67.27%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/20\n",
      "loss: 0.605503  [   70/  658]\n",
      "loss: 0.688473  [  210/  658]\n",
      "loss: 0.781148  [  350/  658]\n",
      "loss: 0.738695  [  490/  658]\n",
      "loss: 0.636197  [  630/  658]\n",
      "Training Loss (Epoch): 0.640582\n",
      "Validating...\n",
      "Validation Loss: 0.748950, Validation Accuracy: 75.76%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/20\n",
      "loss: 0.463100  [   70/  658]\n",
      "loss: 0.407179  [  210/  658]\n",
      "loss: 0.584149  [  350/  658]\n",
      "loss: 0.653544  [  490/  658]\n",
      "loss: 0.559718  [  630/  658]\n",
      "Training Loss (Epoch): 0.486235\n",
      "Validating...\n",
      "Validation Loss: 0.545130, Validation Accuracy: 83.64%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 7/20\n",
      "loss: 0.202217  [   70/  658]\n",
      "loss: 0.322349  [  210/  658]\n",
      "loss: 0.322846  [  350/  658]\n",
      "loss: 0.445914  [  490/  658]\n",
      "loss: 0.358638  [  630/  658]\n",
      "Training Loss (Epoch): 0.318344\n",
      "Validating...\n",
      "Validation Loss: 0.509155, Validation Accuracy: 84.24%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 8/20\n",
      "loss: 0.340382  [   70/  658]\n",
      "loss: 0.264452  [  210/  658]\n",
      "loss: 0.220634  [  350/  658]\n",
      "loss: 0.224144  [  490/  658]\n",
      "loss: 0.333827  [  630/  658]\n",
      "Training Loss (Epoch): 0.260406\n",
      "Validating...\n",
      "Validation Loss: 0.441873, Validation Accuracy: 86.67%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 9/20\n",
      "loss: 0.147623  [   70/  658]\n",
      "loss: 0.150742  [  210/  658]\n",
      "loss: 0.297507  [  350/  658]\n",
      "loss: 0.115092  [  490/  658]\n",
      "loss: 0.295475  [  630/  658]\n",
      "Training Loss (Epoch): 0.204598\n",
      "Validating...\n",
      "Validation Loss: 0.387006, Validation Accuracy: 87.88%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 10/20\n",
      "loss: 0.169840  [   70/  658]\n",
      "loss: 0.134899  [  210/  658]\n",
      "loss: 0.097544  [  350/  658]\n",
      "loss: 0.168189  [  490/  658]\n",
      "loss: 0.184390  [  630/  658]\n",
      "Training Loss (Epoch): 0.171289\n",
      "Validating...\n",
      "Validation Loss: 0.370692, Validation Accuracy: 86.67%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 11/20\n",
      "loss: 0.038645  [   70/  658]\n",
      "loss: 0.086804  [  210/  658]\n",
      "loss: 0.099032  [  350/  658]\n",
      "loss: 0.206361  [  490/  658]\n",
      "loss: 0.228689  [  630/  658]\n",
      "Training Loss (Epoch): 0.137100\n",
      "Validating...\n",
      "Validation Loss: 0.384461, Validation Accuracy: 86.06%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 12/20\n",
      "loss: 0.119608  [   70/  658]\n",
      "loss: 0.108170  [  210/  658]\n",
      "loss: 0.157901  [  350/  658]\n",
      "loss: 0.147602  [  490/  658]\n",
      "loss: 0.120082  [  630/  658]\n",
      "Training Loss (Epoch): 0.115006\n",
      "Validating...\n",
      "Validation Loss: 0.374606, Validation Accuracy: 86.67%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 13/20\n",
      "loss: 0.095050  [   70/  658]\n",
      "loss: 0.101989  [  210/  658]\n",
      "loss: 0.123799  [  350/  658]\n",
      "loss: 0.152779  [  490/  658]\n",
      "loss: 0.102033  [  630/  658]\n",
      "Training Loss (Epoch): 0.115452\n",
      "Validating...\n",
      "Validation Loss: 0.374471, Validation Accuracy: 86.67%\n",
      "Learning Rate: [6.25e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 7\n",
      "Epoch 1/20\n",
      "loss: 2.344054  [   70/  670]\n",
      "loss: 2.331792  [  210/  670]\n",
      "loss: 2.198924  [  350/  670]\n",
      "loss: 2.196474  [  490/  670]\n",
      "loss: 2.147888  [  630/  670]\n",
      "Training Loss (Epoch): 2.231392\n",
      "Validating...\n",
      "Validation Loss: 2.178259, Validation Accuracy: 30.36%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 2.172071  [   70/  670]\n",
      "loss: 2.072592  [  210/  670]\n",
      "loss: 1.943040  [  350/  670]\n",
      "loss: 1.763795  [  490/  670]\n",
      "loss: 1.714744  [  630/  670]\n",
      "Training Loss (Epoch): 1.933409\n",
      "Validating...\n",
      "Validation Loss: 1.563044, Validation Accuracy: 51.79%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 1.422395  [   70/  670]\n",
      "loss: 1.300458  [  210/  670]\n",
      "loss: 1.327731  [  350/  670]\n",
      "loss: 1.229444  [  490/  670]\n",
      "loss: 0.966506  [  630/  670]\n",
      "Training Loss (Epoch): 1.254596\n",
      "Validating...\n",
      "Validation Loss: 1.028240, Validation Accuracy: 63.69%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/20\n",
      "loss: 0.815834  [   70/  670]\n",
      "loss: 0.994833  [  210/  670]\n",
      "loss: 0.933568  [  350/  670]\n",
      "loss: 0.836425  [  490/  670]\n",
      "loss: 0.716018  [  630/  670]\n",
      "Training Loss (Epoch): 0.843649\n",
      "Validating...\n",
      "Validation Loss: 0.890019, Validation Accuracy: 71.43%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/20\n",
      "loss: 0.673733  [   70/  670]\n",
      "loss: 0.746882  [  210/  670]\n",
      "loss: 0.676848  [  350/  670]\n",
      "loss: 0.581481  [  490/  670]\n",
      "loss: 0.655261  [  630/  670]\n",
      "Training Loss (Epoch): 0.622803\n",
      "Validating...\n",
      "Validation Loss: 0.796510, Validation Accuracy: 76.79%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/20\n",
      "loss: 0.518225  [   70/  670]\n",
      "loss: 0.482454  [  210/  670]\n",
      "loss: 0.348191  [  350/  670]\n",
      "loss: 0.510441  [  490/  670]\n",
      "loss: 0.427953  [  630/  670]\n",
      "Training Loss (Epoch): 0.440075\n",
      "Validating...\n",
      "Validation Loss: 0.633535, Validation Accuracy: 79.17%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 7/20\n",
      "loss: 0.364315  [   70/  670]\n",
      "loss: 0.414782  [  210/  670]\n",
      "loss: 0.251929  [  350/  670]\n",
      "loss: 0.371136  [  490/  670]\n",
      "loss: 0.257530  [  630/  670]\n",
      "Training Loss (Epoch): 0.301670\n",
      "Validating...\n",
      "Validation Loss: 0.525069, Validation Accuracy: 82.14%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 8/20\n",
      "loss: 0.281443  [   70/  670]\n",
      "loss: 0.212868  [  210/  670]\n",
      "loss: 0.276953  [  350/  670]\n",
      "loss: 0.230464  [  490/  670]\n",
      "loss: 0.146352  [  630/  670]\n",
      "Training Loss (Epoch): 0.251478\n",
      "Validating...\n",
      "Validation Loss: 0.566445, Validation Accuracy: 82.74%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 9/20\n",
      "loss: 0.171036  [   70/  670]\n",
      "loss: 0.189583  [  210/  670]\n",
      "loss: 0.163070  [  350/  670]\n",
      "loss: 0.177600  [  490/  670]\n",
      "loss: 0.230660  [  630/  670]\n",
      "Training Loss (Epoch): 0.189651\n",
      "Validating...\n",
      "Validation Loss: 0.516851, Validation Accuracy: 83.93%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 10/20\n",
      "loss: 0.140497  [   70/  670]\n",
      "loss: 0.167677  [  210/  670]\n",
      "loss: 0.129882  [  350/  670]\n",
      "loss: 0.168022  [  490/  670]\n",
      "loss: 0.071564  [  630/  670]\n",
      "Training Loss (Epoch): 0.165171\n",
      "Validating...\n",
      "Validation Loss: 0.687219, Validation Accuracy: 82.14%\n",
      "Learning Rate: [5e-05]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 8\n",
      "Epoch 1/20\n",
      "loss: 2.411290  [   70/  644]\n",
      "loss: 2.276499  [  210/  644]\n",
      "loss: 2.262938  [  350/  644]\n",
      "loss: 2.089339  [  490/  644]\n",
      "loss: 2.204193  [  630/  644]\n",
      "Training Loss (Epoch): 2.213643\n",
      "Validating...\n",
      "Validation Loss: 2.210798, Validation Accuracy: 22.22%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 2.211297  [   70/  644]\n",
      "loss: 2.141364  [  210/  644]\n",
      "loss: 2.079042  [  350/  644]\n",
      "loss: 2.035570  [  490/  644]\n",
      "loss: 1.912726  [  630/  644]\n",
      "Training Loss (Epoch): 2.050090\n",
      "Validating...\n",
      "Validation Loss: 1.810331, Validation Accuracy: 47.53%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 1.707781  [   70/  644]\n",
      "loss: 1.467238  [  210/  644]\n",
      "loss: 1.569352  [  350/  644]\n",
      "loss: 1.464319  [  490/  644]\n",
      "loss: 1.282132  [  630/  644]\n",
      "Training Loss (Epoch): 1.441761\n",
      "Validating...\n",
      "Validation Loss: 1.374326, Validation Accuracy: 51.85%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/20\n",
      "loss: 1.076631  [   70/  644]\n",
      "loss: 1.109144  [  210/  644]\n",
      "loss: 1.207921  [  350/  644]\n",
      "loss: 1.094230  [  490/  644]\n",
      "loss: 1.056778  [  630/  644]\n",
      "Training Loss (Epoch): 1.055429\n",
      "Validating...\n",
      "Validation Loss: 1.092878, Validation Accuracy: 60.49%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/20\n",
      "loss: 0.819870  [   70/  644]\n",
      "loss: 0.970526  [  210/  644]\n",
      "loss: 0.839674  [  350/  644]\n",
      "loss: 0.750551  [  490/  644]\n",
      "loss: 0.658137  [  630/  644]\n",
      "Training Loss (Epoch): 0.770109\n",
      "Validating...\n",
      "Validation Loss: 0.847400, Validation Accuracy: 66.67%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/20\n",
      "loss: 0.697021  [   70/  644]\n",
      "loss: 0.602975  [  210/  644]\n",
      "loss: 0.619805  [  350/  644]\n",
      "loss: 0.633934  [  490/  644]\n",
      "loss: 0.438434  [  630/  644]\n",
      "Training Loss (Epoch): 0.705295\n",
      "Validating...\n",
      "Validation Loss: 0.729346, Validation Accuracy: 69.75%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 7/20\n",
      "loss: 0.466386  [   70/  644]\n",
      "loss: 0.662207  [  210/  644]\n",
      "loss: 0.523704  [  350/  644]\n",
      "loss: 0.430702  [  490/  644]\n",
      "loss: 0.414213  [  630/  644]\n",
      "Training Loss (Epoch): 0.554720\n",
      "Validating...\n",
      "Validation Loss: 0.709241, Validation Accuracy: 75.93%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 8/20\n",
      "loss: 0.522345  [   70/  644]\n",
      "loss: 0.444656  [  210/  644]\n",
      "loss: 0.469257  [  350/  644]\n",
      "loss: 0.437356  [  490/  644]\n",
      "loss: 0.474488  [  630/  644]\n",
      "Training Loss (Epoch): 0.432886\n",
      "Validating...\n",
      "Validation Loss: 0.738791, Validation Accuracy: 70.37%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 9/20\n",
      "loss: 0.345804  [   70/  644]\n",
      "loss: 0.463696  [  210/  644]\n",
      "loss: 0.340055  [  350/  644]\n",
      "loss: 0.294935  [  490/  644]\n",
      "loss: 0.220149  [  630/  644]\n",
      "Training Loss (Epoch): 0.343054\n",
      "Validating...\n",
      "Validation Loss: 0.525759, Validation Accuracy: 79.63%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 10/20\n",
      "loss: 0.325173  [   70/  644]\n",
      "loss: 0.263392  [  210/  644]\n",
      "loss: 0.347327  [  350/  644]\n",
      "loss: 0.250417  [  490/  644]\n",
      "loss: 0.251993  [  630/  644]\n",
      "Training Loss (Epoch): 0.262588\n",
      "Validating...\n",
      "Validation Loss: 0.485683, Validation Accuracy: 79.63%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 11/20\n",
      "loss: 0.261686  [   70/  644]\n",
      "loss: 0.223636  [  210/  644]\n",
      "loss: 0.153458  [  350/  644]\n",
      "loss: 0.140891  [  490/  644]\n",
      "loss: 0.210565  [  630/  644]\n",
      "Training Loss (Epoch): 0.218485\n",
      "Validating...\n",
      "Validation Loss: 0.423729, Validation Accuracy: 85.80%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 12/20\n",
      "loss: 0.179432  [   70/  644]\n",
      "loss: 0.235573  [  210/  644]\n",
      "loss: 0.221904  [  350/  644]\n",
      "loss: 0.179844  [  490/  644]\n",
      "loss: 0.133252  [  630/  644]\n",
      "Training Loss (Epoch): 0.211632\n",
      "Validating...\n",
      "Validation Loss: 0.364056, Validation Accuracy: 87.04%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 13/20\n",
      "loss: 0.208309  [   70/  644]\n",
      "loss: 0.165684  [  210/  644]\n",
      "loss: 0.188716  [  350/  644]\n",
      "loss: 0.174083  [  490/  644]\n",
      "loss: 0.132679  [  630/  644]\n",
      "Training Loss (Epoch): 0.187998\n",
      "Validating...\n",
      "Validation Loss: 0.376112, Validation Accuracy: 87.04%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 14/20\n",
      "loss: 0.125965  [   70/  644]\n",
      "loss: 0.225442  [  210/  644]\n",
      "loss: 0.193080  [  350/  644]\n",
      "loss: 0.171266  [  490/  644]\n",
      "loss: 0.113880  [  630/  644]\n",
      "Training Loss (Epoch): 0.174173\n",
      "Validating...\n",
      "Validation Loss: 0.367459, Validation Accuracy: 88.27%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 15/20\n",
      "loss: 0.117707  [   70/  644]\n",
      "loss: 0.141313  [  210/  644]\n",
      "loss: 0.186127  [  350/  644]\n",
      "loss: 0.087422  [  490/  644]\n",
      "loss: 0.169270  [  630/  644]\n",
      "Training Loss (Epoch): 0.141437\n",
      "Validating...\n",
      "Validation Loss: 0.350315, Validation Accuracy: 88.27%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 16/20\n",
      "loss: 0.097965  [   70/  644]\n",
      "loss: 0.346522  [  210/  644]\n",
      "loss: 0.187623  [  350/  644]\n",
      "loss: 0.165773  [  490/  644]\n",
      "loss: 0.084043  [  630/  644]\n",
      "Training Loss (Epoch): 0.140670\n",
      "Validating...\n",
      "Validation Loss: 0.358002, Validation Accuracy: 88.89%\n",
      "Learning Rate: [6.25e-06]\n",
      "Epoch 17/20\n",
      "loss: 0.143478  [   70/  644]\n",
      "loss: 0.134467  [  210/  644]\n",
      "loss: 0.208524  [  350/  644]\n",
      "loss: 0.112767  [  490/  644]\n",
      "loss: 0.168240  [  630/  644]\n",
      "Training Loss (Epoch): 0.152075\n",
      "Validating...\n",
      "Validation Loss: 0.358291, Validation Accuracy: 88.27%\n",
      "Learning Rate: [3.125e-06]\n",
      "Epoch 18/20\n",
      "loss: 0.170095  [   70/  644]\n",
      "loss: 0.142198  [  210/  644]\n",
      "loss: 0.170024  [  350/  644]\n",
      "loss: 0.107210  [  490/  644]\n",
      "loss: 0.243103  [  630/  644]\n",
      "Training Loss (Epoch): 0.185689\n",
      "Validating...\n",
      "Validation Loss: 0.355593, Validation Accuracy: 88.27%\n",
      "Learning Rate: [1.5625e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 9\n",
      "Epoch 1/20\n",
      "loss: 2.433132  [   70/  652]\n",
      "loss: 2.296738  [  210/  652]\n",
      "loss: 2.209934  [  350/  652]\n",
      "loss: 2.067665  [  490/  652]\n",
      "loss: 2.063033  [  630/  652]\n",
      "Training Loss (Epoch): 2.200095\n",
      "Validating...\n",
      "Validation Loss: 2.157857, Validation Accuracy: 23.78%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 2.110832  [   70/  652]\n",
      "loss: 2.039414  [  210/  652]\n",
      "loss: 1.885150  [  350/  652]\n",
      "loss: 1.789798  [  490/  652]\n",
      "loss: 1.654343  [  630/  652]\n",
      "Training Loss (Epoch): 1.871743\n",
      "Validating...\n",
      "Validation Loss: 1.462908, Validation Accuracy: 56.71%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 1.439146  [   70/  652]\n",
      "loss: 1.488502  [  210/  652]\n",
      "loss: 0.990209  [  350/  652]\n",
      "loss: 1.039806  [  490/  652]\n",
      "loss: 1.014498  [  630/  652]\n",
      "Training Loss (Epoch): 1.126494\n",
      "Validating...\n",
      "Validation Loss: 0.942748, Validation Accuracy: 64.02%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/20\n",
      "loss: 0.727872  [   70/  652]\n",
      "loss: 0.721523  [  210/  652]\n",
      "loss: 0.555028  [  350/  652]\n",
      "loss: 0.567787  [  490/  652]\n",
      "loss: 0.557918  [  630/  652]\n",
      "Training Loss (Epoch): 0.746451\n",
      "Validating...\n",
      "Validation Loss: 0.624411, Validation Accuracy: 83.54%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/20\n",
      "loss: 0.643979  [   70/  652]\n",
      "loss: 0.350815  [  210/  652]\n",
      "loss: 0.323757  [  350/  652]\n",
      "loss: 0.481822  [  490/  652]\n",
      "loss: 0.458955  [  630/  652]\n",
      "Training Loss (Epoch): 0.498594\n",
      "Validating...\n",
      "Validation Loss: 0.626302, Validation Accuracy: 82.93%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 6/20\n",
      "loss: 0.337766  [   70/  652]\n",
      "loss: 0.445067  [  210/  652]\n",
      "loss: 0.364117  [  350/  652]\n",
      "loss: 0.250446  [  490/  652]\n",
      "loss: 0.322269  [  630/  652]\n",
      "Training Loss (Epoch): 0.368832\n",
      "Validating...\n",
      "Validation Loss: 0.443539, Validation Accuracy: 88.41%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 7/20\n",
      "loss: 0.182123  [   70/  652]\n",
      "loss: 0.257133  [  210/  652]\n",
      "loss: 0.211892  [  350/  652]\n",
      "loss: 0.235404  [  490/  652]\n",
      "loss: 0.236156  [  630/  652]\n",
      "Training Loss (Epoch): 0.251423\n",
      "Validating...\n",
      "Validation Loss: 0.480157, Validation Accuracy: 86.59%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 8/20\n",
      "loss: 0.197419  [   70/  652]\n",
      "loss: 0.203488  [  210/  652]\n",
      "loss: 0.175381  [  350/  652]\n",
      "loss: 0.256480  [  490/  652]\n",
      "loss: 0.229062  [  630/  652]\n",
      "Training Loss (Epoch): 0.200123\n",
      "Validating...\n",
      "Validation Loss: 0.421526, Validation Accuracy: 89.63%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 9/20\n",
      "loss: 0.206482  [   70/  652]\n",
      "loss: 0.181900  [  210/  652]\n",
      "loss: 0.181879  [  350/  652]\n",
      "loss: 0.117974  [  490/  652]\n",
      "loss: 0.193406  [  630/  652]\n",
      "Training Loss (Epoch): 0.183647\n",
      "Validating...\n",
      "Validation Loss: 0.438205, Validation Accuracy: 87.80%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 10/20\n",
      "loss: 0.129624  [   70/  652]\n",
      "loss: 0.139633  [  210/  652]\n",
      "loss: 0.144480  [  350/  652]\n",
      "loss: 0.173149  [  490/  652]\n",
      "loss: 0.194355  [  630/  652]\n",
      "Training Loss (Epoch): 0.164237\n",
      "Validating...\n",
      "Validation Loss: 0.410149, Validation Accuracy: 89.02%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 11/20\n",
      "loss: 0.135205  [   70/  652]\n",
      "loss: 0.172422  [  210/  652]\n",
      "loss: 0.175506  [  350/  652]\n",
      "loss: 0.158025  [  490/  652]\n",
      "loss: 0.131857  [  630/  652]\n",
      "Training Loss (Epoch): 0.151866\n",
      "Validating...\n",
      "Validation Loss: 0.411348, Validation Accuracy: 89.02%\n",
      "Learning Rate: [6.25e-06]\n",
      "Epoch 12/20\n",
      "loss: 0.211647  [   70/  652]\n",
      "loss: 0.154208  [  210/  652]\n",
      "loss: 0.162423  [  350/  652]\n",
      "loss: 0.110894  [  490/  652]\n",
      "loss: 0.216482  [  630/  652]\n",
      "Training Loss (Epoch): 0.147438\n",
      "Validating...\n",
      "Validation Loss: 0.412926, Validation Accuracy: 89.63%\n",
      "Learning Rate: [3.125e-06]\n",
      "Epoch 13/20\n",
      "loss: 0.190824  [   70/  652]\n",
      "loss: 0.184914  [  210/  652]\n",
      "loss: 0.175206  [  350/  652]\n",
      "loss: 0.124746  [  490/  652]\n",
      "loss: 0.112108  [  630/  652]\n",
      "Training Loss (Epoch): 0.150927\n",
      "Validating...\n",
      "Validation Loss: 0.408868, Validation Accuracy: 89.02%\n",
      "Learning Rate: [1.5625e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 10\n",
      "Epoch 1/20\n",
      "loss: 2.392160  [   70/  669]\n",
      "loss: 2.294991  [  210/  669]\n",
      "loss: 2.178384  [  350/  669]\n",
      "loss: 2.084064  [  490/  669]\n",
      "loss: 2.012289  [  630/  669]\n",
      "Training Loss (Epoch): 2.205460\n",
      "Validating...\n",
      "Validation Loss: 2.183081, Validation Accuracy: 28.57%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 2/20\n",
      "loss: 2.172462  [   70/  669]\n",
      "loss: 2.117773  [  210/  669]\n",
      "loss: 2.043574  [  350/  669]\n",
      "loss: 1.850475  [  490/  669]\n",
      "loss: 1.723173  [  630/  669]\n",
      "Training Loss (Epoch): 1.951933\n",
      "Validating...\n",
      "Validation Loss: 1.453490, Validation Accuracy: 59.52%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 3/20\n",
      "loss: 1.580732  [   70/  669]\n",
      "loss: 1.196206  [  210/  669]\n",
      "loss: 1.394180  [  350/  669]\n",
      "loss: 1.205110  [  490/  669]\n",
      "loss: 1.168351  [  630/  669]\n",
      "Training Loss (Epoch): 1.297088\n",
      "Validating...\n",
      "Validation Loss: 1.001346, Validation Accuracy: 67.86%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 4/20\n",
      "loss: 0.936463  [   70/  669]\n",
      "loss: 0.918652  [  210/  669]\n",
      "loss: 1.132803  [  350/  669]\n",
      "loss: 0.762045  [  490/  669]\n",
      "loss: 0.849305  [  630/  669]\n",
      "Training Loss (Epoch): 0.890793\n",
      "Validating...\n",
      "Validation Loss: 0.816968, Validation Accuracy: 70.83%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 5/20\n",
      "loss: 0.716165  [   70/  669]\n",
      "loss: 0.800231  [  210/  669]\n",
      "loss: 0.533332  [  350/  669]\n",
      "loss: 0.813308  [  490/  669]\n",
      "loss: 0.750886  [  630/  669]\n",
      "Training Loss (Epoch): 0.666048\n",
      "Validating...\n",
      "Validation Loss: 0.687528, Validation Accuracy: 76.79%\n",
      "Learning Rate: [0.0002]\n",
      "Epoch 6/20\n",
      "loss: 0.555806  [   70/  669]\n",
      "loss: 0.587483  [  210/  669]\n",
      "loss: 0.440872  [  350/  669]\n",
      "loss: 0.634203  [  490/  669]\n",
      "loss: 0.380183  [  630/  669]\n",
      "Training Loss (Epoch): 0.548688\n",
      "Validating...\n",
      "Validation Loss: 0.567072, Validation Accuracy: 74.40%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 7/20\n",
      "loss: 0.460352  [   70/  669]\n",
      "loss: 0.394446  [  210/  669]\n",
      "loss: 0.312475  [  350/  669]\n",
      "loss: 0.454300  [  490/  669]\n",
      "loss: 0.521923  [  630/  669]\n",
      "Training Loss (Epoch): 0.435111\n",
      "Validating...\n",
      "Validation Loss: 0.479907, Validation Accuracy: 83.33%\n",
      "Learning Rate: [0.0001]\n",
      "Epoch 8/20\n",
      "loss: 0.386851  [   70/  669]\n",
      "loss: 0.382222  [  210/  669]\n",
      "loss: 0.509971  [  350/  669]\n",
      "loss: 0.309556  [  490/  669]\n",
      "loss: 0.329990  [  630/  669]\n",
      "Training Loss (Epoch): 0.369043\n",
      "Validating...\n",
      "Validation Loss: 0.544371, Validation Accuracy: 81.55%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 9/20\n",
      "loss: 0.356074  [   70/  669]\n",
      "loss: 0.530845  [  210/  669]\n",
      "loss: 0.296939  [  350/  669]\n",
      "loss: 0.354447  [  490/  669]\n",
      "loss: 0.318069  [  630/  669]\n",
      "Training Loss (Epoch): 0.331154\n",
      "Validating...\n",
      "Validation Loss: 0.444890, Validation Accuracy: 85.12%\n",
      "Learning Rate: [5e-05]\n",
      "Epoch 10/20\n",
      "loss: 0.348967  [   70/  669]\n",
      "loss: 0.234391  [  210/  669]\n",
      "loss: 0.306110  [  350/  669]\n",
      "loss: 0.193147  [  490/  669]\n",
      "loss: 0.372599  [  630/  669]\n",
      "Training Loss (Epoch): 0.306516\n",
      "Validating...\n",
      "Validation Loss: 0.432058, Validation Accuracy: 85.12%\n",
      "Learning Rate: [2.5e-05]\n",
      "Epoch 11/20\n",
      "loss: 0.332131  [   70/  669]\n",
      "loss: 0.308736  [  210/  669]\n",
      "loss: 0.208832  [  350/  669]\n",
      "loss: 0.303822  [  490/  669]\n",
      "loss: 0.232135  [  630/  669]\n",
      "Training Loss (Epoch): 0.274379\n",
      "Validating...\n",
      "Validation Loss: 0.434415, Validation Accuracy: 85.71%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 12/20\n",
      "loss: 0.183129  [   70/  669]\n",
      "loss: 0.360097  [  210/  669]\n",
      "loss: 0.213336  [  350/  669]\n",
      "loss: 0.149256  [  490/  669]\n",
      "loss: 0.282321  [  630/  669]\n",
      "Training Loss (Epoch): 0.267220\n",
      "Validating...\n",
      "Validation Loss: 0.432899, Validation Accuracy: 86.90%\n",
      "Learning Rate: [1.25e-05]\n",
      "Epoch 13/20\n",
      "loss: 0.090030  [   70/  669]\n",
      "loss: 0.211007  [  210/  669]\n",
      "loss: 0.267508  [  350/  669]\n",
      "loss: 0.288002  [  490/  669]\n",
      "loss: 0.402049  [  630/  669]\n",
      "Training Loss (Epoch): 0.261899\n",
      "Validating...\n",
      "Validation Loss: 0.437776, Validation Accuracy: 85.12%\n",
      "Learning Rate: [6.25e-06]\n",
      "Early stopping triggered. Training stopped.\n",
      "\n",
      "Cross-Validation Results:\n",
      "Avg Training Loss: 0.625419\n",
      "Avg Validation Loss: 0.745791\n",
      "Avg Validation Accuracy: 75.46%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dense_tune(layer = 4, lr = 2e-4, weight_decay = 0.2, weights = \"DEFAULT\", drop = 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1\n",
      "Epoch 1/20\n",
      "loss: 2.345630  [   70/  698]\n",
      "loss: 2.274077  [  210/  698]\n",
      "loss: 2.140732  [  350/  698]\n",
      "loss: 2.044379  [  490/  698]\n",
      "loss: 2.015721  [  630/  698]\n",
      "Training Loss (Epoch): 2.188375\n",
      "Validating...\n",
      "Validation Loss: 327.955607, Validation Accuracy: 10.86%\n",
      "Learning Rate: [0.002]\n",
      "Epoch 2/20\n",
      "loss: 306.491974  [   70/  698]\n",
      "loss: 2.882579  [  210/  698]\n",
      "loss: 2.343071  [  350/  698]\n",
      "loss: 2.359900  [  490/  698]\n",
      "loss: 2.283572  [  630/  698]\n",
      "Training Loss (Epoch): 33.465685\n",
      "Validating...\n",
      "Validation Loss: 2.239516, Validation Accuracy: 11.43%\n",
      "Learning Rate: [0.001]\n",
      "Epoch 3/20\n",
      "loss: 2.258096  [   70/  698]\n",
      "loss: 2.193193  [  210/  698]\n",
      "loss: 2.309035  [  350/  698]\n",
      "loss: 2.340590  [  490/  698]\n",
      "loss: 2.252954  [  630/  698]\n",
      "Training Loss (Epoch): 2.265103\n",
      "Validating...\n",
      "Validation Loss: 2.230498, Validation Accuracy: 14.29%\n",
      "Learning Rate: [0.001]\n",
      "Epoch 4/20\n",
      "loss: 2.256372  [   70/  698]\n",
      "loss: 2.275185  [  210/  698]\n",
      "loss: 2.336182  [  350/  698]\n",
      "loss: 2.257104  [  490/  698]\n",
      "loss: 2.257459  [  630/  698]\n",
      "Training Loss (Epoch): 2.262826\n",
      "Validating...\n",
      "Validation Loss: 2.240584, Validation Accuracy: 14.29%\n",
      "Learning Rate: [0.0005]\n",
      "Epoch 5/20\n",
      "loss: 2.239847  [   70/  698]\n",
      "loss: 2.269309  [  210/  698]\n",
      "loss: 2.270783  [  350/  698]\n",
      "loss: 2.273699  [  490/  698]\n",
      "loss: 2.276350  [  630/  698]\n",
      "Training Loss (Epoch): 2.257092\n",
      "Validating...\n",
      "Validation Loss: 2.232475, Validation Accuracy: 14.29%\n",
      "Learning Rate: [0.00025]\n",
      "Early stopping triggered. Training stopped.\n",
      "Processing Fold 2\n",
      "Epoch 1/20\n",
      "loss: 2.365016  [   70/  710]\n",
      "loss: 2.158086  [  210/  710]\n",
      "loss: 2.059453  [  350/  710]\n",
      "loss: 1.777672  [  490/  710]\n",
      "loss: 1.623650  [  630/  710]\n",
      "loss: 1.122352  [  110/  710]\n",
      "Training Loss (Epoch): 1.832323\n",
      "Validating...\n",
      "Validation Loss: 49.863866, Validation Accuracy: 12.36%\n",
      "Learning Rate: [0.002]\n",
      "Epoch 2/20\n",
      "loss: 23.321167  [   70/  710]\n",
      "loss: 2.518954  [  210/  710]\n",
      "loss: 2.525353  [  350/  710]\n",
      "loss: 2.290512  [  490/  710]\n",
      "loss: 2.392374  [  630/  710]\n",
      "loss: 2.459463  [  110/  710]\n",
      "Training Loss (Epoch): 4.650807\n",
      "Validating...\n",
      "Validation Loss: 2.286804, Validation Accuracy: 6.74%\n",
      "Learning Rate: [0.001]\n",
      "Epoch 3/20\n",
      "loss: 2.403915  [   70/  710]\n",
      "loss: 2.282569  [  210/  710]\n",
      "loss: 2.278716  [  350/  710]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[101]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdense_tune\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDEFAULT\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.6\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[95]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36mdense_tune\u001b[39m\u001b[34m(layer, lr, weight_decay, weights, drop, SEED)\u001b[39m\n\u001b[32m     45\u001b[39m val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m, collate_fn=custom_collate_fn)\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# Train and validate (over multiple epochs per fold)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m epoch_train_losses, epoch_val_losses, epoch_val_accuracies = \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# Aggregate fold-level metrics (e.g., mean across all epochs)\u001b[39;00m\n\u001b[32m     53\u001b[39m fold_train_losses.append(\u001b[38;5;28msum\u001b[39m(epoch_train_losses) / \u001b[38;5;28mlen\u001b[39m(epoch_train_losses))  \u001b[38;5;66;03m# Mean of training losses\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[91]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mtrain_loop\u001b[39m\u001b[34m(train_dataloader, val_dataloader, model, loss_fn, optimizer, scheduler, epochs)\u001b[39m\n\u001b[32m     18\u001b[39m size = \u001b[38;5;28mlen\u001b[39m(train_dataloader.dataset)\n\u001b[32m     19\u001b[39m total_loss = \u001b[32m0\u001b[39m  \u001b[38;5;66;03m# Initialize variable to accumulate training loss\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Compute prediction and loss\u001b[39;49;00m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_collation:\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataset, \u001b[33m\"\u001b[39m\u001b[33m__getitems__\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__:\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     52\u001b[39m         data = [\u001b[38;5;28mself\u001b[39m.dataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/utils/data/dataset.py:420\u001b[39m, in \u001b[36mSubset.__getitems__\u001b[39m\u001b[34m(self, indices)\u001b[39m\n\u001b[32m    418\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__([\u001b[38;5;28mself\u001b[39m.indices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/utils/data/dataset.py:420\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    418\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__([\u001b[38;5;28mself\u001b[39m.indices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[87]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mUrbanSoundDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Apply transformations\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     waveform = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaveform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Extract the file name from the path\u001b[39;00m\n\u001b[32m     40\u001b[39m file_name = os.path.basename(file_path)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[88]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mtransform_pipeline\u001b[39m\u001b[34m(waveform)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtransform_pipeline\u001b[39m(waveform):\n\u001b[32m     13\u001b[39m     waveform = augment_waveform(waveform)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     spectrogram = \u001b[43mwaveform_to_spectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaveform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# spectrogram = augment_spectrogram(spectrogram)\u001b[39;00m\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m spectrogram\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torchaudio/transforms/_transforms.py:620\u001b[39m, in \u001b[36mMelSpectrogram.forward\u001b[39m\u001b[34m(self, waveform)\u001b[39m\n\u001b[32m    612\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    613\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m    614\u001b[39m \u001b[33;03m    waveform (Tensor): Tensor of audio of dimension (..., time).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    617\u001b[39m \u001b[33;03m    Tensor: Mel frequency spectrogram of size (..., ``n_mels``, time).\u001b[39;00m\n\u001b[32m    618\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    619\u001b[39m specgram = \u001b[38;5;28mself\u001b[39m.spectrogram(waveform)\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m mel_specgram = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmel_scale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspecgram\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    621\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m mel_specgram\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torchaudio/transforms/_transforms.py:412\u001b[39m, in \u001b[36mMelScale.forward\u001b[39m\u001b[34m(self, specgram)\u001b[39m\n\u001b[32m    403\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    404\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m    405\u001b[39m \u001b[33;03m    specgram (Tensor): A spectrogram STFT of dimension (..., freq, time).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    408\u001b[39m \u001b[33;03m    Tensor: Mel frequency spectrogram of size (..., ``n_mels``, time).\u001b[39;00m\n\u001b[32m    409\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    411\u001b[39m \u001b[38;5;66;03m# (..., time, freq) dot (freq, n_mels) -> (..., n_mels, time)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m412\u001b[39m mel_specgram = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspecgram\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfb\u001b[49m\u001b[43m)\u001b[49m.transpose(-\u001b[32m1\u001b[39m, -\u001b[32m2\u001b[39m)\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m mel_specgram\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "dense_tune(layer = 0, lr = 2e-3, weight_decay = 0.2, weights = \"DEFAULT\", drop = 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchaudio\n",
    "\n",
    "# audio_path = \"./UrbanSound8k/audio/fold1/137156-9-0-30.wav\"\n",
    "# waveform, sample_rate = torchaudio.load(audio_path)\n",
    "# print(f\"Shape: {waveform.shape}, Sample Rate: {sample_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_stereogram(spectrogram):\n",
    "    # Convert to numpy\n",
    "    spectrogram_np = spectrogram.numpy()  # Shape: (2, Freq, Time)\n",
    "\n",
    "    # Plot left and right channels\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(6, 6), constrained_layout=True)\n",
    "\n",
    "    axs[0].imshow(spectrogram_np[0], aspect='auto', origin='lower', cmap='magma')\n",
    "    axs[0].set_title(f\"Spectrogram {i+1} - Left Channel\")\n",
    "    axs[0].set_ylabel(\"Frequency Bins\")\n",
    "    axs[0].set_xlabel(\"Time Frames\")\n",
    "\n",
    "    axs[1].imshow(spectrogram_np[1], aspect='auto', origin='lower', cmap='magma')\n",
    "    axs[1].set_title(f\"Spectrogram {i+1} - Right Channel\")\n",
    "    axs[1].set_ylabel(\"Frequency Bins\")\n",
    "    axs[1].set_xlabel(\"Time Frames\")\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "urbad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
